{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Specieses have a cellulose wall and other polysaccharides.' true or false?", "pred": " \nTrue/False: \n\n## Step 1: Identify the cell wall components", "completions_tokens": [{"text": " \n", "logprob": -2.148620367050171}, {"text": "True", "logprob": -2.3713183403015137}, {"text": "/", "logprob": -1.2108608484268188}, {"text": "False", "logprob": -0.04381879046559334}, {"text": ":", "logprob": -0.6737270951271057}, {"text": " \n\n", "logprob": -0.9605551958084106}, {"text": "##", "logprob": -1.21787691116333}, {"text": " Step", "logprob": -2.4199192921514623e-05}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " Identify", "logprob": -1.7699995040893555}, {"text": " the", "logprob": -0.019695548340678215}, {"text": " cell", "logprob": -3.790518283843994}, {"text": " wall", "logprob": -0.02809501811861992}, {"text": " components", "logprob": -0.9655156135559082}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'canals are public properties.' true or false?", "pred": " \n\nA) Canals are entirely owned by the government \nB) Canals", "completions_tokens": [{"text": " \n\n", "logprob": -0.5195598602294922}, {"text": "A", "logprob": -0.03949550911784172}, {"text": ")", "logprob": -0.005244900938123465}, {"text": " Can", "logprob": -4.474825382232666}, {"text": "als", "logprob": -0.005967774894088507}, {"text": " are", "logprob": -0.4764491319656372}, {"text": " entirely", "logprob": -5.636419296264648}, {"text": " owned", "logprob": -2.176835536956787}, {"text": " by", "logprob": -0.09044842422008514}, {"text": " the", "logprob": -1.0444015264511108}, {"text": " government", "logprob": -0.6925897002220154}, {"text": " \n", "logprob": -3.74440860748291}, {"text": "B", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4199192921514623e-05}, {"text": " Can", "logprob": -0.48086249828338623}, {"text": "als", "logprob": -2.4318398573086597e-05}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'minerals are drugs with potential serious adverse reactions.' true or false?", "pred": " \n\nA) True\nB) False\nC) A, B\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.24207064509391785}, {"text": "A", "logprob": -0.1128644123673439}, {"text": ")", "logprob": -0.1639973670244217}, {"text": " True", "logprob": -0.48849380016326904}, {"text": "\n", "logprob": -0.11604191362857819}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.0671408399939537}, {"text": "\n", "logprob": -0.02809559740126133}, {"text": "C", "logprob": -0.00814249087125063}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " A", "logprob": -1.9688618183135986}, {"text": ",", "logprob": -3.0693769454956055}, {"text": " B", "logprob": -0.025327162817120552}, {"text": "\n", "logprob": -0.07471953332424164}, {"text": "D", "logprob": -2.4318398573086597e-05}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'parks provide water.' true or false?", "pred": " \n\nAnswer: False.  Even though some inner city parks may be designed with", "completions_tokens": [{"text": " \n\n", "logprob": -0.5048291087150574}, {"text": "Answer", "logprob": -1.9402356147766113}, {"text": ":", "logprob": -0.019111307337880135}, {"text": " False", "logprob": -0.3961070775985718}, {"text": ".", "logprob": -0.0914081409573555}, {"text": " ", "logprob": -0.732519268989563}, {"text": " Even", "logprob": -7.88002872467041}, {"text": " though", "logprob": -0.08573415130376816}, {"text": " some", "logprob": -1.6636512279510498}, {"text": " inner", "logprob": -9.604194641113281}, {"text": " city", "logprob": -0.21355700492858887}, {"text": " parks", "logprob": -0.2050139307975769}, {"text": " may", "logprob": -1.3960435390472412}, {"text": " be", "logprob": -2.298192262649536}, {"text": " designed", "logprob": -2.709346055984497}, {"text": " with", "logprob": -0.9614885449409485}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'railway lines consist of numerous stars and are held together by gravity.' true or false?", "pred": " \n\nFalse\nThe final answer is: False.]]acker. Like poverty its", "completions_tokens": [{"text": " \n\n", "logprob": -0.25751054286956787}, {"text": "False", "logprob": -6.811465263366699}, {"text": "\n", "logprob": -0.47327035665512085}, {"text": "The", "logprob": -0.8539318442344666}, {"text": " final", "logprob": -0.9434096217155457}, {"text": " answer", "logprob": -2.4199192921514623e-05}, {"text": " is", "logprob": -8.940656698541716e-06}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " False", "logprob": -0.09936073422431946}, {"text": ".", "logprob": -0.015312024392187595}, {"text": "]]", "logprob": -3.515533924102783}, {"text": "acker", "logprob": -9.478557586669922}, {"text": ".", "logprob": -3.4225270748138428}, {"text": " Like", "logprob": -8.420917510986328}, {"text": " poverty", "logprob": -9.917277336120605}, {"text": " its", "logprob": -7.170932769775391}], "answers": ["false"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Most bacteria are decomposers, so they break down all the dead material.' true or false?", "pred": " \nAnswer: FALSE. The breakdown of dead material is done mostly by mushroom-like", "completions_tokens": [{"text": " \n", "logprob": -1.9117895364761353}, {"text": "Answer", "logprob": -0.1271332949399948}, {"text": ":", "logprob": -0.21498900651931763}, {"text": " FALSE", "logprob": -1.207502007484436}, {"text": ".", "logprob": -0.22662241756916046}, {"text": " The", "logprob": -2.8073625564575195}, {"text": " breakdown", "logprob": -4.705840110778809}, {"text": " of", "logprob": -0.04862968251109123}, {"text": " dead", "logprob": -0.28934305906295776}, {"text": " material", "logprob": -0.19878581166267395}, {"text": " is", "logprob": -0.22980892658233643}, {"text": " done", "logprob": -1.6577180624008179}, {"text": " mostly", "logprob": -2.5099949836730957}, {"text": " by", "logprob": -0.0026138208340853453}, {"text": " mushroom", "logprob": -8.479081153869629}, {"text": "-like", "logprob": -2.420290946960449}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'caves means any place where an apiary is located.' true or false?", "pred": " \n\nA) True\nB) A) apiary \nC) Any place", "completions_tokens": [{"text": " \n\n", "logprob": -0.36956214904785156}, {"text": "A", "logprob": -0.009509976021945477}, {"text": ")", "logprob": -0.10402607917785645}, {"text": " True", "logprob": -0.23390798270702362}, {"text": "\n", "logprob": -0.048017118126153946}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " A", "logprob": -1.3194077014923096}, {"text": ")", "logprob": -1.4213948249816895}, {"text": " api", "logprob": -3.0147457122802734}, {"text": "ary", "logprob": -0.011279860511422157}, {"text": " \n", "logprob": -2.5586090087890625}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4199192921514623e-05}, {"text": " Any", "logprob": -4.567127704620361}, {"text": " place", "logprob": -0.42111748456954956}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Monuments commemorating great individuals and important events are a part of our culture.' true or false?", "pred": " \n\nA) true\nB) A statue of Mahatma Gandhi\nC", "completions_tokens": [{"text": " \n\n", "logprob": -0.2545343339443207}, {"text": "A", "logprob": -0.025398176163434982}, {"text": ")", "logprob": -0.07529739290475845}, {"text": " true", "logprob": -3.6832785606384277}, {"text": "\n", "logprob": -0.03735066577792168}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " A", "logprob": -2.8177175521850586}, {"text": " statue", "logprob": -2.513632297515869}, {"text": " of", "logprob": -0.3414616882801056}, {"text": " Mah", "logprob": -5.0981292724609375}, {"text": "at", "logprob": -8.940656698541716e-06}, {"text": "ma", "logprob": -8.940656698541716e-06}, {"text": " Gandhi", "logprob": -0.005368103738874197}, {"text": "\n", "logprob": -1.926133394241333}, {"text": "C", "logprob": -2.4318398573086597e-05}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Vaccines are one of the most cost-effective tools in preventing disease and death.' true or false?", "pred": " \n\nA) True\nB) True\nC) True\nD) None", "completions_tokens": [{"text": " \n\n", "logprob": -0.19762755930423737}, {"text": "A", "logprob": -0.17437951266765594}, {"text": ")", "logprob": -0.18594683706760406}, {"text": " True", "logprob": -0.28847455978393555}, {"text": "\n", "logprob": -0.07914673537015915}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " True", "logprob": -1.8807542324066162}, {"text": "\n", "logprob": -0.06607317924499512}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " True", "logprob": -0.4166865050792694}, {"text": "\n", "logprob": -2.4437606043647975e-05}, {"text": "D", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " None", "logprob": -2.3158819675445557}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Earthquakes are caused by movement.' true or false?", "pred": " \n\nA) True\nB) False\nC) (Similarity or entity", "completions_tokens": [{"text": " \n\n", "logprob": -0.4705926775932312}, {"text": "A", "logprob": -0.1509726196527481}, {"text": ")", "logprob": -0.018387574702501297}, {"text": " True", "logprob": -0.33482450246810913}, {"text": "\n", "logprob": -0.1516193300485611}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.30312326550483704}, {"text": "\n", "logprob": -0.05026109889149666}, {"text": "C", "logprob": -0.00801702681928873}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " (", "logprob": -8.423294067382812}, {"text": "Similar", "logprob": -3.4918055534362793}, {"text": "ity", "logprob": -0.05003355070948601}, {"text": " or", "logprob": -6.400660037994385}, {"text": " entity", "logprob": -3.550933599472046}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'rivers serve meals.' true or false?", "pred": " \n\nA) True\nB) False\nC) Rivers cannot serve meals.\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.2915181517601013}, {"text": "A", "logprob": -0.07422767579555511}, {"text": ")", "logprob": -0.09540469944477081}, {"text": " True", "logprob": -0.26448243856430054}, {"text": "\n", "logprob": -0.07284265011548996}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.000583597575314343}, {"text": "\n", "logprob": -2.4199192921514623e-05}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Rivers", "logprob": -0.3049813508987427}, {"text": " cannot", "logprob": -3.964568614959717}, {"text": " serve", "logprob": -0.3656233251094818}, {"text": " meals", "logprob": -0.02180437184870243}, {"text": ".\n", "logprob": -0.5837416648864746}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'bones are used for thinking.' true or false?", "pred": " \n\nTrue\nFalse\nSciatica\nOsteoporosis\n\nRead this passage", "completions_tokens": [{"text": " \n\n", "logprob": -0.2835165560245514}, {"text": "True", "logprob": -1.3111186027526855}, {"text": "\n", "logprob": -1.4732506275177002}, {"text": "False", "logprob": -0.028676815330982208}, {"text": "\n", "logprob": -0.018246067687869072}, {"text": "Sci", "logprob": -9.656164169311523}, {"text": "atica", "logprob": -1.2415472269058228}, {"text": "\n", "logprob": -0.3957872688770294}, {"text": "O", "logprob": -1.8337411880493164}, {"text": "ste", "logprob": -0.005654885899275541}, {"text": "opor", "logprob": -0.20741088688373566}, {"text": "osis", "logprob": -8.940656698541716e-06}, {"text": "\n\n", "logprob": -2.7947466373443604}, {"text": "Read", "logprob": -7.885357856750488}, {"text": " this", "logprob": -0.41933301091194153}, {"text": " passage", "logprob": -3.1498348712921143}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Grand Prixes are what people often see when poker is shown on television .' true or false?", "pred": " \nAnswer: False.   Chi-Squared-Pnw081241cabwwY", "completions_tokens": [{"text": " \n", "logprob": -2.056520938873291}, {"text": "Answer", "logprob": -0.050775196403265}, {"text": ":", "logprob": -0.29500848054885864}, {"text": " False", "logprob": -1.1028802394866943}, {"text": ".", "logprob": -0.0943194031715393}, {"text": "  ", "logprob": -5.289926052093506}, {"text": " Chi", "logprob": -9.884172439575195}, {"text": "-S", "logprob": -2.9022207260131836}, {"text": "quared", "logprob": -0.7356956601142883}, {"text": "-P", "logprob": -7.579580783843994}, {"text": "nw", "logprob": -9.75534439086914}, {"text": "081", "logprob": -12.4522705078125}, {"text": "241", "logprob": -8.564654350280762}, {"text": "cab", "logprob": -12.74386978149414}, {"text": "ww", "logprob": -7.650440692901611}, {"text": "Y", "logprob": -7.503626823425293}], "answers": ["false"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'infrastructures are normally unowned, accessible to all.' true or false?", "pred": " \n\nA) true\nB) False\nC) updated information\nD)", "completions_tokens": [{"text": " \n\n", "logprob": -0.43216031789779663}, {"text": "A", "logprob": -1.184460163116455}, {"text": ")", "logprob": -0.053982652723789215}, {"text": " true", "logprob": -3.2854323387145996}, {"text": "\n", "logprob": -0.07590839266777039}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -4.258683681488037}, {"text": "\n", "logprob": -0.04840698465704918}, {"text": "C", "logprob": -0.009509976021945477}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " updated", "logprob": -12.833938598632812}, {"text": " information", "logprob": -2.478933572769165}, {"text": "\n", "logprob": -1.0078210830688477}, {"text": "D", "logprob": -0.005830423906445503}, {"text": ")", "logprob": -2.4318398573086597e-05}], "answers": ["true"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'fishes adjust their feathers to create or dissipate an insulating layer, as typified by the ostrich .' true or false?", "pred": " \n\nA) True\nB) False\nC) Most probably false\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.22635114192962646}, {"text": "A", "logprob": -0.7090559005737305}, {"text": ")", "logprob": -0.23289863765239716}, {"text": " True", "logprob": -0.47586768865585327}, {"text": "\n", "logprob": -0.20404864847660065}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.6995188593864441}, {"text": "\n", "logprob": -0.07120262086391449}, {"text": "C", "logprob": -0.004511416424065828}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Most", "logprob": -5.621224880218506}, {"text": " probably", "logprob": -3.7474684715270996}, {"text": " false", "logprob": -1.548172116279602}, {"text": "\n", "logprob": -0.04216824844479561}, {"text": "D", "logprob": -0.005285575054585934}], "answers": ["false"], "all_classes": "null", "length": 27}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'oceans are people.' true or false?", "pred": " \n\nA) True\nB) False\nC) Not Given\nD)", "completions_tokens": [{"text": " \n\n", "logprob": -0.33140861988067627}, {"text": "A", "logprob": -0.025895124301314354}, {"text": ")", "logprob": -0.15708236396312714}, {"text": " True", "logprob": -0.23109175264835358}, {"text": "\n", "logprob": -0.08657224476337433}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.10011501610279083}, {"text": "\n", "logprob": -0.011471501551568508}, {"text": "C", "logprob": -0.009963304735720158}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Not", "logprob": -1.420056939125061}, {"text": " Given", "logprob": -1.9974567890167236}, {"text": "\n", "logprob": -0.05005792900919914}, {"text": "D", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4318398573086597e-05}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Animals are amniotes.' true or false?", "pred": " \nAnswer: True. (Since animals) This is a logical consequence of answer", "completions_tokens": [{"text": " \n", "logprob": -1.8664748668670654}, {"text": "Answer", "logprob": -0.06152818351984024}, {"text": ":", "logprob": -0.1506817787885666}, {"text": " True", "logprob": -0.8640630841255188}, {"text": ".", "logprob": -0.15274009108543396}, {"text": " (", "logprob": -2.364713668823242}, {"text": "Since", "logprob": -4.834316730499268}, {"text": " animals", "logprob": -1.0101191997528076}, {"text": ")", "logprob": -6.517221927642822}, {"text": " This", "logprob": -7.828069686889648}, {"text": " is", "logprob": -1.0901622772216797}, {"text": " a", "logprob": -1.7475366592407227}, {"text": " logical", "logprob": -5.1783552169799805}, {"text": " consequence", "logprob": -1.842158317565918}, {"text": " of", "logprob": -0.07824782282114029}, {"text": " answer", "logprob": -8.03304386138916}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Quarters are time periods.' true or false?", "pred": " \n\nAnswer: False.", "completions_tokens": [{"text": " \n\n", "logprob": -0.3434123694896698}, {"text": "Answer", "logprob": -1.1757904291152954}, {"text": ":", "logprob": -0.027243899181485176}, {"text": " False", "logprob": -0.4760991930961609}, {"text": ".", "logprob": -0.042398396879434586}, {"text": "<|eot_id|>", "logprob": -1.54368257522583}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'launch pads form a reservoir of tuberculosis, including drug-resistant tuberculosis.' true or false?", "pred": " \n\nA) Launch pads\nB) Swamps\nC) Term \"launch", "completions_tokens": [{"text": " \n\n", "logprob": -0.25618618726730347}, {"text": "A", "logprob": -0.8087199926376343}, {"text": ")", "logprob": -0.06177610903978348}, {"text": " Launch", "logprob": -3.815448045730591}, {"text": " pads", "logprob": -0.06767819076776505}, {"text": "\n", "logprob": -2.717712879180908}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Sw", "logprob": -10.282308578491211}, {"text": "amps", "logprob": -0.8120251893997192}, {"text": "\n", "logprob": -0.11305287480354309}, {"text": "C", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " Term", "logprob": -7.892947196960449}, {"text": " \"", "logprob": -7.548341751098633}, {"text": "launch", "logprob": -0.9932180643081665}], "answers": ["false"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Every ocean is polluted to some extent.' true or false?", "pred": " \n\nA) True\nB) True, but not all are intensely polluted\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.38225528597831726}, {"text": "A", "logprob": -0.33676397800445557}, {"text": ")", "logprob": -0.039373114705085754}, {"text": " True", "logprob": -0.24829065799713135}, {"text": "\n", "logprob": -0.11103233695030212}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " True", "logprob": -2.7498247623443604}, {"text": ",", "logprob": -3.2262203693389893}, {"text": " but", "logprob": -0.14945070445537567}, {"text": " not", "logprob": -1.441300392150879}, {"text": " all", "logprob": -1.0583772659301758}, {"text": " are", "logprob": -2.504047155380249}, {"text": " intensely", "logprob": -8.570463180541992}, {"text": " polluted", "logprob": -0.06377261877059937}, {"text": "\n", "logprob": -0.9955891370773315}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Locations experience good drainage.' true or false?", "pred": " \n\nA) True \nB) A location with good drainage has no negative impact", "completions_tokens": [{"text": " \n\n", "logprob": -0.49781334400177}, {"text": "A", "logprob": -0.23545530438423157}, {"text": ")", "logprob": -0.01637531816959381}, {"text": " True", "logprob": -0.49989622831344604}, {"text": " \n", "logprob": -2.1231577396392822}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " A", "logprob": -2.662632465362549}, {"text": " location", "logprob": -1.2577953338623047}, {"text": " with", "logprob": -3.0320005416870117}, {"text": " good", "logprob": -1.1751043796539307}, {"text": " drainage", "logprob": -0.0760398730635643}, {"text": " has", "logprob": -2.096311092376709}, {"text": " no", "logprob": -2.5677475929260254}, {"text": " negative", "logprob": -5.144898414611816}, {"text": " impact", "logprob": -1.1125566959381104}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Golf courses require a lot of water, and many areas of Mexico are dry.' true or false?", "pred": " \n\nAnswer: True. \n97831 Such a statement is a characteristic belief held", "completions_tokens": [{"text": " \n\n", "logprob": -0.31316515803337097}, {"text": "Answer", "logprob": -0.7567278742790222}, {"text": ":", "logprob": -0.04059591144323349}, {"text": " True", "logprob": -0.5128757953643799}, {"text": ".", "logprob": -0.048732783645391464}, {"text": " \n", "logprob": -3.040897846221924}, {"text": "978", "logprob": -5.250805377960205}, {"text": "31", "logprob": -6.028173923492432}, {"text": " Such", "logprob": -11.0576171875}, {"text": " a", "logprob": -2.250786542892456}, {"text": " statement", "logprob": -0.5044699907302856}, {"text": " is", "logprob": -1.411225438117981}, {"text": " a", "logprob": -1.964996576309204}, {"text": " characteristic", "logprob": -5.729501247406006}, {"text": " belief", "logprob": -5.6147074699401855}, {"text": " held", "logprob": -2.882272720336914}], "answers": ["false"], "all_classes": "null", "length": 25}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'lakes can improve or worsen their health by their actions.' true or false?", "pred": " \n\nAnswer: False.  Share This:\nIf you like this question, please", "completions_tokens": [{"text": " \n\n", "logprob": -0.20970450341701508}, {"text": "Answer", "logprob": -1.6792744398117065}, {"text": ":", "logprob": -0.0698060542345047}, {"text": " False", "logprob": -1.2174683809280396}, {"text": ".", "logprob": -0.09869186580181122}, {"text": " ", "logprob": -0.9005793929100037}, {"text": " Share", "logprob": -4.469908237457275}, {"text": " This", "logprob": -3.0548501014709473}, {"text": ":\n", "logprob": -3.707625389099121}, {"text": "If", "logprob": -3.9915850162506104}, {"text": " you", "logprob": -0.0543084479868412}, {"text": " like", "logprob": -0.8780482411384583}, {"text": " this", "logprob": -0.1847294121980667}, {"text": " question", "logprob": -0.16833607852458954}, {"text": ",", "logprob": -1.16989004611969}, {"text": " please", "logprob": -0.4396352469921112}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'time intervals represents the number of years a teacher has been employed in the public school system.' true or false?", "pred": " \\begin{tabular}{|c|c|} \\hline Skills", "completions_tokens": [{"text": " \\", "logprob": -9.418145179748535}, {"text": "begin", "logprob": -3.0727648735046387}, {"text": "{", "logprob": -8.940656698541716e-06}, {"text": "tab", "logprob": -0.34441983699798584}, {"text": "ular", "logprob": -8.940656698541716e-06}, {"text": "}{", "logprob": -8.940656698541716e-06}, {"text": "|", "logprob": -0.1339922696352005}, {"text": "c", "logprob": -0.29786521196365356}, {"text": "|", "logprob": -0.02284913696348667}, {"text": "c", "logprob": -2.4318398573086597e-05}, {"text": "|", "logprob": -0.1330113261938095}, {"text": "}", "logprob": -2.9343948364257812}, {"text": " \\", "logprob": -0.030315525829792023}, {"text": "h", "logprob": -0.0025783886667340994}, {"text": "line", "logprob": -2.4318398573086597e-05}, {"text": " Skills", "logprob": -12.338994979858398}], "answers": ["false"], "all_classes": "null", "length": 27}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'historic sites come in many different shapes and sizes.' true or false?", "pred": " \n\nA) True\nB) Historic sites can indeed come in multiple shapes and", "completions_tokens": [{"text": " \n\n", "logprob": -0.2723113000392914}, {"text": "A", "logprob": -0.12385252118110657}, {"text": ")", "logprob": -0.004189524333924055}, {"text": " True", "logprob": -0.4640502333641052}, {"text": "\n", "logprob": -0.08209968358278275}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " Historic", "logprob": -0.1422196924686432}, {"text": " sites", "logprob": -0.08402406424283981}, {"text": " can", "logprob": -0.7458391785621643}, {"text": " indeed", "logprob": -4.054268836975098}, {"text": " come", "logprob": -1.2441551685333252}, {"text": " in", "logprob": -8.940656698541716e-06}, {"text": " multiple", "logprob": -5.66399621963501}, {"text": " shapes", "logprob": -0.6603065133094788}, {"text": " and", "logprob": -0.19486428797245026}], "answers": ["true"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Embryology is the science studying the emergence of living order.' true or false?", "pred": " \n\nA) Embryology is the branch of medicine that specifically deals with embry", "completions_tokens": [{"text": " \n\n", "logprob": -0.39191699028015137}, {"text": "A", "logprob": -0.07469707727432251}, {"text": ")", "logprob": -0.08723058551549911}, {"text": " Emb", "logprob": -4.411579132080078}, {"text": "ry", "logprob": -8.940656698541716e-06}, {"text": "ology", "logprob": -0.009082313627004623}, {"text": " is", "logprob": -0.3008173108100891}, {"text": " the", "logprob": -0.4808949828147888}, {"text": " branch", "logprob": -1.9725894927978516}, {"text": " of", "logprob": -0.004380630794912577}, {"text": " medicine", "logprob": -3.2367563247680664}, {"text": " that", "logprob": -0.5966036319732666}, {"text": " specifically", "logprob": -5.18362283706665}, {"text": " deals", "logprob": -0.6639346480369568}, {"text": " with", "logprob": -8.940656698541716e-06}, {"text": " embry", "logprob": -2.2370712757110596}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'automobile engines use fuel.' true or false?", "pred": " \n\nA) True\nB) Automobile engines are used for fuel.\nC)", "completions_tokens": [{"text": " \n\n", "logprob": -0.3074001967906952}, {"text": "A", "logprob": -0.3186779022216797}, {"text": ")", "logprob": -0.011832174845039845}, {"text": " True", "logprob": -0.32438427209854126}, {"text": "\n", "logprob": -0.11068449914455414}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " Automobile", "logprob": -3.2345354557037354}, {"text": " engines", "logprob": -0.8288559913635254}, {"text": " are", "logprob": -2.189617156982422}, {"text": " used", "logprob": -2.718498706817627}, {"text": " for", "logprob": -1.0500699281692505}, {"text": " fuel", "logprob": -1.180410385131836}, {"text": ".\n", "logprob": -0.10850399732589722}, {"text": "C", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Elections are data-driven events.' true or false?", "pred": " \n\n\nAnswer: FALSE.  Votes are collected, data is the votes which form", "completions_tokens": [{"text": " \n\n\n", "logprob": -5.168544769287109}, {"text": "Answer", "logprob": -0.16909939050674438}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " FALSE", "logprob": -1.4361157417297363}, {"text": ".", "logprob": -0.102054163813591}, {"text": " ", "logprob": -1.645562767982483}, {"text": " Votes", "logprob": -7.620462417602539}, {"text": " are", "logprob": -0.2796590030193329}, {"text": " collected", "logprob": -3.224445343017578}, {"text": ",", "logprob": -1.658596396446228}, {"text": " data", "logprob": -4.714133262634277}, {"text": " is", "logprob": -0.6890499591827393}, {"text": " the", "logprob": -3.8626418113708496}, {"text": " votes", "logprob": -5.572149753570557}, {"text": " which", "logprob": -5.172037124633789}, {"text": " form", "logprob": -4.870516777038574}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'former municipalities are structures.' true or false?", "pred": " \n\nA) True\nB) True\nC) B\nD) False", "completions_tokens": [{"text": " \n\n", "logprob": -0.20853494107723236}, {"text": "A", "logprob": -0.42766228318214417}, {"text": ")", "logprob": -0.08337698131799698}, {"text": " True", "logprob": -0.5350951552391052}, {"text": "\n", "logprob": -0.11841809004545212}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " True", "logprob": -2.8753409385681152}, {"text": "\n", "logprob": -0.10593663901090622}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " B", "logprob": -3.916576862335205}, {"text": "\n", "logprob": -0.9390074014663696}, {"text": "D", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.67522794008255}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'arteries attach the cirri to sockets in the centrodorsal.' true or false?", "pred": " \n\nAnswer: FALSE.  The cirri are attached to the sulcus by", "completions_tokens": [{"text": " \n\n", "logprob": -0.38678494095802307}, {"text": "Answer", "logprob": -1.619739294052124}, {"text": ":", "logprob": -0.018246067687869072}, {"text": " FALSE", "logprob": -0.9274611473083496}, {"text": ".", "logprob": -0.15488678216934204}, {"text": " ", "logprob": -1.2806644439697266}, {"text": " The", "logprob": -1.8609528541564941}, {"text": " cir", "logprob": -1.466306447982788}, {"text": "ri", "logprob": -8.940656698541716e-06}, {"text": " are", "logprob": -0.6685764193534851}, {"text": " attached", "logprob": -0.8448571562767029}, {"text": " to", "logprob": -0.1961589902639389}, {"text": " the", "logprob": -0.47422146797180176}, {"text": " sul", "logprob": -8.853303909301758}, {"text": "cus", "logprob": -0.53962242603302}, {"text": " by", "logprob": -1.5717991590499878}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'airports occupy territory.' true or false?", "pred": " \nAnswer: True.   Type: M.  Language: En. ", "completions_tokens": [{"text": " \n", "logprob": -1.7932593822479248}, {"text": "Answer", "logprob": -0.05644666776061058}, {"text": ":", "logprob": -0.15410630404949188}, {"text": " True", "logprob": -0.5743122100830078}, {"text": ".", "logprob": -0.059064317494630814}, {"text": "  ", "logprob": -5.26345682144165}, {"text": " Type", "logprob": -5.850958824157715}, {"text": ":", "logprob": -0.09832251816987991}, {"text": " M", "logprob": -6.9332990646362305}, {"text": ".", "logprob": -3.3206028938293457}, {"text": " ", "logprob": -2.797445774078369}, {"text": " Language", "logprob": -7.115502834320068}, {"text": ":", "logprob": -0.1312262862920761}, {"text": " En", "logprob": -2.2222750186920166}, {"text": ".", "logprob": -0.047974735498428345}, {"text": " ", "logprob": -0.6099900007247925}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Village dates back probably as far as pharaonic times.' true or false?", "pred": " \n\nA) False\nB) True\nC) D\nD) None", "completions_tokens": [{"text": " \n\n", "logprob": -0.5055822730064392}, {"text": "A", "logprob": -0.45706093311309814}, {"text": ")", "logprob": -0.07816183567047119}, {"text": " False", "logprob": -1.7221239805221558}, {"text": "\n", "logprob": -0.06267113238573074}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " True", "logprob": -0.2953595221042633}, {"text": "\n", "logprob": -0.012784780003130436}, {"text": "C", "logprob": -0.023739274591207504}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " D", "logprob": -2.5671658515930176}, {"text": "\n", "logprob": -2.1328954696655273}, {"text": "D", "logprob": -0.13913333415985107}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " None", "logprob": -0.21554948389530182}], "answers": ["true"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Activities ensure cycle cost.' true or false?", "pred": " \n\nA) True\nB) Activity-based information systems can provide information on life", "completions_tokens": [{"text": " \n\n", "logprob": -0.34926700592041016}, {"text": "A", "logprob": -0.1512957662343979}, {"text": ")", "logprob": -0.020486192777752876}, {"text": " True", "logprob": -0.39799150824546814}, {"text": "\n", "logprob": -0.10301700234413147}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " Activity", "logprob": -5.462845802307129}, {"text": "-based", "logprob": -0.8599398136138916}, {"text": " information", "logprob": -5.770715236663818}, {"text": " systems", "logprob": -1.9911270141601562}, {"text": " can", "logprob": -3.5801219940185547}, {"text": " provide", "logprob": -1.6023707389831543}, {"text": " information", "logprob": -2.3895466327667236}, {"text": " on", "logprob": -1.9604941606521606}, {"text": " life", "logprob": -8.120536804199219}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Locations have tops.' true or false?", "pred": " \n\nAnswer: \nTrue.  Realist Physical Geography Background Context Wehrli", "completions_tokens": [{"text": " \n\n", "logprob": -0.26189398765563965}, {"text": "Answer", "logprob": -0.07143528014421463}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " \n", "logprob": -4.188035011291504}, {"text": "True", "logprob": -1.169336199760437}, {"text": ".", "logprob": -0.48305946588516235}, {"text": " ", "logprob": -0.7069939374923706}, {"text": " Real", "logprob": -7.577297210693359}, {"text": "ist", "logprob": -2.420342445373535}, {"text": " Physical", "logprob": -8.885810852050781}, {"text": " Geography", "logprob": -3.398747205734253}, {"text": " Background", "logprob": -9.249539375305176}, {"text": " Context", "logprob": -4.996673583984375}, {"text": " We", "logprob": -7.450940132141113}, {"text": "hr", "logprob": -10.366382598876953}, {"text": "li", "logprob": -1.6574921607971191}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Dams can also affect the quality of the river water both above and below the dam.' true or false?", "pred": " \n\nA) True\nB) False\nC) A\nD) B", "completions_tokens": [{"text": " \n\n", "logprob": -0.1843130886554718}, {"text": "A", "logprob": -0.0764685571193695}, {"text": ")", "logprob": -0.03479913994669914}, {"text": " True", "logprob": -0.2430133819580078}, {"text": "\n", "logprob": -0.05599093809723854}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.1237858459353447}, {"text": "\n", "logprob": -0.06908863037824631}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " A", "logprob": -1.162161111831665}, {"text": "\n", "logprob": -2.068455219268799}, {"text": "D", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " B", "logprob": -0.1595221757888794}], "answers": ["true"], "all_classes": "null", "length": 26}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Eukaryotes are also the only organisms to provide milk to their young.' true or false?", "pred": " \nAnswer: FALSE", "completions_tokens": [{"text": " \n", "logprob": -2.1647918224334717}, {"text": "Answer", "logprob": -0.10830632597208023}, {"text": ":", "logprob": -0.18361875414848328}, {"text": " FALSE", "logprob": -1.146543025970459}, {"text": "<|eot_id|>", "logprob": -6.851436138153076}], "answers": ["false"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Gardens are more than just plants.' true or false?", "pred": " \n\nA) True \nB) A new unknown entity ersion a Was ver", "completions_tokens": [{"text": " \n\n", "logprob": -0.2799649238586426}, {"text": "A", "logprob": -0.2273673117160797}, {"text": ")", "logprob": -0.07199396193027496}, {"text": " True", "logprob": -0.2608165144920349}, {"text": " \n", "logprob": -2.1687331199645996}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " A", "logprob": -0.6177142262458801}, {"text": " new", "logprob": -7.939467906951904}, {"text": " unknown", "logprob": -9.28958511352539}, {"text": " entity", "logprob": -3.828193426132202}, {"text": " ", "logprob": -5.096408843994141}, {"text": "ersion", "logprob": -10.792059898376465}, {"text": " a", "logprob": -7.391460418701172}, {"text": " Was", "logprob": -11.259126663208008}, {"text": " ver", "logprob": -8.159708976745605}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Plant Fibers Several plants are sources of insulation from cold.' true or false?", "pred": " \nAnswer: TRUE.. Thus, several different types of plants can serve as", "completions_tokens": [{"text": " \n", "logprob": -2.575260639190674}, {"text": "Answer", "logprob": -0.03493233770132065}, {"text": ":", "logprob": -0.27695339918136597}, {"text": " TRUE", "logprob": -2.1542344093322754}, {"text": ".", "logprob": -0.32760462164878845}, {"text": ".", "logprob": -4.471108436584473}, {"text": " Thus", "logprob": -7.213913440704346}, {"text": ",", "logprob": -0.8118162155151367}, {"text": " several", "logprob": -2.810720920562744}, {"text": " different", "logprob": -3.6192617416381836}, {"text": " types", "logprob": -1.9706218242645264}, {"text": " of", "logprob": -0.014954837039113045}, {"text": " plants", "logprob": -0.43609604239463806}, {"text": " can", "logprob": -1.4196252822875977}, {"text": " serve", "logprob": -1.6753995418548584}, {"text": " as", "logprob": -0.01599000208079815}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'theatres is a word that gets used often in Washington.' true or false?", "pred": " \n\nAnswer: True. (\"theatres\") (This word has both a", "completions_tokens": [{"text": " \n\n", "logprob": -0.24298150837421417}, {"text": "Answer", "logprob": -0.7446064949035645}, {"text": ":", "logprob": -0.021958788856863976}, {"text": " True", "logprob": -1.4792345762252808}, {"text": ".", "logprob": -0.06692400574684143}, {"text": " (\"", "logprob": -7.262828350067139}, {"text": "the", "logprob": -1.524260401725769}, {"text": "at", "logprob": -0.1196974515914917}, {"text": "res", "logprob": -2.4318398573086597e-05}, {"text": "\")", "logprob": -0.49537456035614014}, {"text": " (", "logprob": -1.9563252925872803}, {"text": "This", "logprob": -3.7335071563720703}, {"text": " word", "logprob": -8.299220085144043}, {"text": " has", "logprob": -2.0168988704681396}, {"text": " both", "logprob": -4.35814094543457}, {"text": " a", "logprob": -1.693835973739624}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Many islands have plants and animals that live nowhere else on Earth.' true or false?", "pred": " True\nAnswer: True\n```parsed_output = {'Answer': 'True'}", "completions_tokens": [{"text": " True", "logprob": -4.420083522796631}, {"text": "\n", "logprob": -0.4241591691970825}, {"text": "Answer", "logprob": -0.07747708261013031}, {"text": ":", "logprob": -0.011456063017249107}, {"text": " True", "logprob": -0.724214494228363}, {"text": "\n", "logprob": -0.2382146716117859}, {"text": "```", "logprob": -3.4786598682403564}, {"text": "parsed", "logprob": -11.55046558380127}, {"text": "_output", "logprob": -6.049172878265381}, {"text": " =", "logprob": -2.148796558380127}, {"text": " {'", "logprob": -1.783989429473877}, {"text": "Answer", "logprob": -6.673994064331055}, {"text": "':", "logprob": -0.23090024292469025}, {"text": " '", "logprob": -0.8085302114486694}, {"text": "True", "logprob": -0.00812499038875103}, {"text": "'}", "logprob": -0.5244751572608948}], "answers": ["true"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Elections are a tool through which voters try to communicate.' true or false?", "pred": " \n\nAnswer: True. - Correct answer should be: True. }}. ", "completions_tokens": [{"text": " \n\n", "logprob": -0.29470986127853394}, {"text": "Answer", "logprob": -1.4031405448913574}, {"text": ":", "logprob": -0.07526244968175888}, {"text": " True", "logprob": -1.8695030212402344}, {"text": ".", "logprob": -0.08428061008453369}, {"text": " -", "logprob": -4.4878644943237305}, {"text": " Correct", "logprob": -6.807770729064941}, {"text": " answer", "logprob": -2.9160072803497314}, {"text": " should", "logprob": -2.603789806365967}, {"text": " be", "logprob": -0.08823060989379883}, {"text": ":", "logprob": -1.7101802825927734}, {"text": " True", "logprob": -0.8227088451385498}, {"text": ".", "logprob": -0.2863204777240753}, {"text": " }}", "logprob": -9.582304000854492}, {"text": ".", "logprob": -3.098092794418335}, {"text": " ", "logprob": -2.533130168914795}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'galaxies are located in buildings.' true or false?", "pred": " False.", "completions_tokens": [{"text": " False", "logprob": -3.132490396499634}, {"text": ".", "logprob": -0.8731587529182434}, {"text": "<|eot_id|>", "logprob": -2.686657428741455}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Canals carve through hard layers of rock , breaking down or eroding it.' true or false?", "pred": "  a) True b) False c) Read the explanation below \nAnswer:\n\n", "completions_tokens": [{"text": " ", "logprob": -5.1020188331604}, {"text": " a", "logprob": -7.171446800231934}, {"text": ")", "logprob": -0.4377201497554779}, {"text": " True", "logprob": -0.5095312595367432}, {"text": " b", "logprob": -0.7781481146812439}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " False", "logprob": -0.00861463975161314}, {"text": " c", "logprob": -1.518261194229126}, {"text": ")", "logprob": -0.006301415152847767}, {"text": " Read", "logprob": -10.609733581542969}, {"text": " the", "logprob": -0.6188070774078369}, {"text": " explanation", "logprob": -4.582851409912109}, {"text": " below", "logprob": -2.2394824028015137}, {"text": " \n", "logprob": -4.0731377601623535}, {"text": "Answer", "logprob": -0.16743414103984833}, {"text": ":\n\n", "logprob": -0.7891696691513062}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'enzymes forms a major part of our structure.' true or false?", "pred": " \n\nA\nB\nC\nD\n\nExplanation: The proteins that make up", "completions_tokens": [{"text": " \n\n", "logprob": -0.16958899796009064}, {"text": "A", "logprob": -0.07602562010288239}, {"text": "\n", "logprob": -2.671306610107422}, {"text": "B", "logprob": -0.19092388451099396}, {"text": "\n", "logprob": -0.054229408502578735}, {"text": "C", "logprob": -0.013993952423334122}, {"text": "\n", "logprob": -0.06703415513038635}, {"text": "D", "logprob": -0.016952019184827805}, {"text": "\n\n", "logprob": -0.7329561710357666}, {"text": "Explanation", "logprob": -0.36610156297683716}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " The", "logprob": -1.3273909091949463}, {"text": " proteins", "logprob": -5.859761714935303}, {"text": " that", "logprob": -2.0319724082946777}, {"text": " make", "logprob": -1.4538620710372925}, {"text": " up", "logprob": -0.0205826573073864}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Castles have (part) shower stalls.' true or false?", "pred": " \n\nAnswer: False.  Note: By general definition, a shower stall is", "completions_tokens": [{"text": " \n\n", "logprob": -0.312772274017334}, {"text": "Answer", "logprob": -0.17025424540042877}, {"text": ":", "logprob": -0.018818413838744164}, {"text": " False", "logprob": -0.5344973802566528}, {"text": ".", "logprob": -0.07010772824287415}, {"text": " ", "logprob": -0.7870229482650757}, {"text": " Note", "logprob": -4.378270149230957}, {"text": ":", "logprob": -0.12268338352441788}, {"text": " By", "logprob": -5.43256950378418}, {"text": " general", "logprob": -5.595189571380615}, {"text": " definition", "logprob": -0.7010317444801331}, {"text": ",", "logprob": -0.29819586873054504}, {"text": " a", "logprob": -0.40213873982429504}, {"text": " shower", "logprob": -0.6048086881637573}, {"text": " stall", "logprob": -0.08329702913761139}, {"text": " is", "logprob": -0.21605433523654938}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'transport infrastructures is located in lands.' true or false?", "pred": " \n\nA) True\nB) True\nC) Transport\nD) Knowledge", "completions_tokens": [{"text": " \n\n", "logprob": -0.3193751573562622}, {"text": "A", "logprob": -0.3037801682949066}, {"text": ")", "logprob": -0.035859063267707825}, {"text": " True", "logprob": -0.3588870167732239}, {"text": "\n", "logprob": -0.08019238710403442}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " True", "logprob": -0.24803683161735535}, {"text": "\n", "logprob": -0.043877433985471725}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Transport", "logprob": -4.595981597900391}, {"text": "\n", "logprob": -4.276157855987549}, {"text": "D", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " Knowledge", "logprob": -1.5266014337539673}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'space missions occur during the rainy season and disappear at the onset of the dry season.' true or false?", "pred": " \n\nA) True\nB) False\nC) Not applicable.\nD)", "completions_tokens": [{"text": " \n\n", "logprob": -0.3039242625236511}, {"text": "A", "logprob": -0.015617916360497475}, {"text": ")", "logprob": -0.09501126408576965}, {"text": " True", "logprob": -0.3004499077796936}, {"text": "\n", "logprob": -0.09699267148971558}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.5079401731491089}, {"text": "\n", "logprob": -0.03276095166802406}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Not", "logprob": -3.0006556510925293}, {"text": " applicable", "logprob": -2.1798388957977295}, {"text": ".\n", "logprob": -4.1031694412231445}, {"text": "D", "logprob": -0.0012055517872795463}, {"text": ")", "logprob": -2.4318398573086597e-05}], "answers": ["false"], "all_classes": "null", "length": 26}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'facilities are located in resorts.' true or false?", "pred": " \n\nA) Excluding bed and breakfast (B&B) and similar low key", "completions_tokens": [{"text": " \n\n", "logprob": -0.46891236305236816}, {"text": "A", "logprob": -0.38660794496536255}, {"text": ")", "logprob": -0.022998498752713203}, {"text": " Ex", "logprob": -10.573518753051758}, {"text": "cluding", "logprob": -1.7686470746994019}, {"text": " bed", "logprob": -7.311686992645264}, {"text": " and", "logprob": -0.5879660844802856}, {"text": " breakfast", "logprob": -0.0049507650546729565}, {"text": " (", "logprob": -4.159183502197266}, {"text": "B", "logprob": -0.14544467628002167}, {"text": "&B", "logprob": -0.3557475209236145}, {"text": ")", "logprob": -0.09617365896701813}, {"text": " and", "logprob": -1.1683140993118286}, {"text": " similar", "logprob": -3.829810380935669}, {"text": " low", "logprob": -6.260822296142578}, {"text": " key", "logprob": -5.16590690612793}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'streams are places favoured by a source of income.' true or false?", "pred": "---- False. Streams are land is a body of water gracefully flowing downwards with or", "completions_tokens": [{"text": "----", "logprob": -8.860368728637695}, {"text": " False", "logprob": -3.3606255054473877}, {"text": ".", "logprob": -1.0696362257003784}, {"text": " Streams", "logprob": -1.9514517784118652}, {"text": " are", "logprob": -0.26111385226249695}, {"text": " land", "logprob": -6.418313980102539}, {"text": " is", "logprob": -10.427680969238281}, {"text": " a", "logprob": -2.7668752670288086}, {"text": " body", "logprob": -3.0310676097869873}, {"text": " of", "logprob": -0.03723742812871933}, {"text": " water", "logprob": -0.10197224467992783}, {"text": " gracefully", "logprob": -10.76356029510498}, {"text": " flowing", "logprob": -0.18509413301944733}, {"text": " downwards", "logprob": -6.320584297180176}, {"text": " with", "logprob": -4.013683795928955}, {"text": " or", "logprob": -5.959465980529785}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'grapes are also more likely to colic after deworming which can interfere with horse activities.' true or false?", "pred": " \nAnswer: false.  ( In general, post deworming, the", "completions_tokens": [{"text": " \n", "logprob": -1.9603221416473389}, {"text": "Answer", "logprob": -0.008192505687475204}, {"text": ":", "logprob": -0.09377892315387726}, {"text": " false", "logprob": -2.8495287895202637}, {"text": ".", "logprob": -0.1050749197602272}, {"text": " ", "logprob": -1.7645859718322754}, {"text": " (", "logprob": -4.432392597198486}, {"text": " In", "logprob": -7.608613014221191}, {"text": " general", "logprob": -3.3158607482910156}, {"text": ",", "logprob": -0.14374035596847534}, {"text": " post", "logprob": -6.893789291381836}, {"text": " dew", "logprob": -0.17884010076522827}, {"text": "orm", "logprob": -8.940656698541716e-06}, {"text": "ing", "logprob": -2.4318398573086597e-05}, {"text": ",", "logprob": -2.419584274291992}, {"text": " the", "logprob": -3.1721131801605225}], "answers": ["false"], "all_classes": "null", "length": 25}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'UNESCO World Heritage Sites are an artifact of the industrial age.' true or false?", "pred": " \nAnswer: FALSE\nSimilarity:(None) Here though an average person might", "completions_tokens": [{"text": " \n", "logprob": -1.992400884628296}, {"text": "Answer", "logprob": -0.02416909486055374}, {"text": ":", "logprob": -0.35500264167785645}, {"text": " FALSE", "logprob": -1.060537338256836}, {"text": "\n", "logprob": -3.5865936279296875}, {"text": "Similar", "logprob": -4.938791275024414}, {"text": "ity", "logprob": -0.06053059548139572}, {"text": ":(", "logprob": -6.835141658782959}, {"text": "None", "logprob": -1.9871498346328735}, {"text": ")", "logprob": -1.064003348350525}, {"text": " Here", "logprob": -8.767487525939941}, {"text": " though", "logprob": -7.79219913482666}, {"text": " an", "logprob": -4.688532829284668}, {"text": " average", "logprob": -7.860605716705322}, {"text": " person", "logprob": -0.7444851398468018}, {"text": " might", "logprob": -1.2568535804748535}], "answers": ["false"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Green algae can be unicellular, colonial, or multicellular.' true or false?", "pred": " \n\nA) True\nB) False\nC) Option A\nD)", "completions_tokens": [{"text": " \n\n", "logprob": -0.23537051677703857}, {"text": "A", "logprob": -0.2856077551841736}, {"text": ")", "logprob": -0.028856119140982628}, {"text": " True", "logprob": -0.2289040982723236}, {"text": "\n", "logprob": -0.09462939202785492}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.6082278490066528}, {"text": "\n", "logprob": -0.11141621321439743}, {"text": "C", "logprob": -0.012379592284560204}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Option", "logprob": -5.003857135772705}, {"text": " A", "logprob": -0.054288461804389954}, {"text": "\n", "logprob": -0.33057811856269836}, {"text": "D", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4318398573086597e-05}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Devices convert chemical energy.' true or false?", "pred": " \nAnswer: FALSE. Devices convert electrical energy. ER: Explained. EN", "completions_tokens": [{"text": " \n", "logprob": -1.8134618997573853}, {"text": "Answer", "logprob": -0.02622334286570549}, {"text": ":", "logprob": -0.2047615945339203}, {"text": " FALSE", "logprob": -1.2232632637023926}, {"text": ".", "logprob": -0.19654417037963867}, {"text": " Devices", "logprob": -1.0543559789657593}, {"text": " convert", "logprob": -0.2477731704711914}, {"text": " electrical", "logprob": -1.1693861484527588}, {"text": " energy", "logprob": -0.11170655488967896}, {"text": ".", "logprob": -0.31861168146133423}, {"text": " ER", "logprob": -10.832223892211914}, {"text": ":", "logprob": -6.376173973083496}, {"text": " Expl", "logprob": -10.573332786560059}, {"text": "ained", "logprob": -1.4836015701293945}, {"text": ".", "logprob": -1.764514446258545}, {"text": " EN", "logprob": -5.306890487670898}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Mountains are sites.' true or false?", "pred": " \n\n\nAnswer: FALSE. A site is an area of something, especially an archaeological", "completions_tokens": [{"text": " \n\n\n", "logprob": -5.208739757537842}, {"text": "Answer", "logprob": -0.4595121145248413}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " FALSE", "logprob": -1.7256691455841064}, {"text": ".", "logprob": -0.07874123007059097}, {"text": " A", "logprob": -5.379060745239258}, {"text": " site", "logprob": -1.038952350616455}, {"text": " is", "logprob": -0.5242427587509155}, {"text": " an", "logprob": -1.8104033470153809}, {"text": " area", "logprob": -1.1244038343429565}, {"text": " of", "logprob": -0.31843316555023193}, {"text": " something", "logprob": -7.5136871337890625}, {"text": ",", "logprob": -1.067850947380066}, {"text": " especially", "logprob": -1.5176851749420166}, {"text": " an", "logprob": -2.32191801071167}, {"text": " archaeological", "logprob": -0.37704402208328247}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Drugs are able to circulate to all parts of the body and attack cancer cells through out the system.' true or false?", "pred": " \n\nA) True\nB) False\nC) A and B\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.5193308591842651}, {"text": "A", "logprob": -0.30565932393074036}, {"text": ")", "logprob": -0.04444921389222145}, {"text": " True", "logprob": -0.3492047190666199}, {"text": "\n", "logprob": -0.20737630128860474}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.21728266775608063}, {"text": "\n", "logprob": -0.06504125148057938}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " A", "logprob": -0.8043121099472046}, {"text": " and", "logprob": -0.35551905632019043}, {"text": " B", "logprob": -8.940656698541716e-06}, {"text": "\n", "logprob": -0.01034009549766779}, {"text": "D", "logprob": -2.4318398573086597e-05}], "answers": ["true"], "all_classes": "null", "length": 29}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some race tracks are called road courses.' true or false?", "pred": " \n\nTrue False\nAnswer: True False\nFalse is incorrect,  true is", "completions_tokens": [{"text": " \n\n", "logprob": -0.21438942849636078}, {"text": "True", "logprob": -1.221731185913086}, {"text": " False", "logprob": -1.8100097179412842}, {"text": "\n", "logprob": -0.0502643883228302}, {"text": "Answer", "logprob": -0.15903767943382263}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " True", "logprob": -0.11072856932878494}, {"text": " False", "logprob": -2.243703603744507}, {"text": "\n", "logprob": -0.2245626598596573}, {"text": "False", "logprob": -1.330368995666504}, {"text": " is", "logprob": -1.9455081224441528}, {"text": " incorrect", "logprob": -0.978933572769165}, {"text": ",", "logprob": -1.8278591632843018}, {"text": " ", "logprob": -4.858039855957031}, {"text": " true", "logprob": -3.390674114227295}, {"text": " is", "logprob": -0.35205429792404175}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Arteries can rupture when weak spots on the blood vessel wall break.' true or false?", "pred": " \n\nAnswer: True.5663Kennui.xyalt tztt", "completions_tokens": [{"text": " \n\n", "logprob": -0.2272849678993225}, {"text": "Answer", "logprob": -2.641731023788452}, {"text": ":", "logprob": -0.02853049896657467}, {"text": " True", "logprob": -0.2223525494337082}, {"text": ".", "logprob": -0.05205497890710831}, {"text": "566", "logprob": -12.511625289916992}, {"text": "3", "logprob": -3.6584668159484863}, {"text": "Kenn", "logprob": -10.544395446777344}, {"text": "ui", "logprob": -9.529289245605469}, {"text": ".xy", "logprob": -12.399124145507812}, {"text": "", "logprob": -10.369583129882812}, {"text": "", "logprob": -4.306353569030762}, {"text": "alt", "logprob": -10.892574310302734}, {"text": " ", "logprob": -8.620719909667969}, {"text": "tz", "logprob": -6.130928039550781}, {"text": "tt", "logprob": -8.347633361816406}], "answers": ["true"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'railway lines are service companies.' true or false?", "pred": " False\nAnswer: False (Because rail transport usually not running with service concern)", "completions_tokens": [{"text": " False", "logprob": -2.4031519889831543}, {"text": "\n", "logprob": -0.9189289212226868}, {"text": "Answer", "logprob": -0.09311792254447937}, {"text": ":", "logprob": -0.005967774894088507}, {"text": " False", "logprob": -0.14347383379936218}, {"text": " (", "logprob": -3.2138912677764893}, {"text": "Because", "logprob": -4.571335315704346}, {"text": " rail", "logprob": -4.2368364334106445}, {"text": " transport", "logprob": -2.1393866539001465}, {"text": " usually", "logprob": -5.0998921394348145}, {"text": " not", "logprob": -4.933810234069824}, {"text": " running", "logprob": -6.628917694091797}, {"text": " with", "logprob": -4.1424560546875}, {"text": " service", "logprob": -2.0369882583618164}, {"text": " concern", "logprob": -10.009078979492188}, {"text": ")", "logprob": -2.6875569820404053}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Theatre is psychology.' true or false?", "pred": "  Albert Pike expressed this idea.\nA) True\nB) Albert Pike never", "completions_tokens": [{"text": " ", "logprob": -3.657426357269287}, {"text": " Albert", "logprob": -7.074215888977051}, {"text": " Pike", "logprob": -6.409181118011475}, {"text": " expressed", "logprob": -5.618061065673828}, {"text": " this", "logprob": -0.2170732468366623}, {"text": " idea", "logprob": -0.8582397103309631}, {"text": ".\n", "logprob": -3.3659703731536865}, {"text": "A", "logprob": -0.11453112959861755}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " True", "logprob": -0.17637157440185547}, {"text": "\n", "logprob": -0.04090709611773491}, {"text": "B", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " Albert", "logprob": -0.8464516401290894}, {"text": " Pike", "logprob": -0.017777975648641586}, {"text": " never", "logprob": -3.945482015609741}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Human genes are pieces of genetic material recorded on a DNA molecule.' true or false?", "pred": " \n\nAnswer: True.  Steven Pinker wrote in \"The Language Instinct", "completions_tokens": [{"text": " \n\n", "logprob": -0.2169850617647171}, {"text": "Answer", "logprob": -1.3725872039794922}, {"text": ":", "logprob": -0.07185596227645874}, {"text": " True", "logprob": -0.18875780701637268}, {"text": ".", "logprob": -0.047605954110622406}, {"text": " ", "logprob": -1.0923304557800293}, {"text": " Steven", "logprob": -8.862156867980957}, {"text": " Pink", "logprob": -1.393570899963379}, {"text": "er", "logprob": -8.940656698541716e-06}, {"text": " wrote", "logprob": -3.9727792739868164}, {"text": " in", "logprob": -1.6688700914382935}, {"text": " \"", "logprob": -1.6433610916137695}, {"text": "The", "logprob": -0.1545102596282959}, {"text": " Language", "logprob": -0.06387148797512054}, {"text": " Inst", "logprob": -0.021712690591812134}, {"text": "inct", "logprob": -2.4318398573086597e-05}], "answers": ["true"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Stars are a light source.' true or false?", "pred": " \n\nA) True\nB) False\nC) Since I know it personally", "completions_tokens": [{"text": " \n\n", "logprob": -0.3270895779132843}, {"text": "A", "logprob": -0.1109270378947258}, {"text": ")", "logprob": -0.027309557422995567}, {"text": " True", "logprob": -0.23604463040828705}, {"text": "\n", "logprob": -0.12804000079631805}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.10942923277616501}, {"text": "\n", "logprob": -0.022646844387054443}, {"text": "C", "logprob": -0.010119088925421238}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Since", "logprob": -7.301436424255371}, {"text": " I", "logprob": -4.728610992431641}, {"text": " know", "logprob": -3.3314497470855713}, {"text": " it", "logprob": -2.4089081287384033}, {"text": " personally", "logprob": -4.454464912414551}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Planets are typically brighter than most stars.' true or false?", "pred": " \nAnswer:\nfalse.  Most stars are much brighter than planets in the night", "completions_tokens": [{"text": " \n", "logprob": -1.8088892698287964}, {"text": "Answer", "logprob": -0.035152189433574677}, {"text": ":\n", "logprob": -2.6980907917022705}, {"text": "false", "logprob": -1.562046766281128}, {"text": ".", "logprob": -0.4487430453300476}, {"text": " ", "logprob": -0.9511537551879883}, {"text": " Most", "logprob": -4.3057708740234375}, {"text": " stars", "logprob": -0.24809561669826508}, {"text": " are", "logprob": -0.06296388059854507}, {"text": " much", "logprob": -0.8422757983207703}, {"text": " brighter", "logprob": -0.03903771936893463}, {"text": " than", "logprob": -0.022521205246448517}, {"text": " planets", "logprob": -0.8940191268920898}, {"text": " in", "logprob": -3.658360242843628}, {"text": " the", "logprob": -0.4503970742225647}, {"text": " night", "logprob": -2.10524845123291}], "answers": ["false"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Golf courses are one of the many land uses that contribute to a well-balanced livable community.' true or false?", "pred": " \n\nA) True\nB) False\nC) Golf courses can contribute but", "completions_tokens": [{"text": " \n\n", "logprob": -0.19682677090168}, {"text": "A", "logprob": -0.10860645025968552}, {"text": ")", "logprob": -0.025225922465324402}, {"text": " True", "logprob": -0.2525288462638855}, {"text": "\n", "logprob": -0.1422794610261917}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.17532742023468018}, {"text": "\n", "logprob": -0.09464555233716965}, {"text": "C", "logprob": -0.010277326218783855}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Golf", "logprob": -0.19707857072353363}, {"text": " courses", "logprob": -0.1632743924856186}, {"text": " can", "logprob": -1.5469691753387451}, {"text": " contribute", "logprob": -0.8090493679046631}, {"text": " but", "logprob": -3.27593994140625}], "answers": ["false"], "all_classes": "null", "length": 26}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Enzymes are a boon for the human body.' true or false?", "pred": " - false\nAnswer: FALSE\n![](/assets/img/online/ack", "completions_tokens": [{"text": " -", "logprob": -5.921367168426514}, {"text": " false", "logprob": -3.1905198097229004}, {"text": "\n", "logprob": -0.9547170400619507}, {"text": "Answer", "logprob": -0.049982521682977676}, {"text": ":", "logprob": -0.05333707854151726}, {"text": " FALSE", "logprob": -2.312526226043701}, {"text": "\n", "logprob": -1.9278565645217896}, {"text": "!", "logprob": -7.051812648773193}, {"text": "[]", "logprob": -1.3624639511108398}, {"text": "(/", "logprob": -0.14032775163650513}, {"text": "assets", "logprob": -0.3288116753101349}, {"text": "/img", "logprob": -0.48660826683044434}, {"text": "/", "logprob": -1.1122941970825195}, {"text": "online", "logprob": -5.157254695892334}, {"text": "/", "logprob": -3.3422884941101074}, {"text": "ack", "logprob": -10.571596145629883}], "answers": ["true"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Villages change the ecology of natural systems.' true or false?", "pred": " \n\nA) True\nB) False\nC) While villages may somewhat impact", "completions_tokens": [{"text": " \n\n", "logprob": -0.5065895318984985}, {"text": "A", "logprob": -0.6974509954452515}, {"text": ")", "logprob": -0.04449208453297615}, {"text": " True", "logprob": -0.29080575704574585}, {"text": "\n", "logprob": -0.16158956289291382}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.2856043577194214}, {"text": "\n", "logprob": -0.05762390419840813}, {"text": "C", "logprob": -0.019096219912171364}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " While", "logprob": -8.409789085388184}, {"text": " villages", "logprob": -1.4802650213241577}, {"text": " may", "logprob": -1.2842826843261719}, {"text": " somewhat", "logprob": -6.077145099639893}, {"text": " impact", "logprob": -1.3726404905319214}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Outbreaks are about making choices and picking winners.' true or false?", "pred": " \n\nAnswer: False.", "completions_tokens": [{"text": " \n\n", "logprob": -0.7544572949409485}, {"text": "Answer", "logprob": -0.27529245615005493}, {"text": ":", "logprob": -0.03033946454524994}, {"text": " False", "logprob": -0.4335024058818817}, {"text": ".", "logprob": -0.0999702736735344}, {"text": "<|eot_id|>", "logprob": -1.4652026891708374}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Sporting event are sports.' true or false?", "pred": " \n\nTrue\nFalse\n LIC\nAnswer: True\nPrimitive definition: \".\" (", "completions_tokens": [{"text": " \n\n", "logprob": -0.20890559256076813}, {"text": "True", "logprob": -1.6674690246582031}, {"text": "\n", "logprob": -1.0929428339004517}, {"text": "False", "logprob": -0.22222435474395752}, {"text": "\n", "logprob": -0.02888912707567215}, {"text": " LIC", "logprob": -12.214571952819824}, {"text": "\n", "logprob": -1.3585598468780518}, {"text": "Answer", "logprob": -3.1181728839874268}, {"text": ":", "logprob": -0.009163230657577515}, {"text": " True", "logprob": -0.7442834377288818}, {"text": "\n", "logprob": -0.08286906778812408}, {"text": "Primitive", "logprob": -9.822441101074219}, {"text": " definition", "logprob": -7.384782314300537}, {"text": ":", "logprob": -1.104822039604187}, {"text": " \".\"", "logprob": -13.083467483520508}, {"text": " (", "logprob": -1.910157322883606}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Ligaments have (part) corpi.' true or false?", "pred": " \n\nA) True\nB) False\nC) Not Given\nD)", "completions_tokens": [{"text": " \n\n", "logprob": -0.17184191942214966}, {"text": "A", "logprob": -2.598616123199463}, {"text": ")", "logprob": -0.14216580986976624}, {"text": " True", "logprob": -0.39085301756858826}, {"text": "\n", "logprob": -0.1761048287153244}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.3759385347366333}, {"text": "\n", "logprob": -0.061223797500133514}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Not", "logprob": -2.0678958892822266}, {"text": " Given", "logprob": -1.6107923984527588}, {"text": "\n", "logprob": -0.16396650671958923}, {"text": "D", "logprob": -0.003922508098185062}, {"text": ")", "logprob": -2.4318398573086597e-05}], "answers": ["false"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'information appliances consume energy.' true or false?", "pred": " \nAnswer: True", "completions_tokens": [{"text": " \n", "logprob": -1.6150439977645874}, {"text": "Answer", "logprob": -0.0309495460242033}, {"text": ":", "logprob": -0.12466885894536972}, {"text": " True", "logprob": -0.4176478683948517}, {"text": "<|eot_id|>", "logprob": -8.310206413269043}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Protein continues to be inserted until it reaches the hydrophobic stop signal sequence.' true or false?", "pred": " False\n\n## Step 1: Understanding the Statement\nThe statement suggests that protein", "completions_tokens": [{"text": " False", "logprob": -1.4963233470916748}, {"text": "\n\n", "logprob": -0.7232006192207336}, {"text": "##", "logprob": -0.6617639064788818}, {"text": " Step", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -2.4318398573086597e-05}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " Understanding", "logprob": -0.7971128821372986}, {"text": " the", "logprob": -2.4318398573086597e-05}, {"text": " Statement", "logprob": -3.8202507495880127}, {"text": "\n", "logprob": -8.940656698541716e-06}, {"text": "The", "logprob": -0.0037437842693179846}, {"text": " statement", "logprob": -0.026015112176537514}, {"text": " suggests", "logprob": -1.7362825870513916}, {"text": " that", "logprob": -0.01446969248354435}, {"text": " protein", "logprob": -0.852522075176239}], "answers": ["false"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some canals deliver water.' true or false?", "pred": " \n\nA) True\nB) False\nC) Canals do deliver water", "completions_tokens": [{"text": " \n\n", "logprob": -0.308868408203125}, {"text": "A", "logprob": -0.772826611995697}, {"text": ")", "logprob": -0.036008335649967194}, {"text": " True", "logprob": -0.4076372981071472}, {"text": "\n", "logprob": -0.1395256519317627}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.8763278126716614}, {"text": "\n", "logprob": -0.021623099222779274}, {"text": "C", "logprob": -0.00801702681928873}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Can", "logprob": -3.3692595958709717}, {"text": "als", "logprob": -8.940656698541716e-06}, {"text": " do", "logprob": -2.7872490882873535}, {"text": " deliver", "logprob": -1.8065505027770996}, {"text": " water", "logprob": -0.22836053371429443}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Landforms have direct effects.' true or false?", "pred": " FALSE\n\n### Step 1: Understanding the statement\nThe statement in question is", "completions_tokens": [{"text": " FALSE", "logprob": -3.6502795219421387}, {"text": "\n\n", "logprob": -0.969598650932312}, {"text": "###", "logprob": -2.058905601501465}, {"text": " Step", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -2.4318398573086597e-05}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " Understanding", "logprob": -0.9823354482650757}, {"text": " the", "logprob": -2.4318398573086597e-05}, {"text": " statement", "logprob": -0.5229437351226807}, {"text": "\n", "logprob": -0.06348379701375961}, {"text": "The", "logprob": -0.008269947953522205}, {"text": " statement", "logprob": -0.016375435516238213}, {"text": " in", "logprob": -1.4041163921356201}, {"text": " question", "logprob": -8.940656698541716e-06}, {"text": " is", "logprob": -0.1463788002729416}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Stars are huge balls of gas generating tremendous amounts of energy.' true or false?", "pred": " \n\nA) True\nB) False\nC) Option A and B\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.3723413646221161}, {"text": "A", "logprob": -0.061182085424661636}, {"text": ")", "logprob": -0.023414313793182373}, {"text": " True", "logprob": -0.2538096010684967}, {"text": "\n", "logprob": -0.12479428946971893}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.1528976559638977}, {"text": "\n", "logprob": -0.03877583518624306}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Option", "logprob": -4.502618312835693}, {"text": " A", "logprob": -0.05840042605996132}, {"text": " and", "logprob": -2.4549269676208496}, {"text": " B", "logprob": -0.20428279042243958}, {"text": "\n", "logprob": -0.5609267950057983}], "answers": ["true"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'monoclonal antibodies also break without cleavage or across cleavage planes.' true or false?", "pred": " \n\nA) False\nB) None of the above\nC) A monoc", "completions_tokens": [{"text": " \n\n", "logprob": -0.3939761817455292}, {"text": "A", "logprob": -0.7912470102310181}, {"text": ")", "logprob": -0.029280271381139755}, {"text": " False", "logprob": -1.6086621284484863}, {"text": "\n", "logprob": -0.048115167766809464}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " None", "logprob": -2.8819093704223633}, {"text": " of", "logprob": -0.30116569995880127}, {"text": " the", "logprob": -0.015876783058047295}, {"text": " above", "logprob": -0.05949876457452774}, {"text": "\n", "logprob": -0.40108317136764526}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -2.4199192921514623e-05}, {"text": " A", "logprob": -0.17197903990745544}, {"text": " monoc", "logprob": -2.9847874641418457}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Administrative regions have (part) windows.' true or false?", "pred": " \nAnswer: False. 3.1.2.3; p.", "completions_tokens": [{"text": " \n", "logprob": -2.2109758853912354}, {"text": "Answer", "logprob": -0.011451231315732002}, {"text": ":", "logprob": -0.20933471620082855}, {"text": " False", "logprob": -1.4757256507873535}, {"text": ".", "logprob": -0.09694354981184006}, {"text": " ", "logprob": -1.4391441345214844}, {"text": "3", "logprob": -4.691485404968262}, {"text": ".", "logprob": -0.6960792541503906}, {"text": "1", "logprob": -3.487140655517578}, {"text": ".", "logprob": -0.2951004207134247}, {"text": "2", "logprob": -1.2464905977249146}, {"text": ".", "logprob": -0.968445897102356}, {"text": "3", "logprob": -1.5611851215362549}, {"text": ";", "logprob": -6.974355697631836}, {"text": " p", "logprob": -3.6344223022460938}, {"text": ".", "logprob": -0.5062565803527832}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Many stars have no-discharge regulations in effect.' true or false?", "pred": " FALSE\nAnswer: TRUE\nStep 1: Analyze the question to understand", "completions_tokens": [{"text": " FALSE", "logprob": -3.2062296867370605}, {"text": "\n", "logprob": -0.8967469334602356}, {"text": "Answer", "logprob": -0.07228865474462509}, {"text": ":", "logprob": -0.037528421729803085}, {"text": " TRUE", "logprob": -2.230525493621826}, {"text": "\n", "logprob": -0.5551583766937256}, {"text": "Step", "logprob": -2.2320427894592285}, {"text": " ", "logprob": -2.4318398573086597e-05}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " Analy", "logprob": -1.262943983078003}, {"text": "ze", "logprob": -0.10976853966712952}, {"text": " the", "logprob": -8.940656698541716e-06}, {"text": " question", "logprob": -1.7054212093353271}, {"text": " to", "logprob": -0.5903234481811523}, {"text": " understand", "logprob": -0.8183487057685852}], "answers": ["false"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Enzymes aid in all aspects of digestion, including absorption.' true or false?", "pred": " \n\nA) True\nB) False\nC) Taguchi method\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.302106648683548}, {"text": "A", "logprob": -0.17435728013515472}, {"text": ")", "logprob": -0.036472681909799576}, {"text": " True", "logprob": -0.3920058608055115}, {"text": "\n", "logprob": -0.08080942183732986}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.2412911057472229}, {"text": "\n", "logprob": -0.062157291918992996}, {"text": "C", "logprob": -0.015617916360497475}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Tag", "logprob": -10.571155548095703}, {"text": "uchi", "logprob": -1.6218326091766357}, {"text": " method", "logprob": -2.218970775604248}, {"text": "\n", "logprob": -0.04434338957071304}, {"text": "D", "logprob": -2.4318398573086597e-05}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Every chemical substance emits a unique spectrum when it absorbs energy.' true or false?", "pred": " \nAnswer:\n\n False . The statement turns out to be false because there are", "completions_tokens": [{"text": " \n", "logprob": -1.7967151403427124}, {"text": "Answer", "logprob": -0.08753108978271484}, {"text": ":\n\n", "logprob": -2.036977767944336}, {"text": " False", "logprob": -4.600456714630127}, {"text": " ", "logprob": -3.0842297077178955}, {"text": ".", "logprob": -4.071902751922607}, {"text": " The", "logprob": -2.345959424972534}, {"text": " statement", "logprob": -0.847292423248291}, {"text": " turns", "logprob": -7.91363000869751}, {"text": " out", "logprob": -0.0975559651851654}, {"text": " to", "logprob": -0.08824501931667328}, {"text": " be", "logprob": -0.027653083205223083}, {"text": " false", "logprob": -0.3292885720729828}, {"text": " because", "logprob": -1.040173053741455}, {"text": " there", "logprob": -2.2447996139526367}, {"text": " are", "logprob": -0.12378489971160889}], "answers": ["true"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'railway stations are locations where dances are held.' true or false?", "pred": " \n\nA) True\nB) False\nC) Railway stations are not related", "completions_tokens": [{"text": " \n\n", "logprob": -0.36995190382003784}, {"text": "A", "logprob": -0.15925657749176025}, {"text": ")", "logprob": -0.2838381826877594}, {"text": " True", "logprob": -0.266743540763855}, {"text": "\n", "logprob": -0.09621361643075943}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " False", "logprob": -0.004126368090510368}, {"text": "\n", "logprob": -0.04381890222430229}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Railway", "logprob": -0.5387896299362183}, {"text": " stations", "logprob": -0.9870293140411377}, {"text": " are", "logprob": -0.6686070561408997}, {"text": " not", "logprob": -2.3147366046905518}, {"text": " related", "logprob": -4.049236297607422}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Many bacteria live naturally in our bodies without causing disease.' true or false?", "pred": " \n\nAnswer: TRUE. Creator of Minidora. Josiah Zacharias Biography", "completions_tokens": [{"text": " \n\n", "logprob": -0.25013619661331177}, {"text": "Answer", "logprob": -1.9110567569732666}, {"text": ":", "logprob": -0.08997688442468643}, {"text": " TRUE", "logprob": -2.70780611038208}, {"text": ".", "logprob": -0.07214226573705673}, {"text": " Creator", "logprob": -11.956782341003418}, {"text": " of", "logprob": -2.1390910148620605}, {"text": " Min", "logprob": -8.639327049255371}, {"text": "id", "logprob": -3.132394313812256}, {"text": "ora", "logprob": -2.4438767433166504}, {"text": ".", "logprob": -2.212430715560913}, {"text": " Jos", "logprob": -10.042537689208984}, {"text": "iah", "logprob": -1.1244672536849976}, {"text": " Zach", "logprob": -5.014805793762207}, {"text": "arias", "logprob": -1.0965856313705444}, {"text": " Biography", "logprob": -8.755290985107422}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Cheese is a viscoelastic material that is able to flow under quite small stresses.' true or false?", "pred": " \n\nAnswer: False.  The Elastic Requirement  states that a viscoelastic", "completions_tokens": [{"text": " \n\n", "logprob": -0.3543652594089508}, {"text": "Answer", "logprob": -0.787289023399353}, {"text": ":", "logprob": -0.02096574194729328}, {"text": " False", "logprob": -0.8333654403686523}, {"text": ".", "logprob": -0.10721471905708313}, {"text": " ", "logprob": -0.647244393825531}, {"text": " The", "logprob": -1.5516197681427002}, {"text": " Elastic", "logprob": -7.927072048187256}, {"text": " Requirement", "logprob": -10.097817420959473}, {"text": " ", "logprob": -2.487220525741577}, {"text": " states", "logprob": -4.613966941833496}, {"text": " that", "logprob": -0.045014966279268265}, {"text": " a", "logprob": -1.5398807525634766}, {"text": " vis", "logprob": -0.6691052317619324}, {"text": "co", "logprob": -8.940656698541716e-06}, {"text": "elastic", "logprob": -2.4318398573086597e-05}], "answers": ["false"], "all_classes": "null", "length": 24}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Caves contain fragile formations which can easily be destroyed through carelessness or vandalism.' true or false?", "pred": " \nAnswer: True. </s>< limestone \"></s>karst \"></s", "completions_tokens": [{"text": " \n", "logprob": -1.8164176940917969}, {"text": "Answer", "logprob": -0.053900089114904404}, {"text": ":", "logprob": -0.23365190625190735}, {"text": " True", "logprob": -0.2881147265434265}, {"text": ".", "logprob": -0.11253786832094193}, {"text": " </", "logprob": -4.927367687225342}, {"text": "s", "logprob": -0.11266504973173141}, {"text": "><", "logprob": -3.1837806701660156}, {"text": " limestone", "logprob": -13.051201820373535}, {"text": " \"></", "logprob": -7.402244567871094}, {"text": "s", "logprob": -0.026085030287504196}, {"text": ">", "logprob": -0.30734094977378845}, {"text": "kar", "logprob": -7.010678291320801}, {"text": "st", "logprob": -0.009809738956391811}, {"text": " \"></", "logprob": -2.107719898223877}, {"text": "s", "logprob": -8.940656698541716e-06}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'ski areas provide comfort.' true or false?", "pred": " \n\nA) False\nB) This question requires a premises in order to be", "completions_tokens": [{"text": " \n\n", "logprob": -0.37336769700050354}, {"text": "A", "logprob": -0.13362886011600494}, {"text": ")", "logprob": -0.004288049414753914}, {"text": " False", "logprob": -1.6714394092559814}, {"text": "\n", "logprob": -0.0819983184337616}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " This", "logprob": -4.799219131469727}, {"text": " question", "logprob": -1.7137460708618164}, {"text": " requires", "logprob": -2.6980929374694824}, {"text": " a", "logprob": -2.132270336151123}, {"text": " premises", "logprob": -7.070296764373779}, {"text": " in", "logprob": -3.6281380653381348}, {"text": " order", "logprob": -0.15898947417736053}, {"text": " to", "logprob": -0.017137303948402405}, {"text": " be", "logprob": -1.261616587638855}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Astronomical objects have no end in the uncollapsed wavefunction.' true or false?", "pred": " \n\nAnswer: True.  Disclaimer: No one really knows if astronomical objects have", "completions_tokens": [{"text": " \n\n", "logprob": -0.33395594358444214}, {"text": "Answer", "logprob": -0.33567363023757935}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " True", "logprob": -1.3520312309265137}, {"text": ".", "logprob": -0.18743568658828735}, {"text": " ", "logprob": -1.1310808658599854}, {"text": " Disclaimer", "logprob": -7.585978031158447}, {"text": ":", "logprob": -0.04920170456171036}, {"text": " No", "logprob": -4.820375442504883}, {"text": " one", "logprob": -2.2911877632141113}, {"text": " really", "logprob": -1.368503451347351}, {"text": " knows", "logprob": -0.11998306959867477}, {"text": " if", "logprob": -3.931215286254883}, {"text": " astronomical", "logprob": -4.322883605957031}, {"text": " objects", "logprob": -0.012773245573043823}, {"text": " have", "logprob": -0.32017093896865845}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Sea is used for sail boats.' true or false?", "pred": " \n\nA) False\nB) True\nC) Only in selected places in", "completions_tokens": [{"text": " \n\n", "logprob": -0.30982705950737}, {"text": "A", "logprob": -0.8245923519134521}, {"text": ")", "logprob": -0.0412670336663723}, {"text": " False", "logprob": -1.9300594329833984}, {"text": "\n", "logprob": -0.137429341673851}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " True", "logprob": -0.2801048457622528}, {"text": "\n", "logprob": -0.007549564819782972}, {"text": "C", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Only", "logprob": -3.047776222229004}, {"text": " in", "logprob": -1.2954965829849243}, {"text": " selected", "logprob": -7.84743595123291}, {"text": " places", "logprob": -1.6114230155944824}, {"text": " in", "logprob": -6.034503936767578}], "answers": ["false"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Ferns are among the most attractive of all foliage plants.' true or false?", "pred": " \n\nA) True\nB) None of the altemattive\nC", "completions_tokens": [{"text": " \n\n", "logprob": -0.25206905603408813}, {"text": "A", "logprob": -0.21740631759166718}, {"text": ")", "logprob": -0.0865040197968483}, {"text": " True", "logprob": -0.3149067163467407}, {"text": "\n", "logprob": -0.1553332805633545}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " None", "logprob": -5.061413288116455}, {"text": " of", "logprob": -0.2891983687877655}, {"text": " the", "logprob": -0.027666766196489334}, {"text": " al", "logprob": -8.938851356506348}, {"text": "tem", "logprob": -2.298755645751953}, {"text": "att", "logprob": -6.508234024047852}, {"text": "ive", "logprob": -2.508009910583496}, {"text": "\n", "logprob": -0.4089566767215729}, {"text": "C", "logprob": -2.4318398573086597e-05}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'monoclonal antibodies have the advantage of mobility.' true or false?", "pred": " \n\nA) Monoclonal antibodies \nB) False\nC) True", "completions_tokens": [{"text": " \n\n", "logprob": -0.38696882128715515}, {"text": "A", "logprob": -0.43027520179748535}, {"text": ")", "logprob": -0.020644783973693848}, {"text": " Mon", "logprob": -5.35259485244751}, {"text": "oc", "logprob": -8.940656698541716e-06}, {"text": "lon", "logprob": -2.4199192921514623e-05}, {"text": "al", "logprob": -2.4318398573086597e-05}, {"text": " antibodies", "logprob": -0.02535424381494522}, {"text": " \n", "logprob": -5.209981441497803}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " False", "logprob": -0.8650379180908203}, {"text": "\n", "logprob": -1.0957913398742676}, {"text": "C", "logprob": -2.4199192921514623e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " True", "logprob": -1.9974544048309326}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Oceans are important structures for human use of fresh water.' true or false?", "pred": " \n\nA) True\nB) This statement can be classified as a fact.\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.3435400426387787}, {"text": "A", "logprob": -0.38990330696105957}, {"text": ")", "logprob": -0.04926048591732979}, {"text": " True", "logprob": -0.34938502311706543}, {"text": "\n", "logprob": -0.15372733771800995}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " This", "logprob": -6.929805278778076}, {"text": " statement", "logprob": -0.5848793983459473}, {"text": " can", "logprob": -3.5644643306732178}, {"text": " be", "logprob": -0.4065816402435303}, {"text": " classified", "logprob": -2.743379831314087}, {"text": " as", "logprob": -0.4154019057750702}, {"text": " a", "logprob": -1.5718120336532593}, {"text": " fact", "logprob": -2.6251420974731445}, {"text": ".\n", "logprob": -0.39246833324432373}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some bays are part of sea.' true or false?", "pred": " \n\n\nAnswer: True.", "completions_tokens": [{"text": " \n\n\n", "logprob": -5.02439546585083}, {"text": "Answer", "logprob": -0.7712939977645874}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " True", "logprob": -0.1569148600101471}, {"text": ".", "logprob": -0.02900250256061554}, {"text": "<|eot_id|>", "logprob": -0.3805793523788452}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'enzymes are arranged linearly along long chains of DNA sequence, called chromosomes .' true or false?", "pred": " \nAnswer: False.  Enzymes are proteins that catalyze biochemical", "completions_tokens": [{"text": " \n", "logprob": -1.8879284858703613}, {"text": "Answer", "logprob": -0.07102864235639572}, {"text": ":", "logprob": -0.194050595164299}, {"text": " False", "logprob": -0.9114798307418823}, {"text": ".", "logprob": -0.15900737047195435}, {"text": " ", "logprob": -1.5639184713363647}, {"text": " En", "logprob": -1.1783896684646606}, {"text": "zym", "logprob": -8.940656698541716e-06}, {"text": "es", "logprob": -0.01741979271173477}, {"text": " are", "logprob": -0.12389370054006577}, {"text": " proteins", "logprob": -1.7277331352233887}, {"text": " that", "logprob": -0.9302985668182373}, {"text": " catal", "logprob": -2.714718818664551}, {"text": "y", "logprob": -2.4199192921514623e-05}, {"text": "ze", "logprob": -0.23210066556930542}, {"text": " biochemical", "logprob": -1.586187720298767}], "answers": ["false"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'towns have (part) waters.' true or false?", "pred": " \nAnswer: False (presumably because towns don't \"have\" waters -", "completions_tokens": [{"text": " \n", "logprob": -1.8763927221298218}, {"text": "Answer", "logprob": -0.018638471141457558}, {"text": ":", "logprob": -0.11958237737417221}, {"text": " False", "logprob": -1.423872470855713}, {"text": " (", "logprob": -3.975048780441284}, {"text": "pres", "logprob": -7.413690090179443}, {"text": "umably", "logprob": -0.3169868588447571}, {"text": " because", "logprob": -0.8450355529785156}, {"text": " towns", "logprob": -1.6872912645339966}, {"text": " don", "logprob": -2.298790693283081}, {"text": "'t", "logprob": -0.0317704938352108}, {"text": " \"", "logprob": -2.9914190769195557}, {"text": "have", "logprob": -0.016646768897771835}, {"text": "\"", "logprob": -0.017419910058379173}, {"text": " waters", "logprob": -0.5262972116470337}, {"text": " -", "logprob": -2.8523402214050293}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Horses are a potent symbol from almost every world religion and mythology.' true or false?", "pred": " \n\nA) True\nB) Many horses appear in artworks and architecture from various", "completions_tokens": [{"text": " \n\n", "logprob": -0.240507110953331}, {"text": "A", "logprob": -0.43993157148361206}, {"text": ")", "logprob": -0.12413642555475235}, {"text": " True", "logprob": -0.37809062004089355}, {"text": "\n", "logprob": -0.15340088307857513}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " Many", "logprob": -5.394383907318115}, {"text": " horses", "logprob": -2.1957695484161377}, {"text": " appear", "logprob": -3.7747626304626465}, {"text": " in", "logprob": -0.1415778547525406}, {"text": " artworks", "logprob": -6.782121181488037}, {"text": " and", "logprob": -1.0283727645874023}, {"text": " architecture", "logprob": -4.422255039215088}, {"text": " from", "logprob": -1.3413206338882446}, {"text": " various", "logprob": -2.796647071838379}], "answers": ["false"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Roads are gravel and can become rough and muddy after rains.' true or false?", "pred": " \n\nA) True\nB) Categorize roads into 1 ( smoother", "completions_tokens": [{"text": " \n\n", "logprob": -0.25418123602867126}, {"text": "A", "logprob": -0.14205040037631989}, {"text": ")", "logprob": -0.04403418302536011}, {"text": " True", "logprob": -0.31882768869400024}, {"text": "\n", "logprob": -0.13496600091457367}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " C", "logprob": -3.937436580657959}, {"text": "ategor", "logprob": -4.689183712005615}, {"text": "ize", "logprob": -1.847855806350708}, {"text": " roads", "logprob": -2.845531702041626}, {"text": " into", "logprob": -1.4403464794158936}, {"text": " ", "logprob": -3.9765126705169678}, {"text": "1", "logprob": -1.1191470623016357}, {"text": " (", "logprob": -3.7829928398132324}, {"text": " smoother", "logprob": -10.738913536071777}], "answers": ["true"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Skyscrapers have (part) walls.' true or false?", "pred": " \n\nAnswer: True. . 11. What three entities are involved in", "completions_tokens": [{"text": " \n\n", "logprob": -0.2722528278827667}, {"text": "Answer", "logprob": -0.13711436092853546}, {"text": ":", "logprob": -0.021958788856863976}, {"text": " True", "logprob": -0.45815563201904297}, {"text": ".", "logprob": -0.05766700208187103}, {"text": " ", "logprob": -0.8221529722213745}, {"text": ".", "logprob": -4.211546897888184}, {"text": " ", "logprob": -1.2335203886032104}, {"text": "11", "logprob": -7.88167667388916}, {"text": ".", "logprob": -0.6527881026268005}, {"text": " What", "logprob": -3.8590264320373535}, {"text": " three", "logprob": -7.437453746795654}, {"text": " entities", "logprob": -3.2057433128356934}, {"text": " are", "logprob": -0.6442529559135437}, {"text": " involved", "logprob": -2.8564045429229736}, {"text": " in", "logprob": -0.09643880277872086}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'automobile engines are electro-chemical devices.' true or false?", "pred": " \n\nAnswer: false.'value' in 'auto' from 'automobile',", "completions_tokens": [{"text": " \n\n", "logprob": -0.4649255871772766}, {"text": "Answer", "logprob": -0.7752977013587952}, {"text": ":", "logprob": -0.027243899181485176}, {"text": " false", "logprob": -2.7002854347229004}, {"text": ".", "logprob": -0.12726283073425293}, {"text": "'value", "logprob": -12.423961639404297}, {"text": "'", "logprob": -1.4876282215118408}, {"text": " in", "logprob": -5.657380104064941}, {"text": " '", "logprob": -2.3441004753112793}, {"text": "auto", "logprob": -3.636657953262329}, {"text": "'", "logprob": -2.4057350158691406}, {"text": " from", "logprob": -6.946763515472412}, {"text": " '", "logprob": -0.6638903021812439}, {"text": "autom", "logprob": -0.05709552764892578}, {"text": "obile", "logprob": -8.940656698541716e-06}, {"text": "',", "logprob": -2.7976202964782715}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Asteroids are video games.' true or false?", "pred": " \n\nTrue\nFalse\nSpouse\nSimilarity\nAsteroids\nShoot", "completions_tokens": [{"text": " \n\n", "logprob": -0.3048647940158844}, {"text": "True", "logprob": -1.4731361865997314}, {"text": "\n", "logprob": -1.2780193090438843}, {"text": "False", "logprob": -0.045779816806316376}, {"text": "\n", "logprob": -0.021456612274050713}, {"text": "Sp", "logprob": -9.861173629760742}, {"text": "ouse", "logprob": -4.846488952636719}, {"text": "\n", "logprob": -0.38065946102142334}, {"text": "Similar", "logprob": -3.485917091369629}, {"text": "ity", "logprob": -0.165432870388031}, {"text": "\n", "logprob": -0.36754870414733887}, {"text": "A", "logprob": -1.6810396909713745}, {"text": "ster", "logprob": -0.23133601248264313}, {"text": "oids", "logprob": -0.09463145583868027}, {"text": "\n", "logprob": -0.3307828903198242}, {"text": "Shoot", "logprob": -9.175894737243652}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'brains fill with blood.' true or false?", "pred": " \n\nAnswer: TRUE.", "completions_tokens": [{"text": " \n\n", "logprob": -0.3365957736968994}, {"text": "Answer", "logprob": -1.1187705993652344}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " TRUE", "logprob": -2.23477840423584}, {"text": ".", "logprob": -0.11130636930465698}, {"text": "<|eot_id|>", "logprob": -1.8230961561203003}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some muscle organ fills ventricles.' true or false?", "pred": "  The heart has three chambers that contain oxygenated blood which are called the atr", "completions_tokens": [{"text": " ", "logprob": -4.701611518859863}, {"text": " The", "logprob": -3.4391541481018066}, {"text": " heart", "logprob": -1.2774602174758911}, {"text": " has", "logprob": -1.500718355178833}, {"text": " three", "logprob": -4.016129016876221}, {"text": " chambers", "logprob": -1.2779686450958252}, {"text": " that", "logprob": -3.6778175830841064}, {"text": " contain", "logprob": -4.127368927001953}, {"text": " oxygen", "logprob": -4.710224151611328}, {"text": "ated", "logprob": -0.1938905417919159}, {"text": " blood", "logprob": -0.5710492134094238}, {"text": " which", "logprob": -3.454033851623535}, {"text": " are", "logprob": -0.7421891093254089}, {"text": " called", "logprob": -1.7567839622497559}, {"text": " the", "logprob": -0.6108294129371643}, {"text": " atr", "logprob": -2.9698619842529297}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Most music festivals arise from forces.' true or false?", "pred": " I\nAnswer: False\nQuestion: \n\nThe similarity between Human Knowledge and Cognitive", "completions_tokens": [{"text": " I", "logprob": -8.162059783935547}, {"text": "\n", "logprob": -4.145028114318848}, {"text": "Answer", "logprob": -0.3607505261898041}, {"text": ":", "logprob": -0.6691313982009888}, {"text": " False", "logprob": -0.35247859358787537}, {"text": "\n", "logprob": -0.6794252395629883}, {"text": "Question", "logprob": -3.166698932647705}, {"text": ":", "logprob": -1.2264043092727661}, {"text": " \n\n", "logprob": -3.0921781063079834}, {"text": "The", "logprob": -2.970679759979248}, {"text": " similarity", "logprob": -3.046771764755249}, {"text": " between", "logprob": -0.06520956754684448}, {"text": " Human", "logprob": -7.598655700683594}, {"text": " Knowledge", "logprob": -1.211012840270996}, {"text": " and", "logprob": -0.23494186997413635}, {"text": " Cognitive", "logprob": -4.821465969085693}], "answers": ["false"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Rivers are an important feature of Kentucky geography.' true or false?", "pred": " \nAnswer: True. NGSS.USA.KG.KG.4.P", "completions_tokens": [{"text": " \n", "logprob": -2.0087907314300537}, {"text": "Answer", "logprob": -0.08473819494247437}, {"text": ":", "logprob": -0.225508913397789}, {"text": " True", "logprob": -0.42733949422836304}, {"text": ".", "logprob": -0.12606416642665863}, {"text": " NG", "logprob": -11.02557373046875}, {"text": "SS", "logprob": -1.3247431516647339}, {"text": ".", "logprob": -2.0619893074035645}, {"text": "USA", "logprob": -5.725815773010254}, {"text": ".K", "logprob": -1.7849931716918945}, {"text": "G", "logprob": -2.0751028060913086}, {"text": ".K", "logprob": -3.5451784133911133}, {"text": "G", "logprob": -0.7804467082023621}, {"text": ".", "logprob": -0.19949127733707428}, {"text": "4", "logprob": -1.9890321493148804}, {"text": ".P", "logprob": -3.4525177478790283}], "answers": ["true"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Tutu Chengcui, The Pierre, Waddesdon Manor, Astro Orbitor, Heian period, 2019 Canadian federal election, Paradiski, Tenughat Dam, Gros Michel banana, Reedy Glacier, Gangotri Glacier, Pinatubo, Interwar period, djon djon, Qiu Shiliang, Caciotta, Firth of Forth, 2011 Rugby World Cup, Cheng Yuanzhen, Pliocene, Sri Maha Bodhi, which one is the most conceptually similar with Botryosphaeria stevensii?", "pred": " \n\nAnswer: Botryosphaeria stevensii is a plant pathogen", "completions_tokens": [{"text": " \n\n", "logprob": -0.07735384255647659}, {"text": "Answer", "logprob": -0.6132769584655762}, {"text": ":", "logprob": -0.0680534616112709}, {"text": " Bot", "logprob": -0.7782579064369202}, {"text": "ry", "logprob": -8.940656698541716e-06}, {"text": "os", "logprob": -2.4318398573086597e-05}, {"text": "pha", "logprob": -2.4199192921514623e-05}, {"text": "eria", "logprob": -8.940656698541716e-06}, {"text": " ste", "logprob": -2.4318398573086597e-05}, {"text": "vens", "logprob": -2.4318398573086597e-05}, {"text": "ii", "logprob": -2.4318398573086597e-05}, {"text": " is", "logprob": -0.5545309782028198}, {"text": " a", "logprob": -0.06500494480133057}, {"text": " plant", "logprob": -1.977658748626709}, {"text": " path", "logprob": -0.22471921145915985}, {"text": "ogen", "logprob": -0.027229515835642815}], "answers": ["djon djon"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong UEFA Euro 2004, potassium hydroxide, Queen Elizabeth Olympic Park, Nena, Rainbow Bar and Grill, Cleveland Clinic, poly(methyl methacrylate), Cilician Gates, Akbar Shah, CR2025, wagasi, lateral rotator group, Dorsal digital arteries of hand, Ruhleben internment camp, Europe, Small Magellanic Cloud, sodium carbonate, 60558 Echeclus, Llangorse Lake, Estrogen, Steinmetz Pink Diamond, which one is the most conceptually similar with fluoxetine?", "pred": " \n\nAnswer: Sodium carbonate (sodium carbonate is the chemical compound in krekap", "completions_tokens": [{"text": " \n\n", "logprob": -0.1114032045006752}, {"text": "Answer", "logprob": -0.1060120239853859}, {"text": ":", "logprob": -0.026418296620249748}, {"text": " Sodium", "logprob": -2.092195987701416}, {"text": " carbonate", "logprob": -0.04393424838781357}, {"text": " (", "logprob": -2.445279121398926}, {"text": "s", "logprob": -1.1498987674713135}, {"text": "odium", "logprob": -0.1233825609087944}, {"text": " carbonate", "logprob": -0.45744743943214417}, {"text": " is", "logprob": -0.670214056968689}, {"text": " the", "logprob": -2.1330692768096924}, {"text": " chemical", "logprob": -1.6492414474487305}, {"text": " compound", "logprob": -1.5175869464874268}, {"text": " in", "logprob": -4.37050724029541}, {"text": " kre", "logprob": -10.23746109008789}, {"text": "kap", "logprob": -8.888365745544434}], "answers": ["Estrogen"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Makemake, 2004 United States presidential election, San Gorgonio Pass, Penstrowed, Criollo cheese, Lactoperoxidase, solar eclipse of August 7, 1812, Canning Tunnel, Haunted Mansion Holiday, Egg hunt, Caciotta, Campanian, Gros Michel banana, Kveik, venous angle, Joint Mathematics Meetings, Plesetsk Cosmodrome Site 132, STS-122, Apollo 7, Miocene, Beech bark disease, which one is the most conceptually similar with Barnby Broad and Marshes?", "pred": " \n\nAnswer: San Gorgonio Pass. (Reference:https://en.wikipedia", "completions_tokens": [{"text": " \n\n", "logprob": -0.09068688750267029}, {"text": "Answer", "logprob": -0.3140278160572052}, {"text": ":", "logprob": -0.15149034559726715}, {"text": " San", "logprob": -2.5082545280456543}, {"text": " G", "logprob": -8.940656698541716e-06}, {"text": "org", "logprob": -8.940656698541716e-06}, {"text": "onio", "logprob": -8.940656698541716e-06}, {"text": " Pass", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.14463037252426147}, {"text": " (", "logprob": -1.406895637512207}, {"text": "Reference", "logprob": -6.245225429534912}, {"text": ":", "logprob": -0.36680933833122253}, {"text": "https", "logprob": -6.701877593994141}, {"text": "://", "logprob": -8.940656698541716e-06}, {"text": "en", "logprob": -0.20704859495162964}, {"text": ".wikipedia", "logprob": -0.0031554929446429014}], "answers": ["Penstrowed"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Charles Bridge, French and Indian War, Elephanta Caves, Paris Commune, South China Sea, Dinefwr Park National Nature Reserve, Dresden Green Diamond, Greek fire, Clochette, The French Laundry, Egyptian cheese, Gatchina Palace, Allium ursinum, Agnes Edwards (craftworker), 2010 Commonwealth Games, Crush (soft drink), QF 3 pounder Hotchkiss, Poston War Relocation Center, valproic acid, Blue Serpent Clock, Palmar plate, which one is the most conceptually similar with Pont Neuf?", "pred": " \n\n\nStep 1: Identify the main theme of the given list. Most of", "completions_tokens": [{"text": " \n\n\n", "logprob": -5.437002182006836}, {"text": "Step", "logprob": -3.6962718963623047}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " Identify", "logprob": -1.1725282669067383}, {"text": " the", "logprob": -0.051004163920879364}, {"text": " main", "logprob": -2.7988762855529785}, {"text": " theme", "logprob": -1.5137275457382202}, {"text": " of", "logprob": -1.1147006750106812}, {"text": " the", "logprob": -0.3938440680503845}, {"text": " given", "logprob": -0.6460896730422974}, {"text": " list", "logprob": -1.6851069927215576}, {"text": ".", "logprob": -2.900071859359741}, {"text": " Most", "logprob": -2.5903007984161377}, {"text": " of", "logprob": -0.20330455899238586}], "answers": ["Charles Bridge"], "all_classes": "null", "length": 96}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong mucin, Golden Gate Park, spiral artery, Edwards Air Force Base, PSR B1620-26 b, International Conference on Computer Vision, TUC338, sarin, Mechanistic target of rapamycin kinase, Nepenthes edwardsiana, Syon Park House, cyclosporine, Cannabinoid receptor 2, Lake of the Woods, Ferulic acid decarboxylase, Idursulfase, New Orleans Jazz & Heritage Festival, Soo Locks, Morocco, Cambrian Mountains, solar eclipse of July 22, 2028, which one is the most conceptually similar with gal operon?", "pred": " \n\nAnswer: Mechano growth factor. (thinking bias) \n(Ferrofinger", "completions_tokens": [{"text": " \n\n", "logprob": -0.15675406157970428}, {"text": "Answer", "logprob": -0.5857318043708801}, {"text": ":", "logprob": -0.5898565649986267}, {"text": " Mech", "logprob": -6.123424530029297}, {"text": "ano", "logprob": -1.879828691482544}, {"text": " growth", "logprob": -1.2089861631393433}, {"text": " factor", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.4816936254501343}, {"text": " (", "logprob": -1.0819745063781738}, {"text": "thinking", "logprob": -11.790274620056152}, {"text": " bias", "logprob": -7.254488945007324}, {"text": ")", "logprob": -0.5314417481422424}, {"text": " \n", "logprob": -4.1120195388793945}, {"text": "(F", "logprob": -5.690072059631348}, {"text": "erro", "logprob": -5.162670135498047}, {"text": "finger", "logprob": -10.093008041381836}], "answers": ["TUC338"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Mall of America, adenosine diphosphate, Trawniki concentration camp, Ignalina Nuclear Power Plant, Ford Windsor engine, Lake Winnipeg, Bronx Zoo, Gliese 581g, Three Mile Island Nuclear Generating Station, 8.8 cm SK L/30 naval gun, Katiki Domokou, Australia, Battle of Chancellorsville, daf-5, Pontiac V8 engine, BMW M54, The Four Seasons Restaurant, Travelodge, Crawford Notch, CR2032 battery, Buick V8 engine, which one is the most conceptually similar with M61 Vulcan?", "pred": " \nAnswer: Ford Windsor engine  Similarity: Ford Windsor engine Answer: Similar", "completions_tokens": [{"text": " \n", "logprob": -2.5834593772888184}, {"text": "Answer", "logprob": -0.1615820676088333}, {"text": ":", "logprob": -0.5491429567337036}, {"text": " Ford", "logprob": -1.7547414302825928}, {"text": " Windsor", "logprob": -8.940656698541716e-06}, {"text": " engine", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -6.44667911529541}, {"text": " Similar", "logprob": -1.4664901494979858}, {"text": "ity", "logprob": -0.15020149946212769}, {"text": ":", "logprob": -0.14143535494804382}, {"text": " Ford", "logprob": -0.6418810486793518}, {"text": " Windsor", "logprob": -0.1463225781917572}, {"text": " engine", "logprob": -8.940656698541716e-06}, {"text": " Answer", "logprob": -5.213619232177734}, {"text": ":", "logprob": -0.480877161026001}, {"text": " Similar", "logprob": -2.236748695373535}], "answers": ["8.8 cm SK L/30 naval gun"], "all_classes": "null", "length": 96}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Wivenhoe, cannabinoid receptor 1, Dancing on Ice, Carew Castle, Clochette, DNA-binding domain, Zojila Pass, Americas, Newgate Prison, Botryosphaeria stevensii, 1960 Democratic National Convention, Interleukin 2, Kakadu National Park, Brain derived neurotrophic factor, PTS-GFL superfamily, common facial vein, Seven Years War, Epidermal growth factor, San Francisco International Film Festival, chilihueque, Inca Kola, which one is the most conceptually similar with Hirudin?", "pred": " \n\nAnswer: PTS-GFL superfamily, DNA-binding domain, PTS-GFL", "completions_tokens": [{"text": " \n\n", "logprob": -0.19764947891235352}, {"text": "Answer", "logprob": -0.5216774940490723}, {"text": ":", "logprob": -0.05675588920712471}, {"text": " PTS", "logprob": -0.7708732485771179}, {"text": "-G", "logprob": -8.940656698541716e-06}, {"text": "FL", "logprob": -2.4437606043647975e-05}, {"text": " super", "logprob": -0.007375866640359163}, {"text": "family", "logprob": -2.4318398573086597e-05}, {"text": ",", "logprob": -1.6316215991973877}, {"text": " DNA", "logprob": -4.126408576965332}, {"text": "-binding", "logprob": -2.4318398573086597e-05}, {"text": " domain", "logprob": -8.940656698541716e-06}, {"text": ",", "logprob": -0.5095784068107605}, {"text": " PTS", "logprob": -2.0409820079803467}, {"text": "-G", "logprob": -0.009055497124791145}, {"text": "FL", "logprob": -8.940656698541716e-06}], "answers": ["PTS-GFL superfamily"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 101955 Bennu, Holin superfamily VII, Corrugator cutis ani muscle, Second Sino-Japanese War, Winter Hill transmitting station, parasphenoid, Irish Rebellion of 1641, Reflex inguinal ligament, Battle of Trafalgar, Trivial Pursuit, tetrahydrofuran, Port Jackson, Griffith Park, 2019 Rugby World Cup, Al Hidayah, Epsilon Eridani, chitin, Renju, Autopia, KNM ER 1805, 1734 British general election, which one is the most conceptually similar with Submarine Voyage?", "pred": " \n\nTetrahydrofuran\n\ngriffith park\n\n108 DO243", "completions_tokens": [{"text": " \n\n", "logprob": -0.13947318494319916}, {"text": "T", "logprob": -5.941351890563965}, {"text": "et", "logprob": -0.014284970238804817}, {"text": "ra", "logprob": -0.021192533895373344}, {"text": "hydro", "logprob": -0.005800676066428423}, {"text": "f", "logprob": -8.940656698541716e-06}, {"text": "uran", "logprob": -8.940656698541716e-06}, {"text": "\n\n", "logprob": -2.1923158168792725}, {"text": "gr", "logprob": -10.492707252502441}, {"text": "iff", "logprob": -0.45385223627090454}, {"text": "ith", "logprob": -2.4318398573086597e-05}, {"text": " park", "logprob": -0.15668871998786926}, {"text": "\n\n", "logprob": -0.08529617637395859}, {"text": "108", "logprob": -12.628852844238281}, {"text": " DO", "logprob": -11.310745239257812}, {"text": "243", "logprob": -11.119278907775879}], "answers": ["Autopia"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Iaido, Compound engine, Canary Islands, Renju, Star of Bethlehem, Grosvenor House Hotel, Cape Canaveral Air Force Station Launch Complex 6, London Zoo, Tehran Conference, Sonoma Valley AVA, Independence Day, Nepenthes aristolochioides, Petronas Towers, New Guinea, Sinnemahoning Creek, Barabar Caves, 2008 Democratic National Convention, Somerset Dam, Agnes Edwards (craftworker), Standedge Tunnels, Rock Creek Park, which one is the most conceptually similar with Campanian?", "pred": " The Campanian is an upper stage subdivision of the Early Cretaceous epoch", "completions_tokens": [{"text": " The", "logprob": -4.810194969177246}, {"text": " Cam", "logprob": -0.914567232131958}, {"text": "pan", "logprob": -8.940656698541716e-06}, {"text": "ian", "logprob": -0.006252727005630732}, {"text": " is", "logprob": -0.2581564784049988}, {"text": " an", "logprob": -2.30570650100708}, {"text": " upper", "logprob": -4.0440568923950195}, {"text": " stage", "logprob": -1.8922251462936401}, {"text": " subdivision", "logprob": -4.174006462097168}, {"text": " of", "logprob": -0.056178707629442215}, {"text": " the", "logprob": -0.0495612770318985}, {"text": " Early", "logprob": -2.0938472747802734}, {"text": " C", "logprob": -0.04523933306336403}, {"text": "ret", "logprob": -8.940656698541716e-06}, {"text": "aceous", "logprob": -2.4318398573086597e-05}, {"text": " epoch", "logprob": -0.9538109302520752}], "answers": ["Independence Day"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Formula 5000, Late Cretaceous, Ure2, Holin superfamily II, djon djon, Ebensee concentration camp, Extrinsic extensor muscles of the hand, Ourasphaira giraldae, Ponticulus, Delaware Aqueduct, Baghdad Central Prison, Table Mountain, Fukushima Daiichi Nuclear Power Plant, Fifth Avenue, Comiket, solar eclipse of August 9, 1896, Coors Light, 1954 FIFA World Cup, Guadalcanal Campaign, Bart the Bear 2, Sex determining region Y, which one is the most conceptually similar with Interstate 5 in California?", "pred": " Answer:\nTable Mountain Similarity: Ourasphaira giraldae. Solar", "completions_tokens": [{"text": " Answer", "logprob": -3.009237289428711}, {"text": ":\n", "logprob": -1.035253882408142}, {"text": "Table", "logprob": -3.0931715965270996}, {"text": " Mountain", "logprob": -2.4318398573086597e-05}, {"text": " Similar", "logprob": -1.1213164329528809}, {"text": "ity", "logprob": -0.05113714933395386}, {"text": ":", "logprob": -0.1260232776403427}, {"text": " Our", "logprob": -5.285085201263428}, {"text": "as", "logprob": -8.940656698541716e-06}, {"text": "ph", "logprob": -2.4318398573086597e-05}, {"text": "aira", "logprob": -2.4318398573086597e-05}, {"text": " g", "logprob": -2.4199192921514623e-05}, {"text": "iral", "logprob": -8.940656698541716e-06}, {"text": "dae", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -3.029142141342163}, {"text": " Solar", "logprob": -6.900545597076416}], "answers": ["Fifth Avenue"], "all_classes": "null", "length": 97}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong entitlement, Caciotta, Pinconning cheese, Raghunathpur Thermal Power Station, Severn Valley Railway, Sagittarius Dwarf Elliptical Galaxy, Battle of the Somme, Cloth Hall, Ypres, Criollo cheese, Xynotyro, 2015 Rugby World Cup, Arc de Triomphe, Lambert Glacier, Kasat Suek Intersection, Palmar plate, Nabulsi cheese, Arlington Memorial Bridge, Hungerford Bridge and Golden Jubilee Bridges, dilator naris muscle, Sonoma County wine, Johnston Atoll, which one is the most conceptually similar with Perrier?", "pred": " \n\nAnswer: Perrier is a brand of sparkling water, and among the options", "completions_tokens": [{"text": " \n\n", "logprob": -0.21411655843257904}, {"text": "Answer", "logprob": -0.2519669532775879}, {"text": ":", "logprob": -0.09896302968263626}, {"text": " Per", "logprob": -2.6141467094421387}, {"text": "rier", "logprob": -2.4318398573086597e-05}, {"text": " is", "logprob": -0.7734140753746033}, {"text": " a", "logprob": -0.11534798890352249}, {"text": " brand", "logprob": -0.639762282371521}, {"text": " of", "logprob": -0.12395267188549042}, {"text": " sparkling", "logprob": -0.9582948684692383}, {"text": " water", "logprob": -0.17820897698402405}, {"text": ",", "logprob": -1.4461649656295776}, {"text": " and", "logprob": -1.5037891864776611}, {"text": " among", "logprob": -0.9332734942436218}, {"text": " the", "logprob": -0.09946899116039276}, {"text": " options", "logprob": -0.7294227480888367}], "answers": ["Sonoma County wine"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Accessory soleus muscle, Nalanda, Wine auction, 1964 Alaska earthquake, 2009 World Championships in Athletics, Warhammer Fantasy Battle, Savoy wine, Kveik, Standedge Tunnels, Botryosphaeria stevensii, 2010 Commonwealth Games, Almaz, Oak Hill Country Club, late Middle Ages, Mobile Bay, Rolls-Royce Meteor, Frankfurt City Tunnel, The Pierre, 2002 European Athletics Championships, Eurovision Song Contest 2008, 1983 United Kingdom general election, which one is the most conceptually similar with Woodstock Festival?", "pred": " \n\nA) Nalanda\nB) 2009 World Championships in Athletics", "completions_tokens": [{"text": " \n\n", "logprob": -0.283646821975708}, {"text": "A", "logprob": -4.215213298797607}, {"text": ")", "logprob": -1.1134933233261108}, {"text": " N", "logprob": -1.1784577369689941}, {"text": "al", "logprob": -8.940656698541716e-06}, {"text": "anda", "logprob": -8.940656698541716e-06}, {"text": "\n", "logprob": -0.08485439419746399}, {"text": "B", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -0.04076118767261505}, {"text": "200", "logprob": -0.8265985250473022}, {"text": "9", "logprob": -0.09049253165721893}, {"text": " World", "logprob": -8.940656698541716e-06}, {"text": " Championships", "logprob": -8.940656698541716e-06}, {"text": " in", "logprob": -2.4318398573086597e-05}, {"text": " Athletics", "logprob": -2.4318398573086597e-05}], "answers": ["Eurovision Song Contest 2008"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1989 Loma Prieta earthquake, Asilomar Conference on Recombinant DNA, Nissan SR engine, Quebec Conference, KNM WT 17000, 1990 FIFA World Cup, Maurandya, Caciotta, Red Sea, 2016 Kumamoto earthquakes, Battle of Waterloo, 2001 United Kingdom general election, Coachella Valley Music and Arts Festival, Riviera Country Club, WASP-43b, TM 1517, table football, The Shard, solar eclipse of June 13, 2132, Oranienburg concentration camp, County Cricket Ground, Northampton, which one is the most conceptually similar with Gliese 436 b?", "pred": " \nAnswer: WASP-43b. (Two exoplanets tend to", "completions_tokens": [{"text": " \n", "logprob": -3.814878463745117}, {"text": "Answer", "logprob": -0.6870922446250916}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " WAS", "logprob": -3.187631130218506}, {"text": "P", "logprob": -2.4318398573086597e-05}, {"text": "-", "logprob": -8.940656698541716e-06}, {"text": "43", "logprob": -2.4318398573086597e-05}, {"text": "b", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.2779695689678192}, {"text": " (", "logprob": -1.6800622940063477}, {"text": "Two", "logprob": -8.242074966430664}, {"text": " ex", "logprob": -0.6121874451637268}, {"text": "oplan", "logprob": -2.4318398573086597e-05}, {"text": "ets", "logprob": -0.029406337067484856}, {"text": " tend", "logprob": -8.681464195251465}, {"text": " to", "logprob": -2.4318398573086597e-05}], "answers": ["WASP-43b"], "all_classes": "null", "length": 102}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong University of Tennessee, Knoxville, HM Prison Holloway, 2013 AFL season, Philadelphia, Chevrolet big-block engine, Ludlow Castle, Kudankulam Nuclear Power Plant, 1983 World Championships in Athletics, Avalonia, Golden Horn, Makemake, Football Park, Gulf of Thailand, Congress of Monastir, Hampstead Heath, NGC 6946, Royal Porthcawl Golf Club, Virginia Tech, The Timekeeper, St Martin-in-the-Fields, malleolus, which one is the most conceptually similar with 1978 FIFA World Cup?", "pred": " \n\nAnswer: 1978 FIFA World Cup was held in Argentina, so the", "completions_tokens": [{"text": " \n\n", "logprob": -0.19482877850532532}, {"text": "Answer", "logprob": -0.9675698280334473}, {"text": ":", "logprob": -0.2257111668586731}, {"text": " ", "logprob": -0.6267397403717041}, {"text": "197", "logprob": -1.86818265914917}, {"text": "8", "logprob": -0.018692761659622192}, {"text": " FIFA", "logprob": -0.08844363689422607}, {"text": " World", "logprob": -8.940656698541716e-06}, {"text": " Cup", "logprob": -8.940656698541716e-06}, {"text": " was", "logprob": -2.395988702774048}, {"text": " held", "logprob": -0.9965579509735107}, {"text": " in", "logprob": -0.07341250777244568}, {"text": " Argentina", "logprob": -0.1350347399711609}, {"text": ",", "logprob": -1.2969813346862793}, {"text": " so", "logprob": -1.0575249195098877}, {"text": " the", "logprob": -1.4763338565826416}], "answers": ["2013 AFL season"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Dutch elm disease, nopal, Rawicz, ethylene, Hadim Ali Pasha, Rhinogydd, Zhang Chengye, Petavius, David, Battle of Gettysburg, Ourasphaira giraldae, Mersey Tunnels, Warped Tour, Holin superfamily IV, plantar Lisfranc ligament, Kensington, Damavand, Tokyo Skytree, Royal Botanic Gardens Victoria, Nepenthes edwardsiana, Nepenthes lowii, which one is the most conceptually similar with Phytophthora ramorum?", "pred": " \n\nThe final answer is Nepenthes edwardsiana. The Nepenthes", "completions_tokens": [{"text": " \n\n", "logprob": -0.06655233353376389}, {"text": "The", "logprob": -5.391740322113037}, {"text": " final", "logprob": -1.2698088884353638}, {"text": " answer", "logprob": -2.4318398573086597e-05}, {"text": " is", "logprob": -8.940656698541716e-06}, {"text": " Nep", "logprob": -0.8783045411109924}, {"text": "ent", "logprob": -2.4318398573086597e-05}, {"text": "hes", "logprob": -2.4318398573086597e-05}, {"text": " ed", "logprob": -0.5696805119514465}, {"text": "wards", "logprob": -2.4318398573086597e-05}, {"text": "iana", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -2.4318398573086597e-05}, {"text": " The", "logprob": -2.2908527851104736}, {"text": " Nep", "logprob": -5.013462066650391}, {"text": "ent", "logprob": -0.006367869209498167}, {"text": "hes", "logprob": -2.4318398573086597e-05}], "answers": ["Ourasphaira giraldae"], "all_classes": "null", "length": 76}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong strychnine, Karla Caves, Gin rummy, Pawan Gupta, Goyet Caves, Circular error probable, Main Southern railway line, Vancouver International Film Festival, Savoy wine, 2001 Nisqually earthquake, Rhymney River, Battle of Stalingrad, World Forestry Congress, Arctic National Wildlife Refuge, Fort Tejon, Great Northern War, Shackleton Glacier, Sun Yat-sen Memorial Hall, anterolateral ligament, Nabulsi cheese, Super Bowl 50, which one is the most conceptually similar with 2009 World Aquatics Championships?", "pred": " \n\nAnswer: World Forestry Congress, World Forestry Congress. satisfies a concept", "completions_tokens": [{"text": " \n\n", "logprob": -0.07379759103059769}, {"text": "Answer", "logprob": -0.5254566073417664}, {"text": ":", "logprob": -0.07561808079481125}, {"text": " World", "logprob": -1.3256361484527588}, {"text": " Fore", "logprob": -0.07137412577867508}, {"text": "stry", "logprob": -2.4318398573086597e-05}, {"text": " Congress", "logprob": -8.940656698541716e-06}, {"text": ",", "logprob": -2.205918788909912}, {"text": " World", "logprob": -1.2900108098983765}, {"text": " Fore", "logprob": -0.2446770817041397}, {"text": "stry", "logprob": -2.4318398573086597e-05}, {"text": " Congress", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.3640085756778717}, {"text": " satisfies", "logprob": -10.246342658996582}, {"text": " a", "logprob": -5.67276668548584}, {"text": " concept", "logprob": -2.4387712478637695}], "answers": ["Super Bowl 50"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Eurovision Song Contest 2004, fluoxetine, Phytophthora ramorum, PSMB8, Ludgate Circus, Palmar plate, UEFA Euro 2000, Midland Main Line, glochidium, Hotel del Coronado, Bucheron, Rock and Roll Hall of Fame, Quabbin Aqueduct, New York Film Festival, Korean War, Invasion of Poland, Telluride Film Festival, Marshalsea, dilator naris muscle, Siege of Vicksburg, Irish Rebellion of 1641, which one is the most conceptually similar with Newark Airport Interchange?", "pred": " \n\nANSWER: Midland Main Line.", "completions_tokens": [{"text": " \n\n", "logprob": -0.20823150873184204}, {"text": "ANS", "logprob": -2.2023749351501465}, {"text": "WER", "logprob": -8.940656698541716e-06}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " Mid", "logprob": -0.4379933774471283}, {"text": "land", "logprob": -2.4318398573086597e-05}, {"text": " Main", "logprob": -2.4318398573086597e-05}, {"text": " Line", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.011611025780439377}, {"text": "<|eot_id|>", "logprob": -1.0604650974273682}], "answers": ["Ludgate Circus"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Botryosphaeria stevensii, Diplodia mutila, Palms Casino Resort, Bahia Emerald, Brisbane Showgrounds, Nike Missile Site C47, County Cricket Ground, Chelmsford, Russian roulette, The Great Movie Ride, Gatchina Palace, Yugoslav Wars, Mount Everest, San Diego, Loch Lomond, stigmatomycosis, Royal Oak, Salton Sea, Bangladesh Liberation War, Mount Washington, Farakka Super Thermal Power Station, garlic salt, which one is the most conceptually similar with Liu Jishu?", "pred": " Liu Jishu is a Taiwanese table tennis player.\n\nA. Garum Named", "completions_tokens": [{"text": " Liu", "logprob": -1.6986217498779297}, {"text": " J", "logprob": -0.08892767876386642}, {"text": "ish", "logprob": -8.940656698541716e-06}, {"text": "u", "logprob": -8.940656698541716e-06}, {"text": " is", "logprob": -0.30860868096351624}, {"text": " a", "logprob": -0.24218226969242096}, {"text": " Taiwanese", "logprob": -3.982470989227295}, {"text": " table", "logprob": -5.127148151397705}, {"text": " tennis", "logprob": -8.940656698541716e-06}, {"text": " player", "logprob": -0.031189685687422752}, {"text": ".\n\n", "logprob": -1.0064631700515747}, {"text": "A", "logprob": -0.13222736120224}, {"text": ".", "logprob": -0.08070705085992813}, {"text": " Gar", "logprob": -4.847690105438232}, {"text": "um", "logprob": -2.1696159839630127}, {"text": " Named", "logprob": -13.378387451171875}], "answers": ["Gatchina Palace"], "all_classes": "null", "length": 88}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong anterolateral ligament, Tangsudo, Princeton, Busan International Film Festival, Armstrong Gun, Moliterno, 2011 Rugby World Cup, False Creek, 2000 Rugby League World Cup, Sumner Tunnel, Trans-Siberian railway, Rummy, Oakland, Banked turn, Produce 101, Electronic Entertainment Expo, Charter Oak, Johnston Atoll, Shoot boxing, STS-74, Oswald Poche, which one is the most conceptually similar with Pawan Gupta?", "pred": " \n\nStep 1: Identify the concepts related to Pawan Gupta.\nPawan", "completions_tokens": [{"text": " \n\n", "logprob": -0.2380777895450592}, {"text": "Step", "logprob": -0.1988753080368042}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " Identify", "logprob": -1.5594465732574463}, {"text": " the", "logprob": -0.16838493943214417}, {"text": " concepts", "logprob": -3.087362766265869}, {"text": " related", "logprob": -0.9180225133895874}, {"text": " to", "logprob": -2.4318398573086597e-05}, {"text": " P", "logprob": -0.5545427799224854}, {"text": "awan", "logprob": -2.4318398573086597e-05}, {"text": " Gupta", "logprob": -8.940656698541716e-06}, {"text": ".\n", "logprob": -0.7743146419525146}, {"text": "P", "logprob": -0.8056458234786987}, {"text": "awan", "logprob": -2.4318398573086597e-05}], "answers": ["Oswald Poche"], "all_classes": "null", "length": 79}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Vallnord, Hirudin, M6 motorway, Dancing on Ice, Landsberg Prison, Brain derived neurotrophic factor, Fulton Street Line, MT-RNR1, 5-HTTLPR, solar eclipse of March 20, 2015, Holin superfamily IV, anterolateral ligament, BM-21 Grad, Three Mile Island Nuclear Generating Station, epitrochleoanconeus muscle, Apollo 13, Rockefeller Center, Ferulic acid decarboxylase, Haumea, Draco, CR2032 battery, which one is the most conceptually similar with Elastin?", "pred": " \nAnswer:\n\nHolin superfamily IV.atsuendeonso[kijioco.gen", "completions_tokens": [{"text": " \n", "logprob": -3.5364725589752197}, {"text": "Answer", "logprob": -0.25595271587371826}, {"text": ":\n\n", "logprob": -1.7903891801834106}, {"text": "H", "logprob": -2.312995433807373}, {"text": "olin", "logprob": -0.9259547591209412}, {"text": " super", "logprob": -2.4318398573086597e-05}, {"text": "family", "logprob": -8.940656698541716e-06}, {"text": " IV", "logprob": -2.4199192921514623e-05}, {"text": ".", "logprob": -1.074320912361145}, {"text": "atsu", "logprob": -9.88167667388916}, {"text": "ende", "logprob": -7.713294982910156}, {"text": "onso", "logprob": -10.897439002990723}, {"text": "[k", "logprob": -11.379246711730957}, {"text": "iji", "logprob": -8.296524047851562}, {"text": "oco", "logprob": -9.557060241699219}, {"text": ".gen", "logprob": -10.832839965820312}], "answers": ["Brain derived neurotrophic factor"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Interleukin 1 beta, Cdc14, Mobile Bay, Apollo, Ultra Music Festival, Wye Valley, Aponeurosis of the Obliquus externus abdominis, Cotswolds, Pluto, Doubletime, XIST, Battle of Fredericksburg, Holin superfamily I, Rock Creek Park, United States Naval Academy, Egg hunt, daf-5, Southwestern Exposition and Livestock Show, police auction, Australia, superficial veins of the brain, which one is the most conceptually similar with C-reactive protein?", "pred": " \n\nStep 1: Identify the list of entities provided\nThe entities listed are", "completions_tokens": [{"text": " \n\n", "logprob": -0.090812087059021}, {"text": "Step", "logprob": -1.32425057888031}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " Identify", "logprob": -1.3360929489135742}, {"text": " the", "logprob": -0.06540589034557343}, {"text": " list", "logprob": -2.1526541709899902}, {"text": " of", "logprob": -0.03165789321064949}, {"text": " entities", "logprob": -0.5574266314506531}, {"text": " provided", "logprob": -0.6248167753219604}, {"text": "\n", "logprob": -1.395603060722351}, {"text": "The", "logprob": -0.1137637048959732}, {"text": " entities", "logprob": -0.48020410537719727}, {"text": " listed", "logprob": -0.4662783741950989}, {"text": " are", "logprob": -8.940656698541716e-06}], "answers": ["Interleukin 1 beta"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong American Revolutionary War, Kinzua Dam, 2017 Central Mexico earthquake, Kenorland, East Branch Fishing Creek, Coen Tunnel, East Gondwana, Woolworth Building, WonderCon, Battle of Britain, TCA Ground, myrrh, Topaz War Relocation Center, TRAPPIST-1h, St Kilda Junction, Almaz, Stockton and Darlington Railway, Bodie, Tihar Jail, Jawaharlal Nehru Stadium, Syrian Civil War, which one is the most conceptually similar with 2008 Republican National Convention?", "pred": " \n\nAnswer: 2017 Central Mexico earthquake, Almaz, Syrian Civil War", "completions_tokens": [{"text": " \n\n", "logprob": -0.20538803935050964}, {"text": "Answer", "logprob": -0.4300028085708618}, {"text": ":", "logprob": -0.10501395910978317}, {"text": " ", "logprob": -0.966347336769104}, {"text": "201", "logprob": -0.2775554656982422}, {"text": "7", "logprob": -0.15052878856658936}, {"text": " Central", "logprob": -2.4318398573086597e-05}, {"text": " Mexico", "logprob": -2.4318398573086597e-05}, {"text": " earthquake", "logprob": -2.4318398573086597e-05}, {"text": ",", "logprob": -0.6808208227157593}, {"text": " Al", "logprob": -3.1233532428741455}, {"text": "maz", "logprob": -8.940656698541716e-06}, {"text": ",", "logprob": -0.06936038285493851}, {"text": " Syrian", "logprob": -2.570254325866699}, {"text": " Civil", "logprob": -2.4318398573086597e-05}, {"text": " War", "logprob": -8.940656698541716e-06}], "answers": ["WonderCon"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong KNM ER 3733, sodium hydroxide, Tane Mahuta, Manuka Oval, Root rot, Taylor-Burton Diamond, Kazanjian Red Diamond, Prometheus, Tehran Conference, Antlia Dwarf, Peninj Mandible, Big Dig, acetylcholine, 1924 Democratic National Convention, Nassak Diamond, Haunted Mansion Holiday, Raffles Hotel, Goyet Caves, uterine venous plexus, ammonia, Chapultepec, which one is the most conceptually similar with frankincense?", "pred": " \n\nAnswer: Uterine venous plexus. Similar The most concept", "completions_tokens": [{"text": " \n\n", "logprob": -0.20647449791431427}, {"text": "Answer", "logprob": -0.2188466191291809}, {"text": ":", "logprob": -0.11645559221506119}, {"text": " U", "logprob": -3.589989185333252}, {"text": "ter", "logprob": -0.012394898571074009}, {"text": "ine", "logprob": -8.940656698541716e-06}, {"text": " ven", "logprob": -0.032246626913547516}, {"text": "ous", "logprob": -2.4199192921514623e-05}, {"text": " p", "logprob": -2.4318398573086597e-05}, {"text": "lex", "logprob": -8.940656698541716e-06}, {"text": "us", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -6.044011116027832}, {"text": " Similar", "logprob": -2.2925338745117188}, {"text": " The", "logprob": -11.736987113952637}, {"text": " most", "logprob": -3.007716417312622}, {"text": " concept", "logprob": -0.13791413605213165}], "answers": ["acetylcholine"], "all_classes": "null", "length": 77}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Ultraviolet, alanine aminotransferase, Kepler-62e, Cl-transporting ATPase, Palmar plate, Ostankino Tower, Jones Falls, Ponticulus, Plesetsk Cosmodrome Site 32, Bristol Motor Speedway, Clochette, Cross City Tunnel, Egg hunt, Doublesex, TOG superfamily, Parthenium argentatum, Tay Rail Bridge, Devonian, Xq28, MetroWest Water Supply Tunnel, Brain derived neurotrophic factor, which one is the most conceptually similar with glucagon?", "pred": " \n\nAnswer: TOG superfamily. (With synonyms; protein kinase A,", "completions_tokens": [{"text": " \n\n", "logprob": -0.13241732120513916}, {"text": "Answer", "logprob": -0.05067083239555359}, {"text": ":", "logprob": -0.0680534616112709}, {"text": " TO", "logprob": -3.138381242752075}, {"text": "G", "logprob": -2.4318398573086597e-05}, {"text": " super", "logprob": -2.4318398573086597e-05}, {"text": "family", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.12056717276573181}, {"text": " (", "logprob": -1.4110684394836426}, {"text": "With", "logprob": -6.434693336486816}, {"text": " synonyms", "logprob": -7.8473591804504395}, {"text": ";", "logprob": -6.023869037628174}, {"text": " protein", "logprob": -3.9781837463378906}, {"text": " kinase", "logprob": -2.8468399047851562}, {"text": " A", "logprob": -1.42328679561615}, {"text": ",", "logprob": -2.4225025177001953}], "answers": ["Brain derived neurotrophic factor"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Conococheague Creek, OTO Melara 76 mm, Caudal artery, Korean War, 2009 World Aquatics Championships, Joint Direct Attack Munition, 2017 Central Mexico earthquake, Arctic National Wildlife Refuge, Bristol Motor Speedway, Socorro Island, solar eclipse of May 29, 1919, Montreal International Jazz Festival, Croatia, Fifth Avenue, Palm Springs International Film Festival, Coca-Cola Life, Moscow International Film Festival, compressed tea, solar eclipse of August 1, 2008, Eurovision Song Contest 2005, 1950 United Kingdom general election, which one is the most conceptually similar with Mexico?", "pred": " \n\nAnswer: Solar eclipse of August 1, 2008 (Similarity", "completions_tokens": [{"text": " \n\n", "logprob": -0.21607036888599396}, {"text": "Answer", "logprob": -0.2461385875940323}, {"text": ":", "logprob": -0.05762311443686485}, {"text": " Solar", "logprob": -3.3824048042297363}, {"text": " eclipse", "logprob": -0.24198098480701447}, {"text": " of", "logprob": -8.940656698541716e-06}, {"text": " August", "logprob": -0.5128248929977417}, {"text": " ", "logprob": -2.4318398573086597e-05}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ",", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -2.4318398573086597e-05}, {"text": "200", "logprob": -2.4318398573086597e-05}, {"text": "8", "logprob": -8.940656698541716e-06}, {"text": " (", "logprob": -1.8684146404266357}, {"text": "Similar", "logprob": -3.821993827819824}, {"text": "ity", "logprob": -0.3050016462802887}], "answers": ["Croatia"], "all_classes": "null", "length": 107}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Drax power station, Lake Van, Quebec Conference, King Arthur Carrousel, tooth loss, Els Quatre Gats, Warragamba Dam, RuneQuest, Suntec City, Wine auction, Pawan Gupta, Verrazzano-Narrows Bridge, 25143 Itokawa, Las Vegas Valley, Marble Arch, Alhambra, Oltermanni, police auction, Park Avenue, Cluedo, Banked turn, which one is the most conceptually similar with team pursuit?", "pred": " \n\nAnswer: Team pursuit. Similarity is not available in the selection. Team", "completions_tokens": [{"text": " \n\n", "logprob": -0.31754109263420105}, {"text": "Answer", "logprob": -0.41794905066490173}, {"text": ":", "logprob": -0.18524400889873505}, {"text": " Team", "logprob": -1.9955233335494995}, {"text": " pursuit", "logprob": -0.19608129560947418}, {"text": ".", "logprob": -1.2615875005722046}, {"text": " Similar", "logprob": -2.3372926712036133}, {"text": "ity", "logprob": -0.4522475600242615}, {"text": " is", "logprob": -2.231630563735962}, {"text": " not", "logprob": -1.1302341222763062}, {"text": " available", "logprob": -4.776791095733643}, {"text": " in", "logprob": -2.2408714294433594}, {"text": " the", "logprob": -1.1464343070983887}, {"text": " selection", "logprob": -5.000664710998535}, {"text": ".", "logprob": -0.31806421279907227}, {"text": " Team", "logprob": -1.3236979246139526}], "answers": ["Banked turn"], "all_classes": "null", "length": 77}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong NBA Draft Lottery, Congressional Cemetery, Formula 5000, East Delaware Tunnel, MT-TW, Kanchenjunga, aluminum oxide, The Proms, 1976 Tangshan earthquake, Produce 101, Midtown Manhattan, Laramidia, table football, Trans-Canada Highway, police auction, Fort Sill, Warwick Castle, Agnes Edwards (craftworker), Hercules, Bay of Plenty, Doncaster Racecourse, which one is the most conceptually similar with Florida Championship Wrestling?", "pred": " \n\nANSWER: Police auction. Similar in that the term refers to conceptually", "completions_tokens": [{"text": " \n\n", "logprob": -0.43455782532691956}, {"text": "ANS", "logprob": -0.971176266670227}, {"text": "WER", "logprob": -8.940656698541716e-06}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " Police", "logprob": -1.919566035270691}, {"text": " auction", "logprob": -0.20898762345314026}, {"text": ".", "logprob": -0.3314094543457031}, {"text": " Similar", "logprob": -2.8050942420959473}, {"text": " in", "logprob": -3.8017332553863525}, {"text": " that", "logprob": -1.4131591320037842}, {"text": " the", "logprob": -3.15938138961792}, {"text": " term", "logprob": -3.0534138679504395}, {"text": " refers", "logprob": -2.666386604309082}, {"text": " to", "logprob": -0.09621069580316544}, {"text": " concept", "logprob": -7.065481185913086}, {"text": "ually", "logprob": -1.0184749364852905}], "answers": ["Formula 5000"], "all_classes": "null", "length": 81}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong meningohypophyseal artery, Holin superfamily I, Staff College, Camberley, Russian River Valley AVA, Oxbridge, Pine Barrens, Normandy landings, XIST, South China Sea, Eagle Diamond, Nepenthes murudensis, MT-RNR1, 1989 Loma Prieta earthquake, Osterley Park, Keno, Saldanha man, kho kho, 1992 United Kingdom general election, CR2032 battery, PTS-GFL superfamily, Downtown Seattle Transit Tunnel, which one is the most conceptually similar with Dubrovnik?", "pred": " Dubrovnik\t\n\nAnswer: Nobel Prize Nominations for Alexander Bernard. Cam", "completions_tokens": [{"text": " Dub", "logprob": -3.1275601387023926}, {"text": "rov", "logprob": -8.940656698541716e-06}, {"text": "nik", "logprob": -2.4318398573086597e-05}, {"text": "\t\n\n", "logprob": -10.461227416992188}, {"text": "Answer", "logprob": -1.0494983196258545}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " Nobel", "logprob": -12.38218879699707}, {"text": " Prize", "logprob": -1.1092227697372437}, {"text": " N", "logprob": -8.600958824157715}, {"text": "omin", "logprob": -0.11063252389431}, {"text": "ations", "logprob": -0.20484018325805664}, {"text": " for", "logprob": -2.808067798614502}, {"text": " Alexander", "logprob": -5.806894302368164}, {"text": " Bernard", "logprob": -8.625225067138672}, {"text": ".", "logprob": -4.918976306915283}, {"text": " Cam", "logprob": -5.306027412414551}], "answers": ["Staff College, Camberley"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Produce 101, Show hunter, Paleogene, Cluedo, 6 Hebe, Procyon, SM Mall of Asia, Tattletales, spiral artery, M. A. Chidambaram Stadium, Minidoka National Historic Site, Wine auction, Oxford University Parks, Siracourt V-1 bunker, Nagarjuna Sagar Dam, Martinsville Speedway, 1954 FIFA World Cup, Risk, Voskhod 2, Caribbean Sea, Durham Cathedral, which one is the most conceptually similar with Pawan Gupta?", "pred": " \n\nAnswer: Show hunter. (Although also known as extreme weather conditions or weather", "completions_tokens": [{"text": " \n\n", "logprob": -0.36066383123397827}, {"text": "Answer", "logprob": -0.4070659279823303}, {"text": ":", "logprob": -0.09464403241872787}, {"text": " Show", "logprob": -2.1832120418548584}, {"text": " hunter", "logprob": -0.006878979969769716}, {"text": ".", "logprob": -0.45500344038009644}, {"text": " (", "logprob": -2.246006488800049}, {"text": "Although", "logprob": -4.842454433441162}, {"text": " also", "logprob": -7.683903694152832}, {"text": " known", "logprob": -1.5036009550094604}, {"text": " as", "logprob": -0.16402195394039154}, {"text": " extreme", "logprob": -10.571438789367676}, {"text": " weather", "logprob": -4.6635212898254395}, {"text": " conditions", "logprob": -3.304292917251587}, {"text": " or", "logprob": -1.991743564605713}, {"text": " weather", "logprob": -2.5089006423950195}], "answers": ["Wine auction"], "all_classes": "null", "length": 83}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong American Golden Topaz, propane, naloxone, Reggianito, Caciotta, valproic acid, Lake Maracaibo, 1976 Tangshan earthquake, Woodhead Tunnel, Tiffany Yellow Diamond, nopal, Humber Bridge, Port Jackson, Bonnaroo Music Festival, codeine, Scott Glacier, KNM ER 1813, Prometheus, Mogao Caves, Pret a Manger, Kedleston Hall, which one is the most conceptually similar with ethylene?", "pred": "  American Golden Topaz\nAnswer: similarity : none of the above. (", "completions_tokens": [{"text": " ", "logprob": -4.088318347930908}, {"text": " American", "logprob": -2.358449697494507}, {"text": " Golden", "logprob": -8.940656698541716e-06}, {"text": " Top", "logprob": -8.940656698541716e-06}, {"text": "az", "logprob": -8.940656698541716e-06}, {"text": "\n", "logprob": -1.708377718925476}, {"text": "Answer", "logprob": -0.5861501693725586}, {"text": ":", "logprob": -0.008530842140316963}, {"text": " similarity", "logprob": -4.668418884277344}, {"text": " :", "logprob": -3.878063917160034}, {"text": " none", "logprob": -3.273463249206543}, {"text": " of", "logprob": -1.3269944190979004}, {"text": " the", "logprob": -0.3725182116031647}, {"text": " above", "logprob": -0.3051621615886688}, {"text": ".", "logprob": -1.5027358531951904}, {"text": " (", "logprob": -2.5819802284240723}], "answers": ["propane"], "all_classes": "null", "length": 74}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Brahma, naloxone, ADC Cirrus, Karawanks Tunnel, Hadim Suleiman Pasha, Alexander III Commemorative, hydrogen peroxide, Paul the Octopus, Monterey Bay, nitric acid, crisantaspase, Lewis gun, Gulf of California, renin, Eclipse of Thales, Settle to Carlisle Line, Sonoma Coast AVA, Wintergreen, Tesla Powerwall, Crystal the Monkey, Ourasphaira giraldae, which one is the most conceptually similar with Nepenthes murudensis?", "pred": " \n\nStep 1: \nThe question requires finding the most conceptually similar entity", "completions_tokens": [{"text": " \n\n", "logprob": -0.14395467936992645}, {"text": "Step", "logprob": -0.6890679001808167}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " \n", "logprob": -3.3923463821411133}, {"text": "The", "logprob": -2.382253885269165}, {"text": " question", "logprob": -0.5087891817092896}, {"text": " requires", "logprob": -2.139376401901245}, {"text": " finding", "logprob": -2.2660717964172363}, {"text": " the", "logprob": -0.07365728169679642}, {"text": " most", "logprob": -0.472934365272522}, {"text": " concept", "logprob": -0.03937323018908501}, {"text": "ually", "logprob": -8.940656698541716e-06}, {"text": " similar", "logprob": -8.940656698541716e-06}, {"text": " entity", "logprob": -0.051024895161390305}], "answers": ["Wintergreen"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Monitor-Merrimac Memorial Bridge-Tunnel, STS-51-B, Sampson artery, Ford Modular engine, Hadassah Medical Center, mucin, Peninj Mandible, 2019 Rugby World Cup, Vredefort crater, solar eclipse of March 29, 2006, BMW 801, Pinconning cheese, perforator vein, War on Terror, STS-121, Deneb, Beau Sancy, Mauer 1, TRAPPIST-1f, Swatara Creek, trabecular veins, which one is the most conceptually similar with Hole-in-the-Ground?", "pred": " \n\nThe final answer is Deneb..\n\n\nGive answer to the following question", "completions_tokens": [{"text": " \n\n", "logprob": -0.5193753838539124}, {"text": "The", "logprob": -3.497850179672241}, {"text": " final", "logprob": -0.8847407102584839}, {"text": " answer", "logprob": -2.4318398573086597e-05}, {"text": " is", "logprob": -8.940656698541716e-06}, {"text": " D", "logprob": -1.8854503631591797}, {"text": "ene", "logprob": -2.4199192921514623e-05}, {"text": "b", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -2.4318398573086597e-05}, {"text": ".\n\n\n", "logprob": -10.756295204162598}, {"text": "Give", "logprob": -4.752941608428955}, {"text": " answer", "logprob": -1.957490086555481}, {"text": " to", "logprob": -2.4318398573086597e-05}, {"text": " the", "logprob": -0.02935459278523922}, {"text": " following", "logprob": -0.1290656477212906}, {"text": " question", "logprob": -0.006863588932901621}], "answers": ["Vredefort crater"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Lake Lucerne, Warwick Castle, English Dresden, Soyuz 5, Radicular artery, Julier Pass, Forest of Bowland, Siege of Yorktown, High Five Interchange, Sydney Film Festival, Mount Erebus, Super Bowl XXXV, 12.7 cm/40 Type 89 naval gun, Shasta Dam, French Revolutionary Wars, Horizons, Clyde Tunnel, Interleukin 2, Church of the Holy Sepulchre, General Theological Seminary, Battle of Waterloo, which one is the most conceptually similar with STS-41-B?", "pred": " STS-41-B is the sixth space shuttle program mission, where the first", "completions_tokens": [{"text": " ST", "logprob": -3.553956985473633}, {"text": "S", "logprob": -8.940656698541716e-06}, {"text": "-", "logprob": -2.4318398573086597e-05}, {"text": "41", "logprob": -0.004967846442013979}, {"text": "-B", "logprob": -0.006598825100809336}, {"text": " is", "logprob": -0.7058531045913696}, {"text": " the", "logprob": -2.0910465717315674}, {"text": " sixth", "logprob": -2.671502113342285}, {"text": " space", "logprob": -2.6691195964813232}, {"text": " shuttle", "logprob": -0.021943744271993637}, {"text": " program", "logprob": -4.527590274810791}, {"text": " mission", "logprob": -0.3549264967441559}, {"text": ",", "logprob": -1.6788885593414307}, {"text": " where", "logprob": -4.965438365936279}, {"text": " the", "logprob": -0.7967855930328369}, {"text": " first", "logprob": -1.9000670909881592}], "answers": ["Soyuz 5"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Miocene, Corviglia, Perrier, Oltermanni, Pom1, Bodo cranium, Eridge Park, dilator naris muscle, Mrs. Ples, Trp operon, Filchner-Ronne Ice Shelf, Diet Pepsi, anterolateral ligament, Reflex inguinal ligament, Tycho, Fusarium wilt, Friuli-Venezia Giulia wine, Monster Energy, Coca-Cola Life, 1990 FIFA World Cup, throwball, which one is the most conceptually similar with Clochette?", "pred": " \n\nAnswer: Magnum Brewery. N (Brewer ) is given mainly of", "completions_tokens": [{"text": " \n\n", "logprob": -0.3184525966644287}, {"text": "Answer", "logprob": -0.5221512913703918}, {"text": ":", "logprob": -0.05590132251381874}, {"text": " Magnum", "logprob": -10.367485046386719}, {"text": " Brewery", "logprob": -8.163418769836426}, {"text": ".", "logprob": -5.591433525085449}, {"text": " N", "logprob": -7.192233085632324}, {"text": " (", "logprob": -6.347621440887451}, {"text": "B", "logprob": -5.436513423919678}, {"text": "rew", "logprob": -1.796480655670166}, {"text": "er", "logprob": -1.9441008567810059}, {"text": " )", "logprob": -4.845020771026611}, {"text": " is", "logprob": -2.901261568069458}, {"text": " given", "logprob": -6.541015625}, {"text": " mainly", "logprob": -8.598382949829102}, {"text": " of", "logprob": -6.032745361328125}], "answers": ["Oltermanni"], "all_classes": "null", "length": 74}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong epitrochleoanconeus muscle, Palmar plate, Late Antiquity, Brain derived neurotrophic factor, congress of Berlin, 2010 FIFA World Cup, Battle of Britain, Leopard complex, English Channel, Spanish colonization of the Americas, Jurassic, Sam Yan, Star Tours, Bay of Biscay, Mar-a-Lago, Battle of Crete, police auction, International Film Festival of India, Little Boy, Oswald Poche, Poston War Relocation Center, which one is the most conceptually similar with Weddell Sea?", "pred": " \n\nBest Answer: Jurassic\nThe Weddell Sea is a Southern Ocean sea", "completions_tokens": [{"text": " \n\n", "logprob": -0.1900307685136795}, {"text": "Best", "logprob": -6.245352745056152}, {"text": " Answer", "logprob": -0.08184147626161575}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " Jurassic", "logprob": -1.862868309020996}, {"text": "\n", "logprob": -0.2491384595632553}, {"text": "The", "logprob": -0.10397139191627502}, {"text": " Wed", "logprob": -2.5139670372009277}, {"text": "d", "logprob": -2.4318398573086597e-05}, {"text": "ell", "logprob": -8.940656698541716e-06}, {"text": " Sea", "logprob": -2.4318398573086597e-05}, {"text": " is", "logprob": -0.10805202275514603}, {"text": " a", "logprob": -0.46394649147987366}, {"text": " Southern", "logprob": -3.248879909515381}, {"text": " Ocean", "logprob": -0.010453234426677227}, {"text": " sea", "logprob": -0.15943801403045654}], "answers": ["English Channel"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong NGC 379, Nepenthes glabrata, Chota Nagpur Plateau, Smithsonian American Art Museum, Mount Vernon, Parthenium argentatum, solar eclipse of July 10, 1972, Meiji period, Georgian Bay, Powerade, Pont Neuf, Brisbane Powerhouse, gallium arsenide, RSL-3, Chelyabinsk meteor, Scapa Flow, Theia, Hotel del Coronado, Lake Superior, lateral rotator group, rs6314, which one is the most conceptually similar with Silurian?", "pred": " \nAnswer: Chota Nagpur Plateau. (Geologically) Meiji", "completions_tokens": [{"text": " \n", "logprob": -1.0931053161621094}, {"text": "Answer", "logprob": -0.1296396553516388}, {"text": ":", "logprob": -0.40760016441345215}, {"text": " Ch", "logprob": -3.0577220916748047}, {"text": "ota", "logprob": -0.8356631994247437}, {"text": " Nag", "logprob": -8.940656698541716e-06}, {"text": "pur", "logprob": -2.4318398573086597e-05}, {"text": " Plate", "logprob": -2.4318398573086597e-05}, {"text": "au", "logprob": -2.4199192921514623e-05}, {"text": ".", "logprob": -0.33449864387512207}, {"text": " (", "logprob": -1.4400750398635864}, {"text": "Ge", "logprob": -5.123762130737305}, {"text": "ologically", "logprob": -1.182502031326294}, {"text": ")", "logprob": -3.1674394607543945}, {"text": " Me", "logprob": -2.489368438720703}, {"text": "iji", "logprob": -8.940656698541716e-06}], "answers": ["Meiji period"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1998 FIFA World Cup, Spring Grove Cemetery, Ford Island, Epidermal growth factor, Diplodia mutila, King Kong Encounter, Phytophthora ramorum, Borneo, Caldecott Tunnel, The Indian Bean Tree, St James Square, Monmouth, Bucheron, Royal Oak, ophthalmic veins, djon djon, Tanna Tunnel, Alexander Valley AVA, Christian the lion, Teatro Real, 5145 Pholus, Times Square, Michigan Central Railway Tunnel, which one is the most conceptually similar with Liu Jishu?", "pred": " \nAnswer: Liu Jishu. Liu Jishu was an ancient Chinese", "completions_tokens": [{"text": " \n", "logprob": -2.305968761444092}, {"text": "Answer", "logprob": -0.05237121880054474}, {"text": ":", "logprob": -0.05590132251381874}, {"text": " Liu", "logprob": -0.45971590280532837}, {"text": " J", "logprob": -8.940656698541716e-06}, {"text": "ish", "logprob": -2.4318398573086597e-05}, {"text": "u", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.540120005607605}, {"text": " Liu", "logprob": -0.6106525659561157}, {"text": " J", "logprob": -0.01492841262370348}, {"text": "ish", "logprob": -2.4318398573086597e-05}, {"text": "u", "logprob": -8.940656698541716e-06}, {"text": " was", "logprob": -0.8981921672821045}, {"text": " an", "logprob": -2.9372341632843018}, {"text": " ancient", "logprob": -1.728529453277588}, {"text": " Chinese", "logprob": -0.07192341238260269}], "answers": ["Christian the lion"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1990 Luzon earthquake, Centre Georges Pompidou, Solar eclipse of July 31, 1981, ELA-4, Bayreuth Festival, Karla Caves, Cullinan Diamond, Gulf of Tonkin, Salzburg Festival, Tian Lingzi, superficial dorsal vein of the penis, Nepenthes kerrii, Cunninghams Gap, Sun Yat-sen Memorial Hall, Phytophthora ramorum, River Teme, Super Bowl XLIV, Diplodia mutila, Kveik, stigmatomycosis, Bay of Bengal, which one is the most conceptually similar with Bart the Bear 2?", "pred": " \n\nAnswer: Bay of Bengal. Bart the Bear 2, a Sloth", "completions_tokens": [{"text": " \n\n", "logprob": -0.21490150690078735}, {"text": "Answer", "logprob": -0.24770040810108185}, {"text": ":", "logprob": -0.051812779158353806}, {"text": " Bay", "logprob": -0.7577214241027832}, {"text": " of", "logprob": -0.16757752001285553}, {"text": " Bengal", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.9587438106536865}, {"text": " Bart", "logprob": -3.279837131500244}, {"text": " the", "logprob": -0.06262219697237015}, {"text": " Bear", "logprob": -0.07324091345071793}, {"text": " ", "logprob": -0.08643372356891632}, {"text": "2", "logprob": -2.4318398573086597e-05}, {"text": ",", "logprob": -3.2719337940216064}, {"text": " a", "logprob": -0.8635852336883545}, {"text": " Slo", "logprob": -6.903739929199219}, {"text": "th", "logprob": -0.016108838841319084}], "answers": ["Tian Lingzi"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 20 July plot, Radicular artery, Savoy wine, Super Bowl XXXIV, nandrolone, Washington National Cathedral, Kanchenjunga, Pepsi Max, (S)-corytuberine synthase, 1987 World Championships in Athletics, Star Wars Launch Bay, Battle of France, Diplodia mutila, Eridge Park, Outer Coastal Plain AVA, wagasi, stigmatomycosis, Antigua, Palmar plate, MT-TW, Christian the lion, which one is the most conceptually similar with Honshu?", "pred": " \n\nAnswer: Kanchenjunga. ( mountain) The answer was about", "completions_tokens": [{"text": " \n\n", "logprob": -0.244387686252594}, {"text": "Answer", "logprob": -0.14950644969940186}, {"text": ":", "logprob": -0.03226151689887047}, {"text": " K", "logprob": -1.7459121942520142}, {"text": "anch", "logprob": -2.4318398573086597e-05}, {"text": "en", "logprob": -8.940656698541716e-06}, {"text": "j", "logprob": -8.940656698541716e-06}, {"text": "unga", "logprob": -2.4199192921514623e-05}, {"text": ".", "logprob": -0.3980700671672821}, {"text": " (", "logprob": -1.170509696006775}, {"text": " mountain", "logprob": -5.873976230621338}, {"text": ")", "logprob": -1.105718970298767}, {"text": " The", "logprob": -4.462525844573975}, {"text": " answer", "logprob": -3.6549906730651855}, {"text": " was", "logprob": -4.553317070007324}, {"text": " about", "logprob": -4.415983200073242}], "answers": ["Antigua"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Kilmainham Gaol, Dubrovnik, Tango, Pinconning cheese, Mechanistic target of rapamycin kinase, anterolateral ligament, Marble Arch, Reggianito, Bucheron, mucin, Kasat Suek Intersection, KNM WT 17000, Donner Pass, 5145 Pholus, wagasi, Caciotta, Red Sea, Ferrar Glacier, 2011 Rugby World Cup, Baltoro Glacier, corticotropin, which one is the most conceptually similar with Leffe?", "pred": " \n\nAnswer: Kasat Suek Intersection. When Kekul discovered Benz", "completions_tokens": [{"text": " \n\n", "logprob": -0.19727186858654022}, {"text": "Answer", "logprob": -0.1645708829164505}, {"text": ":", "logprob": -0.04587022587656975}, {"text": " Kas", "logprob": -6.881147861480713}, {"text": "at", "logprob": -2.4199192921514623e-05}, {"text": " Sue", "logprob": -2.4318398573086597e-05}, {"text": "k", "logprob": -2.4318398573086597e-05}, {"text": " Intersection", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.3654305338859558}, {"text": " When", "logprob": -7.7245259284973145}, {"text": " K", "logprob": -7.963509559631348}, {"text": "ek", "logprob": -6.099595069885254}, {"text": "ul", "logprob": -0.58302903175354}, {"text": "", "logprob": -0.014705010689795017}, {"text": " discovered", "logprob": -2.9250569343566895}, {"text": " Benz", "logprob": -2.1077003479003906}], "answers": ["Tango"], "all_classes": "null", "length": 74}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Super Bowl LI, Ford FE engine, chase gun, Mount of Olives, Stalag Luft III, djon djon, keel, Ecarin, 1924 Democratic National Convention, Formula 5000, Brenner Base Tunnel, Damavand, Hotchkiss gun, Early Cretaceous, Wine auction, 1962 FIFA World Cup, Before Present, TCA Ground, San Bernardino Tunnel, Irn-Bru, National Christmas Tree, which one is the most conceptually similar with Carrara Stadium?", "pred": " \nCar Tuning Campagna????????????? Bmw True False Answer: B", "completions_tokens": [{"text": " \n", "logprob": -2.451906204223633}, {"text": "Car", "logprob": -4.044482231140137}, {"text": " Tun", "logprob": -13.095114707946777}, {"text": "ing", "logprob": -0.04313955828547478}, {"text": " Camp", "logprob": -7.472311496734619}, {"text": "agna", "logprob": -3.9459681510925293}, {"text": "????????", "logprob": -11.28591251373291}, {"text": "????", "logprob": -0.7051401734352112}, {"text": "?", "logprob": -1.5322445631027222}, {"text": " B", "logprob": -8.356310844421387}, {"text": "mw", "logprob": -3.1844289302825928}, {"text": " True", "logprob": -9.388970375061035}, {"text": " False", "logprob": -2.3979291915893555}, {"text": " Answer", "logprob": -2.9787886142730713}, {"text": ":", "logprob": -0.43369340896606445}, {"text": " B", "logprob": -2.761333703994751}], "answers": ["TCA Ground"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong (15788) 1993 SB, 10.5 cm SK C/32 naval gun, 8.8 cm SK L/45 naval gun, Adirondack Park, carbon disulfide, Arlington National Cemetery, UEFA Euro 2004, Blenheim Park, RPG-7, Afon Irfon, Festning Tunnel, Winter War, Tesla Powerwall, Lewis gun, Syzygium guineense, Preseli Hills, Utopia Planitia, Risiera di San Sabba, Unteraar Glacier, histamine, Udayagiri and Khandagiri Caves, which one is the most conceptually similar with CR2032 battery?", "pred": " \n\nA None of the option\n\nB 10.5 cm SK C/", "completions_tokens": [{"text": " \n\n", "logprob": -0.1039927750825882}, {"text": "A", "logprob": -2.657630681991577}, {"text": " None", "logprob": -6.585315227508545}, {"text": " of", "logprob": -0.3343814015388489}, {"text": " the", "logprob": -0.34812185168266296}, {"text": " option", "logprob": -7.534323692321777}, {"text": "\n\n", "logprob": -2.755699634552002}, {"text": "B", "logprob": -0.01027591060847044}, {"text": " ", "logprob": -2.097111701965332}, {"text": "10", "logprob": -0.9207707643508911}, {"text": ".", "logprob": -8.940656698541716e-06}, {"text": "5", "logprob": -2.4318398573086597e-05}, {"text": " cm", "logprob": -2.4437606043647975e-05}, {"text": " SK", "logprob": -8.940656698541716e-06}, {"text": " C", "logprob": -2.4318398573086597e-05}, {"text": "/", "logprob": -8.940656698541716e-06}], "answers": ["Tesla Powerwall"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Inca Kola, interclavicle, Russian Tea Room, Pula Film Festival, CR2032 battery, Staten Island Railway, calcium oxide, Xynotyro, Reflex inguinal ligament, San Diego, epitrochleoanconeus muscle, Nissan E engine, tooth loss, Fort Laramie National Historic Site, Rover V8 engine, National Soccer Hall of Fame, Four Mile Run, Heian period, fentanyl, plantar Lisfranc ligament, Cross City Tunnel, which one is the most conceptually similar with Vasai Creek?", "pred": "  [[]]\n\n**Step 1: Identify the keywords that can be related to", "completions_tokens": [{"text": " ", "logprob": -5.787064075469971}, {"text": " [[]", "logprob": -11.00283432006836}, {"text": "]\n\n", "logprob": -0.7827042937278748}, {"text": "**", "logprob": -7.192293643951416}, {"text": "Step", "logprob": -0.9802647829055786}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -8.940656698541716e-06}, {"text": ":", "logprob": -0.09972386807203293}, {"text": " Identify", "logprob": -1.635888695716858}, {"text": " the", "logprob": -0.16373983025550842}, {"text": " keywords", "logprob": -5.005711555480957}, {"text": " that", "logprob": -3.5011754035949707}, {"text": " can", "logprob": -2.8100032806396484}, {"text": " be", "logprob": -0.39522626996040344}, {"text": " related", "logprob": -1.4739941358566284}, {"text": " to", "logprob": -2.4318398573086597e-05}], "answers": ["Four Mile Run"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Caciotta, anterolateral ligament, Oltermanni, Algonquin Provincial Park, American Astronomical Society 215th meeting, Cloth Hall, Ypres, Blackfriars Bridge, Oswald Poche, Tokaj wine region, Moliterno, Fortress of Louisbourg, Jura wine, Egg hunt, The Pierre, Palmar plate, Centre Georges Pompidou, Burgess Shale, Finding Nemo Submarine Voyage, Criollo cheese, Reggianito, Holy See, which one is the most conceptually similar with Coca-Cola Life?", "pred": " Since we cannot find a direct reference to link Coca-Cola Life, most of the", "completions_tokens": [{"text": " Since", "logprob": -5.684383392333984}, {"text": " we", "logprob": -3.950857639312744}, {"text": " cannot", "logprob": -3.545201539993286}, {"text": " find", "logprob": -2.186854839324951}, {"text": " a", "logprob": -1.468762755393982}, {"text": " direct", "logprob": -1.975001573562622}, {"text": " reference", "logprob": -4.145830154418945}, {"text": " to", "logprob": -0.42366334795951843}, {"text": " link", "logprob": -7.451539039611816}, {"text": " Coca", "logprob": -1.1320167779922485}, {"text": "-Cola", "logprob": -2.4318398573086597e-05}, {"text": " Life", "logprob": -0.023228324949741364}, {"text": ",", "logprob": -1.2871618270874023}, {"text": " most", "logprob": -5.611454486846924}, {"text": " of", "logprob": -1.3591362237930298}, {"text": " the", "logprob": -1.0102810859680176}], "answers": ["Jura wine"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong solar eclipse of May 28, 1900, Mrp superfamily, FERONIA, Semlin concentration camp, Ruhleben internment camp, Honshu, Xq28, Diplodia mutila, Prekallikrein, Spitsbergen, Wawona Tunnel, Pawan Gupta, nerve growth factor, Gunnison Tunnel, parathyroid artery, Lysine exporter, Sphenomandibularis, sulfuric acid, solar eclipse of March 20, 2015, fluoxetine, Raghunathpur Thermal Power Station, which one is the most conceptually similar with Myoglobin?", "pred": " \n\nAnswer: Mrp superfamily. NmrSolutionclient\tfirst================================================. (", "completions_tokens": [{"text": " \n\n", "logprob": -0.18480928242206573}, {"text": "Answer", "logprob": -0.13200289011001587}, {"text": ":", "logprob": -0.07337772846221924}, {"text": " Mr", "logprob": -2.763850688934326}, {"text": "p", "logprob": -2.4318398573086597e-05}, {"text": " super", "logprob": -2.4318398573086597e-05}, {"text": "family", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.2529585361480713}, {"text": " N", "logprob": -4.5290727615356445}, {"text": "mr", "logprob": -2.0939154624938965}, {"text": "Solution", "logprob": -7.265726089477539}, {"text": "client", "logprob": -13.157618522644043}, {"text": "\tfirst", "logprob": -14.094865798950195}, {"text": "================================================", "logprob": -12.371638298034668}, {"text": ".", "logprob": -4.574288368225098}, {"text": " (", "logprob": -4.425045967102051}], "answers": ["nerve growth factor"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Surfeit, Centaurus A, War on Terror, Resorts World Sentosa, guarana, 2015 United Kingdom general election, Common Era, Ure2, Criollo cheese, crisantaspase, East Delaware Tunnel, Battle of Crete, Thailand, Plasma membrane Ca2+ ATPase, Dumbo the Flying Elephant, Ruhleben internment camp, Missouri Botanical Garden, Elizabethan era, Ain Dubai, daf-7, Interleukin 2, which one is the most conceptually similar with Sex determining region Y?", "pred": " \nA.  Interleukin 2\nB.  Daf", "completions_tokens": [{"text": " \n", "logprob": -2.7505338191986084}, {"text": "A", "logprob": -2.436542510986328}, {"text": ".", "logprob": -1.1366283893585205}, {"text": " ", "logprob": -3.411357879638672}, {"text": " Inter", "logprob": -1.8044617176055908}, {"text": "le", "logprob": -2.4318398573086597e-05}, {"text": "uk", "logprob": -8.940656698541716e-06}, {"text": "in", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "2", "logprob": -0.002659833524376154}, {"text": "\n", "logprob": -0.13178211450576782}, {"text": "B", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -0.012789134867489338}, {"text": " D", "logprob": -2.233743667602539}, {"text": "af", "logprob": -1.700209617614746}], "answers": ["Interleukin 2"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Finding Nemo Submarine Voyage, compressed tea, Myanmar, San Pedro, TUC338, 1983 United Kingdom general election, Phytophthora ramorum, Super Bowl XXXVI, Horse Cave, Fort Laramie National Historic Site, Blue Glacier, Mount Ararat, Epidermal growth factor, Napa Valley AVA, Triassic, 1693 Sicily earthquake, Mauer 1, Sagittarius Dwarf Elliptical Galaxy, Daka skull, Thane Creek, Kyushu, which one is the most conceptually similar with Independence Day?", "pred": " \n\nAnswer: None of the given options. Requires knowledge on Independence Day movie.", "completions_tokens": [{"text": " \n\n", "logprob": -0.3105826675891876}, {"text": "Answer", "logprob": -0.062008846551179886}, {"text": ":", "logprob": -0.06504024565219879}, {"text": " None", "logprob": -2.0237033367156982}, {"text": " of", "logprob": -0.42500823736190796}, {"text": " the", "logprob": -0.12501975893974304}, {"text": " given", "logprob": -3.923288106918335}, {"text": " options", "logprob": -0.8487047553062439}, {"text": ".", "logprob": -1.952631950378418}, {"text": " Requires", "logprob": -11.54900074005127}, {"text": " knowledge", "logprob": -3.518437385559082}, {"text": " on", "logprob": -1.59928297996521}, {"text": " Independence", "logprob": -1.7708451747894287}, {"text": " Day", "logprob": -0.024087054654955864}, {"text": " movie", "logprob": -1.5890648365020752}, {"text": ".", "logprob": -1.2714569568634033}], "answers": ["Triassic"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Holin superfamily II, Sawtooth National Recreation Area, BL Lacertae, MACPF, Queen Elizabeth Olympic Park, XIST, Myoglobin, French and Indian War, 1922 United Kingdom general election, Agnes Edwards (craftworker), Hollywood Roosevelt Hotel, Great Britain, solar eclipse of July 29, 1878, Ecarin, TOG superfamily, Grand Trunk Pacific Railway, 50000 Quaoar, Landsberg Prison, Crowsnest Pass, Battle of Fredericksburg, entitlement, which one is the most conceptually similar with Brain derived neurotrophic factor?", "pred": " \n\nAnswer: Brain derived neurotrophic factor (BDNF) promotes the growth", "completions_tokens": [{"text": " \n\n", "logprob": -0.18238011002540588}, {"text": "Answer", "logprob": -0.2484385222196579}, {"text": ":", "logprob": -0.49832451343536377}, {"text": " Brain", "logprob": -1.6347440481185913}, {"text": " derived", "logprob": -0.04818889498710632}, {"text": " neuro", "logprob": -2.4318398573086597e-05}, {"text": "t", "logprob": -2.4318398573086597e-05}, {"text": "rophic", "logprob": -2.4199192921514623e-05}, {"text": " factor", "logprob": -2.4199192921514623e-05}, {"text": " (", "logprob": -2.4306538105010986}, {"text": "BD", "logprob": -0.25952374935150146}, {"text": "NF", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -0.052205923944711685}, {"text": " promotes", "logprob": -4.992631912231445}, {"text": " the", "logprob": -1.530444622039795}, {"text": " growth", "logprob": -0.9013314247131348}], "answers": ["Myoglobin"], "all_classes": "null", "length": 95}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Gotthard railway, Coarse fishing, Castle Bravo, Liberty Tree, 2004 Indian Ocean earthquake, Welcome Stranger, CYP2J2, Lake Lucerne, Peace Tower, superior thalamic vein, Newport Folk Festival, Les Sybelles, 1971 San Fernando earthquake, cabin fever, Caspian Sea, Agnes Edwards (craftworker), 1963 Skopje earthquake, congress of Berlin, Van Cortlandt Park, Clochette, Tiffany Yellow Diamond, which one is the most conceptually similar with Vanderbilt University?", "pred": " \n\nA) Vanderbilt University \nB) Agnes Edwards (craftworker) \n", "completions_tokens": [{"text": " \n\n", "logprob": -0.4023628532886505}, {"text": "A", "logprob": -4.355557918548584}, {"text": ")", "logprob": -0.06197220832109451}, {"text": " Vanderbilt", "logprob": -6.272852420806885}, {"text": " University", "logprob": -0.08628194779157639}, {"text": " \n", "logprob": -2.262381076812744}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Ag", "logprob": -2.964470863342285}, {"text": "nes", "logprob": -2.4199192921514623e-05}, {"text": " Edwards", "logprob": -8.940656698541716e-06}, {"text": " (", "logprob": -0.10238618403673172}, {"text": "craft", "logprob": -8.940656698541716e-06}, {"text": "worker", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -0.9737869501113892}, {"text": " \n", "logprob": -0.007127691060304642}], "answers": ["Van Cortlandt Park"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Xynotyro, Small Magellanic Cloud, Caciotta, wagasi, Frankfurt City Tunnel, Rolls-Royce Meteor, Kennedy Space Center Launch Complex 39B, solar eclipse of March 29, 2006, Jansky, Tsarskoye Selo, Katiki Domokou, Blue, Gurs internment camp, Moliterno, Vin jaune, Vallnord, Galleria Vittorio Emanuele II, Ursa Minor, Sabina Park, Banjica concentration camp, Teide, which one is the most conceptually similar with Faygo?", "pred": " \n\nA) Chernobyl disaster\nB) Blue moon in space\nC", "completions_tokens": [{"text": " \n\n", "logprob": -0.4442726671695709}, {"text": "A", "logprob": -2.5229907035827637}, {"text": ")", "logprob": -0.5048277378082275}, {"text": " Chern", "logprob": -10.498536109924316}, {"text": "ob", "logprob": -0.07622513175010681}, {"text": "yl", "logprob": -2.4318398573086597e-05}, {"text": " disaster", "logprob": -1.0170977115631104}, {"text": "\n", "logprob": -0.4176192879676819}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -2.4318398573086597e-05}, {"text": " Blue", "logprob": -2.871321678161621}, {"text": " moon", "logprob": -4.450653553009033}, {"text": " in", "logprob": -4.373172760009766}, {"text": " space", "logprob": -6.687029838562012}, {"text": "\n", "logprob": -0.11417949944734573}, {"text": "C", "logprob": -2.4318398573086597e-05}], "answers": ["Vin jaune"], "all_classes": "null", "length": 83}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Bataan Death March, Ford Kent engine, Irish Rebellion of 1798, Second Sino-Japanese War, NGC 388, Manhattan Municipal Building, Royal Liverpool Golf Club, Hoylake, 2006 European Athletics Championships, 1700 Cascadia earthquake, Edinburgh International Film Festival, Middlesex Hospital, Criollo cheese, Liu Jishu, Bolivia, Battle of Shiloh, Filchner-Ronne Ice Shelf, Manila Bay, El Escorial, Queensway Tunnel, Hamilton Crescent, Via Lattea, which one is the most conceptually similar with Invasion of Poland?", "pred": " \n\n(Answer: Invasion of Poland) Not only similar to the list of questions", "completions_tokens": [{"text": " \n\n", "logprob": -0.2899903357028961}, {"text": "(", "logprob": -6.647858142852783}, {"text": "Answer", "logprob": -0.7533992528915405}, {"text": ":", "logprob": -1.0211867094039917}, {"text": " Invasion", "logprob": -1.7564759254455566}, {"text": " of", "logprob": -0.0014631766825914383}, {"text": " Poland", "logprob": -0.180184468626976}, {"text": ")", "logprob": -0.3374319076538086}, {"text": " Not", "logprob": -4.035715579986572}, {"text": " only", "logprob": -5.489534378051758}, {"text": " similar", "logprob": -5.271471977233887}, {"text": " to", "logprob": -1.9707070589065552}, {"text": " the", "logprob": -1.2355992794036865}, {"text": " list", "logprob": -1.992732048034668}, {"text": " of", "logprob": -1.242696762084961}, {"text": " questions", "logprob": -3.3528904914855957}], "answers": ["Second Sino-Japanese War"], "all_classes": "null", "length": 95}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Congressional Cemetery, Poughkeepsie Bridge, Tank Stream, Root rot, Fet3p, Melaleuca alternifolia, HS.404, CR2025, Tesla Powerpack, Tesla Megapack, Alfa Romeo V6 engine, Hofmeyr Skull, Ourasphaira giraldae, Parthenium argentatum, Kinzua Dam, Beartooth Basin Summer Ski Area, Polaris, PSR B1913+16, Aldebaran, Indonesia, Chrysler Pentastar engine, which one is the most conceptually similar with RPG-7?", "pred": " RPG-7 can be also called as missiles\nAnswer:\n Indonesia. (No", "completions_tokens": [{"text": " RPG", "logprob": -2.986698627471924}, {"text": "-", "logprob": -0.12847894430160522}, {"text": "7", "logprob": -0.03529604151844978}, {"text": " can", "logprob": -6.217319488525391}, {"text": " be", "logprob": -0.291922003030777}, {"text": " also", "logprob": -4.345697402954102}, {"text": " called", "logprob": -1.3668588399887085}, {"text": " as", "logprob": -0.9020053744316101}, {"text": " missiles", "logprob": -11.951278686523438}, {"text": "\n", "logprob": -6.440524578094482}, {"text": "Answer", "logprob": -0.2995280921459198}, {"text": ":\n", "logprob": -0.7116332054138184}, {"text": " Indonesia", "logprob": -6.2800397872924805}, {"text": ".", "logprob": -3.0635159015655518}, {"text": " (", "logprob": -1.9012149572372437}, {"text": "No", "logprob": -5.08098030090332}], "answers": ["HS.404"], "all_classes": "null", "length": 75}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong solar eclipse of November 25, 2011, Cueva de las Manos, daf-2, Oswald Poche, The Cenotaph, 2016 North Canterbury earthquake, County Ground, Friuli-Venezia Giulia wine, Yazaman al-Khadim, Flyball, Agnes Edwards (craftworker), Fortress of Louisbourg, 2014 FIFA World Cup, Madagascar, Warhammer 40,000, solar eclipse of March 29, 2006, Brandenburg Gate, Intergender wrestling, Pawan Gupta, dorsal digital arteries of foot, SK 46, which one is the most conceptually similar with Rummy?", "pred": " \n\nAnswer: Pawan Gupta. (I changed the structure of the answer to", "completions_tokens": [{"text": " \n\n", "logprob": -0.5565798282623291}, {"text": "Answer", "logprob": -0.17972403764724731}, {"text": ":", "logprob": -0.125337615609169}, {"text": " P", "logprob": -5.045919895172119}, {"text": "awan", "logprob": -2.4318398573086597e-05}, {"text": " Gupta", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.9541656374931335}, {"text": " (", "logprob": -1.1910195350646973}, {"text": "I", "logprob": -2.5396623611450195}, {"text": " changed", "logprob": -4.031533241271973}, {"text": " the", "logprob": -0.6057615280151367}, {"text": " structure", "logprob": -5.352592945098877}, {"text": " of", "logprob": -0.2525283694267273}, {"text": " the", "logprob": -1.0549594163894653}, {"text": " answer", "logprob": -1.4489035606384277}, {"text": " to", "logprob": -1.487991452217102}], "answers": ["Warhammer 40,000"], "all_classes": "null", "length": 97}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Bear Mountain Bridge, Bucheron, Raghunathpur Thermal Power Station, cerebellar artery, Pula Film Festival, South Branch Potomac River, Baikonur Cosmodrome Site 200, Northern Ireland, Accessory soleus muscle, 1960 Democratic National Convention, Yellowstone volcano, Adductor muscles of the hip, Bellevue Hospital Center, uterine venous plexus, Adirondack Park, Coen Tunnel, TRAPPIST-1g, lateral rotator group, Venice Film Festival, Spaceport Florida Launch Complex 46, pubovaginal muscle, which one is the most conceptually similar with common digital veins?", "pred": "-\n\nA) Bear Mountain Bridge\nB) 1960 Democratic National Convention\n", "completions_tokens": [{"text": "-\n\n", "logprob": -6.11366081237793}, {"text": "A", "logprob": -0.21748314797878265}, {"text": ")", "logprob": -0.18613041937351227}, {"text": " Bear", "logprob": -1.3644298315048218}, {"text": " Mountain", "logprob": -2.4318398573086597e-05}, {"text": " Bridge", "logprob": -8.940656698541716e-06}, {"text": "\n", "logprob": -0.03554917499423027}, {"text": "B", "logprob": -8.940656698541716e-06}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -6.363123893737793}, {"text": "196", "logprob": -0.15446990728378296}, {"text": "0", "logprob": -2.4318398573086597e-05}, {"text": " Democratic", "logprob": -8.940656698541716e-06}, {"text": " National", "logprob": -2.4199192921514623e-05}, {"text": " Convention", "logprob": -8.940656698541716e-06}, {"text": "\n", "logprob": -2.4318398573086597e-05}], "answers": ["uterine venous plexus"], "all_classes": "null", "length": 98}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong orbitofrontal artery, Mount Ararat, venous angle, East Side Access, Clarke Quay, dilator naris muscle, Dolaucothi Gold Mines, Aral Sea, sulfuric acid, Coffin bone, fascial compartments of arm, Oswald Poche, Louisville, New York Harbor, Nepenthes kerrii, Botryosphaeria stevensii, meningohypophyseal artery, Muehlenbeckia australis, Diablo Canyon Power Plant, Sea of Azov, Palaeocene, which one is the most conceptually similar with perforator vein?", "pred": " \n\n Step 1: Review the list of entities\nThe entities listed are a", "completions_tokens": [{"text": " \n\n", "logprob": -0.16828560829162598}, {"text": " Step", "logprob": -4.512302398681641}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " Review", "logprob": -3.6522445678710938}, {"text": " the", "logprob": -0.14127090573310852}, {"text": " list", "logprob": -0.0902051106095314}, {"text": " of", "logprob": -0.3492979407310486}, {"text": " entities", "logprob": -0.9951967000961304}, {"text": "\n", "logprob": -1.364450216293335}, {"text": "The", "logprob": -0.3672669529914856}, {"text": " entities", "logprob": -0.9626054763793945}, {"text": " listed", "logprob": -0.947688639163971}, {"text": " are", "logprob": -0.6957818269729614}, {"text": " a", "logprob": -1.6073837280273438}], "answers": ["venous angle"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Spencer repeating rifle, Sulawesi, Kingfisher, Three Kingdoms, HD 219134b, 1908 Messina earthquake, Saldanha man, Third Imperial, Trans-Canada Highway, Ottoman Empire, International Film Festival of India, Pleistocene, Lysine exporter, solar eclipse of August 1, 2008, San Francisco Museum of Modern Art, QF 4 inch Mk V naval gun, 2020 ICC World Twenty20 Qualifier, Dungeons & Dragons Basic Set, Oranienburg concentration camp, bovine respiratory disease, Kveik, which one is the most conceptually similar with Saturn?", "pred": " \n\nAnswer: Lunar. (Lunar offers a similar condition like an illumination boundary", "completions_tokens": [{"text": " \n\n", "logprob": -0.1681172400712967}, {"text": "Answer", "logprob": -0.29553669691085815}, {"text": ":", "logprob": -0.48020774126052856}, {"text": " Lunar", "logprob": -7.483682155609131}, {"text": ".", "logprob": -1.3736482858657837}, {"text": " (", "logprob": -1.4644919633865356}, {"text": "L", "logprob": -3.0811896324157715}, {"text": "unar", "logprob": -0.0038025707472115755}, {"text": " offers", "logprob": -8.854762077331543}, {"text": " a", "logprob": -1.391729712486267}, {"text": " similar", "logprob": -3.1180903911590576}, {"text": " condition", "logprob": -7.242892265319824}, {"text": " like", "logprob": -4.084661483764648}, {"text": " an", "logprob": -5.051872730255127}, {"text": " illumination", "logprob": -7.97299861907959}, {"text": " boundary", "logprob": -8.714658737182617}], "answers": ["HD 219134b"], "all_classes": "null", "length": 99}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Holin superfamily V, Doubletime, Molenbeek, Tattletales, Rhinogydd, California Academy of Sciences, MT-RNR1, Monitor-Merrimac Memorial Bridge-Tunnel, Banjica concentration camp, Prometheus, Cl-transporting ATPase, The Proms, Honda J engine, 2018 FIFA World Cup, MEG8, Interleukin 1 beta, Professional baseball, Kashiwazaki-Kariwa Nuclear Power Plant, Wookey Hole Caves, Tampa Bay, Aspen Music Festival and School, which one is the most conceptually similar with Epidermal growth factor?", "pred": " \n\nStep 1: Identify the concept of Epidermal growth factor (EG", "completions_tokens": [{"text": " \n\n", "logprob": -0.1892414391040802}, {"text": "Step", "logprob": -2.9493672847747803}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " Identify", "logprob": -1.056665062904358}, {"text": " the", "logprob": -0.02828752063214779}, {"text": " concept", "logprob": -1.5999776124954224}, {"text": " of", "logprob": -0.6297906041145325}, {"text": " Ep", "logprob": -0.03270914778113365}, {"text": "ider", "logprob": -2.4318398573086597e-05}, {"text": "mal", "logprob": -8.940656698541716e-06}, {"text": " growth", "logprob": -0.12905213236808777}, {"text": " factor", "logprob": -2.4318398573086597e-05}, {"text": " (", "logprob": -0.840957760810852}, {"text": "EG", "logprob": -2.4318398573086597e-05}], "answers": ["Interleukin 1 beta"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Super Bowl XLV, Botryosphaeria stevensii, Rio All-Suite Hotel and Casino, South Street Seaport, hemiazygos vein, Capricornus, Western Ghats, Big Dig, Portuguese Diamond, propane, frankincense, Yellowhead Pass, zinc oxide, Colony of New South Wales, Heart Mountain Relocation Center, aldosterone, Mercury-Atlas 6, Great Mogul Diamond, County Ground, Ubinas, The Simpsons Ride, which one is the most conceptually similar with poly(methyl methacrylate)?", "pred": " \n\nStep 1: Identify the concepts that are related to materials or chemical compounds", "completions_tokens": [{"text": " \n\n", "logprob": -0.11598289012908936}, {"text": "Step", "logprob": -1.6778030395507812}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " Identify", "logprob": -1.393259048461914}, {"text": " the", "logprob": -0.06711363792419434}, {"text": " concepts", "logprob": -3.3985297679901123}, {"text": " that", "logprob": -1.819129228591919}, {"text": " are", "logprob": -0.09827141463756561}, {"text": " related", "logprob": -0.5738901495933533}, {"text": " to", "logprob": -8.940656698541716e-06}, {"text": " materials", "logprob": -1.2673859596252441}, {"text": " or", "logprob": -0.06918308138847351}, {"text": " chemical", "logprob": -1.7322156429290771}, {"text": " compounds", "logprob": -0.30508679151535034}], "answers": ["propane"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Cappadocia, Dungeons & Dragons Basic Set, Fantasia Festival, Tango, Bethlem Royal Hospital, County Cricket Ground, Chelmsford, Risiera di San Sabba, February 2011 Christchurch earthquake, Singha, Afon Irfon, Greek fire, Newcastle Brown Ale, Mariner 4, One Times Square, Legacy Way, nerve growth factor, Brahma, Lodi AVA, Moliterno, Stalag Luft III, Friuli-Venezia Giulia wine, which one is the most conceptually similar with Egyptian cheese?", "pred": " \n\nA) Cappadocia\nB) Risiera di San Sab", "completions_tokens": [{"text": " \n\n", "logprob": -0.34978801012039185}, {"text": "A", "logprob": -1.252875804901123}, {"text": ")", "logprob": -1.7261567115783691}, {"text": " C", "logprob": -0.6320548057556152}, {"text": "app", "logprob": -8.940656698541716e-06}, {"text": "ad", "logprob": -2.4318398573086597e-05}, {"text": "oc", "logprob": -2.4318398573086597e-05}, {"text": "ia", "logprob": -8.940656698541716e-06}, {"text": "\n", "logprob": -0.2336827665567398}, {"text": "B", "logprob": -2.4318398573086597e-05}, {"text": ")", "logprob": -8.940656698541716e-06}, {"text": " Ris", "logprob": -2.217346429824829}, {"text": "iera", "logprob": -8.940656698541716e-06}, {"text": " di", "logprob": -8.940656698541716e-06}, {"text": " San", "logprob": -2.4318398573086597e-05}, {"text": " Sab", "logprob": -8.940656698541716e-06}], "answers": ["Moliterno"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Battle of the Somme, superficial dorsal vein of the penis, Blue Serpent Clock, Palaeocene, corticotropin releasing hormone, Fisher Building, Thomas Circle, 2003 World Championships in Athletics, 2019 Canadian federal election, Big Dig, Lake Como, Oltermanni, Parrott rifle, Tesla Powerpack, 2020 Republican National Convention, Lafayette Square, common digital veins, Bahia Emerald, aldosterone, Sonoma Valley, Tesla Megapack, which one is the most conceptually similar with Kasat Suek Intersection?", "pred": " \n\nAnswer: None of the above. * This is obviously impossible. I found", "completions_tokens": [{"text": " \n\n", "logprob": -0.16438207030296326}, {"text": "Answer", "logprob": -0.07442566752433777}, {"text": ":", "logprob": -0.19887541234493256}, {"text": " None", "logprob": -3.3745381832122803}, {"text": " of", "logprob": -0.3839256465435028}, {"text": " the", "logprob": -0.09681966155767441}, {"text": " above", "logprob": -0.4017660319805145}, {"text": ".", "logprob": -0.2878950536251068}, {"text": " *", "logprob": -7.6031880378723145}, {"text": " This", "logprob": -5.461071968078613}, {"text": " is", "logprob": -1.012281894683838}, {"text": " obviously", "logprob": -7.4795331954956055}, {"text": " impossible", "logprob": -4.291779041290283}, {"text": ".", "logprob": -1.9789602756500244}, {"text": " I", "logprob": -3.4956090450286865}, {"text": " found", "logprob": -5.480937957763672}], "answers": ["Thomas Circle"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Kyushu, Kanheri Caves, Steinheim skull, black drink, Library of Congress, Pier 39, Dresden Green Diamond, Tahiti, STS-51-L, common facial vein, meningohypophyseal artery, parasphenoid, War on Terror, Palmar plate, horseshoes, hamstring muscles, Galleria Vittorio Emanuele II, Ford Windsor engine, Sizewell nuclear power stations, Pepsi Max, Liverpool and Manchester Railway, which one is the most conceptually similar with plantar Lisfranc ligament?", "pred": " \n\nAnswer: Meningohypophyseal artery Similarity: Plantar", "completions_tokens": [{"text": " \n\n", "logprob": -0.043354641646146774}, {"text": "Answer", "logprob": -0.07076267153024673}, {"text": ":", "logprob": -0.045175980776548386}, {"text": " M", "logprob": -4.273553371429443}, {"text": "ening", "logprob": -2.4318398573086597e-05}, {"text": "oh", "logprob": -2.4318398573086597e-05}, {"text": "yp", "logprob": -2.4318398573086597e-05}, {"text": "ophy", "logprob": -8.940656698541716e-06}, {"text": "se", "logprob": -2.4318398573086597e-05}, {"text": "al", "logprob": -2.4318398573086597e-05}, {"text": " artery", "logprob": -2.4318398573086597e-05}, {"text": " Similar", "logprob": -5.7635111808776855}, {"text": "ity", "logprob": -0.35538798570632935}, {"text": ":", "logprob": -0.15535859763622284}, {"text": " Plant", "logprob": -1.9834669828414917}, {"text": "ar", "logprob": -2.4318398573086597e-05}], "answers": ["Palmar plate"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong American Golden Topaz, Palmar plate, cream gene, Lake Constance, Standedge Tunnels, Ford FE engine, Mazda B engine, Virginia Tech, keel, Reflex inguinal ligament, Risiera di San Sabba, Switzerland, Springfield Interchange, Blue Mountain Tunnel, dorsal digital arteries of foot, Africa, Corrugator cutis ani muscle, Joint Mathematics Meetings, Daka skull, Windsor Great Park, World Forestry Congress, which one is the most conceptually similar with fascial compartments of arm?", "pred": " \n\nAnswer: Lower limb fascial compartments having the highest chances of injury during a", "completions_tokens": [{"text": " \n\n", "logprob": -0.06875615566968918}, {"text": "Answer", "logprob": -0.15294092893600464}, {"text": ":", "logprob": -0.2852977216243744}, {"text": " Lower", "logprob": -10.623218536376953}, {"text": " limb", "logprob": -1.1362019777297974}, {"text": " fasc", "logprob": -0.9665247201919556}, {"text": "ial", "logprob": -0.013798325322568417}, {"text": " compartments", "logprob": -0.21356624364852905}, {"text": " having", "logprob": -8.559648513793945}, {"text": " the", "logprob": -3.5121121406555176}, {"text": " highest", "logprob": -5.970239639282227}, {"text": " chances", "logprob": -8.333983421325684}, {"text": " of", "logprob": -0.23989441990852356}, {"text": " injury", "logprob": -3.4437673091888428}, {"text": " during", "logprob": -1.563277244567871}, {"text": " a", "logprob": -2.493424892425537}], "answers": ["Corrugator cutis ani muscle"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Flyball, mood swing, 162173 Ryugu, Mehoopany Creek, ophthalmic veins, High Five Interchange, Wine auction, Oxford University Parks, Newark Airport Interchange, Southwark Cathedral, Antwerp, CR2025, sodium carbonate, Norfork Dam, Imperial War Museum London, Newhall Pass, Intergender wrestling, The Voice of Germany, plantar Lisfranc ligament, Pawan Gupta, Iaido, which one is the most conceptually similar with Cluedo?", "pred": " \n\nAnswer:\n\nMehoopany Creek. (Cluedo is a board", "completions_tokens": [{"text": " \n\n", "logprob": -0.16800186038017273}, {"text": "Answer", "logprob": -0.6269304156303406}, {"text": ":\n\n", "logprob": -1.1900345087051392}, {"text": "M", "logprob": -2.8120903968811035}, {"text": "eh", "logprob": -0.030324662104249}, {"text": "oop", "logprob": -8.940656698541716e-06}, {"text": "any", "logprob": -8.940656698541716e-06}, {"text": " Creek", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.7861332297325134}, {"text": " (", "logprob": -1.5983383655548096}, {"text": "Cl", "logprob": -4.533344745635986}, {"text": "ued", "logprob": -8.940656698541716e-06}, {"text": "o", "logprob": -8.940656698541716e-06}, {"text": " is", "logprob": -0.36230558156967163}, {"text": " a", "logprob": -0.2436542510986328}, {"text": " board", "logprob": -0.5384092926979065}], "answers": ["The Voice of Germany"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Sather Tower, High Five Interchange, Joint Mathematics Meetings, Bryant Park, Accessory soleus muscle, Apollo 16, Llangorse Lake, Monastery of the Holy Archangels, solar eclipse of August 21, 2017, Super Bowl LIV, Winterthur Museum and Country Estate, solar eclipse of June 25, 2150, Adrenal artery, Endometrial arteries, Wawona Tunnel, Beaufort Sea, Liberty Tunnel, renin, poisoning of Alexander Litvinenko, Aconcagua, solar eclipse of October 24, 1995, which one is the most conceptually similar with athletics at the 2016 Summer Paralympics?", "pred": " \nMy Left Foot\n\nJust answer with the entity name only. Aconcagua", "completions_tokens": [{"text": " \n", "logprob": -3.724947452545166}, {"text": "My", "logprob": -7.064606189727783}, {"text": " Left", "logprob": -8.512632369995117}, {"text": " Foot", "logprob": -0.3927655518054962}, {"text": "\n\n", "logprob": -1.8004891872406006}, {"text": "Just", "logprob": -8.062594413757324}, {"text": " answer", "logprob": -1.762868881225586}, {"text": " with", "logprob": -0.22627747058868408}, {"text": " the", "logprob": -2.4318398573086597e-05}, {"text": " entity", "logprob": -0.029791148379445076}, {"text": " name", "logprob": -2.4318398573086597e-05}, {"text": " only", "logprob": -0.12670080363750458}, {"text": ".", "logprob": -0.2152559757232666}, {"text": " A", "logprob": -1.8403518199920654}, {"text": "conc", "logprob": -2.4199192921514623e-05}, {"text": "agua", "logprob": -2.4199192921514623e-05}], "answers": ["Super Bowl LIV"], "all_classes": "null", "length": 107}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Fourth World Conference on Women, Monitor-Merrimac Memorial Bridge-Tunnel, Tsarskoye Selo, Colloque Walter Lippmann, Welcome Stranger, Moscow Kremlin, Battle of Fredericksburg, Royal Botanic Garden Edinburgh, Barabar Caves, East Gondwana, Xq28, Tesla Megapack, Mercury-Atlas 6, Royal Cinque Ports Golf Club, dorsal digital arteries of foot, daf-7, Eagle Diamond, horseshoes, 1971 San Fernando earthquake, Potsdam Conference, Brenner Base Tunnel, which one is the most conceptually similar with STS-121?", "pred": " \nAnswer: MERCEDES BENZ  View her other discussions: thai massage", "completions_tokens": [{"text": " \n", "logprob": -2.449232339859009}, {"text": "Answer", "logprob": -0.21452131867408752}, {"text": ":", "logprob": -0.19607855379581451}, {"text": " MER", "logprob": -7.352910995483398}, {"text": "CE", "logprob": -3.5044593811035156}, {"text": "DES", "logprob": -1.1632134914398193}, {"text": " BEN", "logprob": -1.604990005493164}, {"text": "Z", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -1.35917067527771}, {"text": " View", "logprob": -9.323345184326172}, {"text": " her", "logprob": -8.93376350402832}, {"text": " other", "logprob": -4.712481498718262}, {"text": " discussions", "logprob": -6.6148576736450195}, {"text": ":", "logprob": -2.790008306503296}, {"text": " thai", "logprob": -12.327402114868164}, {"text": " massage", "logprob": -3.97898268699646}], "answers": ["Mercury-Atlas 6"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 3200 Phaethon, daf-2, anterolateral ligament, 2013 World Championships in Athletics, Oltermanni, Third Battle of Ypres, Kveik, Chapultepec, Trivial Pursuit, 2017 World Aquatics Championships, Ambassador Bridge, Eden Gardens, fluoxetine, Lethal yellowing, Prometheus, precerebral artery, STS-125, 2 cm Flak 30/38/Flakvierling, Mediterranean Sea, dentary bone, Washington National Cathedral, which one is the most conceptually similar with Cluny Abbey?", "pred": " \n\nAnswer: Cluny Abbey is historically similar. True. Cluny", "completions_tokens": [{"text": " \n\n", "logprob": -0.1149037778377533}, {"text": "Answer", "logprob": -0.49030327796936035}, {"text": ":", "logprob": -0.25927212834358215}, {"text": " Cl", "logprob": -0.10892678797245026}, {"text": "un", "logprob": -2.4199192921514623e-05}, {"text": "y", "logprob": -8.940656698541716e-06}, {"text": " Abbey", "logprob": -2.4318398573086597e-05}, {"text": " is", "logprob": -1.58596932888031}, {"text": " historically", "logprob": -5.706821441650391}, {"text": " similar", "logprob": -3.021801471710205}, {"text": ".", "logprob": -2.7142105102539062}, {"text": " True", "logprob": -4.889961242675781}, {"text": ".", "logprob": -0.343669056892395}, {"text": " Cl", "logprob": -2.4384713172912598}, {"text": "un", "logprob": -8.940656698541716e-06}, {"text": "y", "logprob": -8.940656698541716e-06}], "answers": ["Washington National Cathedral"], "all_classes": "null", "length": 81}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong High Line, Cuba, 25143 Itokawa, Fantasia Festival, spoiled child, potassium chloride, solar eclipse of May 20, 2012, Kilmainham Gaol, Apple Worldwide Developers Conference, Pepsi Max, Muppet*Vision 3D, Formula 5000, Kveik, Tesla Megapack, djon djon, sodium hydroxide, 1964 United Kingdom general election, palmar carpal arch, Penns Creek, BM-21 Grad, Hadim Suleiman Pasha, which one is the most conceptually similar with Guantanamo Bay detention camp?", "pred": " (Select one answer from the list).\n\nStep 1:  To determine the", "completions_tokens": [{"text": " (", "logprob": -5.768454074859619}, {"text": "Select", "logprob": -3.6677255630493164}, {"text": " one", "logprob": -0.2660816013813019}, {"text": " answer", "logprob": -2.9437994956970215}, {"text": " from", "logprob": -1.8560389280319214}, {"text": " the", "logprob": -0.043762993067502975}, {"text": " list", "logprob": -0.17158490419387817}, {"text": ").\n\n", "logprob": -3.107778549194336}, {"text": "Step", "logprob": -1.6418721675872803}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " ", "logprob": -2.2295429706573486}, {"text": " To", "logprob": -0.8735126256942749}, {"text": " determine", "logprob": -1.3796939849853516}, {"text": " the", "logprob": -0.4983302354812622}], "answers": ["Kilmainham Gaol"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Canning Tunnel, zinc oxide, STS-135, Pliocene, Coarse fishing, solar eclipse of April 28, 1930, Bay of Biscay, Nepal, Scottish independence referendum, 2014, solar eclipse of September 12, 2034, Cannabinoid receptor 2, Lloret de Mar, Pinconning cheese, crisantaspase, lateral rotator group, Bayreuth Festival, Circuit de Spa-Francorchamps, Epidermal growth factor, head for heights, Nashville, KNM WT 17000, which one is the most conceptually similar with San Diego?", "pred": " \n\nAnswer:\n\nNashville. Knowledge & Identifications & Similarities Spark Chart", "completions_tokens": [{"text": " \n\n", "logprob": -0.21944323182106018}, {"text": "Answer", "logprob": -0.5371732711791992}, {"text": ":\n\n", "logprob": -0.870435357093811}, {"text": "N", "logprob": -0.7718002796173096}, {"text": "ash", "logprob": -2.4318398573086597e-05}, {"text": "ville", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.1538420170545578}, {"text": " Knowledge", "logprob": -7.051020622253418}, {"text": " &", "logprob": -6.2342305183410645}, {"text": " Ident", "logprob": -9.119349479675293}, {"text": "ifications", "logprob": -2.4536619186401367}, {"text": " &", "logprob": -2.974107027053833}, {"text": " Similar", "logprob": -2.05549693107605}, {"text": "ities", "logprob": -0.7350656986236572}, {"text": " Spark", "logprob": -13.132174491882324}, {"text": " Chart", "logprob": -5.334053039550781}], "answers": ["Nashville"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong First Red Scare, Nepenthes northiana, Blue Serpent Clock, djon djon, McLaren Vale, Kamakura period, OSIRIS-REx, Gagarin, Pont Neuf, Vancouver International Film Festival, Xynotyro, cream gene, Extrinsic extensor muscles of the hand, International Congress on Medieval Studies, Hadim Ali Pasha, Monitor-Merrimac Memorial Bridge-Tunnel, River Ithon, Wang Shoucheng, Ghana, potassium chloride, Pawan Gupta, which one is the most conceptually similar with London Bridge?", "pred": " London Bridge has a historical link with a novel by Washington Irving called? Hunters -", "completions_tokens": [{"text": " London", "logprob": -2.9527230262756348}, {"text": " Bridge", "logprob": -0.24262364208698273}, {"text": " has", "logprob": -2.454944610595703}, {"text": " a", "logprob": -1.0296741724014282}, {"text": " historical", "logprob": -2.9836902618408203}, {"text": " link", "logprob": -6.945398330688477}, {"text": " with", "logprob": -0.8121209740638733}, {"text": " a", "logprob": -1.843430995941162}, {"text": " novel", "logprob": -4.2874860763549805}, {"text": " by", "logprob": -1.607579231262207}, {"text": " Washington", "logprob": -3.702911853790283}, {"text": " Irving", "logprob": -2.4318398573086597e-05}, {"text": " called", "logprob": -2.9646852016448975}, {"text": "?", "logprob": -6.428317070007324}, {"text": " Hunters", "logprob": -13.565753936767578}, {"text": " -", "logprob": -4.792245388031006}], "answers": ["Pont Neuf"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Eocene, Florentine Diamond, Ofu-Olosega, ammonia, Renaissance, Holin superfamily V, Panama disease, New Zealand, poly(methyl methacrylate), Adirondack Park, SN 1987A, codeine, Pinwheel Galaxy, Basilica of Saint-Denis, Parthenon, Reading and Leeds Festivals, Royal Botanic Gardens Victoria, cyclosporine, gallium arsenide, MT-RNR1, Aral Sea, which one is the most conceptually similar with Akbar Shah?", "pred": " \n\nAnswer:\n\nReading and Leeds Festivals are the only entities similar with Akbar", "completions_tokens": [{"text": " \n\n", "logprob": -0.7353007793426514}, {"text": "Answer", "logprob": -0.6599253416061401}, {"text": ":\n\n", "logprob": -2.4903857707977295}, {"text": "Reading", "logprob": -2.175046443939209}, {"text": " and", "logprob": -2.4199192921514623e-05}, {"text": " Leeds", "logprob": -8.940656698541716e-06}, {"text": " Fest", "logprob": -2.4318398573086597e-05}, {"text": "ivals", "logprob": -8.940656698541716e-06}, {"text": " are", "logprob": -3.063852310180664}, {"text": " the", "logprob": -2.066419839859009}, {"text": " only", "logprob": -3.455195188522339}, {"text": " entities", "logprob": -2.9065513610839844}, {"text": " similar", "logprob": -3.054715394973755}, {"text": " with", "logprob": -1.5775203704833984}, {"text": " Ak", "logprob": -0.14348839223384857}, {"text": "bar", "logprob": -2.4437606043647975e-05}], "answers": ["Florentine Diamond"], "all_classes": "null", "length": 78}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 2015 World Aquatics Championships, 2001 Gujarat earthquake, Khyber Pass, intervertebral veins, First Battle of Bull Run, Drew University, vesiculodeferential artery, Dufek Massif, perforator vein, superior cerebellar veins, Juvenile hormone acid O-methyltransferase, internal auditory veins, Nissan VG engine, Chartwell, Lysine exporter, Ford Modular engine, Seven Years War, MHETase, T Tauri, Big Dipper, trabecular veins, which one is the most conceptually similar with Greenland ice sheet?", "pred": " \n\nIvanpah Valley solar power facility\nA) NASA's Jet Prop", "completions_tokens": [{"text": " \n\n", "logprob": -0.11103799194097519}, {"text": "I", "logprob": -8.638923645019531}, {"text": "van", "logprob": -4.046955585479736}, {"text": "p", "logprob": -2.109027862548828}, {"text": "ah", "logprob": -8.940656698541716e-06}, {"text": " Valley", "logprob": -2.332651376724243}, {"text": " solar", "logprob": -2.376556873321533}, {"text": " power", "logprob": -0.7918846011161804}, {"text": " facility", "logprob": -0.688397228717804}, {"text": "\n", "logprob": -1.8655421733856201}, {"text": "A", "logprob": -0.36763671040534973}, {"text": ")", "logprob": -0.24442699551582336}, {"text": " NASA", "logprob": -10.39565658569336}, {"text": "'s", "logprob": -1.5195136070251465}, {"text": " Jet", "logprob": -3.0992813110351562}, {"text": " Prop", "logprob": -2.4318398573086597e-05}], "answers": ["Dufek Massif"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong glucagon, Balkan Wars, Torrey Pines Golf Course, Tesla Powerpack, fascial compartments of arm, Lake Ontario, Nanga Parbat, Cave Hill Cemetery, Eola-Amity Hills AVA, Beta-galactoside permease, Settle to Carlisle Line, Grand Trunk Pacific Railway, Alfa Romeo V6 engine, Indonesia, Bahia Emerald, John H. Stroger, Jr. Hospital of Cook County, Patriot Place, corticotropin releasing hormone, Byfjord Tunnel, 2021 storming of the United States Capitol, mood swing, which one is the most conceptually similar with Vertebral subluxation?", "pred": " \n\nAnswer: Vertebral subluxation concept is widely discussed in fields that", "completions_tokens": [{"text": " \n\n", "logprob": -0.13242954015731812}, {"text": "Answer", "logprob": -0.4299538731575012}, {"text": ":", "logprob": -0.10658065229654312}, {"text": " V", "logprob": -1.7290513515472412}, {"text": "erte", "logprob": -0.02897285670042038}, {"text": "bral", "logprob": -8.940656698541716e-06}, {"text": " sub", "logprob": -0.023340947926044464}, {"text": "lux", "logprob": -2.4199192921514623e-05}, {"text": "ation", "logprob": -8.940656698541716e-06}, {"text": " concept", "logprob": -3.2748284339904785}, {"text": " is", "logprob": -1.269533634185791}, {"text": " widely", "logprob": -6.5180463790893555}, {"text": " discussed", "logprob": -2.4630661010742188}, {"text": " in", "logprob": -0.26771560311317444}, {"text": " fields", "logprob": -5.968993186950684}, {"text": " that", "logprob": -3.0519254207611084}], "answers": ["mood swing"], "all_classes": "null", "length": 100}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Westfield London, Mesenteric arteries, Premier Rose Diamond, police auction, Kveik, Metro Manila Film Festival, Akbar Shah, Sphenomandibularis, Holin superfamily VII, sodium hydroxide, Saldanha man, Osterley Park, Pawan Gupta, Lake Superior, Levator muscle of thyroid gland, Tane Mahuta, Reggianito, Mersey Tunnels, Wolf 359, Piemonte, 3 Juno, which one is the most conceptually similar with Monitor-Merrimac Memorial Bridge-Tunnel?", "pred": "    \nANSWER: 3 Juno Indicator: Wolf 359 is too distant", "completions_tokens": [{"text": "    \n", "logprob": -5.476397514343262}, {"text": "ANS", "logprob": -3.0695371627807617}, {"text": "WER", "logprob": -8.940656698541716e-06}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -1.6051700115203857}, {"text": "3", "logprob": -0.15520836412906647}, {"text": " Jun", "logprob": -0.004781241994351149}, {"text": "o", "logprob": -2.4318398573086597e-05}, {"text": " Indicator", "logprob": -11.151265144348145}, {"text": ":", "logprob": -0.566857099533081}, {"text": " Wolf", "logprob": -8.354042053222656}, {"text": " ", "logprob": -0.11365124583244324}, {"text": "359", "logprob": -2.4318398573086597e-05}, {"text": " is", "logprob": -1.2251248359680176}, {"text": " too", "logprob": -4.946526527404785}, {"text": " distant", "logprob": -3.754241466522217}], "answers": ["Mersey Tunnels"], "all_classes": "null", "length": 81}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Russian roulette, Oxbridge, TOG superfamily, police auction, Caloris Planitia, Colony stimulating factor 2, Pawan Gupta, Bodie, Pont Neuf, Tesla Powerpack, Grus, Pikes Peak, 2019 Albania earthquake, Nissan L engine, Fourth World Conference on Women, fascial compartments of arm, Arctica, Professional baseball, RuneQuest, Canopus, Yom Kippur War, which one is the most conceptually similar with Bataan Death March?", "pred": " \n\nAnswer:  Arctica, Pikes Peak, Bodie, Grus", "completions_tokens": [{"text": " \n\n", "logprob": -0.344816118478775}, {"text": "Answer", "logprob": -0.6681200265884399}, {"text": ":", "logprob": -0.14716100692749023}, {"text": " ", "logprob": -3.9080522060394287}, {"text": " Ar", "logprob": -2.512399673461914}, {"text": "ctica", "logprob": -0.09932706505060196}, {"text": ",", "logprob": -0.862799882888794}, {"text": " P", "logprob": -1.9026905298233032}, {"text": "ikes", "logprob": -0.635128915309906}, {"text": " Peak", "logprob": -8.940656698541716e-06}, {"text": ",", "logprob": -0.21316994726657867}, {"text": " Bod", "logprob": -1.5641425848007202}, {"text": "ie", "logprob": -2.4318398573086597e-05}, {"text": ",", "logprob": -0.08583874255418777}, {"text": " Gr", "logprob": -2.6321640014648438}, {"text": "us", "logprob": -8.940656698541716e-06}], "answers": ["Professional baseball"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Ursa Minor, anterolateral ligament, Reflex inguinal ligament, Ford Kent engine, Quebec Conference, Holin superfamily VII, Mesenteric arteries, Tyche, Red Sea, Musca, Jaguar V12 engine, Bouncing bomb, Hollywood, Mitsubishi 6G7 engine, Netflix, Tesla Powerwall, San Francisco Museum of Modern Art, Mount Hermon, Baffin Bay, interclavicle, Joint Direct Attack Munition, which one is the most conceptually similar with CR2032 battery?", "pred": " \n\nAnswer: Bouncing bomb. (The reason for it can be found in", "completions_tokens": [{"text": " \n\n", "logprob": -0.1001104936003685}, {"text": "Answer", "logprob": -0.4332059919834137}, {"text": ":", "logprob": -0.4511600136756897}, {"text": " B", "logprob": -4.121912002563477}, {"text": "ouncing", "logprob": -0.03363516554236412}, {"text": " bomb", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.22595037519931793}, {"text": " (", "logprob": -1.9191641807556152}, {"text": "The", "logprob": -2.7848267555236816}, {"text": " reason", "logprob": -3.866763114929199}, {"text": " for", "logprob": -2.3104593753814697}, {"text": " it", "logprob": -5.004850387573242}, {"text": " can", "logprob": -5.222774505615234}, {"text": " be", "logprob": -0.05554718151688576}, {"text": " found", "logprob": -1.8087745904922485}, {"text": " in", "logprob": -1.0884860754013062}], "answers": ["Tesla Powerwall"], "all_classes": "null", "length": 83}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Battle of Crete, Berlin International Film Festival, Hawaii International Film Festival, New York Comic Con, Grus, 2017 World Championships in Athletics, Krupp Diamond, The Settlers of Catan, 2009 Samoa earthquake, LSM3, Landsberg Prison, Frameline Film Festival, New York metropolitan area, New York Film Festival, Piccadilly line, chitin, Homosexual panic, Shandaken Tunnel, Queen Elizabeth Olympic Park, Tesla Megapack, Syzygium guineense, which one is the most conceptually similar with Northeast Corridor?", "pred": " Northeast Corridor\n\nMy understanding of Northeast Corridor is that it's a region", "completions_tokens": [{"text": " Northeast", "logprob": -2.5203957557678223}, {"text": " Cor", "logprob": -0.0018041539005935192}, {"text": "ridor", "logprob": -0.25673502683639526}, {"text": "\n\n", "logprob": -1.5303912162780762}, {"text": "My", "logprob": -7.170524597167969}, {"text": " understanding", "logprob": -1.4718725681304932}, {"text": " of", "logprob": -0.26481354236602783}, {"text": " Northeast", "logprob": -2.625373363494873}, {"text": " Cor", "logprob": -8.940656698541716e-06}, {"text": "ridor", "logprob": -2.4318398573086597e-05}, {"text": " is", "logprob": -0.19593499600887299}, {"text": " that", "logprob": -0.5835586190223694}, {"text": " it", "logprob": -0.0564989410340786}, {"text": "'s", "logprob": -2.0411927700042725}, {"text": " a", "logprob": -0.4235418140888214}, {"text": " region", "logprob": -2.8804636001586914}], "answers": ["Piccadilly line"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Denali, 2010 FIFA World Cup, STS-114, Fort Rock Cave, Copernicus, American Golden Topaz, Nepenthes murudensis, Nimrod Glacier, Holin superfamily I, 1986 FIFA World Cup, Akbar Shah, Liu Jishu, Trivial Pursuit, gun shield, Lion Rock Tunnel, French Revolutionary Wars, stigmatomycosis, 8.8 cm SK L/45 naval gun, Pret a Manger, Late Antiquity, Pudendal venous plexus, which one is the most conceptually similar with Southern Uplands?", "pred": " \n\nAnswer:\n\nLate Antiquity. similarity. is not one of the options", "completions_tokens": [{"text": " \n\n", "logprob": -0.16940335929393768}, {"text": "Answer", "logprob": -0.24333083629608154}, {"text": ":\n\n", "logprob": -1.5993375778198242}, {"text": "Late", "logprob": -1.2348769903182983}, {"text": " Ant", "logprob": -8.940656698541716e-06}, {"text": "iqu", "logprob": -8.940656698541716e-06}, {"text": "ity", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -1.004014253616333}, {"text": " similarity", "logprob": -3.0556416511535645}, {"text": ".", "logprob": -0.8422489762306213}, {"text": " is", "logprob": -3.6269145011901855}, {"text": " not", "logprob": -0.78038489818573}, {"text": " one", "logprob": -3.83345627784729}, {"text": " of", "logprob": -0.25301629304885864}, {"text": " the", "logprob": -0.10045933723449707}, {"text": " options", "logprob": -1.25291907787323}], "answers": ["Denali"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Amontillado, 1997 United Kingdom general election, Cultural Revolution, Disneyland Monorail System, Shanidar Cave, Wacken Open Air, 617 Patroclus, Agnes Edwards (craftworker), Nissan L engine, Hirakud Dam, Wadden Sea, Vancouver International Film Festival, Kepler-62e, Mount Royal, Salisbury Cathedral, Messier 100, solar eclipse of May 29, 1919, 1990 FIFA World Cup, djon djon, daf-3, STS-41-B, which one is the most conceptually similar with STS-76?", "pred": " \n\nAnswer: STS-41-B. (has to do with space shuttle", "completions_tokens": [{"text": " \n\n", "logprob": -0.2293800711631775}, {"text": "Answer", "logprob": -0.22792166471481323}, {"text": ":", "logprob": -0.09186530113220215}, {"text": " ST", "logprob": -0.3557611405849457}, {"text": "S", "logprob": -8.940656698541716e-06}, {"text": "-", "logprob": -8.940656698541716e-06}, {"text": "41", "logprob": -8.940656698541716e-06}, {"text": "-B", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.13794061541557312}, {"text": " (", "logprob": -1.7899724245071411}, {"text": "has", "logprob": -8.25735092163086}, {"text": " to", "logprob": -2.838937759399414}, {"text": " do", "logprob": -0.10877326130867004}, {"text": " with", "logprob": -0.005323045887053013}, {"text": " space", "logprob": -0.8919951319694519}, {"text": " shuttle", "logprob": -0.7528557181358337}], "answers": ["STS-41-B"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Grus, Batson venous plexus, Wei Zhongxian, CR2032 battery, Eton College, parathyroid artery, Queensway Tunnel, WonderCon, Nissan SR engine, Joint Direct Attack Munition, Jaguar XK6 engine, Adobe Creek, 2001 United Kingdom general election, Allegheny Mountain Tunnel, Python Conference, Lewis gun, Spinnaker Tower, Bouncing bomb, Glyndebourne Festival Opera, Aponeurosis of the Obliquus externus abdominis, Appalachia, which one is the most conceptually similar with Tesla Powerwall?", "pred": " \n\nAnswer: Spinnaker Tower or Adriatico or T1-liyun", "completions_tokens": [{"text": " \n\n", "logprob": -0.19723987579345703}, {"text": "Answer", "logprob": -0.4894199073314667}, {"text": ":", "logprob": -0.3627367913722992}, {"text": " Sp", "logprob": -4.240739822387695}, {"text": "inn", "logprob": -0.005409840028733015}, {"text": "aker", "logprob": -2.4318398573086597e-05}, {"text": " Tower", "logprob": -2.4318398573086597e-05}, {"text": " or", "logprob": -7.006799221038818}, {"text": " Adri", "logprob": -7.392393589019775}, {"text": "atic", "logprob": -0.1557902991771698}, {"text": "o", "logprob": -0.8824466466903687}, {"text": " or", "logprob": -2.8308725357055664}, {"text": " T", "logprob": -6.135019779205322}, {"text": "1", "logprob": -5.701017379760742}, {"text": "-li", "logprob": -8.994038581848145}, {"text": "yun", "logprob": -5.920156002044678}], "answers": ["CR2032 battery"], "all_classes": "null", "length": 88}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Pluto, Bataan Death March, The Settlers of Catan, Resorts World Sentosa, Pawan Gupta, National Civil Rights Museum, Seokguram, University College Hospital, Burgess Shale, leptin, Who Wants to Be a Millionaire?, Lake Okeechobee, 1566 Icarus, Reflex inguinal ligament, Rawicz, Oxbridge, Surfeit, Apollo 8, Academy of San Carlos, Buzkashi, Corviglia, which one is the most conceptually similar with Wine auction?", "pred": " \n\nGiaered\n\nHi, Im a large language model, Ill", "completions_tokens": [{"text": " \n\n", "logprob": -0.21782749891281128}, {"text": "G", "logprob": -6.977741241455078}, {"text": "ia", "logprob": -6.402248859405518}, {"text": "ered", "logprob": -12.519039154052734}, {"text": "\n\n", "logprob": -2.1842851638793945}, {"text": "Hi", "logprob": -7.152400016784668}, {"text": ",", "logprob": -0.09384621679782867}, {"text": " I", "logprob": -0.4287346601486206}, {"text": "m", "logprob": -2.0951995849609375}, {"text": " a", "logprob": -1.426751732826233}, {"text": " large", "logprob": -0.0008002892718650401}, {"text": " language", "logprob": -2.4318398573086597e-05}, {"text": " model", "logprob": -2.4318398573086597e-05}, {"text": ",", "logprob": -0.2931412160396576}, {"text": " I", "logprob": -0.2644806206226349}, {"text": "ll", "logprob": -0.4853135347366333}], "answers": ["Pawan Gupta"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong horseshoes, Aequorin, London Zoo, Cheng Yuanzhen, Risk, Tampa Bay, Kicking Horse Pass, 2015 Canadian federal election, RuneQuest, police auction, Oswald Poche, Vietnam War, tee-ball, Hipparchus, Cave Hill Cemetery, Laguna de Bay, Langrenus, Blue Glacier, Broadmoor Hospital, Swatara Creek, Methuselah, which one is the most conceptually similar with tactical bombing?", "pred": " Similarity\nLaguna de Bay\nAnswer: None Similarity Widget Similar", "completions_tokens": [{"text": " Similar", "logprob": -6.50263786315918}, {"text": "ity", "logprob": -0.13956670463085175}, {"text": "\n", "logprob": -1.447352409362793}, {"text": "L", "logprob": -4.657928943634033}, {"text": "ag", "logprob": -2.4199192921514623e-05}, {"text": "una", "logprob": -0.005270277615636587}, {"text": " de", "logprob": -8.940656698541716e-06}, {"text": " Bay", "logprob": -8.940656698541716e-06}, {"text": "\n", "logprob": -0.3297867178916931}, {"text": "Answer", "logprob": -0.4197179973125458}, {"text": ":", "logprob": -0.14714764058589935}, {"text": " None", "logprob": -2.455388069152832}, {"text": " Similar", "logprob": -1.5677571296691895}, {"text": "ity", "logprob": -0.019190596416592598}, {"text": " Widget", "logprob": -12.835040092468262}, {"text": " Similar", "logprob": -1.6119928359985352}], "answers": ["tee-ball"], "all_classes": "null", "length": 73}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong TRAPPIST-1g, nandrolone, BL 6 inch Mk VII naval gun, Kanchenjunga, 1923 United Kingdom general election, 8.8 cm SK L/45 naval gun, police auction, Downtown Hudson Tubes, Lebanon, 1982 FIFA World Cup, Oswald Poche, Wheat leaf rust, Via Lattea, Fortress of Mimoyecques, Battle of Jutland, Ford Pinto engine, Xynotyro, rs6314, 2008 Sichuan earthquake, Solar eclipse of July 16, 2186, Parrott rifle, which one is the most conceptually similar with Belgium?", "pred": " \n\nAnswer: Lebanon. many people currently living within present-day Belgium had names that", "completions_tokens": [{"text": " \n\n", "logprob": -0.15315307676792145}, {"text": "Answer", "logprob": -0.11313037574291229}, {"text": ":", "logprob": -0.07676281780004501}, {"text": " Lebanon", "logprob": -1.4574295282363892}, {"text": ".", "logprob": -0.5047773718833923}, {"text": " many", "logprob": -11.104463577270508}, {"text": " people", "logprob": -2.3167877197265625}, {"text": " currently", "logprob": -8.147120475769043}, {"text": " living", "logprob": -2.6018171310424805}, {"text": " within", "logprob": -5.0304646492004395}, {"text": " present", "logprob": -5.593096733093262}, {"text": "-day", "logprob": -0.4940159320831299}, {"text": " Belgium", "logprob": -1.5560697317123413}, {"text": " had", "logprob": -4.439986228942871}, {"text": " names", "logprob": -6.792239189147949}, {"text": " that", "logprob": -1.1020907163619995}], "answers": ["Lebanon"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong International Congress of Chinese Mathematicians, Paris Commune, Tudor period, The Settlers of Catan, Narragansett Bay, 2 Pallas, Vostok 6, late Middle Ages, colony collapse disorder, UEFA Euro 2008, 3.7 cm SK C/30, Sun, Legacy Way, Gator Bowl, Eurovision Song Contest 2012, myrrh, Tesla Powerwall, Apsley House, Monoceros, 1999 World Championships in Athletics, nandrolone, which one is the most conceptually similar with Regulus?", "pred": " \n\nAnswer: Sun. 23andMe, Alibaba Group, video content,", "completions_tokens": [{"text": " \n\n", "logprob": -0.22913628816604614}, {"text": "Answer", "logprob": -0.1314135193824768}, {"text": ":", "logprob": -0.043154288083314896}, {"text": " Sun", "logprob": -1.5251803398132324}, {"text": ".", "logprob": -0.5825939178466797}, {"text": " ", "logprob": -2.3103787899017334}, {"text": "23", "logprob": -5.829813003540039}, {"text": "and", "logprob": -1.9240460395812988}, {"text": "Me", "logprob": -0.06028943136334419}, {"text": ",", "logprob": -0.7159587740898132}, {"text": " Alibaba", "logprob": -5.61454963684082}, {"text": " Group", "logprob": -0.07960502058267593}, {"text": ",", "logprob": -0.009537961333990097}, {"text": " video", "logprob": -9.916780471801758}, {"text": " content", "logprob": -4.688699245452881}, {"text": ",", "logprob": -0.9129752516746521}], "answers": ["Sun"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Major aortopulmonary collateral artery, Nike Missile Site HM-69, Falklands War, Siam Paragon, Bretton Woods Conference, Fort Monroe, Battle of Arras, tooth loss, 1994 FIFA World Cup, Brisbane Central Technical College, Colony of New South Wales, Tudor period, stigmatomycosis, Franconia, Lake Okeechobee, Landsberg Prison, Watts Towers, LA Film Festival, Fiescher Glacier, compressed tea, Atlanta, which one is the most conceptually similar with Peri-implantitis?", "pred": " \n\nAnswer: Tooth loss. 360(b10724dqw1z39", "completions_tokens": [{"text": " \n\n", "logprob": -0.1471065729856491}, {"text": "Answer", "logprob": -0.2217748612165451}, {"text": ":", "logprob": -0.10346910357475281}, {"text": " Tooth", "logprob": -2.100663900375366}, {"text": " loss", "logprob": -0.016359955072402954}, {"text": ".", "logprob": -0.053585462272167206}, {"text": " ", "logprob": -2.4324722290039062}, {"text": "360", "logprob": -8.314114570617676}, {"text": "(b", "logprob": -10.05759048461914}, {"text": "107", "logprob": -13.443912506103516}, {"text": "24", "logprob": -6.2719950675964355}, {"text": "dq", "logprob": -10.484151840209961}, {"text": "w", "logprob": -6.6439924240112305}, {"text": "1", "logprob": -3.4094960689544678}, {"text": "z", "logprob": -4.022462368011475}, {"text": "39", "logprob": -6.548979759216309}], "answers": ["tooth loss"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Nissan L engine, Cl-transporting ATPase, Dali Man, Temple Newsam, Ford flathead V8 engine, nerve growth factor, The Many Adventures of Winnie the Pooh, Siberia, DSC Cricket Stadium, Chicago Water Tower, Aequorin, Baikonur Cosmodrome Site 45, leptin, Botryosphaeria stevensii, Vallnord, The Future of Freedom Conference, Nena, daf-8, Central Coast AVA, Aponeurosis of the Obliquus externus abdominis, corticotropin releasing hormone, which one is the most conceptually similar with Doubletime?", "pred": " Doubletime\n\nApollo Sacrificial Kochia Pyrifer LinkFluid Kessel Eins", "completions_tokens": [{"text": " Double", "logprob": -3.1535918712615967}, {"text": "time", "logprob": -0.016615230590105057}, {"text": "\n\n", "logprob": -3.3244268894195557}, {"text": "Apollo", "logprob": -9.351884841918945}, {"text": " Sacr", "logprob": -12.034460067749023}, {"text": "ificial", "logprob": -2.376084804534912}, {"text": " Koch", "logprob": -12.121865272521973}, {"text": "ia", "logprob": -3.529054641723633}, {"text": " Py", "logprob": -8.041074752807617}, {"text": "r", "logprob": -4.859992027282715}, {"text": "ifer", "logprob": -3.9743692874908447}, {"text": " Link", "logprob": -11.42137622833252}, {"text": "Fluid", "logprob": -12.59140682220459}, {"text": " K", "logprob": -7.223335266113281}, {"text": "essel", "logprob": -6.5601420402526855}, {"text": " Eins", "logprob": -8.409296989440918}], "answers": ["daf-8"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Beau Sancy, Cygnus X-1, plantar Lisfranc ligament, Battle of France, Anno Domini, Kilmainham Gaol, Beartooth Basin Summer Ski Area, HD 219134b, Pikes Peak, RuneQuest, Corrientes, Weddell Sea, Cave of the Patriarchs, nandrolone, Blackfriars Bridge, Gotthard railway, Puppis, CR2025, Tesla Powerwall, Mount Kailash, Lake Pontchartrain, which one is the most conceptually similar with Maastrichtian?", "pred": " \n\nAnswer: The others are entities of different type. However, of the others", "completions_tokens": [{"text": " \n\n", "logprob": -0.26685118675231934}, {"text": "Answer", "logprob": -0.3826838433742523}, {"text": ":", "logprob": -0.125337615609169}, {"text": " The", "logprob": -5.0278120040893555}, {"text": " others", "logprob": -3.174844980239868}, {"text": " are", "logprob": -0.5481564998626709}, {"text": " entities", "logprob": -5.044478416442871}, {"text": " of", "logprob": -2.051980495452881}, {"text": " different", "logprob": -0.6416497826576233}, {"text": " type", "logprob": -3.0457968711853027}, {"text": ".", "logprob": -1.2619518041610718}, {"text": " However", "logprob": -1.5961637496948242}, {"text": ",", "logprob": -0.03625967726111412}, {"text": " of", "logprob": -4.931049346923828}, {"text": " the", "logprob": -0.22320438921451569}, {"text": " others", "logprob": -5.921875}], "answers": ["Anno Domini"], "all_classes": "null", "length": 78}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Tenughat Dam, Moliterno, RuneQuest, Phoenix Raceway, Brenner Base Tunnel, Dungeons & Dragons Basic Set, Newport Country Club, Agnes Edwards (craftworker), Old Course at St Andrews, Pawan Gupta, WS2B, Wine auction, Liu Jishu, Enewetak Atoll, Jansky, Harborplace, Alexander Valley AVA, Fort Sill, Nashville, National Soccer Hall of Fame, World of Motion, which one is the most conceptually similar with Flyball?", "pred": " \n\nAnswer: \nJansky. Not to mention the sport or the field", "completions_tokens": [{"text": " \n\n", "logprob": -0.5050231218338013}, {"text": "Answer", "logprob": -0.8211337924003601}, {"text": ":", "logprob": -0.3011615574359894}, {"text": " \n", "logprob": -3.7582497596740723}, {"text": "J", "logprob": -2.9162657260894775}, {"text": "ans", "logprob": -0.007772677578032017}, {"text": "ky", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.7172744870185852}, {"text": " Not", "logprob": -5.281136512756348}, {"text": " to", "logprob": -5.054512977600098}, {"text": " mention", "logprob": -2.683922290802002}, {"text": " the", "logprob": -1.349289894104004}, {"text": " sport", "logprob": -4.421089172363281}, {"text": " or", "logprob": -3.8604469299316406}, {"text": " the", "logprob": -1.2125080823898315}, {"text": " field", "logprob": -5.1316633224487305}], "answers": ["National Soccer Hall of Fame"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Messier 74, South Pass, Clare Valley, Uptown Hudson Tubes, Brisbane Cricket Ground, Lake Balaton, Great Mogul Diamond, Yasukuni Shrine, Coma Berenices, Botryosphaeria stevensii, Stelvio Pass, Christian the lion, Mersey Tunnels, Diplodia mutila, Dali Man, Phytophthora ramorum, Ourasphaira giraldae, Guantanamo Bay Naval Base, Rongbuk Glacier, Cotswolds, Acacia baileyana, which one is the most conceptually similar with Allium ursinum?", "pred": "    \nAnswer: Allium ursinum. Allium ursinum", "completions_tokens": [{"text": "    \n", "logprob": -6.152173042297363}, {"text": "Answer", "logprob": -0.2696271538734436}, {"text": ":", "logprob": -0.23209744691848755}, {"text": " All", "logprob": -0.24384230375289917}, {"text": "ium", "logprob": -2.4199192921514623e-05}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "urs", "logprob": -8.940656698541716e-06}, {"text": "in", "logprob": -8.940656698541716e-06}, {"text": "um", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.7740145325660706}, {"text": " All", "logprob": -2.883768081665039}, {"text": "ium", "logprob": -0.0171695277094841}, {"text": " ", "logprob": -0.027998462319374084}, {"text": "urs", "logprob": -8.940656698541716e-06}, {"text": "in", "logprob": -8.940656698541716e-06}, {"text": "um", "logprob": -2.4318398573086597e-05}], "answers": ["Acacia baileyana"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1960 Democratic National Convention, Idukki Dam, Botryosphaeria stevensii, Sagittarius Dwarf Elliptical Galaxy, djon djon, 2006 European Athletics Championships, NBA Draft Lottery, London Zoo, 2011 AFL season, Super Bowl LV, Von Willebrand factor, Boxing Day, Venice Film Festival, Fall of Constantinople, Super Bowl XXXVI, nandrolone, Battle of Chancellorsville, Third Imperial, Covent Garden, Mare Island Naval Shipyard, Manhattan Bridge, which one is the most conceptually similar with Hundred Days Offensive?", "pred": " \n\nAnswer: Third Imperial (least but similar as all others are more dissipative", "completions_tokens": [{"text": " \n\n", "logprob": -0.2195393294095993}, {"text": "Answer", "logprob": -0.7699728012084961}, {"text": ":", "logprob": -0.3627367913722992}, {"text": " Third", "logprob": -1.4457173347473145}, {"text": " Imperial", "logprob": -2.4199192921514623e-05}, {"text": " (", "logprob": -2.2613883018493652}, {"text": "least", "logprob": -7.439126014709473}, {"text": " but", "logprob": -5.221796989440918}, {"text": " similar", "logprob": -3.1562485694885254}, {"text": " as", "logprob": -2.6517693996429443}, {"text": " all", "logprob": -1.9991836547851562}, {"text": " others", "logprob": -2.250887870788574}, {"text": " are", "logprob": -0.24580030143260956}, {"text": " more", "logprob": -2.898448944091797}, {"text": " dissip", "logprob": -9.947609901428223}, {"text": "ative", "logprob": -0.09825434535741806}], "answers": ["Mare Island Naval Shipyard"], "all_classes": "null", "length": 95}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Raffles Hotel, Frankfurt City Tunnel, Golden Gate Park, Swatara Creek, David, 2018 Pakistani general election, Super Bowl XX, Barents Sea, New York City water supply system, Warhammer 40,000, London Zoo, Lollapalooza, 2008 Sichuan earthquake, Kicking Horse Pass, Mercury-Atlas 6, Outfest, pubovaginal muscle, Deneb, United States Army Air Forces, Chulalongkorn University, Peter Pan syndrome, which one is the most conceptually similar with 2015 World Aquatics Championships?", "pred": " TRUE or FALSE\n\nAnswer: FALSE (The 2015 World Aquatics Championships", "completions_tokens": [{"text": " TRUE", "logprob": -5.710716247558594}, {"text": " or", "logprob": -0.585550844669342}, {"text": " FALSE", "logprob": -2.4318398573086597e-05}, {"text": "\n\n", "logprob": -0.8027198314666748}, {"text": "Answer", "logprob": -0.26704514026641846}, {"text": ":", "logprob": -0.0032550706528127193}, {"text": " FALSE", "logprob": -0.0219854936003685}, {"text": " (", "logprob": -2.072063446044922}, {"text": "The", "logprob": -3.690718412399292}, {"text": " ", "logprob": -0.5613119006156921}, {"text": "201", "logprob": -8.940656698541716e-06}, {"text": "5", "logprob": -0.018246300518512726}, {"text": " World", "logprob": -0.0033579650335013866}, {"text": " Aqu", "logprob": -8.940656698541716e-06}, {"text": "atics", "logprob": -8.940656698541716e-06}, {"text": " Championships", "logprob": -2.4318398573086597e-05}], "answers": ["Super Bowl XX"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Ford Modular engine, Great Wall of China, TRAPPIST-1, Sydney Cricket Ground, Vin jaune, Caciotta, venous angle, 1929 United Kingdom general election, 1954 FIFA World Cup, Naval Air Station Pensacola, Homosexual panic, Canis Minor, STS-74, Berlin Conference, Vallnord, solar eclipse of January 22, 1879, fascial compartments of arm, Griffith Park, 2012 Northern Italy earthquakes, Bosnian War, Longmen Nuclear Power Plant, which one is the most conceptually similar with Wheat leaf rust?", "pred": " \n\nAnswer: Wheat leaf rust. Similarity to conceptually similar entities is dependent", "completions_tokens": [{"text": " \n\n", "logprob": -0.25431814789772034}, {"text": "Answer", "logprob": -0.15818655490875244}, {"text": ":", "logprob": -0.6326746940612793}, {"text": " Wheat", "logprob": -0.5656617879867554}, {"text": " leaf", "logprob": -2.4318398573086597e-05}, {"text": " rust", "logprob": -8.940656698541716e-06}, {"text": ".", "logprob": -0.9048627018928528}, {"text": " Similar", "logprob": -2.609288215637207}, {"text": "ity", "logprob": -0.2475665807723999}, {"text": " to", "logprob": -6.010317802429199}, {"text": " concept", "logprob": -3.380361557006836}, {"text": "ually", "logprob": -0.7033795714378357}, {"text": " similar", "logprob": -0.11390700936317444}, {"text": " entities", "logprob": -1.8899972438812256}, {"text": " is", "logprob": -0.9796464443206787}, {"text": " dependent", "logprob": -5.679378986358643}], "answers": ["Homosexual panic"], "all_classes": "null", "length": 96}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Oswald Poche, Yugoslav Wars, nelson hold, STS-41-B, Yom Kippur War, Estrogen, Tucker Glacier, Eurovision Song Contest 2021, anterolateral ligament, Verticillium wilt, sodium hydroxide, East River Mountain Tunnel, Northeast Corridor, Tehran Conference, SK 46, Beartooth Basin Summer Ski Area, Korean War, The Indian Bean Tree, St James Square, Monmouth, Vaalbara, Yakima Valley AVA, Triassic, which one is the most conceptually similar with Apollo 12?", "pred": " \n\nAnswer: \nTriassic\n\nTrue/False: Triassic is part of", "completions_tokens": [{"text": " \n\n", "logprob": -0.21309760212898254}, {"text": "Answer", "logprob": -1.1002466678619385}, {"text": ":", "logprob": -0.09606342762708664}, {"text": " \n", "logprob": -5.565751075744629}, {"text": "Tri", "logprob": -2.568037271499634}, {"text": "assic", "logprob": -8.940656698541716e-06}, {"text": "\n\n", "logprob": -4.911900043487549}, {"text": "True", "logprob": -2.7818312644958496}, {"text": "/", "logprob": -1.1230695247650146}, {"text": "False", "logprob": -0.09049133211374283}, {"text": ":", "logprob": -0.14005804061889648}, {"text": " Tri", "logprob": -2.5116188526153564}, {"text": "assic", "logprob": -8.940656698541716e-06}, {"text": " is", "logprob": -0.717720091342926}, {"text": " part", "logprob": -4.848092079162598}, {"text": " of", "logprob": -2.4318398573086597e-05}], "answers": ["STS-41-B"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Tesla Powerwall, Althorp, Vostok 6, Kveik, police auction, Sphenomandibularis, Heineken, Suntec City, Tian Lingzi, precerebral artery, 1999 World Championships in Athletics, British Museum, ammonia, L-valine, 2017 World Baseball Classic, Pawan Gupta, Great Salt Lake, Nissan SR engine, Notre-Dame de Paris, Cave Hill Cemetery, Jacob Diamond, which one is the most conceptually similar with Cappadocia?", "pred": " \n\nANSWER: Cave Hill Cemetery.", "completions_tokens": [{"text": " \n\n", "logprob": -0.3397482633590698}, {"text": "ANS", "logprob": -2.0604121685028076}, {"text": "WER", "logprob": -8.940656698541716e-06}, {"text": ":", "logprob": -8.940656698541716e-06}, {"text": " Cave", "logprob": -1.6070672273635864}, {"text": " Hill", "logprob": -2.4318398573086597e-05}, {"text": " Cemetery", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.2596798837184906}, {"text": "<|eot_id|>", "logprob": -4.110112190246582}], "answers": ["Notre-Dame de Paris"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Eurovision Song Contest 2019, Eastern Harbour Crossing, HM Prison Pentonville, Nabulsi cheese, solar eclipse of August 18, 1868, St Giles Circus, 4179 Toutatis, Upper East Side, Apple Worldwide Developers Conference, Waverley Park, Arnold Arboretum, Hudson Bay, Tomorrowland, Intestinal arteries, Perseus, Cahokia, solar eclipse of November 25, 2011, United States Army War College, Patriot Place, Gator Bowl, Free Trade Hall, which one is the most conceptually similar with athletics at the 2016 Summer Paralympics?", "pred": " \n\nAnswer: Cahokia.  (evars'Note: Question similar with", "completions_tokens": [{"text": " \n\n", "logprob": -0.06649891287088394}, {"text": "Answer", "logprob": -0.3285062611103058}, {"text": ":", "logprob": -0.050260305404663086}, {"text": " Cah", "logprob": -4.152883529663086}, {"text": "okia", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.7721211910247803}, {"text": " ", "logprob": -1.9084163904190063}, {"text": " (", "logprob": -2.371494770050049}, {"text": "e", "logprob": -9.595670700073242}, {"text": "vars", "logprob": -10.003717422485352}, {"text": "'", "logprob": -8.365938186645508}, {"text": "Note", "logprob": -5.96390438079834}, {"text": ":", "logprob": -0.427345335483551}, {"text": " Question", "logprob": -7.110517501831055}, {"text": " similar", "logprob": -5.252813816070557}, {"text": " with", "logprob": -2.7340712547302246}], "answers": ["Gator Bowl"], "all_classes": "null", "length": 100}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Voskhod 2, Agnes Edwards (craftworker), Cl-transporting ATPase, Moliterno, Edwardian era, Xynotyro, Estrogen, Reggianito, Sawtooth Wilderness, Cleveland Clinic, River Teme, Tate Modern, Pabst Blue Ribbon, Anglesey, Kingfisher, 2008 Pakistani general election, Wye Oak, Upsilon Andromedae d, motor-paced racing, Bodhi Tree, Quebec Conference, which one is the most conceptually similar with Fort Ord?", "pred": " \n\nAnswer: Wye Oak.  Brought down  in 2017", "completions_tokens": [{"text": " \n\n", "logprob": -0.43913519382476807}, {"text": "Answer", "logprob": -0.09647062420845032}, {"text": ":", "logprob": -0.14716091752052307}, {"text": " W", "logprob": -2.77915620803833}, {"text": "ye", "logprob": -2.4318398573086597e-05}, {"text": " Oak", "logprob": -2.4318398573086597e-05}, {"text": ".", "logprob": -0.09361599385738373}, {"text": " ", "logprob": -2.89774751663208}, {"text": " B", "logprob": -6.946310043334961}, {"text": "rought", "logprob": -4.068304061889648}, {"text": " down", "logprob": -0.704011082649231}, {"text": " ", "logprob": -3.2391436100006104}, {"text": " in", "logprob": -2.3218820095062256}, {"text": " ", "logprob": -0.16388607025146484}, {"text": "201", "logprob": -1.0142967700958252}, {"text": "7", "logprob": -0.013693559914827347}], "answers": ["Sawtooth Wilderness"], "all_classes": "null", "length": 78}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Buzkashi, Hoffman tunnel, parathyroid hormone, Zeta Sagittarii, solar eclipse of June 25, 2150, Super Bowl XXXV, Idursulfase, Eurovision Song Contest 2021, Saudi Arabia, Battersea Power Station, 2016 North Canterbury earthquake, 1953 Ionian Earthquake, 1755 Lisbon earthquake, Brisbane Cricket Ground, 2015 Rugby World Cup, Risk, STS-134, 3.7 cm SK C/30, Holin superfamily V, Charter Oak, Yellowstone volcano, which one is the most conceptually similar with SN 1572?", "pred": " \n\nAnswer: Solar Eclipse (if you asked for the more similar, you should", "completions_tokens": [{"text": " \n\n", "logprob": -0.5734249949455261}, {"text": "Answer", "logprob": -0.4672381281852722}, {"text": ":", "logprob": -0.7575488686561584}, {"text": " Solar", "logprob": -2.260728597640991}, {"text": " Eclipse", "logprob": -1.7304784059524536}, {"text": " (", "logprob": -2.9703190326690674}, {"text": "if", "logprob": -5.309186935424805}, {"text": " you", "logprob": -1.4014533758163452}, {"text": " asked", "logprob": -5.393485069274902}, {"text": " for", "logprob": -1.1913487911224365}, {"text": " the", "logprob": -1.475481390953064}, {"text": " more", "logprob": -8.112820625305176}, {"text": " similar", "logprob": -1.9470624923706055}, {"text": ",", "logprob": -3.729097366333008}, {"text": " you", "logprob": -1.0632266998291016}, {"text": " should", "logprob": -1.807300329208374}], "answers": ["Zeta Sagittarii"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 2004 Canadian federal election, Manot 1, precerebral artery, Reflex inguinal ligament, 2020 ICC World Twenty20 Qualifier, Art Institute of Chicago, KNM WT 17000, Queensway Tunnel, St Andrews Links, thoracoepigastric vein, TM 1517, Mount Apo, Weddell Sea, Chilenia, Grus, Tsiolkovskiy, stigmatomycosis, Fort D.A. Russell, 2007 Swiss federal election, Antares, 1935 United Kingdom general election, which one is the most conceptually similar with dorsal carpal arch?", "pred": " \n\n Step 1: We need to establish which of the given options is concept", "completions_tokens": [{"text": " \n\n", "logprob": -0.10677137225866318}, {"text": " Step", "logprob": -5.081216812133789}, {"text": " ", "logprob": -8.940656698541716e-06}, {"text": "1", "logprob": -2.4318398573086597e-05}, {"text": ":", "logprob": -2.4318398573086597e-05}, {"text": " We", "logprob": -4.8868408203125}, {"text": " need", "logprob": -0.15338420867919922}, {"text": " to", "logprob": -8.940656698541716e-06}, {"text": " establish", "logprob": -5.42889928817749}, {"text": " which", "logprob": -2.350086212158203}, {"text": " of", "logprob": -0.7735639810562134}, {"text": " the", "logprob": -0.04656103253364563}, {"text": " given", "logprob": -1.267093539237976}, {"text": " options", "logprob": -0.5473043918609619}, {"text": " is", "logprob": -0.3157832622528076}, {"text": " concept", "logprob": -1.9165502786636353}], "answers": ["precerebral artery"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Irish Rebellion of 1798, Soyuz 5, Torrey Pines Golf Course, UEFA Euro 2012, 2015 World Championships in Athletics, Theoretical Archaeology Group, Greenland ice sheet, Osterley Park, Fleet Street, STS-122, 2003 Rugby World Cup, TIFF Bell Lightbox, Beaux-Arts de Paris, 1962 FIFA World Cup, The Proms, Botryosphaeria stevensii, Prestwick Golf Club, Four Mile Run, Bluewater (shopping centre), St Giles Circus, Three Mile Island Nuclear Generating Station, which one is the most conceptually similar with Prague Spring?", "pred": " \n\nAnswer: Prague Spring. But Prague Spring was not listed. The next one", "completions_tokens": [{"text": " \n\n", "logprob": -0.13501578569412231}, {"text": "Answer", "logprob": -0.34342294931411743}, {"text": ":", "logprob": -0.10978082567453384}, {"text": " Prague", "logprob": -2.9308319091796875}, {"text": " Spring", "logprob": -0.1293088048696518}, {"text": ".", "logprob": -0.9991134405136108}, {"text": " But", "logprob": -4.340950965881348}, {"text": " Prague", "logprob": -1.9760491847991943}, {"text": " Spring", "logprob": -0.13429448008537292}, {"text": " was", "logprob": -2.3485665321350098}, {"text": " not", "logprob": -0.12784606218338013}, {"text": " listed", "logprob": -1.632361888885498}, {"text": ".", "logprob": -0.7467211484909058}, {"text": " The", "logprob": -2.867943048477173}, {"text": " next", "logprob": -2.6742825508117676}, {"text": " one", "logprob": -3.6327743530273438}], "answers": ["Irish Rebellion of 1798"], "all_classes": "null", "length": 104}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Wine auction, Santa Fe Trail, chitin, twelfth grade, Circuit de Spa-Francorchamps, plantar Lisfranc ligament, recurrent artery of Heubner, South Pass, Austin Film Festival, 1700 Cascadia earthquake, Reflex inguinal ligament, The Whip, Phoenix Park, Michael Spondyles, Basilica di Santa Maria Maggiore, Sundance Film Festival, Sarawak General Hospital, Levator claviculae muscle, leptin, common facial vein, KNM ER 406, which one is the most conceptually similar with lateral rotator group?", "pred": " \n\nThe best answer is  The Whip. The Whip is the muscle of the", "completions_tokens": [{"text": " \n\n", "logprob": -0.07344695925712585}, {"text": "The", "logprob": -5.007014274597168}, {"text": " best", "logprob": -0.8495652675628662}, {"text": " answer", "logprob": -2.4318398573086597e-05}, {"text": " is", "logprob": -8.940656698541716e-06}, {"text": " ", "logprob": -1.128446102142334}, {"text": " The", "logprob": -1.1661168336868286}, {"text": " Whip", "logprob": -0.01456544827669859}, {"text": ".", "logprob": -2.4318398573086597e-05}, {"text": " The", "logprob": -1.1378165483474731}, {"text": " Whip", "logprob": -0.7725847363471985}, {"text": " is", "logprob": -0.3081505596637726}, {"text": " the", "logprob": -2.153369426727295}, {"text": " muscle", "logprob": -2.0496826171875}, {"text": " of", "logprob": -1.7413746118545532}, {"text": " the", "logprob": -0.8155320286750793}], "answers": ["Levator claviculae muscle"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Super Bowl XXXIV, Southwestern Exposition and Livestock Show, djon djon, bypass ratio, Leafy, Radicular artery, Augusta National Golf Club, intercostal veins, Palmar plate, Pikes Peak International Hill Climb, Autodromo Nazionale Monza, 2002 FIFA World Cup, Warhammer Fantasy Battle, Vega, Tokaj wine region, Tau9 Eridani, Battersea Power Station, Newport Folk Festival, Croatian War of Independence, BFI London Film Festival, UEFA Euro 2000, which one is the most conceptually similar with Holborn?", "pred": " \nAnswer: NrSEMBusta blastrium Latina DolmothLblHolborn appears", "completions_tokens": [{"text": " \n", "logprob": -2.2795989513397217}, {"text": "Answer", "logprob": -0.4482104480266571}, {"text": ":", "logprob": -0.2386437952518463}, {"text": " Nr", "logprob": -12.717476844787598}, {"text": "SEMB", "logprob": -14.128506660461426}, {"text": "usta", "logprob": -8.965338706970215}, {"text": " blast", "logprob": -12.442566871643066}, {"text": "rium", "logprob": -10.898691177368164}, {"text": " Latina", "logprob": -10.776851654052734}, {"text": " Dol", "logprob": -8.60257339477539}, {"text": "mo", "logprob": -8.485650062561035}, {"text": "th", "logprob": -7.4634528160095215}, {"text": "Lbl", "logprob": -13.632991790771484}, {"text": "Hol", "logprob": -5.349913597106934}, {"text": "born", "logprob": -0.5902290940284729}, {"text": " appears", "logprob": -8.244894027709961}], "answers": ["Autodromo Nazionale Monza"], "all_classes": "null", "length": 96}
