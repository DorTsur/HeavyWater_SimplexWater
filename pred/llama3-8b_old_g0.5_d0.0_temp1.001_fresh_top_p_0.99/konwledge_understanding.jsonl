{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Specieses have a cellulose wall and other polysaccharides.' true or false?", "pred": " False\n\nAnswer: True\nI'll do my other question about it.\n The", "completions_tokens": [{"text": " False", "logprob": -2.00128173828125}, {"text": "\n\n", "logprob": -0.4919964075088501}, {"text": "Answer", "logprob": -1.5532708168029785}, {"text": ":", "logprob": -0.09826860576868057}, {"text": " True", "logprob": -1.5423587560653687}, {"text": "\n", "logprob": -0.1945917159318924}, {"text": "I", "logprob": -4.336452007293701}, {"text": "'ll", "logprob": -3.086648941040039}, {"text": " do", "logprob": -1.4123737812042236}, {"text": " my", "logprob": -0.23649059236049652}, {"text": " other", "logprob": -0.508879542350769}, {"text": " question", "logprob": -1.9587996006011963}, {"text": " about", "logprob": -3.1122283935546875}, {"text": " it", "logprob": -7.401785373687744}, {"text": ".\n", "logprob": -3.2603068351745605}, {"text": " The", "logprob": -5.58034610748291}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'canals are public properties.' true or false?", "pred": " \nAnswer:\nTrue. Conclusion: Truth can be inherrent in any statements and", "completions_tokens": [{"text": " \n", "logprob": -1.230593204498291}, {"text": "Answer", "logprob": -0.0482889749109745}, {"text": ":\n", "logprob": -3.670989751815796}, {"text": "True", "logprob": -2.032611846923828}, {"text": ".", "logprob": -0.31055811047554016}, {"text": " Conclusion", "logprob": -9.097281455993652}, {"text": ":", "logprob": -0.4602314829826355}, {"text": " Truth", "logprob": -7.338373184204102}, {"text": " can", "logprob": -3.30013108253479}, {"text": " be", "logprob": -0.22966709733009338}, {"text": " inher", "logprob": -11.834199905395508}, {"text": "rent", "logprob": -2.1923532485961914}, {"text": " in", "logprob": -0.992676317691803}, {"text": " any", "logprob": -3.029320240020752}, {"text": " statements", "logprob": -4.416021347045898}, {"text": " and", "logprob": -3.1685292720794678}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'minerals are drugs with potential serious adverse reactions.' true or false?", "pred": " \n\nA) False \nB) A doctor is knowledgeable but has no inner peace", "completions_tokens": [{"text": " \n\n", "logprob": -0.5131193399429321}, {"text": "A", "logprob": -0.11490866541862488}, {"text": ")", "logprob": -0.07391561567783356}, {"text": " False", "logprob": -1.560523271560669}, {"text": " \n", "logprob": -2.454516649246216}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -3.179267644882202}, {"text": " doctor", "logprob": -6.063019752502441}, {"text": " is", "logprob": -2.364410877227783}, {"text": " knowledgeable", "logprob": -4.080621719360352}, {"text": " but", "logprob": -4.78971529006958}, {"text": " has", "logprob": -3.161165952682495}, {"text": " no", "logprob": -1.6343181133270264}, {"text": " inner", "logprob": -9.839365005493164}, {"text": " peace", "logprob": -2.8720459938049316}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'parks provide water.' true or false?", "pred": "  Following string method is used.\nString s = \"parks provide water\";\n", "completions_tokens": [{"text": " ", "logprob": -3.684049367904663}, {"text": " Following", "logprob": -9.521949768066406}, {"text": " string", "logprob": -9.658308982849121}, {"text": " method", "logprob": -7.345716953277588}, {"text": " is", "logprob": -2.1558754444122314}, {"text": " used", "logprob": -0.33698782324790955}, {"text": ".\n", "logprob": -5.047314643859863}, {"text": "String", "logprob": -3.1436643600463867}, {"text": " s", "logprob": -1.3608238697052002}, {"text": " =", "logprob": -0.2512953281402588}, {"text": " \"", "logprob": -0.14303791522979736}, {"text": "p", "logprob": -0.34925514459609985}, {"text": "arks", "logprob": -1.3112935448589269e-05}, {"text": " provide", "logprob": -0.24161405861377716}, {"text": " water", "logprob": -0.05297049507498741}, {"text": "\";\n", "logprob": -1.4370671510696411}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'railway lines consist of numerous stars and are held together by gravity.' true or false?", "pred": " \n\nA) False\nB) False\nC) A\nD) False", "completions_tokens": [{"text": " \n\n", "logprob": -0.5222793221473694}, {"text": "A", "logprob": -0.23094074428081512}, {"text": ")", "logprob": -0.1565922051668167}, {"text": " False", "logprob": -1.900425910949707}, {"text": "\n", "logprob": -0.1138792410492897}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -1.9116547107696533}, {"text": "\n", "logprob": -0.08609438687562943}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -0.8539416790008545}, {"text": "\n", "logprob": -1.40709388256073}, {"text": "D", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.9213374853134155}], "answers": ["false"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Most bacteria are decomposers, so they break down all the dead material.' true or false?", "pred": " \n\nA\nB\nC\nD\nE\nF\nG\n\nStep", "completions_tokens": [{"text": " \n\n", "logprob": -0.7337998747825623}, {"text": "A", "logprob": -0.5143401622772217}, {"text": "\n", "logprob": -2.7244677543640137}, {"text": "B", "logprob": -0.1321006566286087}, {"text": "\n", "logprob": -1.3112935448589269e-05}, {"text": "C", "logprob": -0.015615217387676239}, {"text": "\n", "logprob": -0.031759291887283325}, {"text": "D", "logprob": -0.018781563267111778}, {"text": "\n", "logprob": -0.3487148582935333}, {"text": "E", "logprob": -0.4498066008090973}, {"text": "\n", "logprob": -1.3469836711883545}, {"text": "F", "logprob": -0.7744874358177185}, {"text": "\n", "logprob": -0.3627302646636963}, {"text": "G", "logprob": -0.2387695163488388}, {"text": "\n\n", "logprob": -2.1114487648010254}, {"text": "Step", "logprob": -2.22599196434021}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'caves means any place where an apiary is located.' true or false?", "pred": " \nAnswer: Answer: False. Knowledge is not a physical object that can be", "completions_tokens": [{"text": " \n", "logprob": -1.1381313800811768}, {"text": "Answer", "logprob": -0.1252654790878296}, {"text": ":", "logprob": -0.11699233949184418}, {"text": " Answer", "logprob": -6.950954914093018}, {"text": ":", "logprob": -0.8353358507156372}, {"text": " False", "logprob": -0.4116055369377136}, {"text": ".", "logprob": -0.1371000111103058}, {"text": " Knowledge", "logprob": -3.7823877334594727}, {"text": " is", "logprob": -1.9425212144851685}, {"text": " not", "logprob": -2.0422253608703613}, {"text": " a", "logprob": -2.3257193565368652}, {"text": " physical", "logprob": -2.285989284515381}, {"text": " object", "logprob": -1.7354228496551514}, {"text": " that", "logprob": -2.537693738937378}, {"text": " can", "logprob": -0.29911404848098755}, {"text": " be", "logprob": -0.07451684772968292}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Monuments commemorating great individuals and important events are a part of our culture.' true or false?", "pred": " false\nAnswer: True Other True False More Similar Less  Explanation: The statement", "completions_tokens": [{"text": " false", "logprob": -5.450782775878906}, {"text": "\n", "logprob": -1.3785167932510376}, {"text": "Answer", "logprob": -0.018807416781783104}, {"text": ":", "logprob": -0.014017580077052116}, {"text": " True", "logprob": -0.48125818371772766}, {"text": " Other", "logprob": -7.897356986999512}, {"text": " True", "logprob": -7.568334579467773}, {"text": " False", "logprob": -1.0274324417114258}, {"text": " More", "logprob": -6.408042907714844}, {"text": " Similar", "logprob": -1.9321129322052002}, {"text": " Less", "logprob": -1.594988465309143}, {"text": " ", "logprob": -3.7070813179016113}, {"text": " Explanation", "logprob": -4.262360572814941}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " The", "logprob": -0.7120803594589233}, {"text": " statement", "logprob": -0.015381990931928158}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Vaccines are one of the most cost-effective tools in preventing disease and death.' true or false?", "pred": " \nAnswer:\n\n TRUE.    (Source: CDC) TRUE. (Source:", "completions_tokens": [{"text": " \n", "logprob": -1.3149195909500122}, {"text": "Answer", "logprob": -0.013527982868254185}, {"text": ":\n\n", "logprob": -2.238206624984741}, {"text": " TRUE", "logprob": -5.183892250061035}, {"text": ".", "logprob": -0.014276274479925632}, {"text": "   ", "logprob": -4.612844467163086}, {"text": " (", "logprob": -3.453084945678711}, {"text": "Source", "logprob": -5.034665584564209}, {"text": ":", "logprob": -0.13710209727287292}, {"text": " CDC", "logprob": -3.3686342239379883}, {"text": ")", "logprob": -0.5054306387901306}, {"text": " TRUE", "logprob": -4.838407516479492}, {"text": ".", "logprob": -0.15527287125587463}, {"text": " (", "logprob": -1.649124026298523}, {"text": "Source", "logprob": -0.010779603384435177}, {"text": ":", "logprob": -0.013269918039441109}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Earthquakes are caused by movement.' true or false?", "pred": " (Similarity or comparison here is concerned with the overall nature of the cause-and", "completions_tokens": [{"text": " (", "logprob": -6.130918502807617}, {"text": "Similar", "logprob": -4.932967185974121}, {"text": "ity", "logprob": -0.7195162773132324}, {"text": " or", "logprob": -6.181777477264404}, {"text": " comparison", "logprob": -4.4716596603393555}, {"text": " here", "logprob": -7.7455620765686035}, {"text": " is", "logprob": -1.3635659217834473}, {"text": " concerned", "logprob": -7.420954704284668}, {"text": " with", "logprob": -0.2679583430290222}, {"text": " the", "logprob": -0.9417365193367004}, {"text": " overall", "logprob": -5.946477890014648}, {"text": " nature", "logprob": -3.0169594287872314}, {"text": " of", "logprob": -0.3599591851234436}, {"text": " the", "logprob": -0.4898556172847748}, {"text": " cause", "logprob": -1.8038328886032104}, {"text": "-and", "logprob": -5.839545249938965}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'rivers serve meals.' true or false?", "pred": " \nAnswer: False.", "completions_tokens": [{"text": " \n", "logprob": -1.102966070175171}, {"text": "Answer", "logprob": -0.13010311126708984}, {"text": ":", "logprob": -0.08033100515604019}, {"text": " False", "logprob": -0.32048681378364563}, {"text": ".", "logprob": -0.10136080533266068}, {"text": "<|eot_id|>", "logprob": -1.8304258584976196}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'bones are used for thinking.' true or false?", "pred": " \n\nTrue, False, Similar to \"people will live indefinitely\" \nAnswer:", "completions_tokens": [{"text": " \n\n", "logprob": -0.5671699047088623}, {"text": "True", "logprob": -1.3151519298553467}, {"text": ",", "logprob": -5.107044219970703}, {"text": " False", "logprob": -0.04230184108018875}, {"text": ",", "logprob": -2.27254056930542}, {"text": " Similar", "logprob": -1.029915452003479}, {"text": " to", "logprob": -1.670229434967041}, {"text": " \"", "logprob": -1.650689959526062}, {"text": "people", "logprob": -6.305452346801758}, {"text": " will", "logprob": -7.951544761657715}, {"text": " live", "logprob": -2.110898494720459}, {"text": " indefinitely", "logprob": -5.245174407958984}, {"text": "\"", "logprob": -1.8451316356658936}, {"text": " \n", "logprob": -1.4986553192138672}, {"text": "Answer", "logprob": -0.04411676898598671}, {"text": ":", "logprob": -0.021947942674160004}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Grand Prixes are what people often see when poker is shown on television .' true or false?", "pred": " \n\nA) true\nB) B-Poker, Match Poker\nC)", "completions_tokens": [{"text": " \n\n", "logprob": -0.5623682737350464}, {"text": "A", "logprob": -0.17733587324619293}, {"text": ")", "logprob": -0.01880776882171631}, {"text": " true", "logprob": -3.2425684928894043}, {"text": "\n", "logprob": -0.13433490693569183}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " B", "logprob": -2.4788644313812256}, {"text": "-P", "logprob": -11.648131370544434}, {"text": "oker", "logprob": -0.9090601205825806}, {"text": ",", "logprob": -4.229501724243164}, {"text": " Match", "logprob": -8.548494338989258}, {"text": " Poker", "logprob": -0.6135308742523193}, {"text": "\n", "logprob": -1.4275922775268555}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}], "answers": ["false"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'infrastructures are normally unowned, accessible to all.' true or false?", "pred": " Infrastructure  Answer is false as it depicts \"Resulted in violence\" indicators such", "completions_tokens": [{"text": " Infrastructure", "logprob": -7.864144802093506}, {"text": " ", "logprob": -4.843031406402588}, {"text": " Answer", "logprob": -3.4860615730285645}, {"text": " is", "logprob": -2.510409116744995}, {"text": " false", "logprob": -1.4479831457138062}, {"text": " as", "logprob": -2.9209601879119873}, {"text": " it", "logprob": -2.534644842147827}, {"text": " depicts", "logprob": -8.248565673828125}, {"text": " \"", "logprob": -5.32987642288208}, {"text": "Result", "logprob": -12.168526649475098}, {"text": "ed", "logprob": -5.64263916015625}, {"text": " in", "logprob": -1.0615870952606201}, {"text": " violence", "logprob": -8.075052261352539}, {"text": "\"", "logprob": -1.2243751287460327}, {"text": " indicators", "logprob": -11.32188892364502}, {"text": " such", "logprob": -3.554049015045166}], "answers": ["true"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'fishes adjust their feathers to create or dissipate an insulating layer, as typified by the ostrich .' true or false?", "pred": " \nAnswer: False.]]>]]> html\nTRUE.]]>]]> html\nHTML", "completions_tokens": [{"text": " \n", "logprob": -1.073725700378418}, {"text": "Answer", "logprob": -0.020888926461338997}, {"text": ":", "logprob": -0.05241907015442848}, {"text": " False", "logprob": -0.5812731385231018}, {"text": ".", "logprob": -0.16694962978363037}, {"text": "]]>", "logprob": -7.041195869445801}, {"text": "]]>", "logprob": -1.7074660062789917}, {"text": " html", "logprob": -3.590224266052246}, {"text": "\n", "logprob": -0.4500030279159546}, {"text": "TRUE", "logprob": -3.3076229095458984}, {"text": ".", "logprob": -4.001099586486816}, {"text": "]]>", "logprob": -0.6958398222923279}, {"text": "]]>", "logprob": -0.5368252396583557}, {"text": " html", "logprob": -0.4733189344406128}, {"text": "\n", "logprob": -0.2931300103664398}, {"text": "HTML", "logprob": -7.338605880737305}], "answers": ["false"], "all_classes": "null", "length": 27}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'oceans are people.' true or false?", "pred": " \n\nA) True\nB) False\nC) Oceans\nD)", "completions_tokens": [{"text": " \n\n", "logprob": -0.6606233716011047}, {"text": "A", "logprob": -0.025899305939674377}, {"text": ")", "logprob": -0.06513373553752899}, {"text": " True", "logprob": -0.20951850712299347}, {"text": "\n", "logprob": -0.08656097948551178}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.14159730076789856}, {"text": "\n", "logprob": -0.01146018784493208}, {"text": "C", "logprob": -0.009967317804694176}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " O", "logprob": -1.166783332824707}, {"text": "ceans", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.6313698291778564}, {"text": "D", "logprob": -0.004586296156048775}, {"text": ")", "logprob": -1.3112935448589269e-05}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Animals are amniotes.' true or false?", "pred": " \n\nFree response. Accuracy is crucial in this question. \n\nAnswer: True.", "completions_tokens": [{"text": " \n\n", "logprob": -0.6484184861183167}, {"text": "Free", "logprob": -9.77047348022461}, {"text": " response", "logprob": -1.0524053573608398}, {"text": ".", "logprob": -1.4953900575637817}, {"text": " Accuracy", "logprob": -9.741446495056152}, {"text": " is", "logprob": -0.7118714451789856}, {"text": " crucial", "logprob": -5.034031867980957}, {"text": " in", "logprob": -1.930466890335083}, {"text": " this", "logprob": -0.39241254329681396}, {"text": " question", "logprob": -0.9671053886413574}, {"text": ".", "logprob": -0.6510298252105713}, {"text": " \n\n", "logprob": -0.9308032393455505}, {"text": "Answer", "logprob": -1.03616201877594}, {"text": ":", "logprob": -0.21555572748184204}, {"text": " True", "logprob": -0.8792358636856079}, {"text": ".", "logprob": -0.3627689778804779}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Quarters are time periods.' true or false?", "pred": " \nAnswer: False. The term 'quarters' could mean two different things.", "completions_tokens": [{"text": " \n", "logprob": -1.440042495727539}, {"text": "Answer", "logprob": -0.19025708734989166}, {"text": ":", "logprob": -0.11230190098285675}, {"text": " False", "logprob": -0.5346449613571167}, {"text": ".", "logprob": -0.129953533411026}, {"text": " The", "logprob": -3.4468774795532227}, {"text": " term", "logprob": -1.4519034624099731}, {"text": " '", "logprob": -0.9483027458190918}, {"text": "quarters", "logprob": -0.8980989456176758}, {"text": "'", "logprob": -0.01740889810025692}, {"text": " could", "logprob": -3.9902918338775635}, {"text": " mean", "logprob": -2.8656551837921143}, {"text": " two", "logprob": -3.3290562629699707}, {"text": " different", "logprob": -0.53410404920578}, {"text": " things", "logprob": -0.11247768253087997}, {"text": ".", "logprob": -1.3376017808914185}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'launch pads form a reservoir of tuberculosis, including drug-resistant tuberculosis.' true or false?", "pred": " \nAnswer:\n\nFalse. Launch pads are a term used to describe military bases and", "completions_tokens": [{"text": " \n", "logprob": -1.2873270511627197}, {"text": "Answer", "logprob": -0.036331526935100555}, {"text": ":\n\n", "logprob": -3.4686312675476074}, {"text": "False", "logprob": -0.42374372482299805}, {"text": ".", "logprob": -0.029535742476582527}, {"text": " Launch", "logprob": -2.9877090454101562}, {"text": " pads", "logprob": -0.014553229324519634}, {"text": " are", "logprob": -0.8630642294883728}, {"text": " a", "logprob": -3.3231966495513916}, {"text": " term", "logprob": -1.584073781967163}, {"text": " used", "logprob": -0.5744444131851196}, {"text": " to", "logprob": -1.042701005935669}, {"text": " describe", "logprob": -0.21759065985679626}, {"text": " military", "logprob": -4.612844467163086}, {"text": " bases", "logprob": -0.4849584102630615}, {"text": " and", "logprob": -2.357680082321167}], "answers": ["false"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Every ocean is polluted to some extent.' true or false?", "pred": " \n\nA) True\nB) False\nC) There is insufficient information to", "completions_tokens": [{"text": " \n\n", "logprob": -0.6706051826477051}, {"text": "A", "logprob": -0.34730589389801025}, {"text": ")", "logprob": -0.014683984220027924}, {"text": " True", "logprob": -0.19888176023960114}, {"text": "\n", "logprob": -0.10010013729333878}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -1.2923133373260498}, {"text": "\n", "logprob": -0.043807607144117355}, {"text": "C", "logprob": -0.009813870303332806}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " There", "logprob": -3.3694772720336914}, {"text": " is", "logprob": -0.21378064155578613}, {"text": " insufficient", "logprob": -2.421046257019043}, {"text": " information", "logprob": -0.6194671392440796}, {"text": " to", "logprob": -0.30450353026390076}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Locations experience good drainage.' true or false?", "pred": " False\n\nAnswer: False.  Its does not seem that locations are a subjective", "completions_tokens": [{"text": " False", "logprob": -2.146247386932373}, {"text": "\n\n", "logprob": -0.5152466297149658}, {"text": "Answer", "logprob": -2.1383891105651855}, {"text": ":", "logprob": -0.08854510635137558}, {"text": " False", "logprob": -0.5022386312484741}, {"text": ".", "logprob": -1.568037986755371}, {"text": " ", "logprob": -2.086768627166748}, {"text": " Its", "logprob": -6.105527877807617}, {"text": " does", "logprob": -9.0010347366333}, {"text": " not", "logprob": -0.19359658658504486}, {"text": " seem", "logprob": -3.8393335342407227}, {"text": " that", "logprob": -2.385148525238037}, {"text": " locations", "logprob": -0.9186304211616516}, {"text": " are", "logprob": -2.4597644805908203}, {"text": " a", "logprob": -4.073276519775391}, {"text": " subjective", "logprob": -7.221882343292236}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Golf courses require a lot of water, and many areas of Mexico are dry.' true or false?", "pred": " _______ or true or false\n\n## Step 1: Understanding the components of", "completions_tokens": [{"text": " ______", "logprob": -7.13179874420166}, {"text": "_", "logprob": -1.6756670475006104}, {"text": " or", "logprob": -6.504384994506836}, {"text": " true", "logprob": -4.759342670440674}, {"text": " or", "logprob": -0.9897270202636719}, {"text": " false", "logprob": -0.05761276185512543}, {"text": "\n\n", "logprob": -1.7744364738464355}, {"text": "##", "logprob": -0.8671119809150696}, {"text": " Step", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Understanding", "logprob": -2.1252355575561523}, {"text": " the", "logprob": -1.3112935448589269e-05}, {"text": " components", "logprob": -2.029298782348633}, {"text": " of", "logprob": -1.3112935448589269e-05}], "answers": ["false"], "all_classes": "null", "length": 25}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'lakes can improve or worsen their health by their actions.' true or false?", "pred": " \n\nA) Similarity \\to State\nB) A) Information\nC", "completions_tokens": [{"text": " \n\n", "logprob": -0.4192219376564026}, {"text": "A", "logprob": -0.24778518080711365}, {"text": ")", "logprob": -0.04131690412759781}, {"text": " Similar", "logprob": -9.879311561584473}, {"text": "ity", "logprob": -0.33248668909072876}, {"text": " \\", "logprob": -8.377777099609375}, {"text": "to", "logprob": -3.9485833644866943}, {"text": " State", "logprob": -7.429426193237305}, {"text": "\n", "logprob": -1.9450912475585938}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -6.210301399230957}, {"text": ")", "logprob": -3.6808574199676514}, {"text": " Information", "logprob": -9.356396675109863}, {"text": "\n", "logprob": -0.5179956555366516}, {"text": "C", "logprob": -1.3112935448589269e-05}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'time intervals represents the number of years a teacher has been employed in the public school system.' true or false?", "pred": " \n\nA) True\nB) A time interval could be measured in seconds.", "completions_tokens": [{"text": " \n\n", "logprob": -0.5787158012390137}, {"text": "A", "logprob": -0.1153152734041214}, {"text": ")", "logprob": -0.04430541396141052}, {"text": " True", "logprob": -0.45473504066467285}, {"text": "\n", "logprob": -0.12929528951644897}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -3.126439094543457}, {"text": " time", "logprob": -0.3782666027545929}, {"text": " interval", "logprob": -0.004586296156048775}, {"text": " could", "logprob": -3.916102409362793}, {"text": " be", "logprob": -0.7341859936714172}, {"text": " measured", "logprob": -2.53472900390625}, {"text": " in", "logprob": -0.31030887365341187}, {"text": " seconds", "logprob": -2.0807700157165527}, {"text": ".", "logprob": -4.709637641906738}], "answers": ["false"], "all_classes": "null", "length": 27}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'historic sites come in many different shapes and sizes.' true or false?", "pred": " \n\nA) Historic sites come in many different shapes and sizes.\nB) Question", "completions_tokens": [{"text": " \n\n", "logprob": -0.5236663818359375}, {"text": "A", "logprob": -0.1248747855424881}, {"text": ")", "logprob": -0.004178246948868036}, {"text": " Historic", "logprob": -3.6039469242095947}, {"text": " sites", "logprob": -0.16708944737911224}, {"text": " come", "logprob": -1.294297218322754}, {"text": " in", "logprob": -0.015636811032891273}, {"text": " many", "logprob": -0.13528384268283844}, {"text": " different", "logprob": -0.010158148594200611}, {"text": " shapes", "logprob": -0.08772275596857071}, {"text": " and", "logprob": -0.0777701586484909}, {"text": " sizes", "logprob": -0.016817927360534668}, {"text": ".\n", "logprob": -0.3025796711444855}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Question", "logprob": -10.592536926269531}], "answers": ["true"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Embryology is the science studying the emergence of living order.' true or false?", "pred": " \n\nAnswer: False Historical BACKGROUND (DBQ)  Area of STUDY (", "completions_tokens": [{"text": " \n\n", "logprob": -0.7390901446342468}, {"text": "Answer", "logprob": -2.8375630378723145}, {"text": ":", "logprob": -0.025918936356902122}, {"text": " False", "logprob": -0.4521233141422272}, {"text": " Historical", "logprob": -9.509888648986816}, {"text": " BACKGROUND", "logprob": -8.770378112792969}, {"text": " (", "logprob": -4.672094345092773}, {"text": "DB", "logprob": -7.4101762771606445}, {"text": "Q", "logprob": -0.5356388092041016}, {"text": ")", "logprob": -0.41611069440841675}, {"text": " ", "logprob": -2.140979290008545}, {"text": " Area", "logprob": -10.600448608398438}, {"text": " of", "logprob": -0.4963834285736084}, {"text": " STUD", "logprob": -2.376528024673462}, {"text": "Y", "logprob": -0.012577144429087639}, {"text": " (", "logprob": -0.5836657285690308}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'automobile engines use fuel.' true or false?", "pred": " \n\nA) True\nB) False\nC) Cars use fuel\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.5683984756469727}, {"text": "A", "logprob": -0.3240322172641754}, {"text": ")", "logprob": -0.004377544857561588}, {"text": " True", "logprob": -0.29003074765205383}, {"text": "\n", "logprob": -0.10484383255243301}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.21326760947704315}, {"text": "\n", "logprob": -0.01661921665072441}, {"text": "C", "logprob": -0.01423631701618433}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Cars", "logprob": -7.796038627624512}, {"text": " use", "logprob": -1.8344296216964722}, {"text": " fuel", "logprob": -1.4305325746536255}, {"text": "\n", "logprob": -1.3540544509887695}, {"text": "D", "logprob": -0.0035223839804530144}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Elections are data-driven events.' true or false?", "pred": " \nAnswer: True.  the  statement is true. this is Known as", "completions_tokens": [{"text": " \n", "logprob": -1.1862127780914307}, {"text": "Answer", "logprob": -0.049511924386024475}, {"text": ":", "logprob": -0.09415895491838455}, {"text": " True", "logprob": -1.6370997428894043}, {"text": ".", "logprob": -0.1733955293893814}, {"text": " ", "logprob": -1.9126743078231812}, {"text": " the", "logprob": -7.5189313888549805}, {"text": " ", "logprob": -3.4097228050231934}, {"text": " statement", "logprob": -1.6321450471878052}, {"text": " is", "logprob": -2.087904214859009}, {"text": " true", "logprob": -1.2226146459579468}, {"text": ".", "logprob": -1.2926082611083984}, {"text": " this", "logprob": -5.828436851501465}, {"text": " is", "logprob": -0.6392903923988342}, {"text": " Known", "logprob": -11.43806266784668}, {"text": " as", "logprob": -0.44611984491348267}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'former municipalities are structures.' true or false?", "pred": " \n\nAnswer: False. (If you are not sure, please click the button", "completions_tokens": [{"text": " \n\n", "logprob": -0.4203248620033264}, {"text": "Answer", "logprob": -1.214812994003296}, {"text": ":", "logprob": -0.006065414287149906}, {"text": " False", "logprob": -0.4736025035381317}, {"text": ".", "logprob": -0.04204801097512245}, {"text": " (", "logprob": -2.8937978744506836}, {"text": "If", "logprob": -4.648451805114746}, {"text": " you", "logprob": -0.7866077423095703}, {"text": " are", "logprob": -1.5736703872680664}, {"text": " not", "logprob": -1.0805039405822754}, {"text": " sure", "logprob": -0.255464106798172}, {"text": ",", "logprob": -0.48436540365219116}, {"text": " please", "logprob": -1.3676292896270752}, {"text": " click", "logprob": -2.8352346420288086}, {"text": " the", "logprob": -0.008339817635715008}, {"text": " button", "logprob": -0.2256370633840561}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'arteries attach the cirri to sockets in the centrodorsal.' true or false?", "pred": " \n\nA) True\nB) False\nC) Type\nD) All", "completions_tokens": [{"text": " \n\n", "logprob": -0.7559635043144226}, {"text": "A", "logprob": -0.3131689131259918}, {"text": ")", "logprob": -0.05239678546786308}, {"text": " True", "logprob": -0.3174864947795868}, {"text": "\n", "logprob": -0.11182264238595963}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.6301679015159607}, {"text": "\n", "logprob": -0.036461420357227325}, {"text": "C", "logprob": -0.008146628737449646}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Type", "logprob": -5.870182991027832}, {"text": "\n", "logprob": -2.538844585418701}, {"text": "D", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " All", "logprob": -4.521214008331299}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'airports occupy territory.' true or false?", "pred": " \n\nStep 1: Analyze the statement and identify its subject and action.\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.602369487285614}, {"text": "Step", "logprob": -5.169741153717041}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Analy", "logprob": -1.1604028940200806}, {"text": "ze", "logprob": -0.4181531071662903}, {"text": " the", "logprob": -1.3112935448589269e-05}, {"text": " statement", "logprob": -0.2246193289756775}, {"text": " and", "logprob": -4.977816581726074}, {"text": " identify", "logprob": -1.154626727104187}, {"text": " its", "logprob": -1.155281901359558}, {"text": " subject", "logprob": -2.2625904083251953}, {"text": " and", "logprob": -0.22413374483585358}, {"text": " action", "logprob": -3.1275525093078613}, {"text": ".\n", "logprob": -0.3030542731285095}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Village dates back probably as far as pharaonic times.' true or false?", "pred": " \n\nA) False\nB) B) True\nC) A) True", "completions_tokens": [{"text": " \n\n", "logprob": -0.8584823608398438}, {"text": "A", "logprob": -0.4687008261680603}, {"text": ")", "logprob": -0.035715747624635696}, {"text": " False", "logprob": -1.6629233360290527}, {"text": "\n", "logprob": -0.06265982240438461}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " B", "logprob": -3.8741607666015625}, {"text": ")", "logprob": -0.48710519075393677}, {"text": " True", "logprob": -0.19539929926395416}, {"text": "\n", "logprob": -0.026022545993328094}, {"text": "C", "logprob": -0.13699346780776978}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -0.792542040348053}, {"text": ")", "logprob": -0.0792815312743187}, {"text": " True", "logprob": -1.0023821592330933}], "answers": ["true"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Activities ensure cycle cost.' true or false?", "pred": " \nAnswer: False. 7310.105.142.90. False", "completions_tokens": [{"text": " \n", "logprob": -1.4118753671646118}, {"text": "Answer", "logprob": -0.02178850956261158}, {"text": ":", "logprob": -0.061219312250614166}, {"text": " False", "logprob": -0.6379481554031372}, {"text": ".", "logprob": -0.10721814632415771}, {"text": " ", "logprob": -1.4008089303970337}, {"text": "731", "logprob": -9.09499740600586}, {"text": "0", "logprob": -3.2803239822387695}, {"text": ".", "logprob": -1.2010191679000854}, {"text": "105", "logprob": -7.096321105957031}, {"text": ".", "logprob": -1.4470447301864624}, {"text": "142", "logprob": -6.387356281280518}, {"text": ".", "logprob": -0.8881157636642456}, {"text": "90", "logprob": -6.475141525268555}, {"text": ".", "logprob": -0.4759414494037628}, {"text": " False", "logprob": -5.584713935852051}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Locations have tops.' true or false?", "pred": " Background knowledge: There are three most common senses to which locations can refer: (", "completions_tokens": [{"text": " Background", "logprob": -10.177834510803223}, {"text": " knowledge", "logprob": -1.618111491203308}, {"text": ":", "logprob": -0.3455149531364441}, {"text": " There", "logprob": -3.6316606998443604}, {"text": " are", "logprob": -0.45472437143325806}, {"text": " three", "logprob": -3.7001328468322754}, {"text": " most", "logprob": -6.952230930328369}, {"text": " common", "logprob": -1.5696089267730713}, {"text": " senses", "logprob": -4.42329740524292}, {"text": " to", "logprob": -4.499730587005615}, {"text": " which", "logprob": -2.801525115966797}, {"text": " locations", "logprob": -2.654486656188965}, {"text": " can", "logprob": -0.2994132339954376}, {"text": " refer", "logprob": -0.5299555659294128}, {"text": ":", "logprob": -0.5207532048225403}, {"text": " (", "logprob": -2.0080554485321045}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Dams can also affect the quality of the river water both above and below the dam.' true or false?", "pred": " \n\nA) True\nB) False\nC) Dams and reservoirs", "completions_tokens": [{"text": " \n\n", "logprob": -0.3796071410179138}, {"text": "A", "logprob": -0.08651582896709442}, {"text": ")", "logprob": -0.01780818961560726}, {"text": " True", "logprob": -0.20349209010601044}, {"text": "\n", "logprob": -0.055979665368795395}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.1387571543455124}, {"text": "\n", "logprob": -0.06907728314399719}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " D", "logprob": -1.2763266563415527}, {"text": "ams", "logprob": -0.02817614935338497}, {"text": " and", "logprob": -5.22965145111084}, {"text": " reservoir", "logprob": -1.86753249168396}, {"text": "s", "logprob": -1.3112935448589269e-05}], "answers": ["true"], "all_classes": "null", "length": 26}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Eukaryotes are also the only organisms to provide milk to their young.' true or false?", "pred": " True\nAnswer: False\nComment: While it can be argued that only two", "completions_tokens": [{"text": " True", "logprob": -3.775864362716675}, {"text": "\n", "logprob": -1.4133731126785278}, {"text": "Answer", "logprob": -0.39042067527770996}, {"text": ":", "logprob": -0.014458413235843182}, {"text": " False", "logprob": -0.15915389358997345}, {"text": "\n", "logprob": -0.16767551004886627}, {"text": "Comment", "logprob": -7.557156562805176}, {"text": ":", "logprob": -0.30476462841033936}, {"text": " While", "logprob": -2.1258039474487305}, {"text": " it", "logprob": -2.981886863708496}, {"text": " can", "logprob": -4.5273356437683105}, {"text": " be", "logprob": -0.020393338054418564}, {"text": " argued", "logprob": -0.45656853914260864}, {"text": " that", "logprob": -0.04205601289868355}, {"text": " only", "logprob": -3.011176347732544}, {"text": " two", "logprob": -5.892607688903809}], "answers": ["false"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Gardens are more than just plants.' true or false?", "pred": " \nAnswer: True.permalink\nThe statement 'Gardens are more than", "completions_tokens": [{"text": " \n", "logprob": -1.3232399225234985}, {"text": "Answer", "logprob": -0.05731629952788353}, {"text": ":", "logprob": -0.12480881065130234}, {"text": " True", "logprob": -0.609728217124939}, {"text": ".", "logprob": -0.2600831687450409}, {"text": "permalink", "logprob": -13.074687957763672}, {"text": "\n", "logprob": -0.37237751483917236}, {"text": "The", "logprob": -2.5761539936065674}, {"text": " statement", "logprob": -0.33415132761001587}, {"text": " '", "logprob": -0.9617564678192139}, {"text": "G", "logprob": -0.09528321772813797}, {"text": "ard", "logprob": -0.013381198048591614}, {"text": "ens", "logprob": -1.3112935448589269e-05}, {"text": " are", "logprob": -0.011414814740419388}, {"text": " more", "logprob": -0.0205598846077919}, {"text": " than", "logprob": -1.3112935448589269e-05}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Plant Fibers Several plants are sources of insulation from cold.' true or false?", "pred": " \nAnswer: FALSE. Because word'several' implies more than two while", "completions_tokens": [{"text": " \n", "logprob": -1.7508580684661865}, {"text": "Answer", "logprob": -0.06382451206445694}, {"text": ":", "logprob": -0.11110679805278778}, {"text": " FALSE", "logprob": -2.486746311187744}, {"text": ".", "logprob": -0.3604998290538788}, {"text": " Because", "logprob": -4.064826011657715}, {"text": " word", "logprob": -9.803425788879395}, {"text": " '", "logprob": -1.1250954866409302}, {"text": "se", "logprob": -0.23414702713489532}, {"text": "veral", "logprob": -1.3112935448589269e-05}, {"text": "'", "logprob": -0.02278621681034565}, {"text": " implies", "logprob": -2.5619611740112305}, {"text": " more", "logprob": -0.9660865664482117}, {"text": " than", "logprob": -0.011868222616612911}, {"text": " two", "logprob": -0.5584672689437866}, {"text": " while", "logprob": -3.578205108642578}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'theatres is a word that gets used often in Washington.' true or false?", "pred": "        \nAnswer: TRUE.", "completions_tokens": [{"text": "        \n", "logprob": -8.10849380493164}, {"text": "Answer", "logprob": -0.017408546060323715}, {"text": ":", "logprob": -0.05263318493962288}, {"text": " TRUE", "logprob": -2.094548225402832}, {"text": ".", "logprob": -0.4179327189922333}, {"text": "<|eot_id|>", "logprob": -1.295249581336975}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Many islands have plants and animals that live nowhere else on Earth.' true or false?", "pred": " \nAnswer: True. 10000 1 1 1 100", "completions_tokens": [{"text": " \n", "logprob": -1.2038367986679077}, {"text": "Answer", "logprob": -0.2152329981327057}, {"text": ":", "logprob": -0.08897871524095535}, {"text": " True", "logprob": -0.32287392020225525}, {"text": ".", "logprob": -0.222489595413208}, {"text": " ", "logprob": -2.371600389480591}, {"text": "100", "logprob": -5.656176567077637}, {"text": "00", "logprob": -3.6154351234436035}, {"text": " ", "logprob": -2.85837984085083}, {"text": "1", "logprob": -3.184307813644409}, {"text": " ", "logprob": -0.9300214648246765}, {"text": "1", "logprob": -1.755812406539917}, {"text": " ", "logprob": -0.5013816356658936}, {"text": "1", "logprob": -0.9823554754257202}, {"text": " ", "logprob": -0.24625162780284882}, {"text": "100", "logprob": -2.567957878112793}], "answers": ["true"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Elections are a tool through which voters try to communicate.' true or false?", "pred": " \n\nA) False\nB) C) True\n\nAnswer: A) False", "completions_tokens": [{"text": " \n\n", "logprob": -0.5496912002563477}, {"text": "A", "logprob": -0.37038058042526245}, {"text": ")", "logprob": -0.006709546782076359}, {"text": " False", "logprob": -2.2649638652801514}, {"text": "\n", "logprob": -0.10350114107131958}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " C", "logprob": -2.2989630699157715}, {"text": ")", "logprob": -0.28964319825172424}, {"text": " True", "logprob": -0.41785964369773865}, {"text": "\n\n", "logprob": -2.7114241123199463}, {"text": "Answer", "logprob": -1.0516090393066406}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -2.067688226699829}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.004050504416227341}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'galaxies are located in buildings.' true or false?", "pred": " \n\nA) True \nB) False\n\nAnswer: B) False\nStep", "completions_tokens": [{"text": " \n\n", "logprob": -0.6339215636253357}, {"text": "A", "logprob": -0.576830267906189}, {"text": ")", "logprob": -0.07193605601787567}, {"text": " True", "logprob": -0.3011499345302582}, {"text": " \n", "logprob": -2.6466434001922607}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.01611294411122799}, {"text": "\n\n", "logprob": -2.928054094314575}, {"text": "Answer", "logprob": -0.22961518168449402}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -1.0794806480407715}, {"text": "Step", "logprob": -4.092386245727539}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Canals carve through hard layers of rock , breaking down or eroding it.' true or false?", "pred": " \n\nA) True\nB) False\nC)  Neither true nor false", "completions_tokens": [{"text": " \n\n", "logprob": -0.5928723812103271}, {"text": "A", "logprob": -0.09162288159132004}, {"text": ")", "logprob": -0.06786756962537766}, {"text": " True", "logprob": -0.38100865483283997}, {"text": "\n", "logprob": -0.09608790278434753}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.6790398359298706}, {"text": "\n", "logprob": -0.031759291887283325}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -2.698765754699707}, {"text": " Neither", "logprob": -2.9385509490966797}, {"text": " true", "logprob": -1.716975212097168}, {"text": " nor", "logprob": -0.04703392833471298}, {"text": " false", "logprob": -0.026003845036029816}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'enzymes forms a major part of our structure.' true or false?", "pred": " \n\nA) False\nB) True\nC) If one interprets the", "completions_tokens": [{"text": " \n\n", "logprob": -0.36078569293022156}, {"text": "A", "logprob": -0.07694341987371445}, {"text": ")", "logprob": -0.051069751381874084}, {"text": " False", "logprob": -1.9221091270446777}, {"text": "\n", "logprob": -0.05259563401341438}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " True", "logprob": -1.0058711767196655}, {"text": "\n", "logprob": -0.007775871083140373}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " If", "logprob": -3.358036994934082}, {"text": " one", "logprob": -5.1353960037231445}, {"text": " interpre", "logprob": -4.3063554763793945}, {"text": "ts", "logprob": -0.005700047593563795}, {"text": " the", "logprob": -1.1882600784301758}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Castles have (part) shower stalls.' true or false?", "pred": " \nAnswer:\n\nFalse.", "completions_tokens": [{"text": " \n", "logprob": -1.1731464862823486}, {"text": "Answer", "logprob": -0.054096609354019165}, {"text": ":\n\n", "logprob": -2.8879470825195312}, {"text": "False", "logprob": -0.10254349559545517}, {"text": ".", "logprob": -0.04793507978320122}, {"text": "<|eot_id|>", "logprob": -2.7554807662963867}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'transport infrastructures is located in lands.' true or false?", "pred": " \n\nA) False\nB) Transport infrastructures are not located on lands.\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.6132078170776367}, {"text": "A", "logprob": -0.3089202344417572}, {"text": ")", "logprob": -0.016302606090903282}, {"text": " False", "logprob": -1.9148283004760742}, {"text": "\n", "logprob": -0.07034742832183838}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Transport", "logprob": -3.4270613193511963}, {"text": " infra", "logprob": -0.1386885643005371}, {"text": "structures", "logprob": -1.3112935448589269e-05}, {"text": " are", "logprob": -0.654694676399231}, {"text": " not", "logprob": -2.015235185623169}, {"text": " located", "logprob": -0.46247297525405884}, {"text": " on", "logprob": -2.101006269454956}, {"text": " lands", "logprob": -0.4420359134674072}, {"text": ".\n", "logprob": -0.6420946717262268}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'space missions occur during the rainy season and disappear at the onset of the dry season.' true or false?", "pred": " False\n\nNote: Excerpts from scientific publications and actual government / institution reports", "completions_tokens": [{"text": " False", "logprob": -2.033820152282715}, {"text": "\n\n", "logprob": -0.6691908836364746}, {"text": "Note", "logprob": -6.414132118225098}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Ex", "logprob": -8.872902870178223}, {"text": "cer", "logprob": -2.647952079772949}, {"text": "pts", "logprob": -1.139899492263794}, {"text": " from", "logprob": -0.7592847347259521}, {"text": " scientific", "logprob": -5.701354026794434}, {"text": " publications", "logprob": -3.395230770111084}, {"text": " and", "logprob": -1.069081425666809}, {"text": " actual", "logprob": -8.116693496704102}, {"text": " government", "logprob": -6.061057090759277}, {"text": " /", "logprob": -6.940863609313965}, {"text": " institution", "logprob": -4.231683731079102}, {"text": " reports", "logprob": -1.443377137184143}], "answers": ["false"], "all_classes": "null", "length": 26}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'facilities are located in resorts.' true or false?", "pred": " False\n\n## Step 1: Understand the given statement\nThe statement given is", "completions_tokens": [{"text": " False", "logprob": -1.5732982158660889}, {"text": "\n\n", "logprob": -0.5970816612243652}, {"text": "##", "logprob": -1.4494450092315674}, {"text": " Step", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Understand", "logprob": -0.990716814994812}, {"text": " the", "logprob": -0.02228911966085434}, {"text": " given", "logprob": -3.5368096828460693}, {"text": " statement", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.09749314188957214}, {"text": "The", "logprob": -1.3112935448589269e-05}, {"text": " statement", "logprob": -0.2776324152946472}, {"text": " given", "logprob": -0.6580762267112732}, {"text": " is", "logprob": -1.3112935448589269e-05}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'streams are places favoured by a source of income.' true or false?", "pred": " \nAnswer: A. False\n ( In the past, people often associated '", "completions_tokens": [{"text": " \n", "logprob": -1.069166898727417}, {"text": "Answer", "logprob": -0.02384182997047901}, {"text": ":", "logprob": -0.11277665942907333}, {"text": " A", "logprob": -8.083450317382812}, {"text": ".", "logprob": -2.557128429412842}, {"text": " False", "logprob": -0.8901302218437195}, {"text": "\n", "logprob": -4.423222541809082}, {"text": " (", "logprob": -5.277774333953857}, {"text": " In", "logprob": -7.171562671661377}, {"text": " the", "logprob": -2.008324384689331}, {"text": " past", "logprob": -4.275633811950684}, {"text": ",", "logprob": -0.5134390592575073}, {"text": " people", "logprob": -3.070474147796631}, {"text": " often", "logprob": -2.822387933731079}, {"text": " associated", "logprob": -3.325502395629883}, {"text": " '", "logprob": -2.9506096839904785}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'grapes are also more likely to colic after deworming which can interfere with horse activities.' true or false?", "pred": " \n\nA) True\nB) Colic\nC) Analysis\nD)", "completions_tokens": [{"text": " \n\n", "logprob": -0.4852559566497803}, {"text": "A", "logprob": -0.013381079770624638}, {"text": ")", "logprob": -0.018518999218940735}, {"text": " True", "logprob": -0.29078051447868347}, {"text": "\n", "logprob": -0.09848673641681671}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Col", "logprob": -3.1897311210632324}, {"text": "ic", "logprob": -0.03367527946829796}, {"text": "\n", "logprob": -0.10694310069084167}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Analysis", "logprob": -9.54278564453125}, {"text": "\n", "logprob": -0.18014048039913177}, {"text": "D", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}], "answers": ["false"], "all_classes": "null", "length": 25}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'UNESCO World Heritage Sites are an artifact of the industrial age.' true or false?", "pred": " \n\nA) True\nB) The Archaeological Sites\nC) None\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.6006963849067688}, {"text": "A", "logprob": -0.3010149598121643}, {"text": ")", "logprob": -0.01930706575512886}, {"text": " True", "logprob": -0.3745015263557434}, {"text": "\n", "logprob": -0.129964217543602}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " The", "logprob": -0.7466336488723755}, {"text": " Archae", "logprob": -8.483294486999512}, {"text": "ological", "logprob": -0.034995995461940765}, {"text": " Sites", "logprob": -2.001540184020996}, {"text": "\n", "logprob": -1.7306058406829834}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " None", "logprob": -3.220538377761841}, {"text": "\n", "logprob": -1.1107980012893677}], "answers": ["false"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Green algae can be unicellular, colonial, or multicellular.' true or false?", "pred": " \n\nA) True \nB) False\nC) True: but not all", "completions_tokens": [{"text": " \n\n", "logprob": -0.43343648314476013}, {"text": "A", "logprob": -0.30164775252342224}, {"text": ")", "logprob": -0.010727358050644398}, {"text": " True", "logprob": -0.17475664615631104}, {"text": " \n", "logprob": -2.5609018802642822}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.4360430836677551}, {"text": "\n", "logprob": -1.4699718952178955}, {"text": "C", "logprob": -0.005274309776723385}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " True", "logprob": -4.648399353027344}, {"text": ":", "logprob": -6.141665935516357}, {"text": " but", "logprob": -4.141369819641113}, {"text": " not", "logprob": -2.066772937774658}, {"text": " all", "logprob": -2.0806963443756104}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Devices convert chemical energy.' true or false?", "pred": " \nAnswer: False because most devices convert another form of energy. Other forms of", "completions_tokens": [{"text": " \n", "logprob": -1.1831080913543701}, {"text": "Answer", "logprob": -0.03585699200630188}, {"text": ":", "logprob": -0.08036455512046814}, {"text": " False", "logprob": -0.6203675866127014}, {"text": " because", "logprob": -6.080756187438965}, {"text": " most", "logprob": -4.66490364074707}, {"text": " devices", "logprob": -0.13066595792770386}, {"text": " convert", "logprob": -0.5444924831390381}, {"text": " another", "logprob": -5.658341884613037}, {"text": " form", "logprob": -0.4856351613998413}, {"text": " of", "logprob": -0.0043456172570586205}, {"text": " energy", "logprob": -0.006862523499876261}, {"text": ".", "logprob": -2.0220088958740234}, {"text": " Other", "logprob": -6.001495838165283}, {"text": " forms", "logprob": -0.5836263298988342}, {"text": " of", "logprob": -0.16543669998645782}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Mountains are sites.' true or false?", "pred": " \n\nTrueFalse\nAnswer: True\nFalse\nSimilarity:\nAnswer: False", "completions_tokens": [{"text": " \n\n", "logprob": -0.6177133321762085}, {"text": "True", "logprob": -2.1259822845458984}, {"text": "False", "logprob": -4.815274238586426}, {"text": "\n", "logprob": -0.6812914609909058}, {"text": "Answer", "logprob": -1.252887487411499}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " True", "logprob": -1.0770505666732788}, {"text": "\n", "logprob": -0.31047406792640686}, {"text": "False", "logprob": -2.95129656791687}, {"text": "\n", "logprob": -0.49609100818634033}, {"text": "Similar", "logprob": -2.2323520183563232}, {"text": "ity", "logprob": -0.058025795966386795}, {"text": ":\n", "logprob": -1.5963258743286133}, {"text": "Answer", "logprob": -0.3879619836807251}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.4507930874824524}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Drugs are able to circulate to all parts of the body and attack cancer cells through out the system.' true or false?", "pred": " \nAnswer:\n\nFalse.", "completions_tokens": [{"text": " \n", "logprob": -1.446173071861267}, {"text": "Answer", "logprob": -0.05461212247610092}, {"text": ":\n\n", "logprob": -2.9754207134246826}, {"text": "False", "logprob": -0.6805604100227356}, {"text": ".", "logprob": -0.03250133991241455}, {"text": "<|eot_id|>", "logprob": -3.8025729656219482}], "answers": ["true"], "all_classes": "null", "length": 29}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some race tracks are called road courses.' true or false?", "pred": " \n\nAnswer:\n\n True.  Jurisdiction  Similarity: Jurisdiction, Geography", "completions_tokens": [{"text": " \n\n", "logprob": -0.3709890842437744}, {"text": "Answer", "logprob": -0.5297569632530212}, {"text": ":\n\n", "logprob": -4.198462009429932}, {"text": " True", "logprob": -0.8891324400901794}, {"text": ".", "logprob": -0.010698345489799976}, {"text": " ", "logprob": -0.42305344343185425}, {"text": " Jur", "logprob": -9.984434127807617}, {"text": "isdiction", "logprob": -1.1517729759216309}, {"text": " ", "logprob": -1.675767183303833}, {"text": " Similar", "logprob": -0.21506236493587494}, {"text": "ity", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -0.2392977923154831}, {"text": " Jur", "logprob": -2.1030666828155518}, {"text": "isdiction", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -1.9924339056015015}, {"text": " Geography", "logprob": -3.512679100036621}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Arteries can rupture when weak spots on the blood vessel wall break.' true or false?", "pred": " \n\nA) The statement is partially true.\nB) False\nC) True", "completions_tokens": [{"text": " \n\n", "logprob": -0.4529789090156555}, {"text": "A", "logprob": -0.10220732539892197}, {"text": ")", "logprob": -0.023387065157294273}, {"text": " The", "logprob": -5.288020133972168}, {"text": " statement", "logprob": -1.6821036338806152}, {"text": " is", "logprob": -0.38057267665863037}, {"text": " partially", "logprob": -5.20295524597168}, {"text": " true", "logprob": -0.31044802069664}, {"text": ".\n", "logprob": -0.517206072807312}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -2.229034900665283}, {"text": "\n", "logprob": -0.12368883192539215}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " True", "logprob": -1.11642324924469}], "answers": ["true"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'railway lines are service companies.' true or false?", "pred": " \n\nA) False\nB) B) True\nC) D) Neither", "completions_tokens": [{"text": " \n\n", "logprob": -0.7979789972305298}, {"text": "A", "logprob": -0.1000966876745224}, {"text": ")", "logprob": -0.07716294378042221}, {"text": " False", "logprob": -1.8882344961166382}, {"text": "\n", "logprob": -0.12096947431564331}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " B", "logprob": -4.92488431930542}, {"text": ")", "logprob": -0.06596706062555313}, {"text": " True", "logprob": -0.29943662881851196}, {"text": "\n", "logprob": -0.029309097677469254}, {"text": "C", "logprob": -0.04349275678396225}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " D", "logprob": -1.3285448551177979}, {"text": ")", "logprob": -0.02019522152841091}, {"text": " Neither", "logprob": -1.794188380241394}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Theatre is psychology.' true or false?", "pred": " \n\nAnswer: True\nStatement: Theatre is a healing art, because it allows", "completions_tokens": [{"text": " \n\n", "logprob": -0.8027409315109253}, {"text": "Answer", "logprob": -1.9152082204818726}, {"text": ":", "logprob": -0.006454217713326216}, {"text": " True", "logprob": -2.0016112327575684}, {"text": "\n", "logprob": -2.3865468502044678}, {"text": "Statement", "logprob": -7.112241744995117}, {"text": ":", "logprob": -0.6513810157775879}, {"text": " Theatre", "logprob": -1.0788378715515137}, {"text": " is", "logprob": -0.190034419298172}, {"text": " a", "logprob": -1.9253919124603271}, {"text": " healing", "logprob": -7.3319854736328125}, {"text": " art", "logprob": -0.5429544448852539}, {"text": ",", "logprob": -2.060539960861206}, {"text": " because", "logprob": -4.143487930297852}, {"text": " it", "logprob": -0.4407787322998047}, {"text": " allows", "logprob": -2.8795015811920166}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Human genes are pieces of genetic material recorded on a DNA molecule.' true or false?", "pred": " \n\nA) True\nB) False\nC) A and B\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.4064858853816986}, {"text": "A", "logprob": -0.366910845041275}, {"text": ")", "logprob": -0.03829144313931465}, {"text": " True", "logprob": -0.24296709895133972}, {"text": "\n", "logprob": -0.0926986038684845}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.09977155923843384}, {"text": "\n", "logprob": -0.03876471146941185}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -1.4460951089859009}, {"text": " and", "logprob": -0.5418151021003723}, {"text": " B", "logprob": -0.015865519642829895}, {"text": "\n", "logprob": -0.0143114123493433}, {"text": "D", "logprob": -1.3112935448589269e-05}], "answers": ["true"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Stars are a light source.' true or false?", "pred": " False. In what context did Marilia Alves first coin the phrase \"Independent", "completions_tokens": [{"text": " False", "logprob": -3.223505973815918}, {"text": ".", "logprob": -1.9289991855621338}, {"text": " In", "logprob": -5.194194316864014}, {"text": " what", "logprob": -3.0562963485717773}, {"text": " context", "logprob": -2.238656759262085}, {"text": " did", "logprob": -3.838057041168213}, {"text": " Mar", "logprob": -8.8768310546875}, {"text": "ilia", "logprob": -7.212306499481201}, {"text": " Al", "logprob": -4.2520318031311035}, {"text": "ves", "logprob": -0.10988133400678635}, {"text": " first", "logprob": -3.552485466003418}, {"text": " coin", "logprob": -3.768763542175293}, {"text": " the", "logprob": -0.0456278957426548}, {"text": " phrase", "logprob": -2.960460662841797}, {"text": " \"", "logprob": -0.8275302648544312}, {"text": "Independent", "logprob": -9.677379608154297}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Planets are typically brighter than most stars.' true or false?", "pred": " False\n\n## Step 1: Understanding the question\nThe question is asking for", "completions_tokens": [{"text": " False", "logprob": -1.8325598239898682}, {"text": "\n\n", "logprob": -0.6865978240966797}, {"text": "##", "logprob": -1.6504281759262085}, {"text": " Step", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Understanding", "logprob": -0.9533882141113281}, {"text": " the", "logprob": -1.3112935448589269e-05}, {"text": " question", "logprob": -3.5073835849761963}, {"text": "\n", "logprob": -0.007195036858320236}, {"text": "The", "logprob": -0.0630931630730629}, {"text": " question", "logprob": -0.01661921665072441}, {"text": " is", "logprob": -1.6747578382492065}, {"text": " asking", "logprob": -0.021611783653497696}, {"text": " for", "logprob": -1.7240164279937744}], "answers": ["false"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Golf courses are one of the many land uses that contribute to a well-balanced livable community.' true or false?", "pred": " True\n\nAnswer: TRUE\n26 × 1 = 26\n56 ×", "completions_tokens": [{"text": " True", "logprob": -3.267826795578003}, {"text": "\n\n", "logprob": -1.2538412809371948}, {"text": "Answer", "logprob": -2.1613755226135254}, {"text": ":", "logprob": -0.05096791312098503}, {"text": " TRUE", "logprob": -2.556875705718994}, {"text": "\n", "logprob": -0.5989090204238892}, {"text": "26", "logprob": -6.924228668212891}, {"text": " ×", "logprob": -9.523651123046875}, {"text": " ", "logprob": -0.027415573596954346}, {"text": "1", "logprob": -1.4677155017852783}, {"text": " =", "logprob": -0.1791631281375885}, {"text": " ", "logprob": -0.06788305193185806}, {"text": "26", "logprob": -0.003254238748922944}, {"text": "\n", "logprob": -0.5560776591300964}, {"text": "56", "logprob": -5.045243740081787}, {"text": " ×", "logprob": -1.351134181022644}], "answers": ["false"], "all_classes": "null", "length": 26}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Enzymes are a boon for the human body.' true or false?", "pred": " \n\nA) True\nB) False\nC) D) Both\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.569332480430603}, {"text": "A", "logprob": -0.07074213027954102}, {"text": ")", "logprob": -0.032552920281887054}, {"text": " True", "logprob": -0.20263253152370453}, {"text": "\n", "logprob": -0.07922129333019257}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.3433360159397125}, {"text": "\n", "logprob": -0.05674552544951439}, {"text": "C", "logprob": -0.008021166548132896}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " D", "logprob": -3.528815746307373}, {"text": ")", "logprob": -0.268020361661911}, {"text": " Both", "logprob": -1.8805818557739258}, {"text": "\n", "logprob": -1.398186206817627}, {"text": "D", "logprob": -0.05621398240327835}], "answers": ["true"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Villages change the ecology of natural systems.' true or false?", "pred": " \n\nTrue\nFalse\nAnswer: True\nThe best answer is True. Thank", "completions_tokens": [{"text": " \n\n", "logprob": -0.8626634478569031}, {"text": "True", "logprob": -2.3912875652313232}, {"text": "\n", "logprob": -1.3496348857879639}, {"text": "False", "logprob": -0.12280938774347305}, {"text": "\n", "logprob": -0.012638003565371037}, {"text": "Answer", "logprob": -1.1758676767349243}, {"text": ":", "logprob": -0.06408204883337021}, {"text": " True", "logprob": -0.5389460921287537}, {"text": "\n", "logprob": -0.1629355400800705}, {"text": "The", "logprob": -3.679117441177368}, {"text": " best", "logprob": -0.9867416620254517}, {"text": " answer", "logprob": -0.014684101566672325}, {"text": " is", "logprob": -1.3112935448589269e-05}, {"text": " True", "logprob": -0.103459432721138}, {"text": ".", "logprob": -1.3112935448589269e-05}, {"text": " Thank", "logprob": -4.247549057006836}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Outbreaks are about making choices and picking winners.' true or false?", "pred": " \nAnswer:\n\nFalse.  was not in the original FB note; ) however", "completions_tokens": [{"text": " \n", "logprob": -0.7283495664596558}, {"text": "Answer", "logprob": -0.01548916194587946}, {"text": ":\n\n", "logprob": -2.55612850189209}, {"text": "False", "logprob": -0.14661170542240143}, {"text": ".", "logprob": -0.022189902141690254}, {"text": " ", "logprob": -0.663219153881073}, {"text": " was", "logprob": -10.685090065002441}, {"text": " not", "logprob": -0.7070217132568359}, {"text": " in", "logprob": -3.578911304473877}, {"text": " the", "logprob": -0.213187575340271}, {"text": " original", "logprob": -2.121264934539795}, {"text": " FB", "logprob": -11.888741493225098}, {"text": " note", "logprob": -5.35345458984375}, {"text": ";", "logprob": -4.227261066436768}, {"text": " )", "logprob": -6.959377765655518}, {"text": " however", "logprob": -3.9150781631469727}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Sporting event are sports.' true or false?", "pred": " \n\nTrue or False / False. From the second half of the statement it is", "completions_tokens": [{"text": " \n\n", "logprob": -0.4082285463809967}, {"text": "True", "logprob": -1.6800599098205566}, {"text": " or", "logprob": -1.2196072340011597}, {"text": " False", "logprob": -1.3112935448589269e-05}, {"text": " /", "logprob": -5.435614585876465}, {"text": " False", "logprob": -1.8969790935516357}, {"text": ".", "logprob": -0.9481422305107117}, {"text": " From", "logprob": -8.379217147827148}, {"text": " the", "logprob": -1.30734121799469}, {"text": " second", "logprob": -7.027183532714844}, {"text": " half", "logprob": -4.238583087921143}, {"text": " of", "logprob": -0.07340863347053528}, {"text": " the", "logprob": -0.17651617527008057}, {"text": " statement", "logprob": -1.620054841041565}, {"text": " it", "logprob": -4.174346923828125}, {"text": " is", "logprob": -0.8621490001678467}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Ligaments have (part) corpi.' true or false?", "pred": " \n\nAnswer: True.", "completions_tokens": [{"text": " \n\n", "logprob": -0.34106457233428955}, {"text": "Answer", "logprob": -0.11974916607141495}, {"text": ":", "logprob": -0.01093938760459423}, {"text": " True", "logprob": -2.008975028991699}, {"text": ".", "logprob": -0.15659546852111816}, {"text": "<|eot_id|>", "logprob": -1.773711919784546}], "answers": ["false"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'information appliances consume energy.' true or false?", "pred": " \nAnswer: True. \n\nSpeed :: Quickness -> Similarity: Agility \n", "completions_tokens": [{"text": " \n", "logprob": -0.9732570052146912}, {"text": "Answer", "logprob": -0.04238959774374962}, {"text": ":", "logprob": -0.047739844769239426}, {"text": " True", "logprob": -0.3552376627922058}, {"text": ".", "logprob": -0.05954088643193245}, {"text": " \n\n", "logprob": -3.9289770126342773}, {"text": "Speed", "logprob": -3.746979236602783}, {"text": " ::", "logprob": -6.421106338500977}, {"text": " Quick", "logprob": -3.503826856613159}, {"text": "ness", "logprob": -0.3437676429748535}, {"text": " ->", "logprob": -4.834000587463379}, {"text": " Similar", "logprob": -1.6026583909988403}, {"text": "ity", "logprob": -0.007301432080566883}, {"text": ":", "logprob": -0.4721238613128662}, {"text": " Agility", "logprob": -4.331336498260498}, {"text": " \n", "logprob": -1.7949827909469604}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Protein continues to be inserted until it reaches the hydrophobic stop signal sequence.' true or false?", "pred": "  \n Reasons: All incoming protein molecules are analyzed at the channel region of the rib", "completions_tokens": [{"text": "  \n", "logprob": -2.2735679149627686}, {"text": " Reasons", "logprob": -9.118573188781738}, {"text": ":", "logprob": -1.4319332838058472}, {"text": " All", "logprob": -5.868947982788086}, {"text": " incoming", "logprob": -8.82408332824707}, {"text": " protein", "logprob": -2.4359986782073975}, {"text": " molecules", "logprob": -2.008662223815918}, {"text": " are", "logprob": -1.2509698867797852}, {"text": " analyzed", "logprob": -5.090237140655518}, {"text": " at", "logprob": -2.764522075653076}, {"text": " the", "logprob": -0.30005499720573425}, {"text": " channel", "logprob": -5.048982620239258}, {"text": " region", "logprob": -6.375297546386719}, {"text": " of", "logprob": -1.140937328338623}, {"text": " the", "logprob": -0.12063976377248764}, {"text": " rib", "logprob": -0.4776901602745056}], "answers": ["false"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some canals deliver water.' true or false?", "pred": " \nAnswer: True.", "completions_tokens": [{"text": " \n", "logprob": -1.1664867401123047}, {"text": "Answer", "logprob": -0.10282007604837418}, {"text": ":", "logprob": -0.08370079845190048}, {"text": " True", "logprob": -0.3826073408126831}, {"text": ".", "logprob": -0.15250563621520996}, {"text": "<|eot_id|>", "logprob": -1.6442097425460815}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Landforms have direct effects.' true or false?", "pred": " \n\nA) False\nB) Landforms have direct effects.\nC) None", "completions_tokens": [{"text": " \n\n", "logprob": -1.0449771881103516}, {"text": "A", "logprob": -0.563380241394043}, {"text": ")", "logprob": -0.009440542198717594}, {"text": " False", "logprob": -1.8170926570892334}, {"text": "\n", "logprob": -0.10039269924163818}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Land", "logprob": -0.558175265789032}, {"text": "forms", "logprob": -0.10320485383272171}, {"text": " have", "logprob": -1.2028765678405762}, {"text": " direct", "logprob": -0.912002444267273}, {"text": " effects", "logprob": -0.1517164260149002}, {"text": ".\n", "logprob": -0.8730056881904602}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " None", "logprob": -3.873929977416992}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Stars are huge balls of gas generating tremendous amounts of energy.' true or false?", "pred": " \n\nA) True\nB) A statement about multiple choice\nC) True", "completions_tokens": [{"text": " \n\n", "logprob": -0.6512013673782349}, {"text": "A", "logprob": -0.06118612363934517}, {"text": ")", "logprob": -0.01251475140452385}, {"text": " True", "logprob": -0.20846080780029297}, {"text": "\n", "logprob": -0.11781778931617737}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -5.316116809844971}, {"text": " statement", "logprob": -4.95905065536499}, {"text": " about", "logprob": -0.9696012735366821}, {"text": " multiple", "logprob": -9.328214645385742}, {"text": " choice", "logprob": -3.214146852493286}, {"text": "\n", "logprob": -1.4399361610412598}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " True", "logprob": -0.8020796179771423}], "answers": ["true"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'monoclonal antibodies also break without cleavage or across cleavage planes.' true or false?", "pred": " FALSE\n\nSTEP 1: Understanding the statement about monoclonal antibodies.\nThe", "completions_tokens": [{"text": " FALSE", "logprob": -3.3299055099487305}, {"text": "\n\n", "logprob": -0.8644093871116638}, {"text": "STEP", "logprob": -7.528927803039551}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Understanding", "logprob": -1.639215111732483}, {"text": " the", "logprob": -0.09054392576217651}, {"text": " statement", "logprob": -1.1044020652770996}, {"text": " about", "logprob": -1.9472339153289795}, {"text": " monoc", "logprob": -1.3112935448589269e-05}, {"text": "lon", "logprob": -1.3112935448589269e-05}, {"text": "al", "logprob": -1.3112935448589269e-05}, {"text": " antibodies", "logprob": -1.3112935448589269e-05}, {"text": ".\n", "logprob": -2.160529851913452}, {"text": "The", "logprob": -0.3290967643260956}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Administrative regions have (part) windows.' true or false?", "pred": " \n\nAnswer: True. marks (?; relevance follows.) marks Correct - 1", "completions_tokens": [{"text": " \n\n", "logprob": -0.49273964762687683}, {"text": "Answer", "logprob": -0.12189032882452011}, {"text": ":", "logprob": -0.00802104827016592}, {"text": " True", "logprob": -1.6720317602157593}, {"text": ".", "logprob": -0.11851730942726135}, {"text": " marks", "logprob": -13.253934860229492}, {"text": " (?", "logprob": -8.882744789123535}, {"text": ";", "logprob": -8.266504287719727}, {"text": " relevance", "logprob": -9.947061538696289}, {"text": " follows", "logprob": -9.212291717529297}, {"text": ".)", "logprob": -3.89170241355896}, {"text": " marks", "logprob": -1.350337028503418}, {"text": " Correct", "logprob": -9.581435203552246}, {"text": " -", "logprob": -4.704967498779297}, {"text": " ", "logprob": -2.6678967475891113}, {"text": "1", "logprob": -0.9550184011459351}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Many stars have no-discharge regulations in effect.' true or false?", "pred": " \n\nTrue False\nAnswer: False\n### Step 1: Understanding the statement", "completions_tokens": [{"text": " \n\n", "logprob": -0.9566469192504883}, {"text": "True", "logprob": -2.761303424835205}, {"text": " False", "logprob": -1.869821548461914}, {"text": "\n", "logprob": -0.09936430305242538}, {"text": "Answer", "logprob": -0.20772559940814972}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.5561778545379639}, {"text": "\n", "logprob": -0.039307329803705215}, {"text": "###", "logprob": -2.8269057273864746}, {"text": " Step", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Understanding", "logprob": -1.6156995296478271}, {"text": " the", "logprob": -1.3112935448589269e-05}, {"text": " statement", "logprob": -0.6633296608924866}], "answers": ["false"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Enzymes aid in all aspects of digestion, including absorption.' true or false?", "pred": " True. False.\n\nAnswer: True.", "completions_tokens": [{"text": " True", "logprob": -2.85292911529541}, {"text": ".", "logprob": -1.9948025941848755}, {"text": " False", "logprob": -0.7131708860397339}, {"text": ".\n\n", "logprob": -0.7180176973342896}, {"text": "Answer", "logprob": -2.8332645893096924}, {"text": ":", "logprob": -0.012193188071250916}, {"text": " True", "logprob": -0.8434805274009705}, {"text": ".", "logprob": -0.012005689553916454}, {"text": "<|eot_id|>", "logprob": -2.32710862159729}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Every chemical substance emits a unique spectrum when it absorbs energy.' true or false?", "pred": " True/False\n\n### Step 1: Understand the concept of spectroscopy.\n", "completions_tokens": [{"text": " True", "logprob": -2.710466146469116}, {"text": "/", "logprob": -2.6404571533203125}, {"text": "False", "logprob": -0.05340149626135826}, {"text": "\n\n", "logprob": -0.8574967980384827}, {"text": "###", "logprob": -4.65170955657959}, {"text": " Step", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Understand", "logprob": -1.404921531677246}, {"text": " the", "logprob": -1.3112935448589269e-05}, {"text": " concept", "logprob": -1.7274320125579834}, {"text": " of", "logprob": -0.0494607575237751}, {"text": " spectro", "logprob": -2.091294527053833}, {"text": "scopy", "logprob": -1.3112935448589269e-05}, {"text": ".\n", "logprob": -3.290689468383789}], "answers": ["true"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'railway stations are locations where dances are held.' true or false?", "pred": " \nAnswer: False. Or you may answer with any other appropriate words for correct", "completions_tokens": [{"text": " \n", "logprob": -1.085607886314392}, {"text": "Answer", "logprob": -0.0742955207824707}, {"text": ":", "logprob": -0.10276059061288834}, {"text": " False", "logprob": -0.4046262502670288}, {"text": ".", "logprob": -0.1823658049106598}, {"text": " Or", "logprob": -6.408753395080566}, {"text": " you", "logprob": -3.326594114303589}, {"text": " may", "logprob": -1.917845368385315}, {"text": " answer", "logprob": -0.9375268220901489}, {"text": " with", "logprob": -2.68369197845459}, {"text": " any", "logprob": -3.6014628410339355}, {"text": " other", "logprob": -0.9727157354354858}, {"text": " appropriate", "logprob": -2.599609851837158}, {"text": " words", "logprob": -3.123408317565918}, {"text": " for", "logprob": -4.160689830780029}, {"text": " correct", "logprob": -7.824394702911377}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Many bacteria live naturally in our bodies without causing disease.' true or false?", "pred": " \n\nTrue/False: \n____________________________________________________________________\nAnswer: True\nCount how many", "completions_tokens": [{"text": " \n\n", "logprob": -0.4571572244167328}, {"text": "True", "logprob": -2.907042980194092}, {"text": "/", "logprob": -3.142821788787842}, {"text": "False", "logprob": -0.024449720978736877}, {"text": ":", "logprob": -0.2142660915851593}, {"text": " \n", "logprob": -0.7454438209533691}, {"text": "________________________________________________________________", "logprob": -6.039108753204346}, {"text": "____", "logprob": -0.8310792446136475}, {"text": "\n", "logprob": -1.4914441108703613}, {"text": "Answer", "logprob": -0.07949657738208771}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " True", "logprob": -0.048683393746614456}, {"text": "\n", "logprob": -0.7456535696983337}, {"text": "Count", "logprob": -7.215248107910156}, {"text": " how", "logprob": -0.5475820302963257}, {"text": " many", "logprob": -0.011807081289589405}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Cheese is a viscoelastic material that is able to flow under quite small stresses.' true or false?", "pred": " \n\nA) True\nB) False\nC) There is another answer to", "completions_tokens": [{"text": " \n\n", "logprob": -0.6859549880027771}, {"text": "A", "logprob": -1.0002174377441406}, {"text": ")", "logprob": -0.18002817034721375}, {"text": " True", "logprob": -0.29156526923179626}, {"text": "\n", "logprob": -0.12560544908046722}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.44684648513793945}, {"text": "\n", "logprob": -0.04656444862484932}, {"text": "C", "logprob": -0.007422133814543486}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " There", "logprob": -3.600064277648926}, {"text": " is", "logprob": -0.21695685386657715}, {"text": " another", "logprob": -6.083722114562988}, {"text": " answer", "logprob": -1.524878978729248}, {"text": " to", "logprob": -2.8177614212036133}], "answers": ["false"], "all_classes": "null", "length": 24}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Caves contain fragile formations which can easily be destroyed through carelessness or vandalism.' true or false?", "pred": " \n\nAnswer: True. (However, humans need to take specific steps like tri", "completions_tokens": [{"text": " \n\n", "logprob": -0.7091758847236633}, {"text": "Answer", "logprob": -0.6915459036827087}, {"text": ":", "logprob": -0.010123101063072681}, {"text": " True", "logprob": -0.16742043197155}, {"text": ".", "logprob": -0.11695331335067749}, {"text": " (", "logprob": -3.0996885299682617}, {"text": "However", "logprob": -3.235337734222412}, {"text": ",", "logprob": -0.1801379770040512}, {"text": " humans", "logprob": -7.53373384475708}, {"text": " need", "logprob": -5.332500457763672}, {"text": " to", "logprob": -0.707057535648346}, {"text": " take", "logprob": -2.184436321258545}, {"text": " specific", "logprob": -6.082007884979248}, {"text": " steps", "logprob": -2.021127223968506}, {"text": " like", "logprob": -3.8624656200408936}, {"text": " tri", "logprob": -8.525969505310059}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'ski areas provide comfort.' true or false?", "pred": " \n\nA) True\nB) False\nC) A and B\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.6885986924171448}, {"text": "A", "logprob": -0.13494892418384552}, {"text": ")", "logprob": -0.00427677296102047}, {"text": " True", "logprob": -0.41246721148490906}, {"text": "\n", "logprob": -0.10676740854978561}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.39353007078170776}, {"text": "\n", "logprob": -0.010442026890814304}, {"text": "C", "logprob": -0.01093938760459423}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -2.180131435394287}, {"text": " and", "logprob": -0.3628016710281372}, {"text": " B", "logprob": -0.019397683441638947}, {"text": "\n", "logprob": -0.02659301459789276}, {"text": "D", "logprob": -1.3112935448589269e-05}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Astronomical objects have no end in the uncollapsed wavefunction.' true or false?", "pred": "?\n\nA) True\nB) False\nC) Trouble\nD) Many", "completions_tokens": [{"text": "?\n\n", "logprob": -3.0540754795074463}, {"text": "A", "logprob": -0.1255229115486145}, {"text": ")", "logprob": -1.0839591026306152}, {"text": " True", "logprob": -0.24786482751369476}, {"text": "\n", "logprob": -0.019007915630936623}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.5407571792602539}, {"text": "\n", "logprob": -0.009967317804694176}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Trouble", "logprob": -10.772391319274902}, {"text": "\n", "logprob": -0.7888439893722534}, {"text": "D", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Many", "logprob": -0.544742226600647}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Sea is used for sail boats.' true or false?", "pred": " \nAnswer:\n\nTrue. (This answer is based on the fact that people use", "completions_tokens": [{"text": " \n", "logprob": -1.307093858718872}, {"text": "Answer", "logprob": -0.3936731219291687}, {"text": ":\n\n", "logprob": -2.588517427444458}, {"text": "True", "logprob": -1.5520800352096558}, {"text": ".", "logprob": -0.02734992280602455}, {"text": " (", "logprob": -2.9207162857055664}, {"text": "This", "logprob": -3.388458490371704}, {"text": " answer", "logprob": -0.7285836338996887}, {"text": " is", "logprob": -0.49692317843437195}, {"text": " based", "logprob": -1.9739726781845093}, {"text": " on", "logprob": -0.02328353188931942}, {"text": " the", "logprob": -0.564026415348053}, {"text": " fact", "logprob": -1.8165899515151978}, {"text": " that", "logprob": -0.018120110034942627}, {"text": " people", "logprob": -4.2523393630981445}, {"text": " use", "logprob": -1.0467926263809204}], "answers": ["false"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Ferns are among the most attractive of all foliage plants.' true or false?", "pred": " \n\nA) True\nB) False\nC) Some ferns are more", "completions_tokens": [{"text": " \n\n", "logprob": -0.4868201017379761}, {"text": "A", "logprob": -0.23127935826778412}, {"text": ")", "logprob": -0.032735683023929596}, {"text": " True", "logprob": -0.26947376132011414}, {"text": "\n", "logprob": -0.13577498495578766}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -1.275100827217102}, {"text": "\n", "logprob": -0.042489685118198395}, {"text": "C", "logprob": -0.008941609412431717}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Some", "logprob": -4.686226844787598}, {"text": " fern", "logprob": -1.1535989046096802}, {"text": "s", "logprob": -0.03032870963215828}, {"text": " are", "logprob": -0.46963566541671753}, {"text": " more", "logprob": -2.260225296020508}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'monoclonal antibodies have the advantage of mobility.' true or false?", "pred": " False\nAnswer: False\n29. If all that is known about a patient", "completions_tokens": [{"text": " False", "logprob": -1.7953660488128662}, {"text": "\n", "logprob": -1.7555263042449951}, {"text": "Answer", "logprob": -0.08437637239694595}, {"text": ":", "logprob": -0.02651616558432579}, {"text": " False", "logprob": -0.43652772903442383}, {"text": "\n", "logprob": -0.7176705598831177}, {"text": "29", "logprob": -8.212603569030762}, {"text": ".", "logprob": -1.0509902238845825}, {"text": " If", "logprob": -3.889909267425537}, {"text": " all", "logprob": -4.71946382522583}, {"text": " that", "logprob": -6.3379130363464355}, {"text": " is", "logprob": -1.0111730098724365}, {"text": " known", "logprob": -0.44966018199920654}, {"text": " about", "logprob": -0.3364425003528595}, {"text": " a", "logprob": -0.9409961700439453}, {"text": " patient", "logprob": -3.3722498416900635}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Oceans are important structures for human use of fresh water.' true or false?", "pred": " \nAnswer: false.  A knowledge base system can prevent defective or wrong conclusion", "completions_tokens": [{"text": " \n", "logprob": -1.39729905128479}, {"text": "Answer", "logprob": -0.17062881588935852}, {"text": ":", "logprob": -0.1583593338727951}, {"text": " false", "logprob": -2.9929733276367188}, {"text": ".", "logprob": -0.16504724323749542}, {"text": " ", "logprob": -2.027751922607422}, {"text": " A", "logprob": -4.135581016540527}, {"text": " knowledge", "logprob": -4.651104927062988}, {"text": " base", "logprob": -1.3486042022705078}, {"text": " system", "logprob": -3.485142707824707}, {"text": " can", "logprob": -2.096144914627075}, {"text": " prevent", "logprob": -7.204888820648193}, {"text": " defective", "logprob": -9.901652336120605}, {"text": " or", "logprob": -2.8440983295440674}, {"text": " wrong", "logprob": -3.429992914199829}, {"text": " conclusion", "logprob": -4.874393463134766}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some bays are part of sea.' true or false?", "pred": " \n\nA) True\nB) Many \nC) True  A) True", "completions_tokens": [{"text": " \n\n", "logprob": -0.6367583274841309}, {"text": "A", "logprob": -0.30036240816116333}, {"text": ")", "logprob": -0.03405914083123207}, {"text": " True", "logprob": -0.2612988352775574}, {"text": "\n", "logprob": -0.11482800543308258}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Many", "logprob": -2.105154037475586}, {"text": " \n", "logprob": -4.571564197540283}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " True", "logprob": -2.635913372039795}, {"text": " ", "logprob": -6.858426094055176}, {"text": " A", "logprob": -3.1861820220947266}, {"text": ")", "logprob": -0.10561490803956985}, {"text": " True", "logprob": -0.0849551409482956}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'enzymes are arranged linearly along long chains of DNA sequence, called chromosomes .' true or false?", "pred": " False\nAnswer: False. Enzymes are proteins that catalyze specific", "completions_tokens": [{"text": " False", "logprob": -2.326420307159424}, {"text": "\n", "logprob": -1.6517322063446045}, {"text": "Answer", "logprob": -0.02200368605554104}, {"text": ":", "logprob": -0.011110227555036545}, {"text": " False", "logprob": -0.5515363216400146}, {"text": ".", "logprob": -1.1955698728561401}, {"text": " En", "logprob": -0.6302587985992432}, {"text": "zym", "logprob": -1.3112935448589269e-05}, {"text": "es", "logprob": -0.012383713386952877}, {"text": " are", "logprob": -0.12138988822698593}, {"text": " proteins", "logprob": -1.1938703060150146}, {"text": " that", "logprob": -1.1045994758605957}, {"text": " catal", "logprob": -1.8766810894012451}, {"text": "y", "logprob": -1.3112935448589269e-05}, {"text": "ze", "logprob": -0.21041825413703918}, {"text": " specific", "logprob": -1.8022931814193726}], "answers": ["false"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'towns have (part) waters.' true or false?", "pred": " \n\nAnswer: False. Note: Here (part) means (part) in", "completions_tokens": [{"text": " \n\n", "logprob": -0.530278742313385}, {"text": "Answer", "logprob": -0.476095050573349}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -0.7577418684959412}, {"text": ".", "logprob": -0.05823691561818123}, {"text": " Note", "logprob": -6.010683536529541}, {"text": ":", "logprob": -0.1474142074584961}, {"text": " Here", "logprob": -3.780043601989746}, {"text": " (", "logprob": -3.177542209625244}, {"text": "part", "logprob": -0.014524679630994797}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " means", "logprob": -1.4239492416381836}, {"text": " (", "logprob": -3.411012887954712}, {"text": "part", "logprob": -1.0656095743179321}, {"text": ")", "logprob": -1.4347870349884033}, {"text": " in", "logprob": -4.953256607055664}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Horses are a potent symbol from almost every world religion and mythology.' true or false?", "pred": " \n\nAnswer: True. \nThis answer is based on the multidisciplinary consensus", "completions_tokens": [{"text": " \n\n", "logprob": -0.40732067823410034}, {"text": "Answer", "logprob": -1.4990949630737305}, {"text": ":", "logprob": -0.010770994238555431}, {"text": " True", "logprob": -0.2365553379058838}, {"text": ".", "logprob": -0.04314378276467323}, {"text": " \n", "logprob": -2.5310311317443848}, {"text": "This", "logprob": -3.551595449447632}, {"text": " answer", "logprob": -2.817979335784912}, {"text": " is", "logprob": -0.3355940282344818}, {"text": " based", "logprob": -0.8015556335449219}, {"text": " on", "logprob": -0.020936323329806328}, {"text": " the", "logprob": -0.3723815381526947}, {"text": " multid", "logprob": -11.237649917602539}, {"text": "isc", "logprob": -0.11927537620067596}, {"text": "iplinary", "logprob": -0.021611783653497696}, {"text": " consensus", "logprob": -5.983889579772949}], "answers": ["false"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Roads are gravel and can become rough and muddy after rains.' true or false?", "pred": " \n\nA) True\nB) Statement seems false.\nC) Gravel roads", "completions_tokens": [{"text": " \n\n", "logprob": -0.4794002175331116}, {"text": "A", "logprob": -0.15025319159030914}, {"text": ")", "logprob": -0.016445914283394814}, {"text": " True", "logprob": -0.26198992133140564}, {"text": "\n", "logprob": -0.12136434018611908}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Statement", "logprob": -3.9499857425689697}, {"text": " seems", "logprob": -6.125861167907715}, {"text": " false", "logprob": -2.4587223529815674}, {"text": ".\n", "logprob": -2.3412749767303467}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Gr", "logprob": -1.3469979763031006}, {"text": "avel", "logprob": -1.3112935448589269e-05}, {"text": " roads", "logprob": -0.7935774326324463}], "answers": ["true"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Skyscrapers have (part) walls.' true or false?", "pred": " \n\nAnswer: False.cladoacialinary AssistankwhereANSWER: False.", "completions_tokens": [{"text": " \n\n", "logprob": -0.5142849683761597}, {"text": "Answer", "logprob": -0.19182515144348145}, {"text": ":", "logprob": -0.008146628737449646}, {"text": " False", "logprob": -2.164295196533203}, {"text": ".", "logprob": -0.06520018726587296}, {"text": "clado", "logprob": -14.416980743408203}, {"text": "acial", "logprob": -9.538249969482422}, {"text": "inary", "logprob": -10.906052589416504}, {"text": " Assist", "logprob": -11.048578262329102}, {"text": "ank", "logprob": -8.89621353149414}, {"text": "where", "logprob": -10.499080657958984}, {"text": "ANS", "logprob": -9.709667205810547}, {"text": "WER", "logprob": -0.8815115690231323}, {"text": ":", "logprob": -0.6733912825584412}, {"text": " False", "logprob": -0.43163397908210754}, {"text": ".", "logprob": -0.2840272784233093}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'automobile engines are electro-chemical devices.' true or false?", "pred": " \n\nAnswer: False. derivation of word by syn Semiologie_Anren_(Portal", "completions_tokens": [{"text": " \n\n", "logprob": -0.7670609951019287}, {"text": "Answer", "logprob": -0.811593234539032}, {"text": ":", "logprob": -0.010123219341039658}, {"text": " False", "logprob": -0.7689934968948364}, {"text": ".", "logprob": -0.11847124248743057}, {"text": " derivation", "logprob": -13.788190841674805}, {"text": " of", "logprob": -1.1622217893600464}, {"text": " word", "logprob": -7.125644207000732}, {"text": " by", "logprob": -6.264338493347168}, {"text": " syn", "logprob": -7.288797855377197}, {"text": " Semi", "logprob": -12.049846649169922}, {"text": "ologie", "logprob": -6.624974727630615}, {"text": "_An", "logprob": -10.223189353942871}, {"text": "ren", "logprob": -12.558201789855957}, {"text": "_(", "logprob": -8.295101165771484}, {"text": "Portal", "logprob": -10.679534912109375}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Asteroids are video games.' true or false?", "pred": " FALSE\nAnswer: false. Please give answer to the question about knowledge based on", "completions_tokens": [{"text": " FALSE", "logprob": -4.898601055145264}, {"text": "\n", "logprob": -1.5304421186447144}, {"text": "Answer", "logprob": -0.4507168233394623}, {"text": ":", "logprob": -0.026548322290182114}, {"text": " false", "logprob": -4.415014743804932}, {"text": ".", "logprob": -0.7905289530754089}, {"text": " Please", "logprob": -5.860308647155762}, {"text": " give", "logprob": -0.926445484161377}, {"text": " answer", "logprob": -0.9902554750442505}, {"text": " to", "logprob": -0.029868554323911667}, {"text": " the", "logprob": -1.3112935448589269e-05}, {"text": " question", "logprob": -0.8371193408966064}, {"text": " about", "logprob": -1.0526881217956543}, {"text": " knowledge", "logprob": -0.14600348472595215}, {"text": " based", "logprob": -4.111884117126465}, {"text": " on", "logprob": -1.3112935448589269e-05}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'brains fill with blood.' true or false?", "pred": " \nAnswer: True.  A brief description on your choice is not requested,", "completions_tokens": [{"text": " \n", "logprob": -1.3802826404571533}, {"text": "Answer", "logprob": -0.03061235323548317}, {"text": ":", "logprob": -0.05889124795794487}, {"text": " True", "logprob": -0.6473826169967651}, {"text": ".", "logprob": -0.1495460718870163}, {"text": " ", "logprob": -1.5382850170135498}, {"text": " A", "logprob": -4.837471961975098}, {"text": " brief", "logprob": -6.787848949432373}, {"text": " description", "logprob": -2.1529595851898193}, {"text": " on", "logprob": -5.151397228240967}, {"text": " your", "logprob": -5.367260932922363}, {"text": " choice", "logprob": -3.274965286254883}, {"text": " is", "logprob": -1.5483609437942505}, {"text": " not", "logprob": -1.0784306526184082}, {"text": " requested", "logprob": -1.5247764587402344}, {"text": ",", "logprob": -3.3807992935180664}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some muscle organ fills ventricles.' true or false?", "pred": " N/A \n\nAnswer: FALSE.  A ventricle is a chamber of", "completions_tokens": [{"text": " N", "logprob": -10.595087051391602}, {"text": "/A", "logprob": -1.7110365629196167}, {"text": " \n\n", "logprob": -3.7554781436920166}, {"text": "Answer", "logprob": -0.11369635909795761}, {"text": ":", "logprob": -0.010605285875499249}, {"text": " FALSE", "logprob": -1.666784644126892}, {"text": ".", "logprob": -0.9217110276222229}, {"text": " ", "logprob": -1.9396082162857056}, {"text": " A", "logprob": -3.6576271057128906}, {"text": " vent", "logprob": -0.9567716121673584}, {"text": "r", "logprob": -1.3112935448589269e-05}, {"text": "icle", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -0.19988931715488434}, {"text": " a", "logprob": -0.560188889503479}, {"text": " chamber", "logprob": -1.8632243871688843}, {"text": " of", "logprob": -0.8016186952590942}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Most music festivals arise from forces.' true or false?", "pred": " \n\nA) true\nB) true\nC) true\nD) false", "completions_tokens": [{"text": " \n\n", "logprob": -0.54381263256073}, {"text": "A", "logprob": -0.30995070934295654}, {"text": ")", "logprob": -0.0202474407851696}, {"text": " true", "logprob": -1.6348235607147217}, {"text": "\n", "logprob": -0.058227017521858215}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " true", "logprob": -0.7862992286682129}, {"text": "\n", "logprob": -0.041946277022361755}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " true", "logprob": -0.4012569189071655}, {"text": "\n", "logprob": -1.3112935448589269e-05}, {"text": "D", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " false", "logprob": -1.5992074012756348}], "answers": ["false"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Rivers are an important feature of Kentucky geography.' true or false?", "pred": " \n\nAnswer: True\nExplanation: Kentucky is a state located in the eastern United", "completions_tokens": [{"text": " \n\n", "logprob": -0.6908997297286987}, {"text": "Answer", "logprob": -0.5805819630622864}, {"text": ":", "logprob": -0.008534860797226429}, {"text": " True", "logprob": -0.21938195824623108}, {"text": "\n", "logprob": -1.934961199760437}, {"text": "Explanation", "logprob": -5.241532325744629}, {"text": ":", "logprob": -0.04759731516242027}, {"text": " Kentucky", "logprob": -1.701655387878418}, {"text": " is", "logprob": -0.6611269116401672}, {"text": " a", "logprob": -1.180714726448059}, {"text": " state", "logprob": -0.32837820053100586}, {"text": " located", "logprob": -1.125643014907837}, {"text": " in", "logprob": -0.014709357172250748}, {"text": " the", "logprob": -1.3112935448589269e-05}, {"text": " eastern", "logprob": -0.4763115644454956}, {"text": " United", "logprob": -0.262305349111557}], "answers": ["true"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Tutu Chengcui, The Pierre, Waddesdon Manor, Astro Orbitor, Heian period, 2019 Canadian federal election, Paradiski, Tenughat Dam, Gros Michel banana, Reedy Glacier, Gangotri Glacier, Pinatubo, Interwar period, djon djon, Qiu Shiliang, Caciotta, Firth of Forth, 2011 Rugby World Cup, Cheng Yuanzhen, Pliocene, Sri Maha Bodhi, which one is the most conceptually similar with Botryosphaeria stevensii?", "pred": " \n\nThe Pierre\n$\boxed$Waddesdon Manor\nT", "completions_tokens": [{"text": " \n\n", "logprob": -0.12750957906246185}, {"text": "The", "logprob": -2.321610689163208}, {"text": " Pierre", "logprob": -3.028376340866089}, {"text": "\n", "logprob": -0.20784510672092438}, {"text": "$", "logprob": -11.407844543457031}, {"text": "\b", "logprob": -1.3862724304199219}, {"text": "ox", "logprob": -1.3112935448589269e-05}, {"text": "ed", "logprob": -1.3112935448589269e-05}, {"text": "$", "logprob": -1.8670132160186768}, {"text": "W", "logprob": -1.488957166671753}, {"text": "add", "logprob": -1.3112935448589269e-05}, {"text": "es", "logprob": -1.3112935448589269e-05}, {"text": "don", "logprob": -1.3112935448589269e-05}, {"text": " Manor", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.004243655130267143}, {"text": "T", "logprob": -3.033078908920288}], "answers": ["djon djon"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong UEFA Euro 2004, potassium hydroxide, Queen Elizabeth Olympic Park, Nena, Rainbow Bar and Grill, Cleveland Clinic, poly(methyl methacrylate), Cilician Gates, Akbar Shah, CR2025, wagasi, lateral rotator group, Dorsal digital arteries of hand, Ruhleben internment camp, Europe, Small Magellanic Cloud, sodium carbonate, 60558 Echeclus, Llangorse Lake, Estrogen, Steinmetz Pink Diamond, which one is the most conceptually similar with fluoxetine?", "pred": " \n\nAnswer: Poly(methyl methacrylate) is not more conceptually", "completions_tokens": [{"text": " \n\n", "logprob": -0.22074007987976074}, {"text": "Answer", "logprob": -0.13158158957958221}, {"text": ":", "logprob": -0.009813870303332806}, {"text": " Poly", "logprob": -2.881381034851074}, {"text": "(m", "logprob": -0.01913493126630783}, {"text": "ethyl", "logprob": -1.3112935448589269e-05}, {"text": " meth", "logprob": -1.3112935448589269e-05}, {"text": "ac", "logprob": -1.3112935448589269e-05}, {"text": "ry", "logprob": -1.3112935448589269e-05}, {"text": "late", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -0.032025907188653946}, {"text": " is", "logprob": -0.8910483121871948}, {"text": " not", "logprob": -1.6762573719024658}, {"text": " more", "logprob": -4.831024646759033}, {"text": " concept", "logprob": -0.8484553694725037}, {"text": "ually", "logprob": -1.3112935448589269e-05}], "answers": ["Estrogen"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Makemake, 2004 United States presidential election, San Gorgonio Pass, Penstrowed, Criollo cheese, Lactoperoxidase, solar eclipse of August 7, 1812, Canning Tunnel, Haunted Mansion Holiday, Egg hunt, Caciotta, Campanian, Gros Michel banana, Kveik, venous angle, Joint Mathematics Meetings, Plesetsk Cosmodrome Site 132, STS-122, Apollo 7, Miocene, Beech bark disease, which one is the most conceptually similar with Barnby Broad and Marshes?", "pred": " \n\nAnswer: Gros Michel banana. \n\n( I do not know if it went", "completions_tokens": [{"text": " \n\n", "logprob": -0.16737385094165802}, {"text": "Answer", "logprob": -0.36741283535957336}, {"text": ":", "logprob": -0.05849296599626541}, {"text": " Gros", "logprob": -1.9865649938583374}, {"text": " Michel", "logprob": -1.3112935448589269e-05}, {"text": " banana", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.3436494469642639}, {"text": " \n\n", "logprob": -4.675976753234863}, {"text": "(", "logprob": -5.160364627838135}, {"text": " I", "logprob": -6.36204719543457}, {"text": " do", "logprob": -3.692026138305664}, {"text": " not", "logprob": -0.056021369993686676}, {"text": " know", "logprob": -0.793319046497345}, {"text": " if", "logprob": -3.0165157318115234}, {"text": " it", "logprob": -2.2765579223632812}, {"text": " went", "logprob": -8.572676658630371}], "answers": ["Penstrowed"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Charles Bridge, French and Indian War, Elephanta Caves, Paris Commune, South China Sea, Dinefwr Park National Nature Reserve, Dresden Green Diamond, Greek fire, Clochette, The French Laundry, Egyptian cheese, Gatchina Palace, Allium ursinum, Agnes Edwards (craftworker), 2010 Commonwealth Games, Crush (soft drink), QF 3 pounder Hotchkiss, Poston War Relocation Center, valproic acid, Blue Serpent Clock, Palmar plate, which one is the most conceptually similar with Pont Neuf?", "pred": " \n\nStep 1: Identify the type of question\nThe question is asking for", "completions_tokens": [{"text": " \n\n", "logprob": -0.5997020602226257}, {"text": "Step", "logprob": -2.7386786937713623}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Identify", "logprob": -1.0965043306350708}, {"text": " the", "logprob": -0.0707751139998436}, {"text": " type", "logprob": -3.5613393783569336}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " question", "logprob": -1.7580649852752686}, {"text": "\n", "logprob": -1.4892237186431885}, {"text": "The", "logprob": -0.06121247261762619}, {"text": " question", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -0.8815469145774841}, {"text": " asking", "logprob": -0.037595704197883606}, {"text": " for", "logprob": -0.029410503804683685}], "answers": ["Charles Bridge"], "all_classes": "null", "length": 96}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong mucin, Golden Gate Park, spiral artery, Edwards Air Force Base, PSR B1620-26 b, International Conference on Computer Vision, TUC338, sarin, Mechanistic target of rapamycin kinase, Nepenthes edwardsiana, Syon Park House, cyclosporine, Cannabinoid receptor 2, Lake of the Woods, Ferulic acid decarboxylase, Idursulfase, New Orleans Jazz & Heritage Festival, Soo Locks, Morocco, Cambrian Mountains, solar eclipse of July 22, 2028, which one is the most conceptually similar with gal operon?", "pred": " \n\nMagnolia  Journey_Flyingbirds 5428644 (Pensac", "completions_tokens": [{"text": " \n\n", "logprob": -0.2240910530090332}, {"text": "Magn", "logprob": -6.749464988708496}, {"text": "olia", "logprob": -1.5018861293792725}, {"text": " ", "logprob": -4.615486145019531}, {"text": " Journey", "logprob": -9.211099624633789}, {"text": "_F", "logprob": -12.097975730895996}, {"text": "lying", "logprob": -5.786218166351318}, {"text": "birds", "logprob": -6.844020366668701}, {"text": " ", "logprob": -3.0167107582092285}, {"text": "542", "logprob": -9.481134414672852}, {"text": "864", "logprob": -8.20164966583252}, {"text": "4", "logprob": -4.592599391937256}, {"text": " (", "logprob": -4.089086055755615}, {"text": "P", "logprob": -5.374451160430908}, {"text": "ens", "logprob": -6.620272159576416}, {"text": "ac", "logprob": -1.0900185108184814}], "answers": ["TUC338"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Mall of America, adenosine diphosphate, Trawniki concentration camp, Ignalina Nuclear Power Plant, Ford Windsor engine, Lake Winnipeg, Bronx Zoo, Gliese 581g, Three Mile Island Nuclear Generating Station, 8.8 cm SK L/30 naval gun, Katiki Domokou, Australia, Battle of Chancellorsville, daf-5, Pontiac V8 engine, BMW M54, The Four Seasons Restaurant, Travelodge, Crawford Notch, CR2032 battery, Buick V8 engine, which one is the most conceptually similar with M61 Vulcan?", "pred": " Igual aqui. The M61 Vulcan belongs to the category of \n\n## Step", "completions_tokens": [{"text": " Ig", "logprob": -11.123757362365723}, {"text": "ual", "logprob": -2.8034348487854004}, {"text": " aqui", "logprob": -8.801008224487305}, {"text": ".", "logprob": -3.6013894081115723}, {"text": " The", "logprob": -3.469313144683838}, {"text": " M", "logprob": -1.197089433670044}, {"text": "61", "logprob": -0.006350930780172348}, {"text": " Vulcan", "logprob": -0.028387175872921944}, {"text": " belongs", "logprob": -5.77059268951416}, {"text": " to", "logprob": -0.009517297148704529}, {"text": " the", "logprob": -0.7668048143386841}, {"text": " category", "logprob": -0.5026097893714905}, {"text": " of", "logprob": -0.22083041071891785}, {"text": " \n\n", "logprob": -5.133850574493408}, {"text": "##", "logprob": -2.6540541648864746}, {"text": " Step", "logprob": -1.3112935448589269e-05}], "answers": ["8.8 cm SK L/30 naval gun"], "all_classes": "null", "length": 96}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Wivenhoe, cannabinoid receptor 1, Dancing on Ice, Carew Castle, Clochette, DNA-binding domain, Zojila Pass, Americas, Newgate Prison, Botryosphaeria stevensii, 1960 Democratic National Convention, Interleukin 2, Kakadu National Park, Brain derived neurotrophic factor, PTS-GFL superfamily, common facial vein, Seven Years War, Epidermal growth factor, San Francisco International Film Festival, chilihueque, Inca Kola, which one is the most conceptually similar with Hirudin?", "pred": " \n\nANSWER: Epidermal growth factor. The slight knowledge of biochemistry", "completions_tokens": [{"text": " \n\n", "logprob": -0.2886892855167389}, {"text": "ANS", "logprob": -2.0511510372161865}, {"text": "WER", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Ep", "logprob": -1.78303062915802}, {"text": "ider", "logprob": -1.3112935448589269e-05}, {"text": "mal", "logprob": -1.3112935448589269e-05}, {"text": " growth", "logprob": -1.3112935448589269e-05}, {"text": " factor", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.23989874124526978}, {"text": " The", "logprob": -4.597714424133301}, {"text": " slight", "logprob": -10.616365432739258}, {"text": " knowledge", "logprob": -6.648621559143066}, {"text": " of", "logprob": -1.6745506525039673}, {"text": " bio", "logprob": -3.3458170890808105}, {"text": "chemistry", "logprob": -0.019771169871091843}], "answers": ["PTS-GFL superfamily"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 101955 Bennu, Holin superfamily VII, Corrugator cutis ani muscle, Second Sino-Japanese War, Winter Hill transmitting station, parasphenoid, Irish Rebellion of 1641, Reflex inguinal ligament, Battle of Trafalgar, Trivial Pursuit, tetrahydrofuran, Port Jackson, Griffith Park, 2019 Rugby World Cup, Al Hidayah, Epsilon Eridani, chitin, Renju, Autopia, KNM ER 1805, 1734 British general election, which one is the most conceptually similar with Submarine Voyage?", "pred": " \n\nAnswer: Trivial Pursuit Greenwood facility,bingo  -Submarine", "completions_tokens": [{"text": " \n\n", "logprob": -0.2602728605270386}, {"text": "Answer", "logprob": -0.5583873391151428}, {"text": ":", "logprob": -0.021947942674160004}, {"text": " Tr", "logprob": -1.0905954837799072}, {"text": "ivial", "logprob": -1.3112935448589269e-05}, {"text": " Purs", "logprob": -1.3112935448589269e-05}, {"text": "uit", "logprob": -1.3112935448589269e-05}, {"text": " Greenwood", "logprob": -13.11062240600586}, {"text": " facility", "logprob": -9.27069091796875}, {"text": ",", "logprob": -5.953936576843262}, {"text": "bing", "logprob": -13.722071647644043}, {"text": "o", "logprob": -0.3181024491786957}, {"text": " ", "logprob": -4.055558204650879}, {"text": " -", "logprob": -5.570632457733154}, {"text": "Sub", "logprob": -4.658669948577881}, {"text": "marine", "logprob": -0.01666775532066822}], "answers": ["Autopia"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Iaido, Compound engine, Canary Islands, Renju, Star of Bethlehem, Grosvenor House Hotel, Cape Canaveral Air Force Station Launch Complex 6, London Zoo, Tehran Conference, Sonoma Valley AVA, Independence Day, Nepenthes aristolochioides, Petronas Towers, New Guinea, Sinnemahoning Creek, Barabar Caves, 2008 Democratic National Convention, Somerset Dam, Agnes Edwards (craftworker), Standedge Tunnels, Rock Creek Park, which one is the most conceptually similar with Campanian?", "pred": " Campanian is an Italian geologic time period corresponding to the late Cret", "completions_tokens": [{"text": " Cam", "logprob": -2.033207654953003}, {"text": "pan", "logprob": -1.3112935448589269e-05}, {"text": "ian", "logprob": -0.045165497809648514}, {"text": " is", "logprob": -0.3556568920612335}, {"text": " an", "logprob": -2.512634038925171}, {"text": " Italian", "logprob": -1.2626535892486572}, {"text": " ge", "logprob": -3.185898780822754}, {"text": "ologic", "logprob": -1.3112935448589269e-05}, {"text": " time", "logprob": -0.4861261248588562}, {"text": " period", "logprob": -0.30673059821128845}, {"text": " corresponding", "logprob": -5.710438251495361}, {"text": " to", "logprob": -0.05184526741504669}, {"text": " the", "logprob": -0.3496985137462616}, {"text": " late", "logprob": -2.050058364868164}, {"text": " C", "logprob": -0.3746997117996216}, {"text": "ret", "logprob": -1.3112935448589269e-05}], "answers": ["Independence Day"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Formula 5000, Late Cretaceous, Ure2, Holin superfamily II, djon djon, Ebensee concentration camp, Extrinsic extensor muscles of the hand, Ourasphaira giraldae, Ponticulus, Delaware Aqueduct, Baghdad Central Prison, Table Mountain, Fukushima Daiichi Nuclear Power Plant, Fifth Avenue, Comiket, solar eclipse of August 9, 1896, Coors Light, 1954 FIFA World Cup, Guadalcanal Campaign, Bart the Bear 2, Sex determining region Y, which one is the most conceptually similar with Interstate 5 in California?", "pred": " \n\nAnswer: None. Delaware Aqueduct is man-made, and Interstate 5", "completions_tokens": [{"text": " \n\n", "logprob": -0.23247799277305603}, {"text": "Answer", "logprob": -0.3960355222225189}, {"text": ":", "logprob": -0.06804309785366058}, {"text": " None", "logprob": -1.6783671379089355}, {"text": ".", "logprob": -1.5599868297576904}, {"text": " Delaware", "logprob": -6.18958854675293}, {"text": " Aqu", "logprob": -0.029307246208190918}, {"text": "educt", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -1.0467500686645508}, {"text": " man", "logprob": -6.253496170043945}, {"text": "-made", "logprob": -0.26078805327415466}, {"text": ",", "logprob": -1.7694337368011475}, {"text": " and", "logprob": -2.98528790473938}, {"text": " Interstate", "logprob": -0.5938429236412048}, {"text": " ", "logprob": -0.011283867992460728}, {"text": "5", "logprob": -1.3112935448589269e-05}], "answers": ["Fifth Avenue"], "all_classes": "null", "length": 97}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong entitlement, Caciotta, Pinconning cheese, Raghunathpur Thermal Power Station, Severn Valley Railway, Sagittarius Dwarf Elliptical Galaxy, Battle of the Somme, Cloth Hall, Ypres, Criollo cheese, Xynotyro, 2015 Rugby World Cup, Arc de Triomphe, Lambert Glacier, Kasat Suek Intersection, Palmar plate, Nabulsi cheese, Arlington Memorial Bridge, Hungerford Bridge and Golden Jubilee Bridges, dilator naris muscle, Sonoma County wine, Johnston Atoll, which one is the most conceptually similar with Perrier?", "pred": " \nAnswer:\n\nSonoma County wine\nSonoma County wine \nSonoma County", "completions_tokens": [{"text": " \n", "logprob": -1.8286478519439697}, {"text": "Answer", "logprob": -0.19972307980060577}, {"text": ":\n\n", "logprob": -2.528637170791626}, {"text": "Son", "logprob": -0.2616100013256073}, {"text": "oma", "logprob": -1.3112935448589269e-05}, {"text": " County", "logprob": -1.3112935448589269e-05}, {"text": " wine", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -1.9320628643035889}, {"text": "Son", "logprob": -2.8560216426849365}, {"text": "oma", "logprob": -1.3112935448589269e-05}, {"text": " County", "logprob": -0.03972730040550232}, {"text": " wine", "logprob": -0.4556009769439697}, {"text": " \n", "logprob": -4.214832782745361}, {"text": "Son", "logprob": -0.6214044094085693}, {"text": "oma", "logprob": -1.3112935448589269e-05}, {"text": " County", "logprob": -1.3112935448589269e-05}], "answers": ["Sonoma County wine"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Accessory soleus muscle, Nalanda, Wine auction, 1964 Alaska earthquake, 2009 World Championships in Athletics, Warhammer Fantasy Battle, Savoy wine, Kveik, Standedge Tunnels, Botryosphaeria stevensii, 2010 Commonwealth Games, Almaz, Oak Hill Country Club, late Middle Ages, Mobile Bay, Rolls-Royce Meteor, Frankfurt City Tunnel, The Pierre, 2002 European Athletics Championships, Eurovision Song Contest 2008, 1983 United Kingdom general election, which one is the most conceptually similar with Woodstock Festival?", "pred": " \n\nAnswer: 1969 Woodstock Festival. Similarity is similarity by ", "completions_tokens": [{"text": " \n\n", "logprob": -0.4959251582622528}, {"text": "Answer", "logprob": -0.1957661360502243}, {"text": ":", "logprob": -0.045165497809648514}, {"text": " ", "logprob": -1.0265358686447144}, {"text": "196", "logprob": -0.41129347681999207}, {"text": "9", "logprob": -3.194941997528076}, {"text": " Wood", "logprob": -0.1021452248096466}, {"text": "stock", "logprob": -1.3112935448589269e-05}, {"text": " Festival", "logprob": -1.297411322593689}, {"text": ".", "logprob": -1.9456697702407837}, {"text": " Similar", "logprob": -2.3805222511291504}, {"text": "ity", "logprob": -0.4651638865470886}, {"text": " is", "logprob": -2.3220646381378174}, {"text": " similarity", "logprob": -6.510703086853027}, {"text": " by", "logprob": -2.2913427352905273}, {"text": " ", "logprob": -6.053557872772217}], "answers": ["Eurovision Song Contest 2008"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1989 Loma Prieta earthquake, Asilomar Conference on Recombinant DNA, Nissan SR engine, Quebec Conference, KNM WT 17000, 1990 FIFA World Cup, Maurandya, Caciotta, Red Sea, 2016 Kumamoto earthquakes, Battle of Waterloo, 2001 United Kingdom general election, Coachella Valley Music and Arts Festival, Riviera Country Club, WASP-43b, TM 1517, table football, The Shard, solar eclipse of June 13, 2132, Oranienburg concentration camp, County Cricket Ground, Northampton, which one is the most conceptually similar with Gliese 436 b?", "pred": " \n\nStep 1:  Identify the given list of events and terms, which", "completions_tokens": [{"text": " \n\n", "logprob": -0.21066027879714966}, {"text": "Step", "logprob": -0.8492592573165894}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -2.2135796546936035}, {"text": " Identify", "logprob": -2.6383111476898193}, {"text": " the", "logprob": -0.07660692185163498}, {"text": " given", "logprob": -2.676738977432251}, {"text": " list", "logprob": -0.38738298416137695}, {"text": " of", "logprob": -0.03418932855129242}, {"text": " events", "logprob": -1.080754041671753}, {"text": " and", "logprob": -0.38933706283569336}, {"text": " terms", "logprob": -3.1429972648620605}, {"text": ",", "logprob": -2.5282788276672363}, {"text": " which", "logprob": -0.3311363458633423}], "answers": ["WASP-43b"], "all_classes": "null", "length": 102}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong University of Tennessee, Knoxville, HM Prison Holloway, 2013 AFL season, Philadelphia, Chevrolet big-block engine, Ludlow Castle, Kudankulam Nuclear Power Plant, 1983 World Championships in Athletics, Avalonia, Golden Horn, Makemake, Football Park, Gulf of Thailand, Congress of Monastir, Hampstead Heath, NGC 6946, Royal Porthcawl Golf Club, Virginia Tech, The Timekeeper, St Martin-in-the-Fields, malleolus, which one is the most conceptually similar with 1978 FIFA World Cup?", "pred": " \n\nA) Chevy big-block engine\nB) Congress of Monastir\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.31479090452194214}, {"text": "A", "logprob": -0.6039242148399353}, {"text": ")", "logprob": -0.651970386505127}, {"text": " Chevy", "logprob": -7.284004211425781}, {"text": " big", "logprob": -0.9419118165969849}, {"text": "-block", "logprob": -0.05067978799343109}, {"text": " engine", "logprob": -0.11723261326551437}, {"text": "\n", "logprob": -0.3669700026512146}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Congress", "logprob": -1.9211243391036987}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " Mon", "logprob": -1.3112935448589269e-05}, {"text": "ast", "logprob": -1.3112935448589269e-05}, {"text": "ir", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.020317647606134415}], "answers": ["2013 AFL season"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Dutch elm disease, nopal, Rawicz, ethylene, Hadim Ali Pasha, Rhinogydd, Zhang Chengye, Petavius, David, Battle of Gettysburg, Ourasphaira giraldae, Mersey Tunnels, Warped Tour, Holin superfamily IV, plantar Lisfranc ligament, Kensington, Damavand, Tokyo Skytree, Royal Botanic Gardens Victoria, Nepenthes edwardsiana, Nepenthes lowii, which one is the most conceptually similar with Phytophthora ramorum?", "pred": " \n\nAnswer: Ourasphaira giraldae. Thyroid Cancer Tumor", "completions_tokens": [{"text": " \n\n", "logprob": -0.12638306617736816}, {"text": "Answer", "logprob": -0.40340885519981384}, {"text": ":", "logprob": -0.020006295293569565}, {"text": " Our", "logprob": -3.3533530235290527}, {"text": "as", "logprob": -1.3112935448589269e-05}, {"text": "ph", "logprob": -1.3112935448589269e-05}, {"text": "aira", "logprob": -1.3112935448589269e-05}, {"text": " g", "logprob": -1.3112935448589269e-05}, {"text": "iral", "logprob": -1.3112935448589269e-05}, {"text": "dae", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.10080546885728836}, {"text": " Thy", "logprob": -10.859936714172363}, {"text": "roid", "logprob": -2.509852170944214}, {"text": " Cancer", "logprob": -4.8379364013671875}, {"text": " T", "logprob": -5.576406955718994}, {"text": "umor", "logprob": -1.34248685836792}], "answers": ["Ourasphaira giraldae"], "all_classes": "null", "length": 76}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong strychnine, Karla Caves, Gin rummy, Pawan Gupta, Goyet Caves, Circular error probable, Main Southern railway line, Vancouver International Film Festival, Savoy wine, 2001 Nisqually earthquake, Rhymney River, Battle of Stalingrad, World Forestry Congress, Arctic National Wildlife Refuge, Fort Tejon, Great Northern War, Shackleton Glacier, Sun Yat-sen Memorial Hall, anterolateral ligament, Nabulsi cheese, Super Bowl 50, which one is the most conceptually similar with 2009 World Aquatics Championships?", "pred": " \n\nStep 1: We are given a list of entities, and we need", "completions_tokens": [{"text": " \n\n", "logprob": -0.11943851411342621}, {"text": "Step", "logprob": -1.736987590789795}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " We", "logprob": -4.637993812561035}, {"text": " are", "logprob": -1.9031654596328735}, {"text": " given", "logprob": -0.628136932849884}, {"text": " a", "logprob": -0.0103662870824337}, {"text": " list", "logprob": -0.02118774875998497}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " entities", "logprob": -0.4166145920753479}, {"text": ",", "logprob": -0.6342262029647827}, {"text": " and", "logprob": -0.10956396162509918}, {"text": " we", "logprob": -1.3112935448589269e-05}, {"text": " need", "logprob": -0.060292575508356094}], "answers": ["Super Bowl 50"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Eurovision Song Contest 2004, fluoxetine, Phytophthora ramorum, PSMB8, Ludgate Circus, Palmar plate, UEFA Euro 2000, Midland Main Line, glochidium, Hotel del Coronado, Bucheron, Rock and Roll Hall of Fame, Quabbin Aqueduct, New York Film Festival, Korean War, Invasion of Poland, Telluride Film Festival, Marshalsea, dilator naris muscle, Siege of Vicksburg, Irish Rebellion of 1641, which one is the most conceptually similar with Newark Airport Interchange?", "pred": " \n Answer: Rock and Roll Hall of Fame.. Bathymetry, Human", "completions_tokens": [{"text": " \n", "logprob": -1.4651689529418945}, {"text": " Answer", "logprob": -4.316402435302734}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Rock", "logprob": -4.155866622924805}, {"text": " and", "logprob": -1.3112935448589269e-05}, {"text": " Roll", "logprob": -1.3112935448589269e-05}, {"text": " Hall", "logprob": -1.3112935448589269e-05}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " Fame", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.916229248046875}, {"text": ".", "logprob": -5.17694091796875}, {"text": " Bath", "logprob": -12.559183120727539}, {"text": "ym", "logprob": -3.7154483795166016}, {"text": "etry", "logprob": -0.2663458585739136}, {"text": ",", "logprob": -3.3482680320739746}, {"text": " Human", "logprob": -7.327300071716309}], "answers": ["Ludgate Circus"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Botryosphaeria stevensii, Diplodia mutila, Palms Casino Resort, Bahia Emerald, Brisbane Showgrounds, Nike Missile Site C47, County Cricket Ground, Chelmsford, Russian roulette, The Great Movie Ride, Gatchina Palace, Yugoslav Wars, Mount Everest, San Diego, Loch Lomond, stigmatomycosis, Royal Oak, Salton Sea, Bangladesh Liberation War, Mount Washington, Farakka Super Thermal Power Station, garlic salt, which one is the most conceptually similar with Liu Jishu?", "pred": " \n\nStep 1: Liu Jishu was a Chinese general\nStep ", "completions_tokens": [{"text": " \n\n", "logprob": -0.6337552666664124}, {"text": "Step", "logprob": -0.6969877481460571}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Liu", "logprob": -1.4564647674560547}, {"text": " J", "logprob": -1.3112935448589269e-05}, {"text": "ish", "logprob": -1.3112935448589269e-05}, {"text": "u", "logprob": -1.3112935448589269e-05}, {"text": " was", "logprob": -2.437140464782715}, {"text": " a", "logprob": -0.09381528198719025}, {"text": " Chinese", "logprob": -0.31877732276916504}, {"text": " general", "logprob": -1.38949453830719}, {"text": "\n", "logprob": -2.8818445205688477}, {"text": "Step", "logprob": -0.005971922539174557}, {"text": " ", "logprob": -1.3112935448589269e-05}], "answers": ["Gatchina Palace"], "all_classes": "null", "length": 88}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong anterolateral ligament, Tangsudo, Princeton, Busan International Film Festival, Armstrong Gun, Moliterno, 2011 Rugby World Cup, False Creek, 2000 Rugby League World Cup, Sumner Tunnel, Trans-Siberian railway, Rummy, Oakland, Banked turn, Produce 101, Electronic Entertainment Expo, Charter Oak, Johnston Atoll, Shoot boxing, STS-74, Oswald Poche, which one is the most conceptually similar with Pawan Gupta?", "pred": " \n\nStep 1: First, we need to identify what Pawan Gupta is", "completions_tokens": [{"text": " \n\n", "logprob": -0.38331764936447144}, {"text": "Step", "logprob": -0.07791408151388168}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " First", "logprob": -2.1167845726013184}, {"text": ",", "logprob": -1.3112935448589269e-05}, {"text": " we", "logprob": -1.1500215530395508}, {"text": " need", "logprob": -0.012559015303850174}, {"text": " to", "logprob": -1.3112935448589269e-05}, {"text": " identify", "logprob": -1.1058199405670166}, {"text": " what", "logprob": -0.5715160369873047}, {"text": " P", "logprob": -0.023749401792883873}, {"text": "awan", "logprob": -1.3112935448589269e-05}, {"text": " Gupta", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -0.1844547539949417}], "answers": ["Oswald Poche"], "all_classes": "null", "length": 79}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Vallnord, Hirudin, M6 motorway, Dancing on Ice, Landsberg Prison, Brain derived neurotrophic factor, Fulton Street Line, MT-RNR1, 5-HTTLPR, solar eclipse of March 20, 2015, Holin superfamily IV, anterolateral ligament, BM-21 Grad, Three Mile Island Nuclear Generating Station, epitrochleoanconeus muscle, Apollo 13, Rockefeller Center, Ferulic acid decarboxylase, Haumea, Draco, CR2032 battery, which one is the most conceptually similar with Elastin?", "pred": " \n\nAnswer: Ferulic acid decarboxylase, Elastin", "completions_tokens": [{"text": " \n\n", "logprob": -0.26145267486572266}, {"text": "Answer", "logprob": -0.3396049737930298}, {"text": ":", "logprob": -0.06702401489019394}, {"text": " Fer", "logprob": -1.9801024198532104}, {"text": "ul", "logprob": -1.3112935448589269e-05}, {"text": "ic", "logprob": -1.3112935448589269e-05}, {"text": " acid", "logprob": -1.3112935448589269e-05}, {"text": " dec", "logprob": -1.3112935448589269e-05}, {"text": "ar", "logprob": -1.3112935448589269e-05}, {"text": "box", "logprob": -1.3112935448589269e-05}, {"text": "yl", "logprob": -1.3112935448589269e-05}, {"text": "ase", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -1.5676002502441406}, {"text": " El", "logprob": -1.0276844501495361}, {"text": "ast", "logprob": -1.3112935448589269e-05}, {"text": "in", "logprob": -1.3112935448589269e-05}], "answers": ["Brain derived neurotrophic factor"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Interleukin 1 beta, Cdc14, Mobile Bay, Apollo, Ultra Music Festival, Wye Valley, Aponeurosis of the Obliquus externus abdominis, Cotswolds, Pluto, Doubletime, XIST, Battle of Fredericksburg, Holin superfamily I, Rock Creek Park, United States Naval Academy, Egg hunt, daf-5, Southwestern Exposition and Livestock Show, police auction, Australia, superficial veins of the brain, which one is the most conceptually similar with C-reactive protein?", "pred": " \n\nStep 1: Conceptual Similarity with C-reactive protein = Understanding", "completions_tokens": [{"text": " \n\n", "logprob": -0.152642160654068}, {"text": "Step", "logprob": -0.7232090830802917}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Concept", "logprob": -6.693271636962891}, {"text": "ual", "logprob": -0.22229652106761932}, {"text": " Similar", "logprob": -0.8249714374542236}, {"text": "ity", "logprob": -1.3112935448589269e-05}, {"text": " with", "logprob": -4.106861591339111}, {"text": " C", "logprob": -0.06143323332071304}, {"text": "-react", "logprob": -0.031759291887283325}, {"text": "ive", "logprob": -1.3112935448589269e-05}, {"text": " protein", "logprob": -0.5044740438461304}, {"text": " =", "logprob": -7.480861186981201}, {"text": " Understanding", "logprob": -3.73201847076416}], "answers": ["Interleukin 1 beta"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong American Revolutionary War, Kinzua Dam, 2017 Central Mexico earthquake, Kenorland, East Branch Fishing Creek, Coen Tunnel, East Gondwana, Woolworth Building, WonderCon, Battle of Britain, TCA Ground, myrrh, Topaz War Relocation Center, TRAPPIST-1h, St Kilda Junction, Almaz, Stockton and Darlington Railway, Bodie, Tihar Jail, Jawaharlal Nehru Stadium, Syrian Civil War, which one is the most conceptually similar with 2008 Republican National Convention?", "pred": " \nAnswer: 2008 Republican National Convention is a political event. Myrr", "completions_tokens": [{"text": " \n", "logprob": -2.1272449493408203}, {"text": "Answer", "logprob": -0.4818269908428192}, {"text": ":", "logprob": -0.0756080225110054}, {"text": " ", "logprob": -0.7117103934288025}, {"text": "200", "logprob": -1.0530438423156738}, {"text": "8", "logprob": -1.3112935448589269e-05}, {"text": " Republican", "logprob": -0.041202858090400696}, {"text": " National", "logprob": -1.3112935448589269e-05}, {"text": " Convention", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -0.9528215527534485}, {"text": " a", "logprob": -1.4847620725631714}, {"text": " political", "logprob": -0.22211953997612}, {"text": " event", "logprob": -0.19455040991306305}, {"text": ".", "logprob": -0.6707445979118347}, {"text": " My", "logprob": -3.9067816734313965}, {"text": "rr", "logprob": -1.3112935448589269e-05}], "answers": ["WonderCon"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong KNM ER 3733, sodium hydroxide, Tane Mahuta, Manuka Oval, Root rot, Taylor-Burton Diamond, Kazanjian Red Diamond, Prometheus, Tehran Conference, Antlia Dwarf, Peninj Mandible, Big Dig, acetylcholine, 1924 Democratic National Convention, Nassak Diamond, Haunted Mansion Holiday, Raffles Hotel, Goyet Caves, uterine venous plexus, ammonia, Chapultepec, which one is the most conceptually similar with frankincense?", "pred": " \n\nThe best answer is Sodium hydroxide. Reference :https://insights", "completions_tokens": [{"text": " \n\n", "logprob": -0.3753645718097687}, {"text": "The", "logprob": -2.335932493209839}, {"text": " best", "logprob": -0.20707698166370392}, {"text": " answer", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -1.3112935448589269e-05}, {"text": " Sodium", "logprob": -3.780712127685547}, {"text": " hydro", "logprob": -0.2170635461807251}, {"text": "x", "logprob": -1.3112935448589269e-05}, {"text": "ide", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.026417715474963188}, {"text": " Reference", "logprob": -5.427795886993408}, {"text": " :", "logprob": -0.02614646591246128}, {"text": "https", "logprob": -3.3563761711120605}, {"text": "://", "logprob": -1.3112935448589269e-05}, {"text": "ins", "logprob": -8.330561637878418}, {"text": "ights", "logprob": -0.8995381593704224}], "answers": ["acetylcholine"], "all_classes": "null", "length": 77}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Ultraviolet, alanine aminotransferase, Kepler-62e, Cl-transporting ATPase, Palmar plate, Ostankino Tower, Jones Falls, Ponticulus, Plesetsk Cosmodrome Site 32, Bristol Motor Speedway, Clochette, Cross City Tunnel, Egg hunt, Doublesex, TOG superfamily, Parthenium argentatum, Tay Rail Bridge, Devonian, Xq28, MetroWest Water Supply Tunnel, Brain derived neurotrophic factor, which one is the most conceptually similar with glucagon?", "pred": " \n\nAnswer: Bristol Motor Speedway, Ostankino Tower, Tay Rail Bridge,", "completions_tokens": [{"text": " \n\n", "logprob": -0.23030133545398712}, {"text": "Answer", "logprob": -0.06765413284301758}, {"text": ":", "logprob": -0.025606419891119003}, {"text": " Bristol", "logprob": -6.4064435958862305}, {"text": " Motor", "logprob": -1.3112935448589269e-05}, {"text": " Speedway", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -1.4288854598999023}, {"text": " Ost", "logprob": -2.6200428009033203}, {"text": "ank", "logprob": -1.3112935448589269e-05}, {"text": "ino", "logprob": -1.3112935448589269e-05}, {"text": " Tower", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -0.2099793553352356}, {"text": " Tay", "logprob": -2.18143630027771}, {"text": " Rail", "logprob": -1.3112935448589269e-05}, {"text": " Bridge", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -0.30231574177742004}], "answers": ["Brain derived neurotrophic factor"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Conococheague Creek, OTO Melara 76 mm, Caudal artery, Korean War, 2009 World Aquatics Championships, Joint Direct Attack Munition, 2017 Central Mexico earthquake, Arctic National Wildlife Refuge, Bristol Motor Speedway, Socorro Island, solar eclipse of May 29, 1919, Montreal International Jazz Festival, Croatia, Fifth Avenue, Palm Springs International Film Festival, Coca-Cola Life, Moscow International Film Festival, compressed tea, solar eclipse of August 1, 2008, Eurovision Song Contest 2005, 1950 United Kingdom general election, which one is the most conceptually similar with Mexico?", "pred": " \n\nTue, 09 August 2022 |\nfrom olympia wa in", "completions_tokens": [{"text": " \n\n", "logprob": -0.32793858647346497}, {"text": "Tue", "logprob": -11.289416313171387}, {"text": ",", "logprob": -0.4763892889022827}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "09", "logprob": -2.9313790798187256}, {"text": " August", "logprob": -6.709885597229004}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "202", "logprob": -0.05938609689474106}, {"text": "2", "logprob": -1.3112935448589269e-05}, {"text": " |\n", "logprob": -3.134442090988159}, {"text": "from", "logprob": -0.6502785682678223}, {"text": " o", "logprob": -8.521018028259277}, {"text": "lymp", "logprob": -1.8564263582229614}, {"text": "ia", "logprob": -1.5686075687408447}, {"text": " wa", "logprob": -3.455029249191284}, {"text": " in", "logprob": -6.395768642425537}], "answers": ["Croatia"], "all_classes": "null", "length": 107}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Drax power station, Lake Van, Quebec Conference, King Arthur Carrousel, tooth loss, Els Quatre Gats, Warragamba Dam, RuneQuest, Suntec City, Wine auction, Pawan Gupta, Verrazzano-Narrows Bridge, 25143 Itokawa, Las Vegas Valley, Marble Arch, Alhambra, Oltermanni, police auction, Park Avenue, Cluedo, Banked turn, which one is the most conceptually similar with team pursuit?", "pred": " \n\nAnswer: Banked turn.  Banked turn is a concept, which", "completions_tokens": [{"text": " \n\n", "logprob": -0.4933888912200928}, {"text": "Answer", "logprob": -0.5097835659980774}, {"text": ":", "logprob": -0.07227157801389694}, {"text": " Bank", "logprob": -1.067232370376587}, {"text": "ed", "logprob": -1.3112935448589269e-05}, {"text": " turn", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.2294585406780243}, {"text": " ", "logprob": -2.8124382495880127}, {"text": " Bank", "logprob": -2.548248291015625}, {"text": "ed", "logprob": -1.3112935448589269e-05}, {"text": " turn", "logprob": -0.06161864101886749}, {"text": " is", "logprob": -0.5930277109146118}, {"text": " a", "logprob": -0.9539704322814941}, {"text": " concept", "logprob": -1.9422132968902588}, {"text": ",", "logprob": -3.3457553386688232}, {"text": " which", "logprob": -2.236035108566284}], "answers": ["Banked turn"], "all_classes": "null", "length": 77}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong NBA Draft Lottery, Congressional Cemetery, Formula 5000, East Delaware Tunnel, MT-TW, Kanchenjunga, aluminum oxide, The Proms, 1976 Tangshan earthquake, Produce 101, Midtown Manhattan, Laramidia, table football, Trans-Canada Highway, police auction, Fort Sill, Warwick Castle, Agnes Edwards (craftworker), Hercules, Bay of Plenty, Doncaster Racecourse, which one is the most conceptually similar with Florida Championship Wrestling?", "pred": " FCW is a professional wrestling promotion based in Tampa, Florida.\n\nDebate:\n", "completions_tokens": [{"text": " FC", "logprob": -3.6244029998779297}, {"text": "W", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -0.533326268196106}, {"text": " a", "logprob": -0.23268111050128937}, {"text": " professional", "logprob": -0.4133392572402954}, {"text": " wrestling", "logprob": -0.02569333091378212}, {"text": " promotion", "logprob": -0.02650327980518341}, {"text": " based", "logprob": -1.1861584186553955}, {"text": " in", "logprob": -0.041125521063804626}, {"text": " Tampa", "logprob": -0.30299341678619385}, {"text": ",", "logprob": -0.09036598354578018}, {"text": " Florida", "logprob": -0.01755942776799202}, {"text": ".\n\n", "logprob": -0.904201090335846}, {"text": "De", "logprob": -8.07846736907959}, {"text": "bate", "logprob": -2.915969133377075}, {"text": ":\n", "logprob": -3.601210117340088}], "answers": ["Formula 5000"], "all_classes": "null", "length": 81}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong meningohypophyseal artery, Holin superfamily I, Staff College, Camberley, Russian River Valley AVA, Oxbridge, Pine Barrens, Normandy landings, XIST, South China Sea, Eagle Diamond, Nepenthes murudensis, MT-RNR1, 1989 Loma Prieta earthquake, Osterley Park, Keno, Saldanha man, kho kho, 1992 United Kingdom general election, CR2032 battery, PTS-GFL superfamily, Downtown Seattle Transit Tunnel, which one is the most conceptually similar with Dubrovnik?", "pred": " ___\nAnswer: Normandy landings ___ is most conceptually similar with Dub", "completions_tokens": [{"text": " ___", "logprob": -10.475601196289062}, {"text": "\n", "logprob": -0.5152819156646729}, {"text": "Answer", "logprob": -0.048602089285850525}, {"text": ":", "logprob": -0.00951410923153162}, {"text": " Norm", "logprob": -2.254918098449707}, {"text": "andy", "logprob": -1.3112935448589269e-05}, {"text": " land", "logprob": -1.3112935448589269e-05}, {"text": "ings", "logprob": -1.3112935448589269e-05}, {"text": " ___", "logprob": -1.34917151927948}, {"text": " is", "logprob": -1.6007908582687378}, {"text": " most", "logprob": -2.4372024536132812}, {"text": " concept", "logprob": -0.2750151455402374}, {"text": "ually", "logprob": -1.3112935448589269e-05}, {"text": " similar", "logprob": -1.3112935448589269e-05}, {"text": " with", "logprob": -0.19177290797233582}, {"text": " Dub", "logprob": -0.5972961783409119}], "answers": ["Staff College, Camberley"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Produce 101, Show hunter, Paleogene, Cluedo, 6 Hebe, Procyon, SM Mall of Asia, Tattletales, spiral artery, M. A. Chidambaram Stadium, Minidoka National Historic Site, Wine auction, Oxford University Parks, Siracourt V-1 bunker, Nagarjuna Sagar Dam, Martinsville Speedway, 1954 FIFA World Cup, Risk, Voskhod 2, Caribbean Sea, Durham Cathedral, which one is the most conceptually similar with Pawan Gupta?", "pred": " \n\nAnswer: Procyon (its ultimate goal is to bring the contestants to", "completions_tokens": [{"text": " \n\n", "logprob": -0.5608401894569397}, {"text": "Answer", "logprob": -0.7849592566490173}, {"text": ":", "logprob": -0.03590690344572067}, {"text": " Pro", "logprob": -2.527151346206665}, {"text": "cy", "logprob": -1.3112935448589269e-05}, {"text": "on", "logprob": -1.3112935448589269e-05}, {"text": " (", "logprob": -3.2848236560821533}, {"text": "its", "logprob": -6.537712097167969}, {"text": " ultimate", "logprob": -10.211552619934082}, {"text": " goal", "logprob": -1.5012198686599731}, {"text": " is", "logprob": -0.4022187888622284}, {"text": " to", "logprob": -0.5038465857505798}, {"text": " bring", "logprob": -4.96817684173584}, {"text": " the", "logprob": -2.775127649307251}, {"text": " contestants", "logprob": -3.119141101837158}, {"text": " to", "logprob": -1.6037367582321167}], "answers": ["Wine auction"], "all_classes": "null", "length": 83}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong American Golden Topaz, propane, naloxone, Reggianito, Caciotta, valproic acid, Lake Maracaibo, 1976 Tangshan earthquake, Woodhead Tunnel, Tiffany Yellow Diamond, nopal, Humber Bridge, Port Jackson, Bonnaroo Music Festival, codeine, Scott Glacier, KNM ER 1813, Prometheus, Mogao Caves, Pret a Manger, Kedleston Hall, which one is the most conceptually similar with ethylene?", "pred": " \n\nAnswer: Naloxone False, Propane, Woodhead Tunnel,", "completions_tokens": [{"text": " \n\n", "logprob": -0.41957077383995056}, {"text": "Answer", "logprob": -0.2114698439836502}, {"text": ":", "logprob": -0.022987548261880875}, {"text": " N", "logprob": -2.3536899089813232}, {"text": "al", "logprob": -0.031046856194734573}, {"text": "ox", "logprob": -1.3112935448589269e-05}, {"text": "one", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -4.855372905731201}, {"text": ",", "logprob": -2.6317567825317383}, {"text": " Pro", "logprob": -2.630441665649414}, {"text": "pane", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -1.2171273231506348}, {"text": " Wood", "logprob": -3.3794169425964355}, {"text": "head", "logprob": -1.3112935448589269e-05}, {"text": " Tunnel", "logprob": -0.002446041675284505}, {"text": ",", "logprob": -0.12798388302326202}], "answers": ["propane"], "all_classes": "null", "length": 74}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Brahma, naloxone, ADC Cirrus, Karawanks Tunnel, Hadim Suleiman Pasha, Alexander III Commemorative, hydrogen peroxide, Paul the Octopus, Monterey Bay, nitric acid, crisantaspase, Lewis gun, Gulf of California, renin, Eclipse of Thales, Settle to Carlisle Line, Sonoma Coast AVA, Wintergreen, Tesla Powerwall, Crystal the Monkey, Ourasphaira giraldae, which one is the most conceptually similar with Nepenthes murudensis?", "pred": ".\n\n\nANSWER: Tesla Powerwall. nothing else has anything in common with nep", "completions_tokens": [{"text": ".\n\n\n", "logprob": -9.233320236206055}, {"text": "ANS", "logprob": -1.7310312986373901}, {"text": "WER", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Tesla", "logprob": -4.750627517700195}, {"text": " Power", "logprob": -1.3112935448589269e-05}, {"text": "wall", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.41844770312309265}, {"text": " nothing", "logprob": -7.968724727630615}, {"text": " else", "logprob": -1.2504782676696777}, {"text": " has", "logprob": -4.784715175628662}, {"text": " anything", "logprob": -2.606663465499878}, {"text": " in", "logprob": -2.143416404724121}, {"text": " common", "logprob": -0.07865506410598755}, {"text": " with", "logprob": -0.24842633306980133}, {"text": " nep", "logprob": -2.315887212753296}], "answers": ["Wintergreen"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Monitor-Merrimac Memorial Bridge-Tunnel, STS-51-B, Sampson artery, Ford Modular engine, Hadassah Medical Center, mucin, Peninj Mandible, 2019 Rugby World Cup, Vredefort crater, solar eclipse of March 29, 2006, BMW 801, Pinconning cheese, perforator vein, War on Terror, STS-121, Deneb, Beau Sancy, Mauer 1, TRAPPIST-1f, Swatara Creek, trabecular veins, which one is the most conceptually similar with Hole-in-the-Ground?", "pred": " \nAnswer: Hole-in-the-Ground. Context: \"most conceptually similar", "completions_tokens": [{"text": " \n", "logprob": -1.6479699611663818}, {"text": "Answer", "logprob": -0.29776307940483093}, {"text": ":", "logprob": -0.08046476542949677}, {"text": " Hole", "logprob": -1.5625698566436768}, {"text": "-in", "logprob": -1.3112935448589269e-05}, {"text": "-the", "logprob": -1.3112935448589269e-05}, {"text": "-G", "logprob": -0.041885003447532654}, {"text": "round", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.9070876836776733}, {"text": " Context", "logprob": -7.604236602783203}, {"text": ":", "logprob": -0.4429330825805664}, {"text": " \"", "logprob": -5.226927280426025}, {"text": "most", "logprob": -6.540428161621094}, {"text": " concept", "logprob": -0.24024540185928345}, {"text": "ually", "logprob": -1.3112935448589269e-05}, {"text": " similar", "logprob": -0.01910335384309292}], "answers": ["Vredefort crater"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Lake Lucerne, Warwick Castle, English Dresden, Soyuz 5, Radicular artery, Julier Pass, Forest of Bowland, Siege of Yorktown, High Five Interchange, Sydney Film Festival, Mount Erebus, Super Bowl XXXV, 12.7 cm/40 Type 89 naval gun, Shasta Dam, French Revolutionary Wars, Horizons, Clyde Tunnel, Interleukin 2, Church of the Holy Sepulchre, General Theological Seminary, Battle of Waterloo, which one is the most conceptually similar with STS-41-B?", "pred": " STS-41-B mainly involves the shuttle orbiting and astronauts working, nearly", "completions_tokens": [{"text": " ST", "logprob": -2.866729974746704}, {"text": "S", "logprob": -1.3112935448589269e-05}, {"text": "-", "logprob": -1.3112935448589269e-05}, {"text": "41", "logprob": -0.004956696182489395}, {"text": "-B", "logprob": -0.012959894724190235}, {"text": " mainly", "logprob": -8.311490058898926}, {"text": " involves", "logprob": -2.4725892543792725}, {"text": " the", "logprob": -1.2134541273117065}, {"text": " shuttle", "logprob": -4.980052471160889}, {"text": " orbit", "logprob": -5.352823734283447}, {"text": "ing", "logprob": -0.13584460318088531}, {"text": " and", "logprob": -2.310788631439209}, {"text": " astronauts", "logprob": -6.108325481414795}, {"text": " working", "logprob": -2.7908451557159424}, {"text": ",", "logprob": -5.376654624938965}, {"text": " nearly", "logprob": -10.873563766479492}], "answers": ["Soyuz 5"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Miocene, Corviglia, Perrier, Oltermanni, Pom1, Bodo cranium, Eridge Park, dilator naris muscle, Mrs. Ples, Trp operon, Filchner-Ronne Ice Shelf, Diet Pepsi, anterolateral ligament, Reflex inguinal ligament, Tycho, Fusarium wilt, Friuli-Venezia Giulia wine, Monster Energy, Coca-Cola Life, 1990 FIFA World Cup, throwball, which one is the most conceptually similar with Clochette?", "pred": " \nAnswer: Mrs. Ples. Similarity: Mrs. Ples.", "completions_tokens": [{"text": " \n", "logprob": -1.688383936882019}, {"text": "Answer", "logprob": -1.0394911766052246}, {"text": ":", "logprob": -0.03968949615955353}, {"text": " Mrs", "logprob": -2.939589500427246}, {"text": ".", "logprob": -0.042489685118198395}, {"text": " P", "logprob": -1.3112935448589269e-05}, {"text": "les", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.14698103070259094}, {"text": " Similar", "logprob": -4.394102096557617}, {"text": "ity", "logprob": -0.21962182223796844}, {"text": ":", "logprob": -1.0944077968597412}, {"text": " Mrs", "logprob": -1.1293367147445679}, {"text": ".", "logprob": -0.015145775862038136}, {"text": " P", "logprob": -1.3112935448589269e-05}, {"text": "les", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.1106405258178711}], "answers": ["Oltermanni"], "all_classes": "null", "length": 74}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong epitrochleoanconeus muscle, Palmar plate, Late Antiquity, Brain derived neurotrophic factor, congress of Berlin, 2010 FIFA World Cup, Battle of Britain, Leopard complex, English Channel, Spanish colonization of the Americas, Jurassic, Sam Yan, Star Tours, Bay of Biscay, Mar-a-Lago, Battle of Crete, police auction, International Film Festival of India, Little Boy, Oswald Poche, Poston War Relocation Center, which one is the most conceptually similar with Weddell Sea?", "pred": " \n\nAnswer: Jurassic. This is because all of these entities have the only thing", "completions_tokens": [{"text": " \n\n", "logprob": -0.35239285230636597}, {"text": "Answer", "logprob": -0.584075927734375}, {"text": ":", "logprob": -0.18523550033569336}, {"text": " Jurassic", "logprob": -1.249155044555664}, {"text": ".", "logprob": -0.18208175897598267}, {"text": " This", "logprob": -5.38405704498291}, {"text": " is", "logprob": -0.5886030793190002}, {"text": " because", "logprob": -0.40627890825271606}, {"text": " all", "logprob": -2.6132774353027344}, {"text": " of", "logprob": -1.0721114873886108}, {"text": " these", "logprob": -1.1162301301956177}, {"text": " entities", "logprob": -1.1552109718322754}, {"text": " have", "logprob": -2.6482150554656982}, {"text": " the", "logprob": -3.0064334869384766}, {"text": " only", "logprob": -6.0261149406433105}, {"text": " thing", "logprob": -1.9036235809326172}], "answers": ["English Channel"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong NGC 379, Nepenthes glabrata, Chota Nagpur Plateau, Smithsonian American Art Museum, Mount Vernon, Parthenium argentatum, solar eclipse of July 10, 1972, Meiji period, Georgian Bay, Powerade, Pont Neuf, Brisbane Powerhouse, gallium arsenide, RSL-3, Chelyabinsk meteor, Scapa Flow, Theia, Hotel del Coronado, Lake Superior, lateral rotator group, rs6314, which one is the most conceptually similar with Silurian?", "pred": " \nAnswer: \nSilurian is a geological period, thus the similar concept", "completions_tokens": [{"text": " \n", "logprob": -0.5892360806465149}, {"text": "Answer", "logprob": -0.22545430064201355}, {"text": ":", "logprob": -0.17000354826450348}, {"text": " \n", "logprob": -4.074006080627441}, {"text": "Sil", "logprob": -1.253004550933838}, {"text": "ur", "logprob": -1.3112935448589269e-05}, {"text": "ian", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -0.9682669639587402}, {"text": " a", "logprob": -0.2562124729156494}, {"text": " geological", "logprob": -2.5069093704223633}, {"text": " period", "logprob": -0.676676869392395}, {"text": ",", "logprob": -1.4728589057922363}, {"text": " thus", "logprob": -2.8705286979675293}, {"text": " the", "logprob": -0.9557954668998718}, {"text": " similar", "logprob": -4.751830101013184}, {"text": " concept", "logprob": -1.7362498044967651}], "answers": ["Meiji period"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1998 FIFA World Cup, Spring Grove Cemetery, Ford Island, Epidermal growth factor, Diplodia mutila, King Kong Encounter, Phytophthora ramorum, Borneo, Caldecott Tunnel, The Indian Bean Tree, St James Square, Monmouth, Bucheron, Royal Oak, ophthalmic veins, djon djon, Tanna Tunnel, Alexander Valley AVA, Christian the lion, Teatro Real, 5145 Pholus, Times Square, Michigan Central Railway Tunnel, which one is the most conceptually similar with Liu Jishu?", "pred": " \n\nStep 1: Let's start by analyzing the list of entities given.", "completions_tokens": [{"text": " \n\n", "logprob": -0.7220586538314819}, {"text": "Step", "logprob": -0.4686432182788849}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Let", "logprob": -5.706474304199219}, {"text": "'s", "logprob": -0.020317647606134415}, {"text": " start", "logprob": -2.442664623260498}, {"text": " by", "logprob": -0.02027500979602337}, {"text": " analyzing", "logprob": -1.482546091079712}, {"text": " the", "logprob": -0.15332357585430145}, {"text": " list", "logprob": -1.0524601936340332}, {"text": " of", "logprob": -0.27563872933387756}, {"text": " entities", "logprob": -0.4906403422355652}, {"text": " given", "logprob": -1.651168704032898}, {"text": ".", "logprob": -0.8314416408538818}], "answers": ["Christian the lion"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1990 Luzon earthquake, Centre Georges Pompidou, Solar eclipse of July 31, 1981, ELA-4, Bayreuth Festival, Karla Caves, Cullinan Diamond, Gulf of Tonkin, Salzburg Festival, Tian Lingzi, superficial dorsal vein of the penis, Nepenthes kerrii, Cunninghams Gap, Sun Yat-sen Memorial Hall, Phytophthora ramorum, River Teme, Super Bowl XLIV, Diplodia mutila, Kveik, stigmatomycosis, Bay of Bengal, which one is the most conceptually similar with Bart the Bear 2?", "pred": " \n\nA) The Great Bear.\nB) Bart the Bear 2.\nC", "completions_tokens": [{"text": " \n\n", "logprob": -0.306694358587265}, {"text": "A", "logprob": -2.229058265686035}, {"text": ")", "logprob": -0.26281529664993286}, {"text": " The", "logprob": -4.993473529815674}, {"text": " Great", "logprob": -4.392688751220703}, {"text": " Bear", "logprob": -2.622068405151367}, {"text": ".\n", "logprob": -5.177923202514648}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Bart", "logprob": -1.6918648481369019}, {"text": " the", "logprob": -0.10600537061691284}, {"text": " Bear", "logprob": -0.009920341894030571}, {"text": " ", "logprob": -0.37475067377090454}, {"text": "2", "logprob": -0.010123219341039658}, {"text": ".\n", "logprob": -0.17994950711727142}, {"text": "C", "logprob": -1.3112935448589269e-05}], "answers": ["Tian Lingzi"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 20 July plot, Radicular artery, Savoy wine, Super Bowl XXXIV, nandrolone, Washington National Cathedral, Kanchenjunga, Pepsi Max, (S)-corytuberine synthase, 1987 World Championships in Athletics, Star Wars Launch Bay, Battle of France, Diplodia mutila, Eridge Park, Outer Coastal Plain AVA, wagasi, stigmatomycosis, Antigua, Palmar plate, MT-TW, Christian the lion, which one is the most conceptually similar with Honshu?", "pred": " \nAnswer: MT-TW is a mitochondrial transfer RNA, which does not have", "completions_tokens": [{"text": " \n", "logprob": -1.6713428497314453}, {"text": "Answer", "logprob": -0.10962966829538345}, {"text": ":", "logprob": -0.01423631701618433}, {"text": " MT", "logprob": -2.307363748550415}, {"text": "-T", "logprob": -1.3112935448589269e-05}, {"text": "W", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -2.4134621620178223}, {"text": " a", "logprob": -1.0963104963302612}, {"text": " mitochondrial", "logprob": -0.749689519405365}, {"text": " transfer", "logprob": -0.7968745231628418}, {"text": " RNA", "logprob": -0.04903111979365349}, {"text": ",", "logprob": -1.4376752376556396}, {"text": " which", "logprob": -1.831373691558838}, {"text": " does", "logprob": -3.8803257942199707}, {"text": " not", "logprob": -0.010370888747274876}, {"text": " have", "logprob": -0.9957953691482544}], "answers": ["Antigua"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Kilmainham Gaol, Dubrovnik, Tango, Pinconning cheese, Mechanistic target of rapamycin kinase, anterolateral ligament, Marble Arch, Reggianito, Bucheron, mucin, Kasat Suek Intersection, KNM WT 17000, Donner Pass, 5145 Pholus, wagasi, Caciotta, Red Sea, Ferrar Glacier, 2011 Rugby World Cup, Baltoro Glacier, corticotropin, which one is the most conceptually similar with Leffe?", "pred": " \nBy: Abdullah Wahyudi Rahmadhani (University of Mataram)\n\n", "completions_tokens": [{"text": " \n", "logprob": -1.7255610227584839}, {"text": "By", "logprob": -3.9250056743621826}, {"text": ":", "logprob": -0.040283024311065674}, {"text": " Abdullah", "logprob": -5.661092281341553}, {"text": " Wah", "logprob": -6.756296157836914}, {"text": "y", "logprob": -0.12666992843151093}, {"text": "udi", "logprob": -0.103459432721138}, {"text": " Rah", "logprob": -5.472294807434082}, {"text": "mad", "logprob": -1.4364317655563354}, {"text": "hani", "logprob": -1.4515959024429321}, {"text": " (", "logprob": -0.03788188472390175}, {"text": "University", "logprob": -3.1279048919677734}, {"text": " of", "logprob": -0.0071951556019485}, {"text": " Mat", "logprob": -4.219388961791992}, {"text": "aram", "logprob": -1.3112935448589269e-05}, {"text": ")\n\n", "logprob": -0.03447384014725685}], "answers": ["Tango"], "all_classes": "null", "length": 74}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Super Bowl LI, Ford FE engine, chase gun, Mount of Olives, Stalag Luft III, djon djon, keel, Ecarin, 1924 Democratic National Convention, Formula 5000, Brenner Base Tunnel, Damavand, Hotchkiss gun, Early Cretaceous, Wine auction, 1962 FIFA World Cup, Before Present, TCA Ground, San Bernardino Tunnel, Irn-Bru, National Christmas Tree, which one is the most conceptually similar with Carrara Stadium?", "pred": " \nAnswer: Formula 5000. [[]] [[]] [[]] [[]]", "completions_tokens": [{"text": " \n", "logprob": -1.6042828559875488}, {"text": "Answer", "logprob": -0.6163438558578491}, {"text": ":", "logprob": -0.05674552544951439}, {"text": " Formula", "logprob": -1.6953203678131104}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "500", "logprob": -1.3112935448589269e-05}, {"text": "0", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.09625822305679321}, {"text": " [[]", "logprob": -11.20176887512207}, {"text": "]", "logprob": -1.3112935448589269e-05}, {"text": " [[]", "logprob": -0.37609896063804626}, {"text": "]", "logprob": -0.009081368334591389}, {"text": " [[]", "logprob": -0.11093920469284058}, {"text": "]", "logprob": -1.3112935448589269e-05}, {"text": " [[]", "logprob": -0.04236125946044922}, {"text": "]", "logprob": -1.3112935448589269e-05}], "answers": ["TCA Ground"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong (15788) 1993 SB, 10.5 cm SK C/32 naval gun, 8.8 cm SK L/45 naval gun, Adirondack Park, carbon disulfide, Arlington National Cemetery, UEFA Euro 2004, Blenheim Park, RPG-7, Afon Irfon, Festning Tunnel, Winter War, Tesla Powerwall, Lewis gun, Syzygium guineense, Preseli Hills, Utopia Planitia, Risiera di San Sabba, Unteraar Glacier, histamine, Udayagiri and Khandagiri Caves, which one is the most conceptually similar with CR2032 battery?", "pred": " \n\nStep 1: Understanding the concept of similarity in a battery context\nTo", "completions_tokens": [{"text": " \n\n", "logprob": -0.15352614223957062}, {"text": "Step", "logprob": -2.5272059440612793}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Understanding", "logprob": -5.084049224853516}, {"text": " the", "logprob": -0.05675194784998894}, {"text": " concept", "logprob": -1.4120678901672363}, {"text": " of", "logprob": -0.034332629293203354}, {"text": " similarity", "logprob": -0.7828122973442078}, {"text": " in", "logprob": -1.5501246452331543}, {"text": " a", "logprob": -2.830151081085205}, {"text": " battery", "logprob": -4.082890510559082}, {"text": " context", "logprob": -0.6819753050804138}, {"text": "\n", "logprob": -0.2719497084617615}, {"text": "To", "logprob": -0.3978790044784546}], "answers": ["Tesla Powerwall"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Inca Kola, interclavicle, Russian Tea Room, Pula Film Festival, CR2032 battery, Staten Island Railway, calcium oxide, Xynotyro, Reflex inguinal ligament, San Diego, epitrochleoanconeus muscle, Nissan E engine, tooth loss, Fort Laramie National Historic Site, Rover V8 engine, National Soccer Hall of Fame, Four Mile Run, Heian period, fentanyl, plantar Lisfranc ligament, Cross City Tunnel, which one is the most conceptually similar with Vasai Creek?", "pred": " \n\nAnswer: Cross City Tunnel is most similar with the Vasai Creek as both", "completions_tokens": [{"text": " \n\n", "logprob": -1.3402124643325806}, {"text": "Answer", "logprob": -0.24924001097679138}, {"text": ":", "logprob": -0.05761276185512543}, {"text": " Cross", "logprob": -4.016251564025879}, {"text": " City", "logprob": -1.3112935448589269e-05}, {"text": " Tunnel", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -3.1819562911987305}, {"text": " most", "logprob": -1.8415448665618896}, {"text": " similar", "logprob": -1.149845004081726}, {"text": " with", "logprob": -0.7412992715835571}, {"text": " the", "logprob": -5.095727443695068}, {"text": " Vas", "logprob": -0.8251500725746155}, {"text": "ai", "logprob": -1.3112935448589269e-05}, {"text": " Creek", "logprob": -0.02128087915480137}, {"text": " as", "logprob": -2.32717227935791}, {"text": " both", "logprob": -0.6148393750190735}], "answers": ["Four Mile Run"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Caciotta, anterolateral ligament, Oltermanni, Algonquin Provincial Park, American Astronomical Society 215th meeting, Cloth Hall, Ypres, Blackfriars Bridge, Oswald Poche, Tokaj wine region, Moliterno, Fortress of Louisbourg, Jura wine, Egg hunt, The Pierre, Palmar plate, Centre Georges Pompidou, Burgess Shale, Finding Nemo Submarine Voyage, Criollo cheese, Reggianito, Holy See, which one is the most conceptually similar with Coca-Cola Life?", "pred": " \nSolution:\n\nCriollo cheese\n\nThe Criollo cheese has also been branded under", "completions_tokens": [{"text": " \n", "logprob": -1.8078105449676514}, {"text": "Solution", "logprob": -9.492647171020508}, {"text": ":\n\n", "logprob": -1.0052064657211304}, {"text": "Cri", "logprob": -0.5822655558586121}, {"text": "ollo", "logprob": -1.3112935448589269e-05}, {"text": " cheese", "logprob": -1.3112935448589269e-05}, {"text": "\n\n", "logprob": -0.5563106536865234}, {"text": "The", "logprob": -1.1424071788787842}, {"text": " Cri", "logprob": -1.1997894048690796}, {"text": "ollo", "logprob": -1.3112935448589269e-05}, {"text": " cheese", "logprob": -0.075524240732193}, {"text": " has", "logprob": -3.2390801906585693}, {"text": " also", "logprob": -4.61651086807251}, {"text": " been", "logprob": -0.9075460433959961}, {"text": " branded", "logprob": -2.8780088424682617}, {"text": " under", "logprob": -2.137251377105713}], "answers": ["Jura wine"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong solar eclipse of May 28, 1900, Mrp superfamily, FERONIA, Semlin concentration camp, Ruhleben internment camp, Honshu, Xq28, Diplodia mutila, Prekallikrein, Spitsbergen, Wawona Tunnel, Pawan Gupta, nerve growth factor, Gunnison Tunnel, parathyroid artery, Lysine exporter, Sphenomandibularis, sulfuric acid, solar eclipse of March 20, 2015, fluoxetine, Raghunathpur Thermal Power Station, which one is the most conceptually similar with Myoglobin?", "pred": " \n\nAnswer: None of the above.. Langendorff preparation is conceptually", "completions_tokens": [{"text": " \n\n", "logprob": -0.2616264224052429}, {"text": "Answer", "logprob": -0.19023314118385315}, {"text": ":", "logprob": -0.02765551768243313}, {"text": " None", "logprob": -3.417525291442871}, {"text": " of", "logprob": -0.4025280773639679}, {"text": " the", "logprob": -0.22876830399036407}, {"text": " above", "logprob": -0.37790772318840027}, {"text": ".", "logprob": -0.34048500657081604}, {"text": ".", "logprob": -5.465443134307861}, {"text": " Lang", "logprob": -11.809146881103516}, {"text": "endor", "logprob": -4.303009986877441}, {"text": "ff", "logprob": -0.029410503804683685}, {"text": " preparation", "logprob": -1.885257601737976}, {"text": " is", "logprob": -1.5926764011383057}, {"text": " concept", "logprob": -2.833953857421875}, {"text": "ually", "logprob": -1.3112935448589269e-05}], "answers": ["nerve growth factor"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Surfeit, Centaurus A, War on Terror, Resorts World Sentosa, guarana, 2015 United Kingdom general election, Common Era, Ure2, Criollo cheese, crisantaspase, East Delaware Tunnel, Battle of Crete, Thailand, Plasma membrane Ca2+ ATPase, Dumbo the Flying Elephant, Ruhleben internment camp, Missouri Botanical Garden, Elizabethan era, Ain Dubai, daf-7, Interleukin 2, which one is the most conceptually similar with Sex determining region Y?", "pred": " \n\nA Surfeit\nB Centaurus A\nC War on Terror\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.3200959861278534}, {"text": "A", "logprob": -0.9276289343833923}, {"text": " Sur", "logprob": -3.3208866119384766}, {"text": "feit", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.0396435521543026}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": " Cent", "logprob": -0.16844627261161804}, {"text": "aurus", "logprob": -1.3112935448589269e-05}, {"text": " A", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -1.3112935448589269e-05}, {"text": "C", "logprob": -1.3112935448589269e-05}, {"text": " War", "logprob": -0.04148789495229721}, {"text": " on", "logprob": -1.3112935448589269e-05}, {"text": " Terror", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -1.3112935448589269e-05}, {"text": "D", "logprob": -1.3112935448589269e-05}], "answers": ["Interleukin 2"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Finding Nemo Submarine Voyage, compressed tea, Myanmar, San Pedro, TUC338, 1983 United Kingdom general election, Phytophthora ramorum, Super Bowl XXXVI, Horse Cave, Fort Laramie National Historic Site, Blue Glacier, Mount Ararat, Epidermal growth factor, Napa Valley AVA, Triassic, 1693 Sicily earthquake, Mauer 1, Sagittarius Dwarf Elliptical Galaxy, Daka skull, Thane Creek, Kyushu, which one is the most conceptually similar with Independence Day?", "pred": " It is a reference to an event after other events happening in which the country where", "completions_tokens": [{"text": " It", "logprob": -7.1506123542785645}, {"text": " is", "logprob": -0.5691964030265808}, {"text": " a", "logprob": -1.7182509899139404}, {"text": " reference", "logprob": -5.735301971435547}, {"text": " to", "logprob": -0.06518545001745224}, {"text": " an", "logprob": -3.2057600021362305}, {"text": " event", "logprob": -0.7306656241416931}, {"text": " after", "logprob": -6.874658107757568}, {"text": " other", "logprob": -6.785128593444824}, {"text": " events", "logprob": -1.9312564134597778}, {"text": " happening", "logprob": -6.470964431762695}, {"text": " in", "logprob": -1.1369959115982056}, {"text": " which", "logprob": -5.624944686889648}, {"text": " the", "logprob": -1.8406518697738647}, {"text": " country", "logprob": -4.374202728271484}, {"text": " where", "logprob": -5.553127288818359}], "answers": ["Triassic"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Holin superfamily II, Sawtooth National Recreation Area, BL Lacertae, MACPF, Queen Elizabeth Olympic Park, XIST, Myoglobin, French and Indian War, 1922 United Kingdom general election, Agnes Edwards (craftworker), Hollywood Roosevelt Hotel, Great Britain, solar eclipse of July 29, 1878, Ecarin, TOG superfamily, Grand Trunk Pacific Railway, 50000 Quaoar, Landsberg Prison, Crowsnest Pass, Battle of Fredericksburg, entitlement, which one is the most conceptually similar with Brain derived neurotrophic factor?", "pred": " Answer:\n\nMyoglobin\nFalse\nFalse\nFalse\nSimilar\nTrue\nFalse", "completions_tokens": [{"text": " Answer", "logprob": -3.3013947010040283}, {"text": ":\n\n", "logprob": -0.42468327283859253}, {"text": "My", "logprob": -0.7529204487800598}, {"text": "oglobin", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -1.3311594724655151}, {"text": "False", "logprob": -2.4888722896575928}, {"text": "\n", "logprob": -0.10900963842868805}, {"text": "False", "logprob": -2.9561095237731934}, {"text": "\n", "logprob": -1.3112935448589269e-05}, {"text": "False", "logprob": -0.3553186357021332}, {"text": "\n", "logprob": -1.3112935448589269e-05}, {"text": "Similar", "logprob": -4.592759609222412}, {"text": "\n", "logprob": -0.8602044582366943}, {"text": "True", "logprob": -3.2541985511779785}, {"text": "\n", "logprob": -1.3112935448589269e-05}, {"text": "False", "logprob": -0.7678257822990417}], "answers": ["Myoglobin"], "all_classes": "null", "length": 95}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Gotthard railway, Coarse fishing, Castle Bravo, Liberty Tree, 2004 Indian Ocean earthquake, Welcome Stranger, CYP2J2, Lake Lucerne, Peace Tower, superior thalamic vein, Newport Folk Festival, Les Sybelles, 1971 San Fernando earthquake, cabin fever, Caspian Sea, Agnes Edwards (craftworker), 1963 Skopje earthquake, congress of Berlin, Van Cortlandt Park, Clochette, Tiffany Yellow Diamond, which one is the most conceptually similar with Vanderbilt University?", "pred": " Vanderbilt University is in the United States, and was formally named in 1793", "completions_tokens": [{"text": " Vanderbilt", "logprob": -2.1018030643463135}, {"text": " University", "logprob": -0.042848825454711914}, {"text": " is", "logprob": -0.4420788884162903}, {"text": " in", "logprob": -3.6934590339660645}, {"text": " the", "logprob": -1.1050565242767334}, {"text": " United", "logprob": -0.36856257915496826}, {"text": " States", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -2.3807601928710938}, {"text": " and", "logprob": -1.1417807340621948}, {"text": " was", "logprob": -4.346155166625977}, {"text": " formally", "logprob": -6.487922191619873}, {"text": " named", "logprob": -2.3989663124084473}, {"text": " in", "logprob": -2.049917221069336}, {"text": " ", "logprob": -0.9242580533027649}, {"text": "179", "logprob": -0.20663148164749146}, {"text": "3", "logprob": -3.009366035461426}], "answers": ["Van Cortlandt Park"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Xynotyro, Small Magellanic Cloud, Caciotta, wagasi, Frankfurt City Tunnel, Rolls-Royce Meteor, Kennedy Space Center Launch Complex 39B, solar eclipse of March 29, 2006, Jansky, Tsarskoye Selo, Katiki Domokou, Blue, Gurs internment camp, Moliterno, Vin jaune, Vallnord, Galleria Vittorio Emanuele II, Ursa Minor, Sabina Park, Banjica concentration camp, Teide, which one is the most conceptually similar with Faygo?", "pred": " \n\nAnswer:\n\nFaygo is a brand of soft drinks, therefore the most", "completions_tokens": [{"text": " \n\n", "logprob": -0.8292982578277588}, {"text": "Answer", "logprob": -0.4175094962120056}, {"text": ":\n\n", "logprob": -2.249891519546509}, {"text": "F", "logprob": -1.3303604125976562}, {"text": "ay", "logprob": -1.3112935448589269e-05}, {"text": "go", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -0.7583428025245667}, {"text": " a", "logprob": -0.11004301905632019}, {"text": " brand", "logprob": -0.4490932822227478}, {"text": " of", "logprob": -0.05834869667887688}, {"text": " soft", "logprob": -0.7852694988250732}, {"text": " drinks", "logprob": -1.1363751888275146}, {"text": ",", "logprob": -0.9268712997436523}, {"text": " therefore", "logprob": -1.183855414390564}, {"text": " the", "logprob": -1.0889217853546143}, {"text": " most", "logprob": -0.4316592216491699}], "answers": ["Vin jaune"], "all_classes": "null", "length": 83}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Bataan Death March, Ford Kent engine, Irish Rebellion of 1798, Second Sino-Japanese War, NGC 388, Manhattan Municipal Building, Royal Liverpool Golf Club, Hoylake, 2006 European Athletics Championships, 1700 Cascadia earthquake, Edinburgh International Film Festival, Middlesex Hospital, Criollo cheese, Liu Jishu, Bolivia, Battle of Shiloh, Filchner-Ronne Ice Shelf, Manila Bay, El Escorial, Queensway Tunnel, Hamilton Crescent, Via Lattea, which one is the most conceptually similar with Invasion of Poland?", "pred": " \n\n Fibonacci Sequence\nAnswer: Fibonacci Sequence\nopenhagen. Adoption of Children Act ", "completions_tokens": [{"text": " \n\n", "logprob": -0.5455824136734009}, {"text": " Fibonacci", "logprob": -10.903056144714355}, {"text": " Sequence", "logprob": -2.212660312652588}, {"text": "\n", "logprob": -1.9346740245819092}, {"text": "Answer", "logprob": -2.226073980331421}, {"text": ":", "logprob": -0.010605285875499249}, {"text": " Fibonacci", "logprob": -1.8004717826843262}, {"text": " Sequence", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.8297699093818665}, {"text": "openhagen", "logprob": -11.172157287597656}, {"text": ".", "logprob": -4.565873146057129}, {"text": " Adoption", "logprob": -10.917203903198242}, {"text": " of", "logprob": -0.5696406364440918}, {"text": " Children", "logprob": -5.696572303771973}, {"text": " Act", "logprob": -0.8751015663146973}, {"text": " ", "logprob": -0.37486064434051514}], "answers": ["Second Sino-Japanese War"], "all_classes": "null", "length": 95}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Congressional Cemetery, Poughkeepsie Bridge, Tank Stream, Root rot, Fet3p, Melaleuca alternifolia, HS.404, CR2025, Tesla Powerpack, Tesla Megapack, Alfa Romeo V6 engine, Hofmeyr Skull, Ourasphaira giraldae, Parthenium argentatum, Kinzua Dam, Beartooth Basin Summer Ski Area, Polaris, PSR B1913+16, Aldebaran, Indonesia, Chrysler Pentastar engine, which one is the most conceptually similar with RPG-7?", "pred": " \n\nAnswer: Parthenium argentatum, Petroglyphs, Pollen count", "completions_tokens": [{"text": " \n\n", "logprob": -0.7383685111999512}, {"text": "Answer", "logprob": -0.1808100789785385}, {"text": ":", "logprob": -0.03536071255803108}, {"text": " Par", "logprob": -3.193678140640259}, {"text": "then", "logprob": -1.3112935448589269e-05}, {"text": "ium", "logprob": -1.3112935448589269e-05}, {"text": " argent", "logprob": -1.3112935448589269e-05}, {"text": "atum", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -2.753493547439575}, {"text": " Petro", "logprob": -8.779829025268555}, {"text": "glyph", "logprob": -0.9093496799468994}, {"text": "s", "logprob": -1.4311394691467285}, {"text": ",", "logprob": -0.8119515180587769}, {"text": " Poll", "logprob": -8.383094787597656}, {"text": "en", "logprob": -0.38923537731170654}, {"text": " count", "logprob": -3.186573028564453}], "answers": ["HS.404"], "all_classes": "null", "length": 75}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong solar eclipse of November 25, 2011, Cueva de las Manos, daf-2, Oswald Poche, The Cenotaph, 2016 North Canterbury earthquake, County Ground, Friuli-Venezia Giulia wine, Yazaman al-Khadim, Flyball, Agnes Edwards (craftworker), Fortress of Louisbourg, 2014 FIFA World Cup, Madagascar, Warhammer 40,000, solar eclipse of March 29, 2006, Brandenburg Gate, Intergender wrestling, Pawan Gupta, dorsal digital arteries of foot, SK 46, which one is the most conceptually similar with Rummy?", "pred": "  Among solar eclipse of November 25, 2011, Cueva de", "completions_tokens": [{"text": " ", "logprob": -6.0298027992248535}, {"text": " Among", "logprob": -6.028322219848633}, {"text": " solar", "logprob": -0.18878179788589478}, {"text": " eclipse", "logprob": -1.3112935448589269e-05}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " November", "logprob": -0.002427133498713374}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "25", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "201", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -1.3112935448589269e-05}, {"text": " C", "logprob": -1.3112935448589269e-05}, {"text": "ueva", "logprob": -1.3112935448589269e-05}, {"text": " de", "logprob": -1.3112935448589269e-05}], "answers": ["Warhammer 40,000"], "all_classes": "null", "length": 97}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Bear Mountain Bridge, Bucheron, Raghunathpur Thermal Power Station, cerebellar artery, Pula Film Festival, South Branch Potomac River, Baikonur Cosmodrome Site 200, Northern Ireland, Accessory soleus muscle, 1960 Democratic National Convention, Yellowstone volcano, Adductor muscles of the hip, Bellevue Hospital Center, uterine venous plexus, Adirondack Park, Coen Tunnel, TRAPPIST-1g, lateral rotator group, Venice Film Festival, Spaceport Florida Launch Complex 46, pubovaginal muscle, which one is the most conceptually similar with common digital veins?", "pred": " \n\nAnswer:  uterine venous plexus (venous p", "completions_tokens": [{"text": " \n\n", "logprob": -0.22463427484035492}, {"text": "Answer", "logprob": -0.22583186626434326}, {"text": ":", "logprob": -0.014913144521415234}, {"text": " ", "logprob": -2.672393560409546}, {"text": " ut", "logprob": -1.0544559955596924}, {"text": "er", "logprob": -1.3112935448589269e-05}, {"text": "ine", "logprob": -1.3112935448589269e-05}, {"text": " ven", "logprob": -1.3112935448589269e-05}, {"text": "ous", "logprob": -1.3112935448589269e-05}, {"text": " p", "logprob": -1.3112935448589269e-05}, {"text": "lex", "logprob": -1.3112935448589269e-05}, {"text": "us", "logprob": -1.3112935448589269e-05}, {"text": " (", "logprob": -3.545755624771118}, {"text": "ven", "logprob": -3.694417953491211}, {"text": "ous", "logprob": -1.3112935448589269e-05}, {"text": " p", "logprob": -0.5011411905288696}], "answers": ["uterine venous plexus"], "all_classes": "null", "length": 98}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong orbitofrontal artery, Mount Ararat, venous angle, East Side Access, Clarke Quay, dilator naris muscle, Dolaucothi Gold Mines, Aral Sea, sulfuric acid, Coffin bone, fascial compartments of arm, Oswald Poche, Louisville, New York Harbor, Nepenthes kerrii, Botryosphaeria stevensii, meningohypophyseal artery, Muehlenbeckia australis, Diablo Canyon Power Plant, Sea of Azov, Palaeocene, which one is the most conceptually similar with perforator vein?", "pred": " \nNote: Conceptual similarity refers to similarity in meaning, function, or application", "completions_tokens": [{"text": " \n", "logprob": -1.3916808366775513}, {"text": "Note", "logprob": -5.684910774230957}, {"text": ":", "logprob": -0.02896174043416977}, {"text": " Concept", "logprob": -2.5508034229278564}, {"text": "ual", "logprob": -0.30041441321372986}, {"text": " similarity", "logprob": -0.07837888598442078}, {"text": " refers", "logprob": -1.4817239046096802}, {"text": " to", "logprob": -0.00621055206283927}, {"text": " similarity", "logprob": -3.3835039138793945}, {"text": " in", "logprob": -0.17389605939388275}, {"text": " meaning", "logprob": -0.6771249175071716}, {"text": ",", "logprob": -0.9634609222412109}, {"text": " function", "logprob": -0.9669510126113892}, {"text": ",", "logprob": -0.3441448211669922}, {"text": " or", "logprob": -0.2577933967113495}, {"text": " application", "logprob": -3.3199222087860107}], "answers": ["venous angle"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Spencer repeating rifle, Sulawesi, Kingfisher, Three Kingdoms, HD 219134b, 1908 Messina earthquake, Saldanha man, Third Imperial, Trans-Canada Highway, Ottoman Empire, International Film Festival of India, Pleistocene, Lysine exporter, solar eclipse of August 1, 2008, San Francisco Museum of Modern Art, QF 4 inch Mk V naval gun, 2020 ICC World Twenty20 Qualifier, Dungeons & Dragons Basic Set, Oranienburg concentration camp, bovine respiratory disease, Kveik, which one is the most conceptually similar with Saturn?", "pred": " \nStep 1: Analyze each option to see which one shares a connection", "completions_tokens": [{"text": " \n", "logprob": -2.4170241355895996}, {"text": "Step", "logprob": -3.077261447906494}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Analy", "logprob": -1.8915575742721558}, {"text": "ze", "logprob": -0.2592644691467285}, {"text": " each", "logprob": -1.7386384010314941}, {"text": " option", "logprob": -0.49097615480422974}, {"text": " to", "logprob": -0.9095036387443542}, {"text": " see", "logprob": -1.6404001712799072}, {"text": " which", "logprob": -1.5252091884613037}, {"text": " one", "logprob": -0.025743404403328896}, {"text": " shares", "logprob": -2.7287380695343018}, {"text": " a", "logprob": -0.9514745473861694}, {"text": " connection", "logprob": -4.182707786560059}], "answers": ["HD 219134b"], "all_classes": "null", "length": 99}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Holin superfamily V, Doubletime, Molenbeek, Tattletales, Rhinogydd, California Academy of Sciences, MT-RNR1, Monitor-Merrimac Memorial Bridge-Tunnel, Banjica concentration camp, Prometheus, Cl-transporting ATPase, The Proms, Honda J engine, 2018 FIFA World Cup, MEG8, Interleukin 1 beta, Professional baseball, Kashiwazaki-Kariwa Nuclear Power Plant, Wookey Hole Caves, Tampa Bay, Aspen Music Festival and School, which one is the most conceptually similar with Epidermal growth factor?", "pred": " \n\nAnswer: None of the above. Epidermal growth factor belongs to the", "completions_tokens": [{"text": " \n\n", "logprob": -0.3403082489967346}, {"text": "Answer", "logprob": -0.45722466707229614}, {"text": ":", "logprob": -0.06405442953109741}, {"text": " None", "logprob": -3.697199821472168}, {"text": " of", "logprob": -0.44510072469711304}, {"text": " the", "logprob": -0.20495818555355072}, {"text": " above", "logprob": -0.4868486523628235}, {"text": ".", "logprob": -0.3575967848300934}, {"text": " Ep", "logprob": -1.1516876220703125}, {"text": "ider", "logprob": -1.3112935448589269e-05}, {"text": "mal", "logprob": -1.3112935448589269e-05}, {"text": " growth", "logprob": -0.06214597821235657}, {"text": " factor", "logprob": -1.3112935448589269e-05}, {"text": " belongs", "logprob": -3.0395264625549316}, {"text": " to", "logprob": -1.3112935448589269e-05}, {"text": " the", "logprob": -0.7890436053276062}], "answers": ["Interleukin 1 beta"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Super Bowl XLV, Botryosphaeria stevensii, Rio All-Suite Hotel and Casino, South Street Seaport, hemiazygos vein, Capricornus, Western Ghats, Big Dig, Portuguese Diamond, propane, frankincense, Yellowhead Pass, zinc oxide, Colony of New South Wales, Heart Mountain Relocation Center, aldosterone, Mercury-Atlas 6, Great Mogul Diamond, County Ground, Ubinas, The Simpsons Ride, which one is the most conceptually similar with poly(methyl methacrylate)?", "pred": " \n\nAnswer: Ubinas. Colony of New South Wales. Portuguese Diamond.", "completions_tokens": [{"text": " \n\n", "logprob": -0.20279079675674438}, {"text": "Answer", "logprob": -0.5587691068649292}, {"text": ":", "logprob": -0.05024976283311844}, {"text": " U", "logprob": -4.002028942108154}, {"text": "bin", "logprob": -1.3112935448589269e-05}, {"text": "as", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.5919782519340515}, {"text": " Colony", "logprob": -4.6722869873046875}, {"text": " of", "logprob": -0.028826700523495674}, {"text": " New", "logprob": -1.3112935448589269e-05}, {"text": " South", "logprob": -1.3112935448589269e-05}, {"text": " Wales", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.2642320394515991}, {"text": " Portuguese", "logprob": -3.5613131523132324}, {"text": " Diamond", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.015607119537889957}], "answers": ["propane"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Cappadocia, Dungeons & Dragons Basic Set, Fantasia Festival, Tango, Bethlem Royal Hospital, County Cricket Ground, Chelmsford, Risiera di San Sabba, February 2011 Christchurch earthquake, Singha, Afon Irfon, Greek fire, Newcastle Brown Ale, Mariner 4, One Times Square, Legacy Way, nerve growth factor, Brahma, Lodi AVA, Moliterno, Stalag Luft III, Friuli-Venezia Giulia wine, which one is the most conceptually similar with Egyptian cheese?", "pred": " This question tests the generally scientific knowledge  rather than artistic knowledge.\n\nAfon I", "completions_tokens": [{"text": " This", "logprob": -6.65001916885376}, {"text": " question", "logprob": -1.5654913187026978}, {"text": " tests", "logprob": -4.082218647003174}, {"text": " the", "logprob": -1.3132028579711914}, {"text": " generally", "logprob": -10.058385848999023}, {"text": " scientific", "logprob": -8.677310943603516}, {"text": " knowledge", "logprob": -0.6547020077705383}, {"text": " ", "logprob": -7.112007141113281}, {"text": " rather", "logprob": -6.266742706298828}, {"text": " than", "logprob": -0.0015852991491556168}, {"text": " artistic", "logprob": -5.632031440734863}, {"text": " knowledge", "logprob": -1.2903833389282227}, {"text": ".\n\n", "logprob": -1.1538091897964478}, {"text": "A", "logprob": -0.7817102670669556}, {"text": "fon", "logprob": -0.22993104159832}, {"text": " I", "logprob": -1.3112935448589269e-05}], "answers": ["Moliterno"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Battle of the Somme, superficial dorsal vein of the penis, Blue Serpent Clock, Palaeocene, corticotropin releasing hormone, Fisher Building, Thomas Circle, 2003 World Championships in Athletics, 2019 Canadian federal election, Big Dig, Lake Como, Oltermanni, Parrott rifle, Tesla Powerpack, 2020 Republican National Convention, Lafayette Square, common digital veins, Bahia Emerald, aldosterone, Sonoma Valley, Tesla Megapack, which one is the most conceptually similar with Kasat Suek Intersection?", "pred": " \n\nAnswer: Tesla Powerpack, Tesla Megapack. Both are conceptually", "completions_tokens": [{"text": " \n\n", "logprob": -0.28020942211151123}, {"text": "Answer", "logprob": -0.10330656170845032}, {"text": ":", "logprob": -0.07791419327259064}, {"text": " Tesla", "logprob": -3.63651442527771}, {"text": " Power", "logprob": -0.6548979878425598}, {"text": "pack", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -0.6966593265533447}, {"text": " Tesla", "logprob": -0.15772400796413422}, {"text": " Meg", "logprob": -1.3112935448589269e-05}, {"text": "ap", "logprob": -1.3112935448589269e-05}, {"text": "ack", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.5040996670722961}, {"text": " Both", "logprob": -5.376826286315918}, {"text": " are", "logprob": -0.3057887554168701}, {"text": " concept", "logprob": -3.864759683609009}, {"text": "ually", "logprob": -1.3112935448589269e-05}], "answers": ["Thomas Circle"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Kyushu, Kanheri Caves, Steinheim skull, black drink, Library of Congress, Pier 39, Dresden Green Diamond, Tahiti, STS-51-L, common facial vein, meningohypophyseal artery, parasphenoid, War on Terror, Palmar plate, horseshoes, hamstring muscles, Galleria Vittorio Emanuele II, Ford Windsor engine, Sizewell nuclear power stations, Pepsi Max, Liverpool and Manchester Railway, which one is the most conceptually similar with plantar Lisfranc ligament?", "pred": " \n\nAnswer: Liverpool and Manchester Railway. Similar entity related to plantar Lisfr", "completions_tokens": [{"text": " \n\n", "logprob": -0.08498995751142502}, {"text": "Answer", "logprob": -0.14807790517807007}, {"text": ":", "logprob": -0.016878293827176094}, {"text": " Liverpool", "logprob": -2.789565324783325}, {"text": " and", "logprob": -1.3112935448589269e-05}, {"text": " Manchester", "logprob": -1.3112935448589269e-05}, {"text": " Railway", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.25056710839271545}, {"text": " Similar", "logprob": -2.6152849197387695}, {"text": " entity", "logprob": -4.085463523864746}, {"text": " related", "logprob": -5.7620697021484375}, {"text": " to", "logprob": -0.12105397880077362}, {"text": " plant", "logprob": -1.2186323404312134}, {"text": "ar", "logprob": -1.3112935448589269e-05}, {"text": " Lis", "logprob": -0.28962472081184387}, {"text": "fr", "logprob": -1.3112935448589269e-05}], "answers": ["Palmar plate"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong American Golden Topaz, Palmar plate, cream gene, Lake Constance, Standedge Tunnels, Ford FE engine, Mazda B engine, Virginia Tech, keel, Reflex inguinal ligament, Risiera di San Sabba, Switzerland, Springfield Interchange, Blue Mountain Tunnel, dorsal digital arteries of foot, Africa, Corrugator cutis ani muscle, Joint Mathematics Meetings, Daka skull, Windsor Great Park, World Forestry Congress, which one is the most conceptually similar with fascial compartments of arm?", "pred": " \n\nAnswer: Dorsal digital arteries of foot. Springfield Interchange\nRef", "completions_tokens": [{"text": " \n\n", "logprob": -0.1462128907442093}, {"text": "Answer", "logprob": -0.23697181046009064}, {"text": ":", "logprob": -0.1147422343492508}, {"text": " D", "logprob": -2.107696056365967}, {"text": "ors", "logprob": -0.10970935970544815}, {"text": "al", "logprob": -1.3112935448589269e-05}, {"text": " digital", "logprob": -0.00692112697288394}, {"text": " arteries", "logprob": -1.3112935448589269e-05}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " foot", "logprob": -0.005612330511212349}, {"text": ".", "logprob": -0.1553918719291687}, {"text": " Springfield", "logprob": -9.306731224060059}, {"text": " Inter", "logprob": -0.026008374989032745}, {"text": "change", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -7.569361686706543}, {"text": "Ref", "logprob": -4.9027557373046875}], "answers": ["Corrugator cutis ani muscle"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Flyball, mood swing, 162173 Ryugu, Mehoopany Creek, ophthalmic veins, High Five Interchange, Wine auction, Oxford University Parks, Newark Airport Interchange, Southwark Cathedral, Antwerp, CR2025, sodium carbonate, Norfork Dam, Imperial War Museum London, Newhall Pass, Intergender wrestling, The Voice of Germany, plantar Lisfranc ligament, Pawan Gupta, Iaido, which one is the most conceptually similar with Cluedo?", "pred": " \n\nAnswer: Cluedo is a game about deduction and Sherlock type detective work", "completions_tokens": [{"text": " \n\n", "logprob": -0.3496206998825073}, {"text": "Answer", "logprob": -1.0390640497207642}, {"text": ":", "logprob": -0.14930205047130585}, {"text": " Cl", "logprob": -1.329265832901001}, {"text": "ued", "logprob": -1.3112935448589269e-05}, {"text": "o", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -1.8478938341140747}, {"text": " a", "logprob": -0.08052954822778702}, {"text": " game", "logprob": -3.4650681018829346}, {"text": " about", "logprob": -2.38267183303833}, {"text": " deduction", "logprob": -2.282438278198242}, {"text": " and", "logprob": -0.9765461683273315}, {"text": " Sherlock", "logprob": -8.413986206054688}, {"text": " type", "logprob": -5.327202796936035}, {"text": " detective", "logprob": -1.8499572277069092}, {"text": " work", "logprob": -0.5550676584243774}], "answers": ["The Voice of Germany"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Sather Tower, High Five Interchange, Joint Mathematics Meetings, Bryant Park, Accessory soleus muscle, Apollo 16, Llangorse Lake, Monastery of the Holy Archangels, solar eclipse of August 21, 2017, Super Bowl LIV, Winterthur Museum and Country Estate, solar eclipse of June 25, 2150, Adrenal artery, Endometrial arteries, Wawona Tunnel, Beaufort Sea, Liberty Tunnel, renin, poisoning of Alexander Litvinenko, Aconcagua, solar eclipse of October 24, 1995, which one is the most conceptually similar with athletics at the 2016 Summer Paralympics?", "pred": " \nAnswer: Adrenal artery, Endometrial arteries, & renin.", "completions_tokens": [{"text": " \n", "logprob": -2.778944969177246}, {"text": "Answer", "logprob": -0.7574509382247925}, {"text": ":", "logprob": -0.015865519642829895}, {"text": " Ad", "logprob": -2.7781691551208496}, {"text": "renal", "logprob": -1.3112935448589269e-05}, {"text": " artery", "logprob": -0.015635285526514053}, {"text": ",", "logprob": -1.121289610862732}, {"text": " End", "logprob": -0.09726797789335251}, {"text": "omet", "logprob": -1.3112935448589269e-05}, {"text": "rial", "logprob": -1.3112935448589269e-05}, {"text": " arteries", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -0.33497288823127747}, {"text": " &", "logprob": -7.589710235595703}, {"text": " ren", "logprob": -0.557654082775116}, {"text": "in", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.3625963628292084}], "answers": ["Super Bowl LIV"], "all_classes": "null", "length": 107}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Fourth World Conference on Women, Monitor-Merrimac Memorial Bridge-Tunnel, Tsarskoye Selo, Colloque Walter Lippmann, Welcome Stranger, Moscow Kremlin, Battle of Fredericksburg, Royal Botanic Garden Edinburgh, Barabar Caves, East Gondwana, Xq28, Tesla Megapack, Mercury-Atlas 6, Royal Cinque Ports Golf Club, dorsal digital arteries of foot, daf-7, Eagle Diamond, horseshoes, 1971 San Fernando earthquake, Potsdam Conference, Brenner Base Tunnel, which one is the most conceptually similar with STS-121?", "pred": " \n\nKEXP-FM\nAns: STS-121. True. (", "completions_tokens": [{"text": " \n\n", "logprob": -0.41855645179748535}, {"text": "K", "logprob": -8.236936569213867}, {"text": "EXP", "logprob": -9.748412132263184}, {"text": "-F", "logprob": -0.1824425905942917}, {"text": "M", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.9729398488998413}, {"text": "Ans", "logprob": -4.770487308502197}, {"text": ":", "logprob": -0.19044294953346252}, {"text": " ST", "logprob": -1.7498961687088013}, {"text": "S", "logprob": -1.3112935448589269e-05}, {"text": "-", "logprob": -0.0021275284234434366}, {"text": "121", "logprob": -0.16164423525333405}, {"text": ".", "logprob": -1.9907746315002441}, {"text": " True", "logprob": -3.986346960067749}, {"text": ".", "logprob": -0.7342687249183655}, {"text": " (", "logprob": -2.9912028312683105}], "answers": ["Mercury-Atlas 6"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 3200 Phaethon, daf-2, anterolateral ligament, 2013 World Championships in Athletics, Oltermanni, Third Battle of Ypres, Kveik, Chapultepec, Trivial Pursuit, 2017 World Aquatics Championships, Ambassador Bridge, Eden Gardens, fluoxetine, Lethal yellowing, Prometheus, precerebral artery, STS-125, 2 cm Flak 30/38/Flakvierling, Mediterranean Sea, dentary bone, Washington National Cathedral, which one is the most conceptually similar with Cluny Abbey?", "pred": " \n\nStep 1: Determine the theme or subject related to the list of entities", "completions_tokens": [{"text": " \n\n", "logprob": -0.20133496820926666}, {"text": "Step", "logprob": -1.3876097202301025}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Determine", "logprob": -4.488533973693848}, {"text": " the", "logprob": -0.21061885356903076}, {"text": " theme", "logprob": -3.5394349098205566}, {"text": " or", "logprob": -0.9039496183395386}, {"text": " subject", "logprob": -2.4614644050598145}, {"text": " related", "logprob": -4.164922714233398}, {"text": " to", "logprob": -1.3112935448589269e-05}, {"text": " the", "logprob": -1.2461193799972534}, {"text": " list", "logprob": -2.479914903640747}, {"text": " of", "logprob": -0.17240524291992188}, {"text": " entities", "logprob": -0.4803737998008728}], "answers": ["Washington National Cathedral"], "all_classes": "null", "length": 81}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong High Line, Cuba, 25143 Itokawa, Fantasia Festival, spoiled child, potassium chloride, solar eclipse of May 20, 2012, Kilmainham Gaol, Apple Worldwide Developers Conference, Pepsi Max, Muppet*Vision 3D, Formula 5000, Kveik, Tesla Megapack, djon djon, sodium hydroxide, 1964 United Kingdom general election, palmar carpal arch, Penns Creek, BM-21 Grad, Hadim Suleiman Pasha, which one is the most conceptually similar with Guantanamo Bay detention camp?", "pred": "  \n\nAnswer: BM-21 Grad.. revision 718501926, original", "completions_tokens": [{"text": "  \n\n", "logprob": -5.002610683441162}, {"text": "Answer", "logprob": -0.6343316435813904}, {"text": ":", "logprob": -0.5692567229270935}, {"text": " BM", "logprob": -2.1835780143737793}, {"text": "-", "logprob": -1.3112935448589269e-05}, {"text": "21", "logprob": -1.3112935448589269e-05}, {"text": " Grad", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.20071916282176971}, {"text": ".", "logprob": -5.6930413246154785}, {"text": " revision", "logprob": -13.11158561706543}, {"text": " ", "logprob": -1.9761751890182495}, {"text": "718", "logprob": -6.704078674316406}, {"text": "501", "logprob": -6.593691349029541}, {"text": "926", "logprob": -7.419221878051758}, {"text": ",", "logprob": -2.490795850753784}, {"text": " original", "logprob": -8.962993621826172}], "answers": ["Kilmainham Gaol"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Canning Tunnel, zinc oxide, STS-135, Pliocene, Coarse fishing, solar eclipse of April 28, 1930, Bay of Biscay, Nepal, Scottish independence referendum, 2014, solar eclipse of September 12, 2034, Cannabinoid receptor 2, Lloret de Mar, Pinconning cheese, crisantaspase, lateral rotator group, Bayreuth Festival, Circuit de Spa-Francorchamps, Epidermal growth factor, head for heights, Nashville, KNM WT 17000, which one is the most conceptually similar with San Diego?", "pred": " \n\nAnswer: Nashville, Knoxville, St. Louis, Colorado Springs, Austin are", "completions_tokens": [{"text": " \n\n", "logprob": -0.39955875277519226}, {"text": "Answer", "logprob": -0.6527828574180603}, {"text": ":", "logprob": -0.23534244298934937}, {"text": " Nashville", "logprob": -0.7696686387062073}, {"text": ",", "logprob": -2.37278151512146}, {"text": " Knoxville", "logprob": -3.4300568103790283}, {"text": ",", "logprob": -0.755286455154419}, {"text": " St", "logprob": -4.860142707824707}, {"text": ".", "logprob": -0.289621502161026}, {"text": " Louis", "logprob": -0.49451160430908203}, {"text": ",", "logprob": -0.20849525928497314}, {"text": " Colorado", "logprob": -5.907634258270264}, {"text": " Springs", "logprob": -0.15961699187755585}, {"text": ",", "logprob": -0.10999934375286102}, {"text": " Austin", "logprob": -3.7002134323120117}, {"text": " are", "logprob": -3.7725648880004883}], "answers": ["Nashville"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong First Red Scare, Nepenthes northiana, Blue Serpent Clock, djon djon, McLaren Vale, Kamakura period, OSIRIS-REx, Gagarin, Pont Neuf, Vancouver International Film Festival, Xynotyro, cream gene, Extrinsic extensor muscles of the hand, International Congress on Medieval Studies, Hadim Ali Pasha, Monitor-Merrimac Memorial Bridge-Tunnel, River Ithon, Wang Shoucheng, Ghana, potassium chloride, Pawan Gupta, which one is the most conceptually similar with London Bridge?", "pred": " \nAnswer: Pont Neuf. (I removed the comma from your topic as", "completions_tokens": [{"text": " \n", "logprob": -1.383148431777954}, {"text": "Answer", "logprob": -0.4258621037006378}, {"text": ":", "logprob": -0.20747512578964233}, {"text": " Pont", "logprob": -2.0867340564727783}, {"text": " Ne", "logprob": -1.3112935448589269e-05}, {"text": "uf", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.30485278367996216}, {"text": " (", "logprob": -2.2399251461029053}, {"text": "I", "logprob": -2.8547043800354004}, {"text": " removed", "logprob": -3.0815045833587646}, {"text": " the", "logprob": -0.9315847158432007}, {"text": " comma", "logprob": -4.140379905700684}, {"text": " from", "logprob": -2.8119077682495117}, {"text": " your", "logprob": -1.9125785827636719}, {"text": " topic", "logprob": -8.094566345214844}, {"text": " as", "logprob": -4.518279075622559}], "answers": ["Pont Neuf"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Eocene, Florentine Diamond, Ofu-Olosega, ammonia, Renaissance, Holin superfamily V, Panama disease, New Zealand, poly(methyl methacrylate), Adirondack Park, SN 1987A, codeine, Pinwheel Galaxy, Basilica of Saint-Denis, Parthenon, Reading and Leeds Festivals, Royal Botanic Gardens Victoria, cyclosporine, gallium arsenide, MT-RNR1, Aral Sea, which one is the most conceptually similar with Akbar Shah?", "pred": " \n\nStep 1:  Identify what the Eocene, Florentine Diamond", "completions_tokens": [{"text": " \n\n", "logprob": -1.0588129758834839}, {"text": "Step", "logprob": -2.5883827209472656}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -1.810119867324829}, {"text": " Identify", "logprob": -2.4117023944854736}, {"text": " what", "logprob": -1.7322534322738647}, {"text": " the", "logprob": -4.740681171417236}, {"text": " E", "logprob": -5.606746673583984}, {"text": "ocene", "logprob": -0.006332569755613804}, {"text": ",", "logprob": -1.0717397928237915}, {"text": " Flo", "logprob": -0.0634130910038948}, {"text": "rent", "logprob": -1.3112935448589269e-05}, {"text": "ine", "logprob": -1.3112935448589269e-05}, {"text": " Diamond", "logprob": -1.3112935448589269e-05}], "answers": ["Florentine Diamond"], "all_classes": "null", "length": 78}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 2015 World Aquatics Championships, 2001 Gujarat earthquake, Khyber Pass, intervertebral veins, First Battle of Bull Run, Drew University, vesiculodeferential artery, Dufek Massif, perforator vein, superior cerebellar veins, Juvenile hormone acid O-methyltransferase, internal auditory veins, Nissan VG engine, Chartwell, Lysine exporter, Ford Modular engine, Seven Years War, MHETase, T Tauri, Big Dipper, trabecular veins, which one is the most conceptually similar with Greenland ice sheet?", "pred": " \n\nAnswer: Big Dipper. An asterism in the northern celestial hemisphere.", "completions_tokens": [{"text": " \n\n", "logprob": -0.19738274812698364}, {"text": "Answer", "logprob": -0.39553317427635193}, {"text": ":", "logprob": -0.10500430315732956}, {"text": " Big", "logprob": -2.0980679988861084}, {"text": " Dip", "logprob": -1.3112935448589269e-05}, {"text": "per", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.3052539825439453}, {"text": " An", "logprob": -7.147939682006836}, {"text": " aster", "logprob": -0.12792284786701202}, {"text": "ism", "logprob": -1.3112935448589269e-05}, {"text": " in", "logprob": -1.1287761926651}, {"text": " the", "logprob": -0.10877539962530136}, {"text": " northern", "logprob": -2.5379843711853027}, {"text": " celestial", "logprob": -1.6425573825836182}, {"text": " hemisphere", "logprob": -0.151811882853508}, {"text": ".", "logprob": -0.8676890134811401}], "answers": ["Dufek Massif"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong glucagon, Balkan Wars, Torrey Pines Golf Course, Tesla Powerpack, fascial compartments of arm, Lake Ontario, Nanga Parbat, Cave Hill Cemetery, Eola-Amity Hills AVA, Beta-galactoside permease, Settle to Carlisle Line, Grand Trunk Pacific Railway, Alfa Romeo V6 engine, Indonesia, Bahia Emerald, John H. Stroger, Jr. Hospital of Cook County, Patriot Place, corticotropin releasing hormone, Byfjord Tunnel, 2021 storming of the United States Capitol, mood swing, which one is the most conceptually similar with Vertebral subluxation?", "pred": " \n\nAnswer: Beta-galactoside permease, Alfa Romeo V", "completions_tokens": [{"text": " \n\n", "logprob": -0.2086995244026184}, {"text": "Answer", "logprob": -0.5409899353981018}, {"text": ":", "logprob": -0.04058538004755974}, {"text": " Beta", "logprob": -1.4330824613571167}, {"text": "-g", "logprob": -1.3112935448589269e-05}, {"text": "al", "logprob": -1.3112935448589269e-05}, {"text": "act", "logprob": -1.3112935448589269e-05}, {"text": "os", "logprob": -1.3112935448589269e-05}, {"text": "ide", "logprob": -1.3112935448589269e-05}, {"text": " perme", "logprob": -1.3112935448589269e-05}, {"text": "ase", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -1.859346866607666}, {"text": " Al", "logprob": -2.911687135696411}, {"text": "fa", "logprob": -1.3112935448589269e-05}, {"text": " Romeo", "logprob": -1.3112935448589269e-05}, {"text": " V", "logprob": -1.3112935448589269e-05}], "answers": ["mood swing"], "all_classes": "null", "length": 100}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Westfield London, Mesenteric arteries, Premier Rose Diamond, police auction, Kveik, Metro Manila Film Festival, Akbar Shah, Sphenomandibularis, Holin superfamily VII, sodium hydroxide, Saldanha man, Osterley Park, Pawan Gupta, Lake Superior, Levator muscle of thyroid gland, Tane Mahuta, Reggianito, Mersey Tunnels, Wolf 359, Piemonte, 3 Juno, which one is the most conceptually similar with Monitor-Merrimac Memorial Bridge-Tunnel?", "pred": " \nAnswer: Westfield London, Scoist superfamily VII and Mersey T", "completions_tokens": [{"text": " \n", "logprob": -1.712442398071289}, {"text": "Answer", "logprob": -0.09638510644435883}, {"text": ":", "logprob": -0.023344790562987328}, {"text": " West", "logprob": -6.60932731628418}, {"text": "field", "logprob": -1.3112935448589269e-05}, {"text": " London", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -2.3922266960144043}, {"text": " Sco", "logprob": -12.816938400268555}, {"text": "ist", "logprob": -9.837193489074707}, {"text": " super", "logprob": -6.374267578125}, {"text": "family", "logprob": -0.009299179539084435}, {"text": " VII", "logprob": -1.509722113609314}, {"text": " and", "logprob": -3.0710558891296387}, {"text": " Mer", "logprob": -4.52813720703125}, {"text": "sey", "logprob": -1.3112935448589269e-05}, {"text": " T", "logprob": -0.013970911502838135}], "answers": ["Mersey Tunnels"], "all_classes": "null", "length": 81}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Russian roulette, Oxbridge, TOG superfamily, police auction, Caloris Planitia, Colony stimulating factor 2, Pawan Gupta, Bodie, Pont Neuf, Tesla Powerpack, Grus, Pikes Peak, 2019 Albania earthquake, Nissan L engine, Fourth World Conference on Women, fascial compartments of arm, Arctica, Professional baseball, RuneQuest, Canopus, Yom Kippur War, which one is the most conceptually similar with Bataan Death March?", "pred": " \n\nAnswer: Bodie.ist ia not relevant; The Bodie Federal Gold", "completions_tokens": [{"text": " \n\n", "logprob": -0.5031479001045227}, {"text": "Answer", "logprob": -0.8458368182182312}, {"text": ":", "logprob": -0.05674552544951439}, {"text": " Bod", "logprob": -2.433025360107422}, {"text": "ie", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.9343423843383789}, {"text": "ist", "logprob": -12.388250350952148}, {"text": " ia", "logprob": -10.598851203918457}, {"text": " not", "logprob": -1.7735894918441772}, {"text": " relevant", "logprob": -3.9391980171203613}, {"text": ";", "logprob": -4.919189453125}, {"text": " The", "logprob": -3.6647722721099854}, {"text": " Bod", "logprob": -1.4290456771850586}, {"text": "ie", "logprob": -1.3112935448589269e-05}, {"text": " Federal", "logprob": -7.033716201782227}, {"text": " Gold", "logprob": -1.3757939338684082}], "answers": ["Professional baseball"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Ursa Minor, anterolateral ligament, Reflex inguinal ligament, Ford Kent engine, Quebec Conference, Holin superfamily VII, Mesenteric arteries, Tyche, Red Sea, Musca, Jaguar V12 engine, Bouncing bomb, Hollywood, Mitsubishi 6G7 engine, Netflix, Tesla Powerwall, San Francisco Museum of Modern Art, Mount Hermon, Baffin Bay, interclavicle, Joint Direct Attack Munition, which one is the most conceptually similar with CR2032 battery?", "pred": " \n\nA) anterolateral ligament\nB) Ford Kent engine\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.18197880685329437}, {"text": "A", "logprob": -2.7680931091308594}, {"text": ")", "logprob": -0.3253425359725952}, {"text": " ant", "logprob": -3.7920961380004883}, {"text": "er", "logprob": -1.3112935448589269e-05}, {"text": "ol", "logprob": -1.3112935448589269e-05}, {"text": "ateral", "logprob": -1.3112935448589269e-05}, {"text": " lig", "logprob": -1.3112935448589269e-05}, {"text": "ament", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.11744622886180878}, {"text": "B", "logprob": -1.3112935448589269e-05}, {"text": ")", "logprob": -1.3112935448589269e-05}, {"text": " Ford", "logprob": -2.933969020843506}, {"text": " Kent", "logprob": -1.3112935448589269e-05}, {"text": " engine", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.01093938760459423}], "answers": ["Tesla Powerwall"], "all_classes": "null", "length": 83}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Battle of Crete, Berlin International Film Festival, Hawaii International Film Festival, New York Comic Con, Grus, 2017 World Championships in Athletics, Krupp Diamond, The Settlers of Catan, 2009 Samoa earthquake, LSM3, Landsberg Prison, Frameline Film Festival, New York metropolitan area, New York Film Festival, Piccadilly line, chitin, Homosexual panic, Shandaken Tunnel, Queen Elizabeth Olympic Park, Tesla Megapack, Syzygium guineense, which one is the most conceptually similar with Northeast Corridor?", "pred": " \n\nThe Settlers of Catan, LSM3, Piccadilly line", "completions_tokens": [{"text": " \n\n", "logprob": -0.37566524744033813}, {"text": "The", "logprob": -0.3809214234352112}, {"text": " Set", "logprob": -0.044276103377342224}, {"text": "t", "logprob": -1.3112935448589269e-05}, {"text": "lers", "logprob": -1.3112935448589269e-05}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " C", "logprob": -1.3112935448589269e-05}, {"text": "atan", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -3.3470640182495117}, {"text": " LSM", "logprob": -1.4849157333374023}, {"text": "3", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -0.14337365329265594}, {"text": " Pic", "logprob": -1.3810689449310303}, {"text": "cad", "logprob": -1.3112935448589269e-05}, {"text": "illy", "logprob": -1.3112935448589269e-05}, {"text": " line", "logprob": -1.3112935448589269e-05}], "answers": ["Piccadilly line"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Denali, 2010 FIFA World Cup, STS-114, Fort Rock Cave, Copernicus, American Golden Topaz, Nepenthes murudensis, Nimrod Glacier, Holin superfamily I, 1986 FIFA World Cup, Akbar Shah, Liu Jishu, Trivial Pursuit, gun shield, Lion Rock Tunnel, French Revolutionary Wars, stigmatomycosis, 8.8 cm SK L/45 naval gun, Pret a Manger, Late Antiquity, Pudendal venous plexus, which one is the most conceptually similar with Southern Uplands?", "pred": " \n\nAnswer: South Hebrides. (This is a region of orogenic", "completions_tokens": [{"text": " \n\n", "logprob": -0.3221023976802826}, {"text": "Answer", "logprob": -0.3077503442764282}, {"text": ":", "logprob": -0.08915472775697708}, {"text": " South", "logprob": -5.632413387298584}, {"text": " He", "logprob": -7.818646430969238}, {"text": "br", "logprob": -0.05256792530417442}, {"text": "ides", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.8096433877944946}, {"text": " (", "logprob": -2.2690043449401855}, {"text": "This", "logprob": -3.6493985652923584}, {"text": " is", "logprob": -1.2205830812454224}, {"text": " a", "logprob": -1.6028510332107544}, {"text": " region", "logprob": -3.168275833129883}, {"text": " of", "logprob": -1.9086345434188843}, {"text": " or", "logprob": -7.756165504455566}, {"text": "ogenic", "logprob": -3.0418622493743896}], "answers": ["Denali"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Amontillado, 1997 United Kingdom general election, Cultural Revolution, Disneyland Monorail System, Shanidar Cave, Wacken Open Air, 617 Patroclus, Agnes Edwards (craftworker), Nissan L engine, Hirakud Dam, Wadden Sea, Vancouver International Film Festival, Kepler-62e, Mount Royal, Salisbury Cathedral, Messier 100, solar eclipse of May 29, 1919, 1990 FIFA World Cup, djon djon, daf-3, STS-41-B, which one is the most conceptually similar with STS-76?", "pred": " A. Amontillado\nB. STS-41-B\nC", "completions_tokens": [{"text": " A", "logprob": -5.124703884124756}, {"text": ".", "logprob": -3.526353597640991}, {"text": " Am", "logprob": -1.2833751440048218}, {"text": "ont", "logprob": -1.3112935448589269e-05}, {"text": "ill", "logprob": -1.3112935448589269e-05}, {"text": "ado", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.6738690137863159}, {"text": "B", "logprob": -0.00880383886396885}, {"text": ".", "logprob": -1.3112935448589269e-05}, {"text": " ST", "logprob": -3.7370076179504395}, {"text": "S", "logprob": -1.3112935448589269e-05}, {"text": "-", "logprob": -1.3112935448589269e-05}, {"text": "41", "logprob": -1.3112935448589269e-05}, {"text": "-B", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -1.3112935448589269e-05}, {"text": "C", "logprob": -1.3112935448589269e-05}], "answers": ["STS-41-B"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Grus, Batson venous plexus, Wei Zhongxian, CR2032 battery, Eton College, parathyroid artery, Queensway Tunnel, WonderCon, Nissan SR engine, Joint Direct Attack Munition, Jaguar XK6 engine, Adobe Creek, 2001 United Kingdom general election, Allegheny Mountain Tunnel, Python Conference, Lewis gun, Spinnaker Tower, Bouncing bomb, Glyndebourne Festival Opera, Aponeurosis of the Obliquus externus abdominis, Appalachia, which one is the most conceptually similar with Tesla Powerwall?", "pred": " \nAnswer: \n\nJaguar XK6 engine False Note: Tesla Powerwall", "completions_tokens": [{"text": " \n", "logprob": -2.2619094848632812}, {"text": "Answer", "logprob": -0.3102492690086365}, {"text": ":", "logprob": -0.1774701476097107}, {"text": " \n\n", "logprob": -3.4098448753356934}, {"text": "J", "logprob": -2.585590362548828}, {"text": "ag", "logprob": -1.3112935448589269e-05}, {"text": "uar", "logprob": -1.3112935448589269e-05}, {"text": " XK", "logprob": -1.3112935448589269e-05}, {"text": "6", "logprob": -1.3112935448589269e-05}, {"text": " engine", "logprob": -1.3112935448589269e-05}, {"text": " False", "logprob": -3.906576156616211}, {"text": " Note", "logprob": -4.464831829071045}, {"text": ":", "logprob": -0.025521477684378624}, {"text": " Tesla", "logprob": -2.772045612335205}, {"text": " Power", "logprob": -0.038987044245004654}, {"text": "wall", "logprob": -1.3112935448589269e-05}], "answers": ["CR2032 battery"], "all_classes": "null", "length": 88}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Pluto, Bataan Death March, The Settlers of Catan, Resorts World Sentosa, Pawan Gupta, National Civil Rights Museum, Seokguram, University College Hospital, Burgess Shale, leptin, Who Wants to Be a Millionaire?, Lake Okeechobee, 1566 Icarus, Reflex inguinal ligament, Rawicz, Oxbridge, Surfeit, Apollo 8, Academy of San Carlos, Buzkashi, Corviglia, which one is the most conceptually similar with Wine auction?", "pred": " \n\nThe Settlers of Catan\nBataan Death March\nO", "completions_tokens": [{"text": " \n\n", "logprob": -0.4028712511062622}, {"text": "The", "logprob": -0.7212504148483276}, {"text": " Set", "logprob": -0.2684552073478699}, {"text": "t", "logprob": -1.3112935448589269e-05}, {"text": "lers", "logprob": -1.3112935448589269e-05}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " C", "logprob": -1.3112935448589269e-05}, {"text": "atan", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -0.44266483187675476}, {"text": "B", "logprob": -1.5947285890579224}, {"text": "ata", "logprob": -0.20978733897209167}, {"text": "an", "logprob": -1.3112935448589269e-05}, {"text": " Death", "logprob": -1.3112935448589269e-05}, {"text": " March", "logprob": -1.3112935448589269e-05}, {"text": "\n", "logprob": -1.3112935448589269e-05}, {"text": "O", "logprob": -3.286931037902832}], "answers": ["Pawan Gupta"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong horseshoes, Aequorin, London Zoo, Cheng Yuanzhen, Risk, Tampa Bay, Kicking Horse Pass, 2015 Canadian federal election, RuneQuest, police auction, Oswald Poche, Vietnam War, tee-ball, Hipparchus, Cave Hill Cemetery, Laguna de Bay, Langrenus, Blue Glacier, Broadmoor Hospital, Swatara Creek, Methuselah, which one is the most conceptually similar with tactical bombing?", "pred": " None of the above\n Answer: None of the above\n\nMaybe related with \"", "completions_tokens": [{"text": " None", "logprob": -6.020252227783203}, {"text": " of", "logprob": -0.5252640843391418}, {"text": " the", "logprob": -0.5056021809577942}, {"text": " above", "logprob": -0.4072584807872772}, {"text": "\n", "logprob": -2.979353904724121}, {"text": " Answer", "logprob": -2.984778642654419}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " None", "logprob": -0.35165393352508545}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " the", "logprob": -1.3112935448589269e-05}, {"text": " above", "logprob": -1.3112935448589269e-05}, {"text": "\n\n", "logprob": -1.1940478086471558}, {"text": "Maybe", "logprob": -9.443099021911621}, {"text": " related", "logprob": -1.8337721824645996}, {"text": " with", "logprob": -0.011995912529528141}, {"text": " \"", "logprob": -0.1863379329442978}], "answers": ["tee-ball"], "all_classes": "null", "length": 73}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong TRAPPIST-1g, nandrolone, BL 6 inch Mk VII naval gun, Kanchenjunga, 1923 United Kingdom general election, 8.8 cm SK L/45 naval gun, police auction, Downtown Hudson Tubes, Lebanon, 1982 FIFA World Cup, Oswald Poche, Wheat leaf rust, Via Lattea, Fortress of Mimoyecques, Battle of Jutland, Ford Pinto engine, Xynotyro, rs6314, 2008 Sichuan earthquake, Solar eclipse of July 16, 2186, Parrott rifle, which one is the most conceptually similar with Belgium?", "pred": " \n\nAnswer: Parrott rifle. Parrott rifle was invented by a Belgian inventor", "completions_tokens": [{"text": " \n\n", "logprob": -0.26876094937324524}, {"text": "Answer", "logprob": -0.14574900269508362}, {"text": ":", "logprob": -0.02896174043416977}, {"text": " Par", "logprob": -3.5859944820404053}, {"text": "rott", "logprob": -1.3112935448589269e-05}, {"text": " rifle", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.3767244219779968}, {"text": " Par", "logprob": -3.041288137435913}, {"text": "rott", "logprob": -1.3112935448589269e-05}, {"text": " rifle", "logprob": -0.1702415645122528}, {"text": " was", "logprob": -1.5580418109893799}, {"text": " invented", "logprob": -1.1166057586669922}, {"text": " by", "logprob": -0.30235055088996887}, {"text": " a", "logprob": -1.4409217834472656}, {"text": " Belgian", "logprob": -0.7345073223114014}, {"text": " inventor", "logprob": -3.747462272644043}], "answers": ["Lebanon"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong International Congress of Chinese Mathematicians, Paris Commune, Tudor period, The Settlers of Catan, Narragansett Bay, 2 Pallas, Vostok 6, late Middle Ages, colony collapse disorder, UEFA Euro 2008, 3.7 cm SK C/30, Sun, Legacy Way, Gator Bowl, Eurovision Song Contest 2012, myrrh, Tesla Powerwall, Apsley House, Monoceros, 1999 World Championships in Athletics, nandrolone, which one is the most conceptually similar with Regulus?", "pred": " \n\nAnswer: Regulus is a star. Sun, Monoceros, Sun", "completions_tokens": [{"text": " \n\n", "logprob": -0.3658303916454315}, {"text": "Answer", "logprob": -0.23753111064434052}, {"text": ":", "logprob": -0.01611294411122799}, {"text": " Reg", "logprob": -0.9635968208312988}, {"text": "ulus", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -1.0107381343841553}, {"text": " a", "logprob": -0.22325922548770905}, {"text": " star", "logprob": -0.1730087548494339}, {"text": ".", "logprob": -0.9155653715133667}, {"text": " Sun", "logprob": -2.8105039596557617}, {"text": ",", "logprob": -2.3178799152374268}, {"text": " Mon", "logprob": -0.1676192581653595}, {"text": "oc", "logprob": -1.3112935448589269e-05}, {"text": "eros", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -1.5344902276992798}, {"text": " Sun", "logprob": -4.402928829193115}], "answers": ["Sun"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Major aortopulmonary collateral artery, Nike Missile Site HM-69, Falklands War, Siam Paragon, Bretton Woods Conference, Fort Monroe, Battle of Arras, tooth loss, 1994 FIFA World Cup, Brisbane Central Technical College, Colony of New South Wales, Tudor period, stigmatomycosis, Franconia, Lake Okeechobee, Landsberg Prison, Watts Towers, LA Film Festival, Fiescher Glacier, compressed tea, Atlanta, which one is the most conceptually similar with Peri-implantitis?", "pred": " \n\nShip Linkman Kowloon Throw AIA Holy Adrian AZ Reno Chrome Ston", "completions_tokens": [{"text": " \n\n", "logprob": -0.2886311411857605}, {"text": "Ship", "logprob": -10.369669914245605}, {"text": " Link", "logprob": -9.937914848327637}, {"text": "man", "logprob": -6.452929496765137}, {"text": " K", "logprob": -6.637609481811523}, {"text": "ow", "logprob": -5.2696123123168945}, {"text": "loon", "logprob": -0.3124653100967407}, {"text": " Throw", "logprob": -13.20094108581543}, {"text": " A", "logprob": -6.350549697875977}, {"text": "IA", "logprob": -7.027125835418701}, {"text": " Holy", "logprob": -9.90478515625}, {"text": " Adrian", "logprob": -10.50333309173584}, {"text": " AZ", "logprob": -10.182455062866211}, {"text": " Reno", "logprob": -10.409160614013672}, {"text": " Chrome", "logprob": -9.668290138244629}, {"text": " Ston", "logprob": -9.745351791381836}], "answers": ["tooth loss"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Nissan L engine, Cl-transporting ATPase, Dali Man, Temple Newsam, Ford flathead V8 engine, nerve growth factor, The Many Adventures of Winnie the Pooh, Siberia, DSC Cricket Stadium, Chicago Water Tower, Aequorin, Baikonur Cosmodrome Site 45, leptin, Botryosphaeria stevensii, Vallnord, The Future of Freedom Conference, Nena, daf-8, Central Coast AVA, Aponeurosis of the Obliquus externus abdominis, corticotropin releasing hormone, which one is the most conceptually similar with Doubletime?", "pred": " \n\n Answer: Daf-8 is a binding protein of C. elegans", "completions_tokens": [{"text": " \n\n", "logprob": -0.549246609210968}, {"text": " Answer", "logprob": -4.065260410308838}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " D", "logprob": -1.84345281124115}, {"text": "af", "logprob": -1.364877700805664}, {"text": "-", "logprob": -1.3112935448589269e-05}, {"text": "8", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -2.3688292503356934}, {"text": " a", "logprob": -0.9588292837142944}, {"text": " binding", "logprob": -9.655521392822266}, {"text": " protein", "logprob": -0.3359355330467224}, {"text": " of", "logprob": -1.962180495262146}, {"text": " C", "logprob": -3.589056968688965}, {"text": ".", "logprob": -0.20325542986392975}, {"text": " eleg", "logprob": -1.3112935448589269e-05}, {"text": "ans", "logprob": -1.3112935448589269e-05}], "answers": ["daf-8"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Beau Sancy, Cygnus X-1, plantar Lisfranc ligament, Battle of France, Anno Domini, Kilmainham Gaol, Beartooth Basin Summer Ski Area, HD 219134b, Pikes Peak, RuneQuest, Corrientes, Weddell Sea, Cave of the Patriarchs, nandrolone, Blackfriars Bridge, Gotthard railway, Puppis, CR2025, Tesla Powerwall, Mount Kailash, Lake Pontchartrain, which one is the most conceptually similar with Maastrichtian?", "pred": " \nAnswer: Maastrichtian. Similar: Maastrichtian", "completions_tokens": [{"text": " \n", "logprob": -1.7860397100448608}, {"text": "Answer", "logprob": -0.2874002456665039}, {"text": ":", "logprob": -0.07909243553876877}, {"text": " M", "logprob": -0.5265048742294312}, {"text": "aa", "logprob": -1.3112935448589269e-05}, {"text": "str", "logprob": -1.3112935448589269e-05}, {"text": "icht", "logprob": -1.3112935448589269e-05}, {"text": "ian", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.8032104969024658}, {"text": " Similar", "logprob": -2.0882320404052734}, {"text": ":", "logprob": -2.094696521759033}, {"text": " M", "logprob": -0.5227317810058594}, {"text": "aa", "logprob": -1.3112935448589269e-05}, {"text": "str", "logprob": -1.3112935448589269e-05}, {"text": "icht", "logprob": -1.3112935448589269e-05}, {"text": "ian", "logprob": -1.3112935448589269e-05}], "answers": ["Anno Domini"], "all_classes": "null", "length": 78}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Tenughat Dam, Moliterno, RuneQuest, Phoenix Raceway, Brenner Base Tunnel, Dungeons & Dragons Basic Set, Newport Country Club, Agnes Edwards (craftworker), Old Course at St Andrews, Pawan Gupta, WS2B, Wine auction, Liu Jishu, Enewetak Atoll, Jansky, Harborplace, Alexander Valley AVA, Fort Sill, Nashville, National Soccer Hall of Fame, World of Motion, which one is the most conceptually similar with Flyball?", "pred": " \nChhindwara \nAnswer: Wine auction Similarity NATIONAL GOLF CLUB", "completions_tokens": [{"text": " \n", "logprob": -0.6806710958480835}, {"text": "Ch", "logprob": -6.24578857421875}, {"text": "hind", "logprob": -7.742378234863281}, {"text": "w", "logprob": -0.01795526221394539}, {"text": "ara", "logprob": -1.3112935448589269e-05}, {"text": " \n", "logprob": -3.011355400085449}, {"text": "Answer", "logprob": -1.6051299571990967}, {"text": ":", "logprob": -0.1089240089058876}, {"text": " Wine", "logprob": -3.843569278717041}, {"text": " auction", "logprob": -1.3112935448589269e-05}, {"text": " Similar", "logprob": -2.6488656997680664}, {"text": "ity", "logprob": -0.23235289752483368}, {"text": " NATIONAL", "logprob": -9.270970344543457}, {"text": " G", "logprob": -5.819210529327393}, {"text": "OLF", "logprob": -0.5897812247276306}, {"text": " CLUB", "logprob": -0.3171227276325226}], "answers": ["National Soccer Hall of Fame"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Messier 74, South Pass, Clare Valley, Uptown Hudson Tubes, Brisbane Cricket Ground, Lake Balaton, Great Mogul Diamond, Yasukuni Shrine, Coma Berenices, Botryosphaeria stevensii, Stelvio Pass, Christian the lion, Mersey Tunnels, Diplodia mutila, Dali Man, Phytophthora ramorum, Ourasphaira giraldae, Guantanamo Bay Naval Base, Rongbuk Glacier, Cotswolds, Acacia baileyana, which one is the most conceptually similar with Allium ursinum?", "pred": " \n\nStep 1: Understand the concepts and the list given \nStep 2", "completions_tokens": [{"text": " \n\n", "logprob": -0.2484990507364273}, {"text": "Step", "logprob": -0.2182549089193344}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Understand", "logprob": -1.9909347295761108}, {"text": " the", "logprob": -0.19516532123088837}, {"text": " concepts", "logprob": -6.322698593139648}, {"text": " and", "logprob": -2.5003316402435303}, {"text": " the", "logprob": -4.7486982345581055}, {"text": " list", "logprob": -2.2396440505981445}, {"text": " given", "logprob": -2.2045528888702393}, {"text": " \n", "logprob": -3.8750827312469482}, {"text": "Step", "logprob": -1.6944562196731567}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "2", "logprob": -1.3112935448589269e-05}], "answers": ["Acacia baileyana"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1960 Democratic National Convention, Idukki Dam, Botryosphaeria stevensii, Sagittarius Dwarf Elliptical Galaxy, djon djon, 2006 European Athletics Championships, NBA Draft Lottery, London Zoo, 2011 AFL season, Super Bowl LV, Von Willebrand factor, Boxing Day, Venice Film Festival, Fall of Constantinople, Super Bowl XXXVI, nandrolone, Battle of Chancellorsville, Third Imperial, Covent Garden, Mare Island Naval Shipyard, Manhattan Bridge, which one is the most conceptually similar with Hundred Days Offensive?", "pred": " \n\nAnswer: Hundred Days Offensive is more similar with Third Imperial. They both involve", "completions_tokens": [{"text": " \n\n", "logprob": -0.4372973144054413}, {"text": "Answer", "logprob": -1.0894396305084229}, {"text": ":", "logprob": -0.14930205047130585}, {"text": " Hundred", "logprob": -1.3697017431259155}, {"text": " Days", "logprob": -1.3112935448589269e-05}, {"text": " Offensive", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -1.6613078117370605}, {"text": " more", "logprob": -3.7248289585113525}, {"text": " similar", "logprob": -1.73903489112854}, {"text": " with", "logprob": -0.7755695581436157}, {"text": " Third", "logprob": -1.3536990880966187}, {"text": " Imperial", "logprob": -0.04823308438062668}, {"text": ".", "logprob": -0.6582021713256836}, {"text": " They", "logprob": -4.420485973358154}, {"text": " both", "logprob": -1.4318760633468628}, {"text": " involve", "logprob": -3.5696985721588135}], "answers": ["Mare Island Naval Shipyard"], "all_classes": "null", "length": 95}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Raffles Hotel, Frankfurt City Tunnel, Golden Gate Park, Swatara Creek, David, 2018 Pakistani general election, Super Bowl XX, Barents Sea, New York City water supply system, Warhammer 40,000, London Zoo, Lollapalooza, 2008 Sichuan earthquake, Kicking Horse Pass, Mercury-Atlas 6, Outfest, pubovaginal muscle, Deneb, United States Army Air Forces, Chulalongkorn University, Peter Pan syndrome, which one is the most conceptually similar with 2015 World Aquatics Championships?", "pred": " \nAnswer:\n\nWarhammer 40,000 is about the galaxy ''Humb", "completions_tokens": [{"text": " \n", "logprob": -2.2292628288269043}, {"text": "Answer", "logprob": -0.25177001953125}, {"text": ":\n\n", "logprob": -2.138939619064331}, {"text": "War", "logprob": -1.9915096759796143}, {"text": "hammer", "logprob": -1.3112935448589269e-05}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "40", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -1.3112935448589269e-05}, {"text": "000", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -1.64820396900177}, {"text": " about", "logprob": -6.277113914489746}, {"text": " the", "logprob": -2.29757022857666}, {"text": " galaxy", "logprob": -4.660765647888184}, {"text": " ''", "logprob": -7.6391777992248535}, {"text": "H", "logprob": -1.4232861995697021}, {"text": "umb", "logprob": -3.681014060974121}], "answers": ["Super Bowl XX"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Ford Modular engine, Great Wall of China, TRAPPIST-1, Sydney Cricket Ground, Vin jaune, Caciotta, venous angle, 1929 United Kingdom general election, 1954 FIFA World Cup, Naval Air Station Pensacola, Homosexual panic, Canis Minor, STS-74, Berlin Conference, Vallnord, solar eclipse of January 22, 1879, fascial compartments of arm, Griffith Park, 2012 Northern Italy earthquakes, Bosnian War, Longmen Nuclear Power Plant, which one is the most conceptually similar with Wheat leaf rust?", "pred": " \nAnswer: Wheat leaf rust. Wheat leaf rust is a fungal disease that infect", "completions_tokens": [{"text": " \n", "logprob": -1.5805028676986694}, {"text": "Answer", "logprob": -0.176551952958107}, {"text": ":", "logprob": -0.1800248771905899}, {"text": " Wheat", "logprob": -0.9665942192077637}, {"text": " leaf", "logprob": -1.3112935448589269e-05}, {"text": " rust", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.9942235946655273}, {"text": " Wheat", "logprob": -3.7085466384887695}, {"text": " leaf", "logprob": -0.004767953883856535}, {"text": " rust", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -0.2603583037853241}, {"text": " a", "logprob": -0.18402285873889923}, {"text": " fungal", "logprob": -1.7123697996139526}, {"text": " disease", "logprob": -0.06672464311122894}, {"text": " that", "logprob": -0.9949772357940674}, {"text": " infect", "logprob": -1.5909857749938965}], "answers": ["Homosexual panic"], "all_classes": "null", "length": 96}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Oswald Poche, Yugoslav Wars, nelson hold, STS-41-B, Yom Kippur War, Estrogen, Tucker Glacier, Eurovision Song Contest 2021, anterolateral ligament, Verticillium wilt, sodium hydroxide, East River Mountain Tunnel, Northeast Corridor, Tehran Conference, SK 46, Beartooth Basin Summer Ski Area, Korean War, The Indian Bean Tree, St James Square, Monmouth, Vaalbara, Yakima Valley AVA, Triassic, which one is the most conceptually similar with Apollo 12?", "pred": " \n\n Step 1: Analyzing the given list of entities\nWe are given", "completions_tokens": [{"text": " \n\n", "logprob": -0.3681388795375824}, {"text": " Step", "logprob": -4.620656967163086}, {"text": " ", "logprob": -1.3112935448589269e-05}, {"text": "1", "logprob": -1.3112935448589269e-05}, {"text": ":", "logprob": -1.3112935448589269e-05}, {"text": " Analy", "logprob": -1.3302903175354004}, {"text": "zing", "logprob": -2.0431811809539795}, {"text": " the", "logprob": -0.011639305390417576}, {"text": " given", "logprob": -0.9699169993400574}, {"text": " list", "logprob": -0.5452409982681274}, {"text": " of", "logprob": -0.3670726418495178}, {"text": " entities", "logprob": -0.6432032585144043}, {"text": "\n", "logprob": -0.8210932016372681}, {"text": "We", "logprob": -1.8080227375030518}, {"text": " are", "logprob": -1.6484962701797485}, {"text": " given", "logprob": -0.504124641418457}], "answers": ["STS-41-B"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Tesla Powerwall, Althorp, Vostok 6, Kveik, police auction, Sphenomandibularis, Heineken, Suntec City, Tian Lingzi, precerebral artery, 1999 World Championships in Athletics, British Museum, ammonia, L-valine, 2017 World Baseball Classic, Pawan Gupta, Great Salt Lake, Nissan SR engine, Notre-Dame de Paris, Cave Hill Cemetery, Jacob Diamond, which one is the most conceptually similar with Cappadocia?", "pred": " \n\nAnswer: Suntec City. However my analysis software is able to randomly check", "completions_tokens": [{"text": " \n\n", "logprob": -0.6131617426872253}, {"text": "Answer", "logprob": -0.5277243256568909}, {"text": ":", "logprob": -0.06617672741413116}, {"text": " Sun", "logprob": -3.2246148586273193}, {"text": "tec", "logprob": -1.3112935448589269e-05}, {"text": " City", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.6738308668136597}, {"text": " However", "logprob": -4.498192310333252}, {"text": " my", "logprob": -6.17095947265625}, {"text": " analysis", "logprob": -4.353895664215088}, {"text": " software", "logprob": -8.765933990478516}, {"text": " is", "logprob": -2.485262393951416}, {"text": " able", "logprob": -5.483531951904297}, {"text": " to", "logprob": -0.009995879605412483}, {"text": " randomly", "logprob": -9.635194778442383}, {"text": " check", "logprob": -6.678050994873047}], "answers": ["Notre-Dame de Paris"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Eurovision Song Contest 2019, Eastern Harbour Crossing, HM Prison Pentonville, Nabulsi cheese, solar eclipse of August 18, 1868, St Giles Circus, 4179 Toutatis, Upper East Side, Apple Worldwide Developers Conference, Waverley Park, Arnold Arboretum, Hudson Bay, Tomorrowland, Intestinal arteries, Perseus, Cahokia, solar eclipse of November 25, 2011, United States Army War College, Patriot Place, Gator Bowl, Free Trade Hall, which one is the most conceptually similar with athletics at the 2016 Summer Paralympics?", "pred": " \n\nAnswer: Patriot Place. (The most similar concert venue among given choices is", "completions_tokens": [{"text": " \n\n", "logprob": -0.13301289081573486}, {"text": "Answer", "logprob": -0.45021599531173706}, {"text": ":", "logprob": -0.018807416781783104}, {"text": " Patriot", "logprob": -2.4257521629333496}, {"text": " Place", "logprob": -1.3112935448589269e-05}, {"text": ".", "logprob": -0.42964354157447815}, {"text": " (", "logprob": -1.474770426750183}, {"text": "The", "logprob": -3.3275458812713623}, {"text": " most", "logprob": -4.138052940368652}, {"text": " similar", "logprob": -1.9180831909179688}, {"text": " concert", "logprob": -10.434370994567871}, {"text": " venue", "logprob": -0.7139862775802612}, {"text": " among", "logprob": -3.021529197692871}, {"text": " given", "logprob": -4.09479284286499}, {"text": " choices", "logprob": -1.859492301940918}, {"text": " is", "logprob": -1.4447706937789917}], "answers": ["Gator Bowl"], "all_classes": "null", "length": 100}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Voskhod 2, Agnes Edwards (craftworker), Cl-transporting ATPase, Moliterno, Edwardian era, Xynotyro, Estrogen, Reggianito, Sawtooth Wilderness, Cleveland Clinic, River Teme, Tate Modern, Pabst Blue Ribbon, Anglesey, Kingfisher, 2008 Pakistani general election, Wye Oak, Upsilon Andromedae d, motor-paced racing, Bodhi Tree, Quebec Conference, which one is the most conceptually similar with Fort Ord?", "pred": " \nXenith I\n\nTrue/False: Function of molecula enzymes", "completions_tokens": [{"text": " \n", "logprob": -0.9170827269554138}, {"text": "X", "logprob": -5.009138584136963}, {"text": "en", "logprob": -5.4012908935546875}, {"text": "ith", "logprob": -6.6732707023620605}, {"text": " I", "logprob": -8.233124732971191}, {"text": "\n\n", "logprob": -1.2903934717178345}, {"text": "True", "logprob": -3.344050168991089}, {"text": "/", "logprob": -1.831925630569458}, {"text": "False", "logprob": -0.02128087915480137}, {"text": ":", "logprob": -0.2164715677499771}, {"text": " Function", "logprob": -9.048724174499512}, {"text": " of", "logprob": -0.5179124474525452}, {"text": " mole", "logprob": -10.204564094543457}, {"text": "cul", "logprob": -1.282602071762085}, {"text": "a", "logprob": -1.8265726566314697}, {"text": " enzymes", "logprob": -5.873645305633545}], "answers": ["Sawtooth Wilderness"], "all_classes": "null", "length": 78}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Buzkashi, Hoffman tunnel, parathyroid hormone, Zeta Sagittarii, solar eclipse of June 25, 2150, Super Bowl XXXV, Idursulfase, Eurovision Song Contest 2021, Saudi Arabia, Battersea Power Station, 2016 North Canterbury earthquake, 1953 Ionian Earthquake, 1755 Lisbon earthquake, Brisbane Cricket Ground, 2015 Rugby World Cup, Risk, STS-134, 3.7 cm SK C/30, Holin superfamily V, Charter Oak, Yellowstone volcano, which one is the most conceptually similar with SN 1572?", "pred": " \n\nAnswer: Holin superfamily V (implies an intracellular bacterial toxin", "completions_tokens": [{"text": " \n\n", "logprob": -0.7888053059577942}, {"text": "Answer", "logprob": -0.5522855520248413}, {"text": ":", "logprob": -0.3487148582935333}, {"text": " Hol", "logprob": -1.695221185684204}, {"text": "in", "logprob": -1.3112935448589269e-05}, {"text": " super", "logprob": -1.3112935448589269e-05}, {"text": "family", "logprob": -1.3112935448589269e-05}, {"text": " V", "logprob": -1.3112935448589269e-05}, {"text": " (", "logprob": -3.4719014167785645}, {"text": "impl", "logprob": -9.31452465057373}, {"text": "ies", "logprob": -0.00357512547634542}, {"text": " an", "logprob": -3.742908000946045}, {"text": " intr", "logprob": -5.668572902679443}, {"text": "acellular", "logprob": -0.9091097116470337}, {"text": " bacterial", "logprob": -3.6832306385040283}, {"text": " toxin", "logprob": -0.809801459312439}], "answers": ["Zeta Sagittarii"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 2004 Canadian federal election, Manot 1, precerebral artery, Reflex inguinal ligament, 2020 ICC World Twenty20 Qualifier, Art Institute of Chicago, KNM WT 17000, Queensway Tunnel, St Andrews Links, thoracoepigastric vein, TM 1517, Mount Apo, Weddell Sea, Chilenia, Grus, Tsiolkovskiy, stigmatomycosis, Fort D.A. Russell, 2007 Swiss federal election, Antares, 1935 United Kingdom general election, which one is the most conceptually similar with dorsal carpal arch?", "pred": " \n\nThe best answer is Intermetatarsal veins. Note: the question you", "completions_tokens": [{"text": " \n\n", "logprob": -0.1686701774597168}, {"text": "The", "logprob": -1.7134872674942017}, {"text": " best", "logprob": -0.16753658652305603}, {"text": " answer", "logprob": -1.3112935448589269e-05}, {"text": " is", "logprob": -1.3112935448589269e-05}, {"text": " Inter", "logprob": -9.034214973449707}, {"text": "met", "logprob": -3.9330105781555176}, {"text": "atars", "logprob": -0.18516209721565247}, {"text": "al", "logprob": -1.3112935448589269e-05}, {"text": " veins", "logprob": -1.4544678926467896}, {"text": ".", "logprob": -0.3851657509803772}, {"text": " Note", "logprob": -3.245305299758911}, {"text": ":", "logprob": -0.016860710456967354}, {"text": " the", "logprob": -4.093904495239258}, {"text": " question", "logprob": -1.956161618232727}, {"text": " you", "logprob": -5.738058090209961}], "answers": ["precerebral artery"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Irish Rebellion of 1798, Soyuz 5, Torrey Pines Golf Course, UEFA Euro 2012, 2015 World Championships in Athletics, Theoretical Archaeology Group, Greenland ice sheet, Osterley Park, Fleet Street, STS-122, 2003 Rugby World Cup, TIFF Bell Lightbox, Beaux-Arts de Paris, 1962 FIFA World Cup, The Proms, Botryosphaeria stevensii, Prestwick Golf Club, Four Mile Run, Bluewater (shopping centre), St Giles Circus, Three Mile Island Nuclear Generating Station, which one is the most conceptually similar with Prague Spring?", "pred": " \nAnswer: none of the above. (which is the answer when one do", "completions_tokens": [{"text": " \n", "logprob": -2.0799334049224854}, {"text": "Answer", "logprob": -0.3650766909122467}, {"text": ":", "logprob": -0.04800586774945259}, {"text": " none", "logprob": -6.840044975280762}, {"text": " of", "logprob": -0.21187983453273773}, {"text": " the", "logprob": -0.3438366949558258}, {"text": " above", "logprob": -0.3256639838218689}, {"text": ".", "logprob": -0.775056779384613}, {"text": " (", "logprob": -3.0777764320373535}, {"text": "which", "logprob": -7.247350215911865}, {"text": " is", "logprob": -0.9330897331237793}, {"text": " the", "logprob": -2.4010939598083496}, {"text": " answer", "logprob": -2.81215238571167}, {"text": " when", "logprob": -4.421945095062256}, {"text": " one", "logprob": -3.7034504413604736}, {"text": " do", "logprob": -5.417327404022217}], "answers": ["Irish Rebellion of 1798"], "all_classes": "null", "length": 104}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Wine auction, Santa Fe Trail, chitin, twelfth grade, Circuit de Spa-Francorchamps, plantar Lisfranc ligament, recurrent artery of Heubner, South Pass, Austin Film Festival, 1700 Cascadia earthquake, Reflex inguinal ligament, The Whip, Phoenix Park, Michael Spondyles, Basilica di Santa Maria Maggiore, Sundance Film Festival, Sarawak General Hospital, Levator claviculae muscle, leptin, common facial vein, KNM ER 406, which one is the most conceptually similar with lateral rotator group?", "pred": " \n\nAnswer: Levator claviculae muscle, recurrent artery of Heub", "completions_tokens": [{"text": " \n\n", "logprob": -0.1474817991256714}, {"text": "Answer", "logprob": -0.33276331424713135}, {"text": ":", "logprob": -0.10500430315732956}, {"text": " Lev", "logprob": -0.5044634342193604}, {"text": "ator", "logprob": -1.3112935448589269e-05}, {"text": " cl", "logprob": -1.3112935448589269e-05}, {"text": "avic", "logprob": -1.3112935448589269e-05}, {"text": "ula", "logprob": -1.3112935448589269e-05}, {"text": "e", "logprob": -1.3112935448589269e-05}, {"text": " muscle", "logprob": -1.3112935448589269e-05}, {"text": ",", "logprob": -2.061600685119629}, {"text": " recurrent", "logprob": -0.8782886862754822}, {"text": " artery", "logprob": -1.3112935448589269e-05}, {"text": " of", "logprob": -1.3112935448589269e-05}, {"text": " He", "logprob": -1.3112935448589269e-05}, {"text": "ub", "logprob": -1.3112935448589269e-05}], "answers": ["Levator claviculae muscle"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Super Bowl XXXIV, Southwestern Exposition and Livestock Show, djon djon, bypass ratio, Leafy, Radicular artery, Augusta National Golf Club, intercostal veins, Palmar plate, Pikes Peak International Hill Climb, Autodromo Nazionale Monza, 2002 FIFA World Cup, Warhammer Fantasy Battle, Vega, Tokaj wine region, Tau9 Eridani, Battersea Power Station, Newport Folk Festival, Croatian War of Independence, BFI London Film Festival, UEFA Euro 2000, which one is the most conceptually similar with Holborn?", "pred": " Patronajes are related to this physical assets?\n\nA. Neighborhoo normal (what", "completions_tokens": [{"text": " Patron", "logprob": -13.080859184265137}, {"text": "ajes", "logprob": -10.854515075683594}, {"text": " are", "logprob": -3.091135025024414}, {"text": " related", "logprob": -3.915194034576416}, {"text": " to", "logprob": -0.22189421951770782}, {"text": " this", "logprob": -3.23988676071167}, {"text": " physical", "logprob": -8.517875671386719}, {"text": " assets", "logprob": -9.28104305267334}, {"text": "?\n\n", "logprob": -3.7280499935150146}, {"text": "A", "logprob": -0.19304980337619781}, {"text": ".", "logprob": -0.2931300103664398}, {"text": " Neighbor", "logprob": -10.643721580505371}, {"text": "hoo", "logprob": -4.244146347045898}, {"text": " normal", "logprob": -12.224398612976074}, {"text": " (", "logprob": -5.5833740234375}, {"text": "what", "logprob": -7.68511962890625}], "answers": ["Autodromo Nazionale Monza"], "all_classes": "null", "length": 96}
