{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Specieses have a cellulose wall and other polysaccharides.' true or false?", "pred": " \n\nTrue\nFalse\nPlant cell walls are primarily made up of cellulose (", "completions_tokens": [{"text": " \n\n", "logprob": -0.14738890528678894}, {"text": "True", "logprob": -1.1552925109863281}, {"text": "\n", "logprob": -1.0263652801513672}, {"text": "False", "logprob": -0.46777889132499695}, {"text": "\n", "logprob": -0.2777252495288849}, {"text": "Plant", "logprob": -2.4886059761047363}, {"text": " cell", "logprob": -0.9570407867431641}, {"text": " walls", "logprob": -0.1327218860387802}, {"text": " are", "logprob": -0.3150571286678314}, {"text": " primarily", "logprob": -0.8498967885971069}, {"text": " made", "logprob": -0.7324690222740173}, {"text": " up", "logprob": -0.09991860389709473}, {"text": " of", "logprob": -6.9141146923357155e-06}, {"text": " cellul", "logprob": -0.022450687363743782}, {"text": "ose", "logprob": -0.00013791563105769455}, {"text": " (", "logprob": -1.8882558345794678}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'canals are public properties.' true or false?", "pred": " FALSE\nAnswer: FALSE\nStep 1: Understanding the Question \nThe statement", "completions_tokens": [{"text": " FALSE", "logprob": -3.63399338722229}, {"text": "\n", "logprob": -0.2197333127260208}, {"text": "Answer", "logprob": -0.0767587348818779}, {"text": ":", "logprob": -0.028672993183135986}, {"text": " FALSE", "logprob": -0.2313915342092514}, {"text": "\n", "logprob": -1.4436664581298828}, {"text": "Step", "logprob": -2.023568630218506}, {"text": " ", "logprob": -0.4024772346019745}, {"text": "1", "logprob": -0.00013779645087197423}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " Understanding", "logprob": -4.400679588317871}, {"text": " the", "logprob": -6.9141146923357155e-06}, {"text": " Question", "logprob": -1.9125981330871582}, {"text": " \n", "logprob": -2.1880178451538086}, {"text": "The", "logprob": -1.3546380996704102}, {"text": " statement", "logprob": -3.6934149265289307}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'minerals are drugs with potential serious adverse reactions.' true or false?", "pred": " \n\nAnswer: FALSE. 1 Minerals are relatively safe compared to drugs. ", "completions_tokens": [{"text": " \n\n", "logprob": -0.07143761217594147}, {"text": "Answer", "logprob": -2.3127567768096924}, {"text": ":", "logprob": -0.15158747136592865}, {"text": " FALSE", "logprob": -0.35479357838630676}, {"text": ".", "logprob": -0.0537569634616375}, {"text": " ", "logprob": -0.8320046663284302}, {"text": "1", "logprob": -3.6259584426879883}, {"text": " Minerals", "logprob": -6.341835021972656}, {"text": " are", "logprob": -0.321755975484848}, {"text": " relatively", "logprob": -8.228599548339844}, {"text": " safe", "logprob": -1.5076252222061157}, {"text": " compared", "logprob": -3.387695074081421}, {"text": " to", "logprob": -0.11318658292293549}, {"text": " drugs", "logprob": -0.24230802059173584}, {"text": ".", "logprob": -0.19173304736614227}, {"text": " ", "logprob": -0.27830010652542114}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'parks provide water.' true or false?", "pred": " \n\nA) True\nB) True \nC) True \nD) False", "completions_tokens": [{"text": " \n\n", "logprob": -0.26408523321151733}, {"text": "A", "logprob": -0.25192245841026306}, {"text": ")", "logprob": -0.003990901168435812}, {"text": " True", "logprob": -0.9044228792190552}, {"text": "\n", "logprob": -0.17782865464687347}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -2.267155885696411}, {"text": " \n", "logprob": -1.8875885009765625}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " True", "logprob": -0.24542003870010376}, {"text": " \n", "logprob": -0.09836195409297943}, {"text": "D", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " False", "logprob": -0.5637890696525574}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'railway lines consist of numerous stars and are held together by gravity.' true or false?", "pred": " \n\nA\nThe statement that \"when an object is moved closer to an observer", "completions_tokens": [{"text": " \n\n", "logprob": -0.09177112579345703}, {"text": "A", "logprob": -0.22094176709651947}, {"text": "\n", "logprob": -0.5525455474853516}, {"text": "The", "logprob": -3.3268961906433105}, {"text": " statement", "logprob": -0.6932883262634277}, {"text": " that", "logprob": -1.147447109222412}, {"text": " \"", "logprob": -1.1133573055267334}, {"text": "when", "logprob": -5.805418014526367}, {"text": " an", "logprob": -2.7584986686706543}, {"text": " object", "logprob": -0.313047856092453}, {"text": " is", "logprob": -0.5943688750267029}, {"text": " moved", "logprob": -3.065741777420044}, {"text": " closer", "logprob": -2.9281959533691406}, {"text": " to", "logprob": -0.15241402387619019}, {"text": " an", "logprob": -2.51340389251709}, {"text": " observer", "logprob": -0.42010408639907837}], "answers": ["false"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Most bacteria are decomposers, so they break down all the dead material.' true or false?", "pred": " \n\nA\nTrue or false\n\nThe best answer is A.  Bacteria", "completions_tokens": [{"text": " \n\n", "logprob": -0.1433211863040924}, {"text": "A", "logprob": -0.4839330315589905}, {"text": "\n", "logprob": -0.605244517326355}, {"text": "True", "logprob": -6.231143474578857}, {"text": " or", "logprob": -1.2616500854492188}, {"text": " false", "logprob": -0.07578551769256592}, {"text": "\n\n", "logprob": -1.4305778741836548}, {"text": "The", "logprob": -0.1062157154083252}, {"text": " best", "logprob": -0.00386040355078876}, {"text": " answer", "logprob": -0.00013767725613433868}, {"text": " is", "logprob": -6.794906312279636e-06}, {"text": " A", "logprob": -1.6541062593460083}, {"text": ".", "logprob": -6.9141146923357155e-06}, {"text": " ", "logprob": -0.05160482972860336}, {"text": " B", "logprob": -0.20876173675060272}, {"text": "acteria", "logprob": -0.06349363923072815}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'caves means any place where an apiary is located.' true or false?", "pred": " \n\nA) True\nB) A\nC) A\\({}^", "completions_tokens": [{"text": " \n\n", "logprob": -0.1488567441701889}, {"text": "A", "logprob": -0.00950796902179718}, {"text": ")", "logprob": -0.4849364757537842}, {"text": " True", "logprob": -0.48141878843307495}, {"text": "\n", "logprob": -0.048130616545677185}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " A", "logprob": -1.251197338104248}, {"text": "\n", "logprob": -5.512749671936035}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " A", "logprob": -2.8247461318969727}, {"text": "\\", "logprob": -6.548545837402344}, {"text": "({", "logprob": -4.106688022613525}, {"text": "}", "logprob": -0.06695254892110825}, {"text": "^", "logprob": -0.2691119611263275}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Monuments commemorating great individuals and important events are a part of our culture.' true or false?", "pred": " \n\nA) True\nB) True\nC) True\nD) False", "completions_tokens": [{"text": " \n\n", "logprob": -0.12441036105155945}, {"text": "A", "logprob": -0.025396199896931648}, {"text": ")", "logprob": -0.3840683102607727}, {"text": " True", "logprob": -0.5827729105949402}, {"text": "\n", "logprob": -0.06263227760791779}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -0.4125075340270996}, {"text": "\n", "logprob": -0.2514934241771698}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " True", "logprob": -0.15679329633712769}, {"text": "\n", "logprob": -0.00013755806139670312}, {"text": "D", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " False", "logprob": -2.210320234298706}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Vaccines are one of the most cost-effective tools in preventing disease and death.' true or false?", "pred": " \n\nA\nfalse\nB\ntrue\nAnswer: B\nRatio of False", "completions_tokens": [{"text": " \n\n", "logprob": -0.07098544389009476}, {"text": "A", "logprob": -0.17152082920074463}, {"text": "\n", "logprob": -0.9123274683952332}, {"text": "false", "logprob": -5.036577224731445}, {"text": "\n", "logprob": -0.18799415230751038}, {"text": "B", "logprob": -0.11778706312179565}, {"text": "\n", "logprob": -0.00013767725613433868}, {"text": "true", "logprob": -0.029330167919397354}, {"text": "\n", "logprob": -0.08665434271097183}, {"text": "Answer", "logprob": -2.003946304321289}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " B", "logprob": -0.001917668036185205}, {"text": "\n", "logprob": -0.9200630187988281}, {"text": "Ratio", "logprob": -7.410996913909912}, {"text": " of", "logprob": -0.3041621148586273}, {"text": " False", "logprob": -3.643968105316162}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Earthquakes are caused by movement.' true or false?", "pred": " FALSE\nAnswer: FALSE (New Scientist)  Quiz by stateofthemachine", "completions_tokens": [{"text": " FALSE", "logprob": -3.0480618476867676}, {"text": "\n", "logprob": -0.23731008172035217}, {"text": "Answer", "logprob": -0.06312885880470276}, {"text": ":", "logprob": -0.03053269162774086}, {"text": " FALSE", "logprob": -0.28404495120048523}, {"text": " (", "logprob": -1.5982518196105957}, {"text": "New", "logprob": -6.524971008300781}, {"text": " Scientist", "logprob": -4.729907512664795}, {"text": ")", "logprob": -0.7131061553955078}, {"text": " ", "logprob": -1.8250136375427246}, {"text": " Quiz", "logprob": -8.089767456054688}, {"text": " by", "logprob": -3.6061527729034424}, {"text": " state", "logprob": -9.256553649902344}, {"text": "of", "logprob": -1.5077035427093506}, {"text": "them", "logprob": -4.289929389953613}, {"text": "achine", "logprob": -7.228059768676758}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'rivers serve meals.' true or false?", "pred": " \n\nA) True\nB) False\nC) 19\nD)", "completions_tokens": [{"text": " \n\n", "logprob": -0.10061004757881165}, {"text": "A", "logprob": -0.07307914644479752}, {"text": ")", "logprob": -0.5188454985618591}, {"text": " True", "logprob": -0.4711582660675049}, {"text": "\n", "logprob": -0.07295569777488708}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -8.475421054754406e-05}, {"text": "\n", "logprob": -0.00013791563105769455}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -4.7822346687316895}, {"text": "19", "logprob": -6.676335334777832}, {"text": "\n", "logprob": -0.6832043528556824}, {"text": "D", "logprob": -6.9141146923357155e-06}, {"text": ")", "logprob": -0.00013767725613433868}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'bones are used for thinking.' true or false?", "pred": " \n\nA\nB\nC\nD\nExplanation: None\n\nAnswer is:", "completions_tokens": [{"text": " \n\n", "logprob": -0.10289342701435089}, {"text": "A", "logprob": -0.40373554825782776}, {"text": "\n", "logprob": -1.0262775421142578}, {"text": "B", "logprob": -1.4299581050872803}, {"text": "\n", "logprob": -0.00013779645087197423}, {"text": "C", "logprob": -0.0040963320061564445}, {"text": "\n", "logprob": -0.3488008975982666}, {"text": "D", "logprob": -0.005787757225334644}, {"text": "\n", "logprob": -0.4685368239879608}, {"text": "Explanation", "logprob": -2.866820812225342}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " None", "logprob": -3.375493288040161}, {"text": "\n\n", "logprob": -0.12075693160295486}, {"text": "Answer", "logprob": -1.1659164428710938}, {"text": " is", "logprob": -6.794906312279636e-06}, {"text": ":", "logprob": -0.00013767725613433868}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Grand Prixes are what people often see when poker is shown on television .' true or false?", "pred": " \n\nA) True\nB) False\nC) Grand Prixes\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.10912658274173737}, {"text": "A", "logprob": -0.17275413870811462}, {"text": ")", "logprob": -0.1737370491027832}, {"text": " True", "logprob": -1.0200462341308594}, {"text": "\n", "logprob": -0.3877272605895996}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.5792927742004395}, {"text": "\n", "logprob": -0.05861764773726463}, {"text": "C", "logprob": -0.01145405974239111}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Grand", "logprob": -1.7278540134429932}, {"text": " Prix", "logprob": -0.028018979355692863}, {"text": "es", "logprob": -1.6134511232376099}, {"text": "\n", "logprob": -0.08050711452960968}, {"text": "D", "logprob": -0.0036746615078300238}], "answers": ["false"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'infrastructures are normally unowned, accessible to all.' true or false?", "pred": " \n\nAnswer: FALSE. However, according to report \" Public Goods Information Comparability", "completions_tokens": [{"text": " \n\n", "logprob": -0.19214098155498505}, {"text": "Answer", "logprob": -0.3942628800868988}, {"text": ":", "logprob": -0.14304453134536743}, {"text": " FALSE", "logprob": -0.47299861907958984}, {"text": ".", "logprob": -0.08194516599178314}, {"text": " However", "logprob": -4.676058769226074}, {"text": ",", "logprob": -0.07133039087057114}, {"text": " according", "logprob": -4.504251480102539}, {"text": " to", "logprob": -6.794906312279636e-06}, {"text": " report", "logprob": -8.597553253173828}, {"text": " \"", "logprob": -5.498388767242432}, {"text": " Public", "logprob": -7.0427422523498535}, {"text": " Goods", "logprob": -1.404318928718567}, {"text": " Information", "logprob": -5.4346513748168945}, {"text": " Compar", "logprob": -10.03425407409668}, {"text": "ability", "logprob": -2.9675087928771973}], "answers": ["true"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'fishes adjust their feathers to create or dissipate an insulating layer, as typified by the ostrich .' true or false?", "pred": " \n\nA\nB\nC\nD\nE\n\nAnswer is: A\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.056674566119909286}, {"text": "A", "logprob": -0.6757932901382446}, {"text": "\n", "logprob": -0.7465358972549438}, {"text": "B", "logprob": -0.9632519483566284}, {"text": "\n", "logprob": -0.00013779645087197423}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -0.2523157298564911}, {"text": "D", "logprob": -0.004076623823493719}, {"text": "\n", "logprob": -0.3352796733379364}, {"text": "E", "logprob": -0.45227181911468506}, {"text": "\n\n", "logprob": -2.180373191833496}, {"text": "Answer", "logprob": -1.2934616804122925}, {"text": " is", "logprob": -0.32216677069664}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " A", "logprob": -1.1085597276687622}, {"text": "\n", "logprob": -0.030900077894330025}], "answers": ["false"], "all_classes": "null", "length": 27}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'oceans are people.' true or false?", "pred": " \n\nA. True\nB. False\nC. Realistic claim\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.1127045601606369}, {"text": "A", "logprob": -0.025893032550811768}, {"text": ".", "logprob": -0.8853954672813416}, {"text": " True", "logprob": -0.4690013527870178}, {"text": "\n", "logprob": -0.04855791851878166}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -6.9141146923357155e-06}, {"text": " False", "logprob": -0.015218806453049183}, {"text": "\n", "logprob": -0.012508394196629524}, {"text": "C", "logprob": -0.01257090549916029}, {"text": ".", "logprob": -6.794906312279636e-06}, {"text": " Real", "logprob": -9.640604019165039}, {"text": "istic", "logprob": -1.3358256816864014}, {"text": " claim", "logprob": -5.237269401550293}, {"text": "\n", "logprob": -0.07088550180196762}, {"text": "D", "logprob": -0.00013767725613433868}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Animals are amniotes.' true or false?", "pred": " \n\nA. Birds are a subset of Reptilia.\nB. Animals are", "completions_tokens": [{"text": " \n\n", "logprob": -0.14743992686271667}, {"text": "A", "logprob": -1.1047924757003784}, {"text": ".", "logprob": -1.4037315845489502}, {"text": " Birds", "logprob": -5.555271148681641}, {"text": " are", "logprob": -0.8363170623779297}, {"text": " a", "logprob": -1.9523066282272339}, {"text": " subset", "logprob": -2.0881941318511963}, {"text": " of", "logprob": -6.794906312279636e-06}, {"text": " Re", "logprob": -3.99617338180542}, {"text": "pt", "logprob": -6.9141146923357155e-06}, {"text": "ilia", "logprob": -0.9788950085639954}, {"text": ".\n", "logprob": -0.1616431176662445}, {"text": "B", "logprob": -6.9141146923357155e-06}, {"text": ".", "logprob": -0.00013779645087197423}, {"text": " Animals", "logprob": -1.1214606761932373}, {"text": " are", "logprob": -0.055040836334228516}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Quarters are time periods.' true or false?", "pred": " \n\nA) True.\nB) False.\nC) Quarters contain four equal", "completions_tokens": [{"text": " \n\n", "logprob": -0.1292606145143509}, {"text": "A", "logprob": -1.0320111513137817}, {"text": ")", "logprob": -0.37721651792526245}, {"text": " True", "logprob": -0.5931292176246643}, {"text": ".\n", "logprob": -4.089603900909424}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.24591413140296936}, {"text": ".\n", "logprob": -0.0596383735537529}, {"text": "C", "logprob": -0.006548967212438583}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Qu", "logprob": -0.824776828289032}, {"text": "arters", "logprob": -6.9141146923357155e-06}, {"text": " contain", "logprob": -7.033058166503906}, {"text": " four", "logprob": -2.858110189437866}, {"text": " equal", "logprob": -2.3117260932922363}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'launch pads form a reservoir of tuberculosis, including drug-resistant tuberculosis.' true or false?", "pred": "  True/False:\n\n## Step 1: Understand the claim\nThe statement", "completions_tokens": [{"text": " ", "logprob": -4.3294358253479}, {"text": " True", "logprob": -1.896785855293274}, {"text": "/", "logprob": -2.1619620323181152}, {"text": "False", "logprob": -0.12004967778921127}, {"text": ":\n\n", "logprob": -0.8804112672805786}, {"text": "##", "logprob": -0.18565687537193298}, {"text": " Step", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -0.00013767725613433868}, {"text": "1", "logprob": -0.00013779645087197423}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " Understand", "logprob": -0.6868168711662292}, {"text": " the", "logprob": -6.9141146923357155e-06}, {"text": " claim", "logprob": -1.3055325746536255}, {"text": "\n", "logprob": -1.5279810428619385}, {"text": "The", "logprob": -0.00013779645087197423}, {"text": " statement", "logprob": -0.4625965356826782}], "answers": ["false"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Every ocean is polluted to some extent.' true or false?", "pred": " \n\nA) True\nB) Not true\nC) Plastic Pollution\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.19785167276859283}, {"text": "A", "logprob": -0.3314102292060852}, {"text": ")", "logprob": -0.25935930013656616}, {"text": " True", "logprob": -0.6446582674980164}, {"text": "\n", "logprob": -0.21512600779533386}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " Not", "logprob": -4.522929668426514}, {"text": " true", "logprob": -1.296967625617981}, {"text": "\n", "logprob": -0.5974791049957275}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Plastic", "logprob": -4.759130477905273}, {"text": " Pollution", "logprob": -4.320991516113281}, {"text": "\n", "logprob": -0.605940043926239}, {"text": "D", "logprob": -0.00013767725613433868}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Locations experience good drainage.' true or false?", "pred": " \n\nA) False\nB) Curbless\nC) A porous pavement", "completions_tokens": [{"text": " \n\n", "logprob": -0.2720579504966736}, {"text": "A", "logprob": -0.23164716362953186}, {"text": ")", "logprob": -0.11485255509614944}, {"text": " False", "logprob": -2.3463964462280273}, {"text": "\n", "logprob": -0.686656653881073}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " C", "logprob": -2.4062156677246094}, {"text": "urb", "logprob": -5.792332172393799}, {"text": "less", "logprob": -4.317427158355713}, {"text": "\n", "logprob": -1.6465048789978027}, {"text": "C", "logprob": -0.00013791563105769455}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " A", "logprob": -0.4601250886917114}, {"text": " porous", "logprob": -6.091148376464844}, {"text": " pavement", "logprob": -1.2011690139770508}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Golf courses require a lot of water, and many areas of Mexico are dry.' true or false?", "pred": " \n\nAnswer: FALSE. Similarity. Carnegie Museum. Similarity. Library.", "completions_tokens": [{"text": " \n\n", "logprob": -0.16674412786960602}, {"text": "Answer", "logprob": -0.7338101863861084}, {"text": ":", "logprob": -0.26657426357269287}, {"text": " FALSE", "logprob": -1.040050983428955}, {"text": ".", "logprob": -0.06305745989084244}, {"text": " Similar", "logprob": -2.5944435596466064}, {"text": "ity", "logprob": -0.11346970498561859}, {"text": ".", "logprob": -5.404999256134033}, {"text": " Carnegie", "logprob": -9.416084289550781}, {"text": " Museum", "logprob": -1.926347255706787}, {"text": ".", "logprob": -1.7964985370635986}, {"text": " Similar", "logprob": -2.6700291633605957}, {"text": "ity", "logprob": -0.00013779645087197423}, {"text": ".", "logprob": -0.2810017168521881}, {"text": " Library", "logprob": -3.147982597351074}, {"text": ".", "logprob": -1.6670035123825073}], "answers": ["false"], "all_classes": "null", "length": 25}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'lakes can improve or worsen their health by their actions.' true or false?", "pred": " \n\nAnswer:\n\nfalse. 1 Similarity: Environmental impact  Similarity:", "completions_tokens": [{"text": " \n\n", "logprob": -0.08477674424648285}, {"text": "Answer", "logprob": -1.6769615411758423}, {"text": ":\n\n", "logprob": -1.8477599620819092}, {"text": "false", "logprob": -1.9261093139648438}, {"text": ".", "logprob": -0.02979033812880516}, {"text": " ", "logprob": -0.3139598071575165}, {"text": "1", "logprob": -4.781515598297119}, {"text": " Similar", "logprob": -1.9030635356903076}, {"text": "ity", "logprob": -0.026046238839626312}, {"text": ":", "logprob": -0.0960688441991806}, {"text": " Environmental", "logprob": -2.563115119934082}, {"text": " impact", "logprob": -2.471055507659912}, {"text": " ", "logprob": -1.719783067703247}, {"text": " Similar", "logprob": -0.21211503446102142}, {"text": "ity", "logprob": -0.00013791563105769455}, {"text": ":", "logprob": -0.00013767725613433868}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'time intervals represents the number of years a teacher has been employed in the public school system.' true or false?", "pred": " \n\nA) True\nB) Time intervals may signify the entropy of an atomic", "completions_tokens": [{"text": " \n\n", "logprob": -0.09923757612705231}, {"text": "A", "logprob": -0.11166699975728989}, {"text": ")", "logprob": -0.45311397314071655}, {"text": " True", "logprob": -1.5082346200942993}, {"text": "\n", "logprob": -0.20809036493301392}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " Time", "logprob": -0.10545561462640762}, {"text": " intervals", "logprob": -0.030462851747870445}, {"text": " may", "logprob": -3.149308681488037}, {"text": " signify", "logprob": -6.301246166229248}, {"text": " the", "logprob": -0.6207786798477173}, {"text": " entropy", "logprob": -10.983589172363281}, {"text": " of", "logprob": -2.1956896781921387}, {"text": " an", "logprob": -1.6338196992874146}, {"text": " atomic", "logprob": -3.850187301635742}], "answers": ["false"], "all_classes": "null", "length": 27}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'historic sites come in many different shapes and sizes.' true or false?", "pred": " \n\nA) True\nB) C) False\nC) D) None", "completions_tokens": [{"text": " \n\n", "logprob": -0.11684481799602509}, {"text": "A", "logprob": -0.12333714962005615}, {"text": ")", "logprob": -0.004303005523979664}, {"text": " True", "logprob": -1.1326570510864258}, {"text": "\n", "logprob": -0.0822126716375351}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " C", "logprob": -5.102921485900879}, {"text": ")", "logprob": -0.06888824701309204}, {"text": " False", "logprob": -0.10909216105937958}, {"text": "\n", "logprob": -0.035268425941467285}, {"text": "C", "logprob": -0.5438026785850525}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " D", "logprob": -2.791687488555908}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " None", "logprob": -0.13787539303302765}], "answers": ["true"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Embryology is the science studying the emergence of living order.' true or false?", "pred": " \n\nA) False\nB) True\nC) Facies anomala described", "completions_tokens": [{"text": " \n\n", "logprob": -0.1572953760623932}, {"text": "A", "logprob": -0.07469497621059418}, {"text": ")", "logprob": -0.46389222145080566}, {"text": " False", "logprob": -2.3925528526306152}, {"text": "\n", "logprob": -0.13893571496009827}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -0.5686357617378235}, {"text": "\n", "logprob": -0.012508394196629524}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Fac", "logprob": -8.900786399841309}, {"text": "ies", "logprob": -2.9567413330078125}, {"text": " anom", "logprob": -8.558158874511719}, {"text": "ala", "logprob": -0.41454336047172546}, {"text": " described", "logprob": -6.994448661804199}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'automobile engines use fuel.' true or false?", "pred": " \n\nTrue False\nA -  Consider the characteristics of the parts that make up", "completions_tokens": [{"text": " \n\n", "logprob": -0.1445731222629547}, {"text": "True", "logprob": -1.9237362146377563}, {"text": " False", "logprob": -1.4443979263305664}, {"text": "\n", "logprob": -0.028056882321834564}, {"text": "A", "logprob": -1.184110403060913}, {"text": " -", "logprob": -1.498055338859558}, {"text": " ", "logprob": -0.271564245223999}, {"text": " Consider", "logprob": -8.690972328186035}, {"text": " the", "logprob": -1.9441802501678467}, {"text": " characteristics", "logprob": -4.242580890655518}, {"text": " of", "logprob": -0.12970906496047974}, {"text": " the", "logprob": -1.79608154296875}, {"text": " parts", "logprob": -5.248958110809326}, {"text": " that", "logprob": -0.8939796686172485}, {"text": " make", "logprob": -0.20476219058036804}, {"text": " up", "logprob": -0.011104922741651535}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Elections are data-driven events.' true or false?", "pred": " \n\nA) True\nB) False\nC) True.\nD) A", "completions_tokens": [{"text": " \n\n", "logprob": -0.17628233134746552}, {"text": "A", "logprob": -0.2280350774526596}, {"text": ")", "logprob": -0.1310676783323288}, {"text": " True", "logprob": -0.5178319811820984}, {"text": "\n", "logprob": -0.20681025087833405}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.13815566897392273}, {"text": "\n", "logprob": -0.07025108486413956}, {"text": "C", "logprob": -0.012966719456017017}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " True", "logprob": -3.552412509918213}, {"text": ".\n", "logprob": -3.5497548580169678}, {"text": "D", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " A", "logprob": -1.5332387685775757}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'former municipalities are structures.' true or false?", "pred": " \n\nTrue  False\n/The False / The Answer is false / The /H", "completions_tokens": [{"text": " \n\n", "logprob": -0.08200403302907944}, {"text": "True", "logprob": -3.187141180038452}, {"text": " ", "logprob": -3.0026865005493164}, {"text": " False", "logprob": -0.6143636107444763}, {"text": "\n", "logprob": -0.42498719692230225}, {"text": "/The", "logprob": -9.761049270629883}, {"text": " False", "logprob": -5.171224594116211}, {"text": " /", "logprob": -3.133213758468628}, {"text": " The", "logprob": -1.379656434059143}, {"text": " Answer", "logprob": -2.8138508796691895}, {"text": " is", "logprob": -0.8117289543151855}, {"text": " false", "logprob": -1.354156255722046}, {"text": " /", "logprob": -2.273425817489624}, {"text": " The", "logprob": -2.9629721641540527}, {"text": " /", "logprob": -5.008410453796387}, {"text": "H", "logprob": -11.753866195678711}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'arteries attach the cirri to sockets in the centrodorsal.' true or false?", "pred": " \n\nA\nB\nC\nD\nAnswer: C\nExplanation: Center", "completions_tokens": [{"text": " \n\n", "logprob": -0.131900817155838}, {"text": "A", "logprob": -0.3062155544757843}, {"text": "\n", "logprob": -1.4411733150482178}, {"text": "B", "logprob": -0.0903567299246788}, {"text": "\n", "logprob": -0.00013779645087197423}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -0.20180067420005798}, {"text": "D", "logprob": -0.007925373502075672}, {"text": "\n", "logprob": -0.28541475534439087}, {"text": "Answer", "logprob": -1.0241764783859253}, {"text": ":", "logprob": -0.9933159351348877}, {"text": " C", "logprob": -1.669274926185608}, {"text": "\n", "logprob": -0.27404502034187317}, {"text": "Explanation", "logprob": -0.5024808645248413}, {"text": ":", "logprob": -0.00013791563105769455}, {"text": " Center", "logprob": -10.530553817749023}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'airports occupy territory.' true or false?", "pred": " \n\nAnswer: True. \nLet me explain it:\nThe  world population has", "completions_tokens": [{"text": " \n\n", "logprob": -0.12300104647874832}, {"text": "Answer", "logprob": -1.1075340509414673}, {"text": ":", "logprob": -0.00013767725613433868}, {"text": " True", "logprob": -0.570893406867981}, {"text": ".", "logprob": -0.023908058181405067}, {"text": " \n", "logprob": -2.408102512359619}, {"text": "Let", "logprob": -4.0354413986206055}, {"text": " me", "logprob": -0.8957195281982422}, {"text": " explain", "logprob": -3.663391590118408}, {"text": " it", "logprob": -1.8569397926330566}, {"text": ":\n", "logprob": -4.701250076293945}, {"text": "The", "logprob": -0.8079233169555664}, {"text": " ", "logprob": -6.643235206604004}, {"text": " world", "logprob": -5.930944442749023}, {"text": " population", "logprob": -5.645785331726074}, {"text": " has", "logprob": -1.436726450920105}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Village dates back probably as far as pharaonic times.' true or false?", "pred": " \n\nA) False\nB) True\nC) Turkey\nD) None", "completions_tokens": [{"text": " \n\n", "logprob": -0.26576927304267883}, {"text": "A", "logprob": -0.45114457607269287}, {"text": ")", "logprob": -0.4283340871334076}, {"text": " False", "logprob": -2.1795411109924316}, {"text": "\n", "logprob": -0.06278488039970398}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -0.23287898302078247}, {"text": "\n", "logprob": -0.012898231856524944}, {"text": "C", "logprob": -0.02373717911541462}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Turkey", "logprob": -10.310993194580078}, {"text": "\n", "logprob": -0.7185265421867371}, {"text": "D", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " None", "logprob": -1.0527386665344238}], "answers": ["true"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Activities ensure cycle cost.' true or false?", "pred": " \n\nA) True\nB) False\nC)  Activity B has fewer", "completions_tokens": [{"text": " \n\n", "logprob": -0.13752855360507965}, {"text": "A", "logprob": -0.14717994630336761}, {"text": ")", "logprob": -0.1420089304447174}, {"text": " True", "logprob": -0.9090224504470825}, {"text": "\n", "logprob": -0.10313034057617188}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.5782985687255859}, {"text": "\n", "logprob": -0.03494742140173912}, {"text": "C", "logprob": -0.008935347199440002}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -2.7154734134674072}, {"text": " Activity", "logprob": -3.15584659576416}, {"text": " B", "logprob": -4.204086780548096}, {"text": " has", "logprob": -2.8160781860351562}, {"text": " fewer", "logprob": -5.668789863586426}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Locations have tops.' true or false?", "pred": " \n\nAnswer: FALSE. \n\nExplanation:  There are many possible alternatives to '", "completions_tokens": [{"text": " \n\n", "logprob": -0.17288240790367126}, {"text": "Answer", "logprob": -0.05242099240422249}, {"text": ":", "logprob": -0.00013767725613433868}, {"text": " FALSE", "logprob": -0.8004685640335083}, {"text": ".", "logprob": -0.14833518862724304}, {"text": " \n\n", "logprob": -4.448684215545654}, {"text": "Explanation", "logprob": -2.131748914718628}, {"text": ":", "logprob": -0.04685990512371063}, {"text": " ", "logprob": -2.3444221019744873}, {"text": " There", "logprob": -2.6025896072387695}, {"text": " are", "logprob": -0.5268401503562927}, {"text": " many", "logprob": -0.9397028684616089}, {"text": " possible", "logprob": -5.706305027008057}, {"text": " alternatives", "logprob": -4.118053436279297}, {"text": " to", "logprob": -0.4114465117454529}, {"text": " '", "logprob": -1.6242209672927856}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Dams can also affect the quality of the river water both above and below the dam.' true or false?", "pred": " \n\nA) True\nB) False\nC) Cannels D\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.06927818804979324}, {"text": "A", "logprob": -0.07136780023574829}, {"text": ")", "logprob": -0.19179268181324005}, {"text": " True", "logprob": -0.5730268955230713}, {"text": "\n", "logprob": -0.05610455200076103}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.11615665256977081}, {"text": "\n", "logprob": -0.06920187920331955}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " C", "logprob": -0.9333549737930298}, {"text": "annels", "logprob": -8.473599433898926}, {"text": " D", "logprob": -6.805986404418945}, {"text": "\n", "logprob": -0.6872217655181885}, {"text": "D", "logprob": -0.33105790615081787}], "answers": ["true"], "all_classes": "null", "length": 26}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Eukaryotes are also the only organisms to provide milk to their young.' true or false?", "pred": " \n\nAnswer: FALSE.  Eucarya are not known for secretion of large", "completions_tokens": [{"text": " \n\n", "logprob": -0.1290586292743683}, {"text": "Answer", "logprob": -1.7350571155548096}, {"text": ":", "logprob": -0.16293089091777802}, {"text": " FALSE", "logprob": -0.3284342586994171}, {"text": ".", "logprob": -0.2832932472229004}, {"text": " ", "logprob": -1.20258629322052}, {"text": " E", "logprob": -0.785277783870697}, {"text": "uc", "logprob": -2.973416805267334}, {"text": "arya", "logprob": -1.0845938920974731}, {"text": " are", "logprob": -1.971456527709961}, {"text": " not", "logprob": -1.849043607711792}, {"text": " known", "logprob": -4.081056594848633}, {"text": " for", "logprob": -0.22301612794399261}, {"text": " secretion", "logprob": -6.366991996765137}, {"text": " of", "logprob": -0.05393657088279724}, {"text": " large", "logprob": -2.830751895904541}], "answers": ["false"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Gardens are more than just plants.' true or false?", "pred": " \n\nA. False\nB. A statement which correctly presents a view from aesthetics", "completions_tokens": [{"text": " \n\n", "logprob": -0.1276344507932663}, {"text": "A", "logprob": -0.22256316244602203}, {"text": ".", "logprob": -1.2033990621566772}, {"text": " False", "logprob": -2.4972362518310547}, {"text": "\n", "logprob": -0.1436222344636917}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -6.9141146923357155e-06}, {"text": " A", "logprob": -1.2653753757476807}, {"text": " statement", "logprob": -1.8540596961975098}, {"text": " which", "logprob": -3.36012601852417}, {"text": " correctly", "logprob": -6.6467814445495605}, {"text": " presents", "logprob": -3.752568483352661}, {"text": " a", "logprob": -0.901891827583313}, {"text": " view", "logprob": -2.777088165283203}, {"text": " from", "logprob": -4.453111171722412}, {"text": " aesthetics", "logprob": -6.375035762786865}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Plant Fibers Several plants are sources of insulation from cold.' true or false?", "pred": " \n\nAnswer: FALSE Text: Most plants are sensitive to cold. \nWater has", "completions_tokens": [{"text": " \n\n", "logprob": -0.09377110749483109}, {"text": "Answer", "logprob": -0.6457580327987671}, {"text": ":", "logprob": -0.4290176331996918}, {"text": " FALSE", "logprob": -0.5339796543121338}, {"text": " Text", "logprob": -10.200772285461426}, {"text": ":", "logprob": -0.229768767952919}, {"text": " Most", "logprob": -3.769465684890747}, {"text": " plants", "logprob": -1.3594835996627808}, {"text": " are", "logprob": -0.8268076181411743}, {"text": " sensitive", "logprob": -5.412428855895996}, {"text": " to", "logprob": -0.40629318356513977}, {"text": " cold", "logprob": -0.3777387738227844}, {"text": ".", "logprob": -1.1323463916778564}, {"text": " \n", "logprob": -3.693392276763916}, {"text": "Water", "logprob": -5.935241222381592}, {"text": " has", "logprob": -2.6701598167419434}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'theatres is a word that gets used often in Washington.' true or false?", "pred": " \n\nA) The keyword lists of theatre in pages using Robots.txt file contained none", "completions_tokens": [{"text": " \n\n", "logprob": -0.14747273921966553}, {"text": "A", "logprob": -1.7135086059570312}, {"text": ")", "logprob": -0.3209385871887207}, {"text": " The", "logprob": -1.1995880603790283}, {"text": " keyword", "logprob": -7.730716705322266}, {"text": " lists", "logprob": -9.538718223571777}, {"text": " of", "logprob": -2.183487892150879}, {"text": " theatre", "logprob": -4.343982696533203}, {"text": " in", "logprob": -1.4549851417541504}, {"text": " pages", "logprob": -9.312064170837402}, {"text": " using", "logprob": -6.074553966522217}, {"text": " Robots", "logprob": -12.250808715820312}, {"text": ".txt", "logprob": -0.20225904881954193}, {"text": " file", "logprob": -2.546339988708496}, {"text": " contained", "logprob": -5.4955620765686035}, {"text": " none", "logprob": -6.217160224914551}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Many islands have plants and animals that live nowhere else on Earth.' true or false?", "pred": " \n\nA. The statement made in the question is true.\nB. The statement", "completions_tokens": [{"text": " \n\n", "logprob": -0.11014467477798462}, {"text": "A", "logprob": -0.6107392311096191}, {"text": ".", "logprob": -0.7779613733291626}, {"text": " The", "logprob": -2.7484514713287354}, {"text": " statement", "logprob": -0.9690775871276855}, {"text": " made", "logprob": -4.139510631561279}, {"text": " in", "logprob": -0.8035672903060913}, {"text": " the", "logprob": -1.2918072938919067}, {"text": " question", "logprob": -1.576570987701416}, {"text": " is", "logprob": -2.1827492713928223}, {"text": " true", "logprob": -0.44692206382751465}, {"text": ".\n", "logprob": -0.08250689506530762}, {"text": "B", "logprob": -6.9141146923357155e-06}, {"text": ".", "logprob": -0.00013779645087197423}, {"text": " The", "logprob": -0.24059070646762848}, {"text": " statement", "logprob": -0.009507850743830204}], "answers": ["true"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Elections are a tool through which voters try to communicate.' true or false?", "pred": " \n\nAnswer: False.  Philosophy Exams, Oxford 2001. ", "completions_tokens": [{"text": " \n\n", "logprob": -0.13648992776870728}, {"text": "Answer", "logprob": -1.3883732557296753}, {"text": ":", "logprob": -0.4551342725753784}, {"text": " False", "logprob": -1.9146795272827148}, {"text": ".", "logprob": -0.04302297905087471}, {"text": " ", "logprob": -0.9103443026542664}, {"text": " Philosophy", "logprob": -7.808213233947754}, {"text": " Ex", "logprob": -11.388107299804688}, {"text": "ams", "logprob": -0.36492109298706055}, {"text": ",", "logprob": -1.7286856174468994}, {"text": " Oxford", "logprob": -4.350930213928223}, {"text": " ", "logprob": -1.593969702720642}, {"text": "200", "logprob": -0.4144905209541321}, {"text": "1", "logprob": -2.061666965484619}, {"text": ".", "logprob": -0.3256278336048126}, {"text": " ", "logprob": -0.8054030537605286}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'galaxies are located in buildings.' true or false?", "pred": " \n\nTrue\nFalse\nActually, it is an isometric spatial relationship question that", "completions_tokens": [{"text": " \n\n", "logprob": -0.11960247159004211}, {"text": "True", "logprob": -0.958060085773468}, {"text": "\n", "logprob": -1.6125541925430298}, {"text": "False", "logprob": -0.01693045347929001}, {"text": "\n", "logprob": -0.1738038808107376}, {"text": "Actually", "logprob": -8.084331512451172}, {"text": ",", "logprob": -0.15165896713733673}, {"text": " it", "logprob": -1.3512930870056152}, {"text": " is", "logprob": -0.9601562023162842}, {"text": " an", "logprob": -3.8240084648132324}, {"text": " is", "logprob": -6.01239013671875}, {"text": "ometric", "logprob": -2.8077783584594727}, {"text": " spatial", "logprob": -5.722283363342285}, {"text": " relationship", "logprob": -0.7463836669921875}, {"text": " question", "logprob": -2.332277774810791}, {"text": " that", "logprob": -2.2763025760650635}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Canals carve through hard layers of rock , breaking down or eroding it.' true or false?", "pred": " \n\nA\nThey carve into and do not necessarily break down the rock layers.\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.08732683211565018}, {"text": "A", "logprob": -0.08639872819185257}, {"text": "\n", "logprob": -0.7540120482444763}, {"text": "They", "logprob": -6.568894386291504}, {"text": " carve", "logprob": -2.0718066692352295}, {"text": " into", "logprob": -4.479629039764404}, {"text": " and", "logprob": -3.049349784851074}, {"text": " do", "logprob": -5.667938709259033}, {"text": " not", "logprob": -0.271747887134552}, {"text": " necessarily", "logprob": -1.7557895183563232}, {"text": " break", "logprob": -0.3150310218334198}, {"text": " down", "logprob": -0.150581493973732}, {"text": " the", "logprob": -0.9051033854484558}, {"text": " rock", "logprob": -0.09508996456861496}, {"text": " layers", "logprob": -5.637014865875244}, {"text": ".\n", "logprob": -0.22920235991477966}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'enzymes forms a major part of our structure.' true or false?", "pred": " \n\nA) false\nB) True\nC) all of the above.\n", "completions_tokens": [{"text": " \n\n", "logprob": -0.057359639555215836}, {"text": "A", "logprob": -0.07556292414665222}, {"text": ")", "logprob": -0.46107184886932373}, {"text": " false", "logprob": -1.4486538171768188}, {"text": "\n", "logprob": -0.19981464743614197}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -1.0574309825897217}, {"text": "\n", "logprob": -0.10678637772798538}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " all", "logprob": -5.6607818603515625}, {"text": " of", "logprob": -0.1516026258468628}, {"text": " the", "logprob": -0.007900536991655827}, {"text": " above", "logprob": -0.0034258030354976654}, {"text": ".\n", "logprob": -2.119448661804199}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Castles have (part) shower stalls.' true or false?", "pred": " False\nAnswer: FALSE\nStep 1: Analyze the statement\nThe", "completions_tokens": [{"text": " False", "logprob": -5.200996398925781}, {"text": "\n", "logprob": -0.19626814126968384}, {"text": "Answer", "logprob": -0.21080811321735382}, {"text": ":", "logprob": -0.010435893200337887}, {"text": " FALSE", "logprob": -2.7721011638641357}, {"text": "\n", "logprob": -0.2560248076915741}, {"text": "Step", "logprob": -0.41763395071029663}, {"text": " ", "logprob": -0.00013767725613433868}, {"text": "1", "logprob": -0.00013779645087197423}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " Analy", "logprob": -0.39990493655204773}, {"text": "ze", "logprob": -0.010118262842297554}, {"text": " the", "logprob": -6.9141146923357155e-06}, {"text": " statement", "logprob": -0.9206756353378296}, {"text": "\n", "logprob": -0.8865845203399658}, {"text": "The", "logprob": -0.017002299427986145}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'transport infrastructures is located in lands.' true or false?", "pred": " \n\nAnswer: False.  New Info: Infrastructure found on the territories of:", "completions_tokens": [{"text": " \n\n", "logprob": -0.13051751255989075}, {"text": "Answer", "logprob": -1.7372440099716187}, {"text": ":", "logprob": -0.15158747136592865}, {"text": " False", "logprob": -2.254960060119629}, {"text": ".", "logprob": -0.02747391164302826}, {"text": " ", "logprob": -1.015320897102356}, {"text": " New", "logprob": -5.825384616851807}, {"text": " Info", "logprob": -5.514130592346191}, {"text": ":", "logprob": -2.4458632469177246}, {"text": " Infrastructure", "logprob": -4.227359771728516}, {"text": " found", "logprob": -8.14931869506836}, {"text": " on", "logprob": -0.6483412384986877}, {"text": " the", "logprob": -1.583918571472168}, {"text": " territories", "logprob": -6.631983280181885}, {"text": " of", "logprob": -0.5713074803352356}, {"text": ":", "logprob": -8.447126388549805}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'space missions occur during the rainy season and disappear at the onset of the dry season.' true or false?", "pred": " \n\nA) True\nB) False\nC) A and B\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.10864922404289246}, {"text": "A", "logprob": -0.015615804120898247}, {"text": ")", "logprob": -0.4492380619049072}, {"text": " True", "logprob": -0.7414373159408569}, {"text": "\n", "logprob": -0.14326323568820953}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.49334871768951416}, {"text": "\n", "logprob": -0.032874695956707}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " A", "logprob": -2.4941625595092773}, {"text": " and", "logprob": -0.17213933169841766}, {"text": " B", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -0.006252964027225971}, {"text": "D", "logprob": -0.00013767725613433868}], "answers": ["false"], "all_classes": "null", "length": 26}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'facilities are located in resorts.' true or false?", "pred": " \n\nA) true\nB) true\nC) resorts include facilities\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.21255357563495636}, {"text": "A", "logprob": -0.3845718204975128}, {"text": ")", "logprob": -0.1583026647567749}, {"text": " true", "logprob": -3.5584523677825928}, {"text": "\n", "logprob": -0.1957523077726364}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " true", "logprob": -2.750368595123291}, {"text": "\n", "logprob": -0.42110365629196167}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " resorts", "logprob": -5.074621200561523}, {"text": " include", "logprob": -3.667752742767334}, {"text": " facilities", "logprob": -0.7702009677886963}, {"text": "\n", "logprob": -0.24637024104595184}, {"text": "D", "logprob": -0.00013767725613433868}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'streams are places favoured by a source of income.' true or false?", "pred": " \n\nA) false\nB) False\nC) Falseness is a", "completions_tokens": [{"text": " \n\n", "logprob": -0.18961912393569946}, {"text": "A", "logprob": -0.17282874882221222}, {"text": ")", "logprob": -0.42685896158218384}, {"text": " false", "logprob": -1.452662706375122}, {"text": "\n", "logprob": -0.2870006859302521}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.9759559631347656}, {"text": "\n", "logprob": -0.3221511244773865}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " F", "logprob": -3.30601167678833}, {"text": "als", "logprob": -0.36490339040756226}, {"text": "eness", "logprob": -1.2896397113800049}, {"text": " is", "logprob": -2.273772716522217}, {"text": " a", "logprob": -1.6652683019638062}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'grapes are also more likely to colic after deworming which can interfere with horse activities.' true or false?", "pred": " \n\nA) false\nB) Not Given\nC) The Given Condition Sup", "completions_tokens": [{"text": " \n\n", "logprob": -0.06747875362634659}, {"text": "A", "logprob": -0.013374963775277138}, {"text": ")", "logprob": -0.018643854185938835}, {"text": " false", "logprob": -2.2191073894500732}, {"text": "\n", "logprob": -0.2825050354003906}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " Not", "logprob": -4.035801887512207}, {"text": " Given", "logprob": -4.755025863647461}, {"text": "\n", "logprob": -0.44794467091560364}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " The", "logprob": -5.09156608581543}, {"text": " Given", "logprob": -5.981254577636719}, {"text": " Condition", "logprob": -3.9464588165283203}, {"text": " Sup", "logprob": -8.690707206726074}], "answers": ["false"], "all_classes": "null", "length": 25}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'UNESCO World Heritage Sites are an artifact of the industrial age.' true or false?", "pred": " \n\nA) it's true.\nB) it is false.\nC) false", "completions_tokens": [{"text": " \n\n", "logprob": -0.11750251054763794}, {"text": "A", "logprob": -0.28869786858558655}, {"text": ")", "logprob": -0.2434663325548172}, {"text": " it", "logprob": -6.7730841636657715}, {"text": "'s", "logprob": -2.649590253829956}, {"text": " true", "logprob": -0.7765409350395203}, {"text": ".\n", "logprob": -1.3694374561309814}, {"text": "B", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " it", "logprob": -0.5110018849372864}, {"text": " is", "logprob": -0.5814739465713501}, {"text": " false", "logprob": -0.14154411852359772}, {"text": ".\n", "logprob": -0.028267471119761467}, {"text": "C", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " false", "logprob": -2.8736772537231445}], "answers": ["false"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Green algae can be unicellular, colonial, or multicellular.' true or false?", "pred": " \n\nTrue\nFalse (Prokaryotic organisms have the form that is characteristic", "completions_tokens": [{"text": " \n\n", "logprob": -0.11842624098062515}, {"text": "True", "logprob": -3.251016616821289}, {"text": "\n", "logprob": -0.9469798803329468}, {"text": "False", "logprob": -0.4331347346305847}, {"text": " (", "logprob": -3.3829054832458496}, {"text": "Pro", "logprob": -6.19620418548584}, {"text": "k", "logprob": -0.3406963348388672}, {"text": "ary", "logprob": -0.00013767725613433868}, {"text": "otic", "logprob": -0.7872956991195679}, {"text": " organisms", "logprob": -1.7724742889404297}, {"text": " have", "logprob": -2.9540867805480957}, {"text": " the", "logprob": -1.9765421152114868}, {"text": " form", "logprob": -5.342928886413574}, {"text": " that", "logprob": -1.628491997718811}, {"text": " is", "logprob": -0.582625150680542}, {"text": " characteristic", "logprob": -2.645825147628784}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Devices convert chemical energy.' true or false?", "pred": " \n\nA) false\nB) C) true\nThe best answer is B", "completions_tokens": [{"text": " \n\n", "logprob": -0.13862308859825134}, {"text": "A", "logprob": -0.208731546998024}, {"text": ")", "logprob": -0.11093568056821823}, {"text": " false", "logprob": -1.41910719871521}, {"text": "\n", "logprob": -0.11768385022878647}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " C", "logprob": -2.541902542114258}, {"text": ")", "logprob": -0.20880430936813354}, {"text": " true", "logprob": -0.36856621503829956}, {"text": "\n", "logprob": -0.012846332974731922}, {"text": "The", "logprob": -3.6275415420532227}, {"text": " best", "logprob": -6.9141146923357155e-06}, {"text": " answer", "logprob": -6.794906312279636e-06}, {"text": " is", "logprob": -6.794906312279636e-06}, {"text": " B", "logprob": -0.32651540637016296}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Mountains are sites.' true or false?", "pred": " \n\nA) True B) False C) Both D) None\n\nUnknown Answer", "completions_tokens": [{"text": " \n\n", "logprob": -0.10486594587564468}, {"text": "A", "logprob": -0.5784835815429688}, {"text": ")", "logprob": -0.26294517517089844}, {"text": " True", "logprob": -1.0581978559494019}, {"text": " B", "logprob": -2.7721147537231445}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " False", "logprob": -6.9141146923357155e-06}, {"text": " C", "logprob": -0.7813208103179932}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Both", "logprob": -3.9015889167785645}, {"text": " D", "logprob": -0.22904233634471893}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " None", "logprob": -0.5439308285713196}, {"text": "\n\n", "logprob": -0.11326003819704056}, {"text": "Unknown", "logprob": -5.374815464019775}, {"text": " Answer", "logprob": -3.08833646774292}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Drugs are able to circulate to all parts of the body and attack cancer cells through out the system.' true or false?", "pred": " TRUE, for it is \nAnswer: False\nModification History  no modifyes", "completions_tokens": [{"text": " TRUE", "logprob": -2.7979986667633057}, {"text": ",", "logprob": -2.526883840560913}, {"text": " for", "logprob": -3.193178653717041}, {"text": " it", "logprob": -2.152912139892578}, {"text": " is", "logprob": -0.4830018877983093}, {"text": " \n", "logprob": -7.619664192199707}, {"text": "Answer", "logprob": -0.7128123641014099}, {"text": ":", "logprob": -0.006548967212438583}, {"text": " False", "logprob": -1.9472905397415161}, {"text": "\n", "logprob": -0.7436100244522095}, {"text": "Modification", "logprob": -7.129827499389648}, {"text": " History", "logprob": -0.2710476815700531}, {"text": " ", "logprob": -2.690258741378784}, {"text": " no", "logprob": -6.885365962982178}, {"text": " modify", "logprob": -6.195921897888184}, {"text": "es", "logprob": -1.7896933555603027}], "answers": ["true"], "all_classes": "null", "length": 29}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some race tracks are called road courses.' true or false?", "pred": " \n\nTrue\nFalse\nUnited States Constitution\nArticle One of the United States Constitution", "completions_tokens": [{"text": " \n\n", "logprob": -0.12510265409946442}, {"text": "True", "logprob": -1.2164250612258911}, {"text": "\n", "logprob": -0.5613642334938049}, {"text": "False", "logprob": -0.6376319527626038}, {"text": "\n", "logprob": -0.0947471559047699}, {"text": "United", "logprob": -7.557177543640137}, {"text": " States", "logprob": -0.010950706899166107}, {"text": " Constitution", "logprob": -3.310136318206787}, {"text": "\n", "logprob": -0.10094751417636871}, {"text": "Article", "logprob": -4.305602073669434}, {"text": " One", "logprob": -2.362764358520508}, {"text": " of", "logprob": -0.731490969657898}, {"text": " the", "logprob": -0.004237482324242592}, {"text": " United", "logprob": -0.14948119223117828}, {"text": " States", "logprob": -6.794906312279636e-06}, {"text": " Constitution", "logprob": -6.9141146923357155e-06}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Arteries can rupture when weak spots on the blood vessel wall break.' true or false?", "pred": " \n\nA) The statement that arteries can burst under high internal blood pressure. B", "completions_tokens": [{"text": " \n\n", "logprob": -0.09081001579761505}, {"text": "A", "logprob": -0.09496963769197464}, {"text": ")", "logprob": -0.2562743127346039}, {"text": " The", "logprob": -2.6570420265197754}, {"text": " statement", "logprob": -1.1306324005126953}, {"text": " that", "logprob": -1.663449764251709}, {"text": " arteries", "logprob": -0.6269668340682983}, {"text": " can", "logprob": -1.8466238975524902}, {"text": " burst", "logprob": -2.4493894577026367}, {"text": " under", "logprob": -3.00486421585083}, {"text": " high", "logprob": -1.131191611289978}, {"text": " internal", "logprob": -2.193570375442505}, {"text": " blood", "logprob": -1.0313222408294678}, {"text": " pressure", "logprob": -0.012470484711229801}, {"text": ".", "logprob": -2.838653802871704}, {"text": " B", "logprob": -1.156172752380371}], "answers": ["true"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'railway lines are service companies.' true or false?", "pred": " \n\nA) service company\nB) Product company\nC) True\nD", "completions_tokens": [{"text": " \n\n", "logprob": -0.15825381875038147}, {"text": "A", "logprob": -0.09604231268167496}, {"text": ")", "logprob": -0.8088462948799133}, {"text": " service", "logprob": -6.339567184448242}, {"text": " company", "logprob": -0.389676958322525}, {"text": "\n", "logprob": -0.40036123991012573}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Product", "logprob": -6.108528137207031}, {"text": " company", "logprob": -0.29196304082870483}, {"text": "\n", "logprob": -0.0009243983076885343}, {"text": "C", "logprob": -0.00013791563105769455}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " True", "logprob": -0.5981627702713013}, {"text": "\n", "logprob": -0.005540254060178995}, {"text": "D", "logprob": -0.00013767725613433868}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Theatre is psychology.' true or false?", "pred": " \n\nA) True\nB) False\nC)  Neither True nor False", "completions_tokens": [{"text": " \n\n", "logprob": -0.20975176990032196}, {"text": "A", "logprob": -0.2068103402853012}, {"text": ")", "logprob": -0.609004020690918}, {"text": " True", "logprob": -1.1732635498046875}, {"text": "\n", "logprob": -0.2606673538684845}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.7609791159629822}, {"text": "\n", "logprob": -0.06041737273335457}, {"text": "C", "logprob": -0.012377472594380379}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -3.3800487518310547}, {"text": " Neither", "logprob": -1.9191404581069946}, {"text": " True", "logprob": -0.5737709403038025}, {"text": " nor", "logprob": -0.6604618430137634}, {"text": " False", "logprob": -0.04447532445192337}], "answers": ["false"], "all_classes": "null", "length": 13}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Human genes are pieces of genetic material recorded on a DNA molecule.' true or false?", "pred": " \n\nAnswer: True.  Current: True. Correctness: High (because", "completions_tokens": [{"text": " \n\n", "logprob": -0.10591155290603638}, {"text": "Answer", "logprob": -1.3680553436279297}, {"text": ":", "logprob": -0.4378335773944855}, {"text": " True", "logprob": -0.23992781341075897}, {"text": ".", "logprob": -0.022570623084902763}, {"text": " ", "logprob": -1.0213476419448853}, {"text": " Current", "logprob": -8.568397521972656}, {"text": ":", "logprob": -3.754516839981079}, {"text": " True", "logprob": -0.9213542938232422}, {"text": ".", "logprob": -0.1068926453590393}, {"text": " Correct", "logprob": -3.6853060722351074}, {"text": "ness", "logprob": -0.3164277970790863}, {"text": ":", "logprob": -0.6937516331672668}, {"text": " High", "logprob": -4.342374324798584}, {"text": " (", "logprob": -4.308612823486328}, {"text": "because", "logprob": -5.0253753662109375}], "answers": ["true"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Stars are a light source.' true or false?", "pred": " From an astronomical perspective?\nID: 23588\nOption 1: False", "completions_tokens": [{"text": " From", "logprob": -9.127215385437012}, {"text": " an", "logprob": -1.2323853969573975}, {"text": " astronomical", "logprob": -0.6486276388168335}, {"text": " perspective", "logprob": -0.2380676418542862}, {"text": "?\n", "logprob": -3.3265039920806885}, {"text": "ID", "logprob": -3.468667507171631}, {"text": ":", "logprob": -6.9141146923357155e-06}, {"text": " ", "logprob": -0.21142719686031342}, {"text": "235", "logprob": -6.856715202331543}, {"text": "88", "logprob": -6.397160053253174}, {"text": "\n", "logprob": -0.017382187768816948}, {"text": "Option", "logprob": -0.8012350797653198}, {"text": " ", "logprob": -0.8906093835830688}, {"text": "1", "logprob": -0.00046885941992513835}, {"text": ":", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -1.3597761392593384}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Planets are typically brighter than most stars.' true or false?", "pred": " \n\nA) The moon reflects about 12 percent of the incident sunlight. But", "completions_tokens": [{"text": " \n\n", "logprob": -0.12848356366157532}, {"text": "A", "logprob": -0.13072778284549713}, {"text": ")", "logprob": -0.2470083087682724}, {"text": " The", "logprob": -2.617846965789795}, {"text": " moon", "logprob": -3.950131416320801}, {"text": " reflects", "logprob": -2.403362512588501}, {"text": " about", "logprob": -1.3218125104904175}, {"text": " ", "logprob": -0.7544362545013428}, {"text": "12", "logprob": -0.06175997108221054}, {"text": " percent", "logprob": -0.2595871090888977}, {"text": " of", "logprob": -0.007827561348676682}, {"text": " the", "logprob": -0.047800417989492416}, {"text": " incident", "logprob": -2.110175371170044}, {"text": " sunlight", "logprob": -0.2164732962846756}, {"text": ".", "logprob": -1.1686832904815674}, {"text": " But", "logprob": -5.022848129272461}], "answers": ["false"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Golf courses are one of the many land uses that contribute to a well-balanced livable community.' true or false?", "pred": " \n\nA. True\nB. False\nC. Golf courses are one A", "completions_tokens": [{"text": " \n\n", "logprob": -0.08468562364578247}, {"text": "A", "logprob": -0.10860441625118256}, {"text": ".", "logprob": -1.842768669128418}, {"text": " True", "logprob": -0.4145394265651703}, {"text": "\n", "logprob": -0.13072244822978973}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -6.9141146923357155e-06}, {"text": " False", "logprob": -0.1216050460934639}, {"text": "\n", "logprob": -0.12730398774147034}, {"text": "C", "logprob": -0.02031145617365837}, {"text": ".", "logprob": -6.794906312279636e-06}, {"text": " Golf", "logprob": -0.0832553505897522}, {"text": " courses", "logprob": -0.17110320925712585}, {"text": " are", "logprob": -0.849250316619873}, {"text": " one", "logprob": -0.9681435823440552}, {"text": " A", "logprob": -5.0609235763549805}], "answers": ["false"], "all_classes": "null", "length": 26}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Enzymes are a boon for the human body.' true or false?", "pred": " \nAnswer:\n\n## Step 1: Identify what the statement claims.\nThe statement", "completions_tokens": [{"text": " \n", "logprob": -4.241762161254883}, {"text": "Answer", "logprob": -0.015344308689236641}, {"text": ":\n\n", "logprob": -0.6514333486557007}, {"text": "##", "logprob": -0.2216230034828186}, {"text": " Step", "logprob": -0.00013779645087197423}, {"text": " ", "logprob": -6.794906312279636e-06}, {"text": "1", "logprob": -6.9141146923357155e-06}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " Identify", "logprob": -2.319841146469116}, {"text": " what", "logprob": -0.2665046751499176}, {"text": " the", "logprob": -0.43634033203125}, {"text": " statement", "logprob": -0.4569748640060425}, {"text": " claims", "logprob": -0.25486043095588684}, {"text": ".\n", "logprob": -0.12364006042480469}, {"text": "The", "logprob": -0.00013779645087197423}, {"text": " statement", "logprob": -6.9141146923357155e-06}], "answers": ["true"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Villages change the ecology of natural systems.' true or false?", "pred": " \n\nA) True. \nB) Villages often alter the geology through", "completions_tokens": [{"text": " \n\n", "logprob": -0.2638750374317169}, {"text": "A", "logprob": -0.6853293776512146}, {"text": ")", "logprob": -0.2892790734767914}, {"text": " True", "logprob": -0.7061364650726318}, {"text": ".", "logprob": -3.3856558799743652}, {"text": " \n", "logprob": -0.8616162538528442}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Vill", "logprob": -0.5579258799552917}, {"text": "ages", "logprob": -0.0005553610390052199}, {"text": " often", "logprob": -3.1255393028259277}, {"text": " alter", "logprob": -2.5242457389831543}, {"text": " the", "logprob": -0.35795795917510986}, {"text": " ge", "logprob": -6.069760322570801}, {"text": "ology", "logprob": -0.10308872908353806}, {"text": " through", "logprob": -2.607804775238037}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Outbreaks are about making choices and picking winners.' true or false?", "pred": " \n\nAnswer: False. 105.111.32.98 1435", "completions_tokens": [{"text": " \n\n", "logprob": -0.39955219626426697}, {"text": "Answer", "logprob": -0.25477728247642517}, {"text": ":", "logprob": -0.20466960966587067}, {"text": " False", "logprob": -1.4843499660491943}, {"text": ".", "logprob": -0.0540207140147686}, {"text": " ", "logprob": -1.2002196311950684}, {"text": "105", "logprob": -7.129719257354736}, {"text": ".", "logprob": -1.550826907157898}, {"text": "111", "logprob": -4.646816253662109}, {"text": ".", "logprob": -0.04011869803071022}, {"text": "32", "logprob": -4.6355719566345215}, {"text": ".", "logprob": -0.1934019774198532}, {"text": "98", "logprob": -5.069766521453857}, {"text": " ", "logprob": -1.5954556465148926}, {"text": "143", "logprob": -6.55242919921875}, {"text": "5", "logprob": -2.657163381576538}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Sporting event are sports.' true or false?", "pred": " \n\nA) false\nB) True \nC) false \nD) False", "completions_tokens": [{"text": " \n\n", "logprob": -0.09109247475862503}, {"text": "A", "logprob": -0.5371884703636169}, {"text": ")", "logprob": -0.21027055382728577}, {"text": " false", "logprob": -2.019726037979126}, {"text": "\n", "logprob": -0.3450343608856201}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -3.2903196811676025}, {"text": " \n", "logprob": -1.7885026931762695}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " false", "logprob": -1.2485411167144775}, {"text": " \n", "logprob": -0.5907500386238098}, {"text": "D", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " False", "logprob": -1.4244388341903687}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Ligaments have (part) corpi.' true or false?", "pred": " \n\nAnswer: FALSE.  I couldn't find the word \"corpi.\"", "completions_tokens": [{"text": " \n\n", "logprob": -0.07433658093214035}, {"text": "Answer", "logprob": -0.0915910080075264}, {"text": ":", "logprob": -0.19896793365478516}, {"text": " FALSE", "logprob": -0.30982932448387146}, {"text": ".", "logprob": -0.06510704010725021}, {"text": " ", "logprob": -1.1404626369476318}, {"text": " I", "logprob": -3.4581751823425293}, {"text": " couldn", "logprob": -3.047333240509033}, {"text": "'t", "logprob": -0.0010737375123426318}, {"text": " find", "logprob": -1.4701032638549805}, {"text": " the", "logprob": -0.7839764356613159}, {"text": " word", "logprob": -0.7339552044868469}, {"text": " \"", "logprob": -0.44033190608024597}, {"text": "cor", "logprob": -0.05304183438420296}, {"text": "pi", "logprob": -6.794906312279636e-06}, {"text": ".\"", "logprob": -0.39033612608909607}], "answers": ["false"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'information appliances consume energy.' true or false?", "pred": " \n\nAnswer: True. \nThis statement relates to the chapter on electricity. \n", "completions_tokens": [{"text": " \n\n", "logprob": -0.18496949970722198}, {"text": "Answer", "logprob": -1.9849495887756348}, {"text": ":", "logprob": -0.12916506826877594}, {"text": " True", "logprob": -0.24461482465267181}, {"text": ".", "logprob": -0.013229567557573318}, {"text": " \n", "logprob": -2.4055428504943848}, {"text": "This", "logprob": -2.999983072280884}, {"text": " statement", "logprob": -1.9273983240127563}, {"text": " relates", "logprob": -3.7639589309692383}, {"text": " to", "logprob": -0.4151262044906616}, {"text": " the", "logprob": -0.28322991728782654}, {"text": " chapter", "logprob": -6.635814666748047}, {"text": " on", "logprob": -0.5727033615112305}, {"text": " electricity", "logprob": -5.154419422149658}, {"text": ".", "logprob": -0.4428037106990814}, {"text": " \n", "logprob": -1.9740352630615234}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Protein continues to be inserted until it reaches the hydrophobic stop signal sequence.' true or false?", "pred": " \n\nAnswer: FALSE. The process continues until it is terminated by one or a", "completions_tokens": [{"text": " \n\n", "logprob": -0.4853536784648895}, {"text": "Answer", "logprob": -0.48602062463760376}, {"text": ":", "logprob": -0.14304453134536743}, {"text": " FALSE", "logprob": -0.4327954649925232}, {"text": ".", "logprob": -0.11057905107736588}, {"text": " The", "logprob": -2.366574287414551}, {"text": " process", "logprob": -3.146275520324707}, {"text": " continues", "logprob": -3.0181150436401367}, {"text": " until", "logprob": -0.634032130241394}, {"text": " it", "logprob": -0.27466610074043274}, {"text": " is", "logprob": -0.5275497436523438}, {"text": " terminated", "logprob": -2.289336681365967}, {"text": " by", "logprob": -1.2738035917282104}, {"text": " one", "logprob": -1.3425945043563843}, {"text": " or", "logprob": -3.8168327808380127}, {"text": " a", "logprob": -1.6193697452545166}], "answers": ["false"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some canals deliver water.' true or false?", "pred": " \n\nA) True\n\nB) Some canals may obstruct navigation\n\nC)", "completions_tokens": [{"text": " \n\n", "logprob": -0.13728053867816925}, {"text": "A", "logprob": -0.7654628753662109}, {"text": ")", "logprob": -0.23927883803844452}, {"text": " True", "logprob": -1.0050972700119019}, {"text": "\n\n", "logprob": -3.5969011783599854}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " Some", "logprob": -0.8062747716903687}, {"text": " can", "logprob": -0.10913694649934769}, {"text": "als", "logprob": -6.794906312279636e-06}, {"text": " may", "logprob": -2.9750351905822754}, {"text": " obstruct", "logprob": -7.971245765686035}, {"text": " navigation", "logprob": -5.163277626037598}, {"text": "\n\n", "logprob": -1.1429189443588257}, {"text": "C", "logprob": -0.00013791563105769455}, {"text": ")", "logprob": -0.00013767725613433868}], "answers": ["true"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Landforms have direct effects.' true or false?", "pred": " \n\nAnswer: FALSE.", "completions_tokens": [{"text": " \n\n", "logprob": -0.26533105969429016}, {"text": "Answer", "logprob": -1.0494166612625122}, {"text": ":", "logprob": -0.1254374235868454}, {"text": " FALSE", "logprob": -0.40679943561553955}, {"text": ".", "logprob": -0.17772896587848663}, {"text": "<|eom_id|>", "logprob": -9.581713676452637}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Stars are huge balls of gas generating tremendous amounts of energy.' true or false?", "pred": " \n\nA) false B) Partially true, but far from complete. C", "completions_tokens": [{"text": " \n\n", "logprob": -0.19554400444030762}, {"text": "A", "logprob": -0.061179954558610916}, {"text": ")", "logprob": -0.12721392512321472}, {"text": " false", "logprob": -2.4888620376586914}, {"text": " B", "logprob": -2.042571783065796}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Partial", "logprob": -5.677996635437012}, {"text": "ly", "logprob": -0.3273587226867676}, {"text": " true", "logprob": -0.3654308617115021}, {"text": ",", "logprob": -1.4718722105026245}, {"text": " but", "logprob": -0.5904810428619385}, {"text": " far", "logprob": -7.046208381652832}, {"text": " from", "logprob": -0.42351028323173523}, {"text": " complete", "logprob": -0.45749354362487793}, {"text": ".", "logprob": -0.46357402205467224}, {"text": " C", "logprob": -0.006481932941824198}], "answers": ["true"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'monoclonal antibodies also break without cleavage or across cleavage planes.' true or false?", "pred": " \n\nA) False\nB) None of the above\nC) A monoc", "completions_tokens": [{"text": " \n\n", "logprob": -0.1684679388999939}, {"text": "A", "logprob": -0.7642133235931396}, {"text": ")", "logprob": -0.153392493724823}, {"text": " False", "logprob": -2.048457384109497}, {"text": "\n", "logprob": -0.04822865501046181}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " None", "logprob": -2.706328868865967}, {"text": " of", "logprob": -0.3012789785861969}, {"text": " the", "logprob": -0.015990471467375755}, {"text": " above", "logprob": -0.23737674951553345}, {"text": "\n", "logprob": -1.0019218921661377}, {"text": "C", "logprob": -6.9141146923357155e-06}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " A", "logprob": -0.1239241361618042}, {"text": " monoc", "logprob": -2.140155553817749}], "answers": ["false"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Administrative regions have (part) windows.' true or false?", "pred": " \n\nAnswer: False.", "completions_tokens": [{"text": " \n\n", "logprob": -0.11805246770381927}, {"text": "Answer", "logprob": -0.0990016832947731}, {"text": ":", "logprob": -0.14940841495990753}, {"text": " False", "logprob": -2.3969624042510986}, {"text": ".", "logprob": -0.03198838606476784}, {"text": "<|eot_id|>", "logprob": -1.4119343757629395}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Many stars have no-discharge regulations in effect.' true or false?", "pred": "_________\nAnswer: FALSE  Next Question >", "completions_tokens": [{"text": "________", "logprob": -8.774497032165527}, {"text": "_\n", "logprob": -1.5973124504089355}, {"text": "Answer", "logprob": -0.01122033316642046}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " FALSE", "logprob": -0.8235476016998291}, {"text": " ", "logprob": -2.3593358993530273}, {"text": " Next", "logprob": -3.645313262939453}, {"text": " Question", "logprob": -0.6866215467453003}, {"text": " >", "logprob": -0.05983635038137436}, {"text": "<|end_of_text|>", "logprob": -1.5597491264343262}], "answers": ["false"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Enzymes aid in all aspects of digestion, including absorption.' true or false?", "pred": " FALSE\nAnswer: FALSE\nMinor changes to enzymes led to wide-ranging biochemical consequences", "completions_tokens": [{"text": " FALSE", "logprob": -4.056605339050293}, {"text": "\n", "logprob": -0.3142133951187134}, {"text": "Answer", "logprob": -0.0038272717501968145}, {"text": ":", "logprob": -0.02826329879462719}, {"text": " FALSE", "logprob": -0.9154273271560669}, {"text": "\n", "logprob": -0.5219067335128784}, {"text": "Minor", "logprob": -9.83584213256836}, {"text": " changes", "logprob": -4.097869873046875}, {"text": " to", "logprob": -1.5029188394546509}, {"text": " enzymes", "logprob": -1.9367083311080933}, {"text": " led", "logprob": -6.636633396148682}, {"text": " to", "logprob": -0.002056390279904008}, {"text": " wide", "logprob": -11.068882942199707}, {"text": "-ranging", "logprob": -1.5262023210525513}, {"text": " biochemical", "logprob": -3.808244466781616}, {"text": " consequences", "logprob": -1.7316224575042725}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Every chemical substance emits a unique spectrum when it absorbs energy.' true or false?", "pred": " \n\nThe final answer is: False.  (in Chemistry, empirical formula gives", "completions_tokens": [{"text": " \n\n", "logprob": -0.3345073461532593}, {"text": "The", "logprob": -6.5536675453186035}, {"text": " final", "logprob": -0.2225627899169922}, {"text": " answer", "logprob": -0.00013779645087197423}, {"text": " is", "logprob": -6.794906312279636e-06}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " False", "logprob": -0.4625762701034546}, {"text": ".", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -1.4569456577301025}, {"text": " (", "logprob": -3.530933380126953}, {"text": "in", "logprob": -6.309200763702393}, {"text": " Chemistry", "logprob": -5.241389751434326}, {"text": ",", "logprob": -0.1668495535850525}, {"text": " empirical", "logprob": -8.488785743713379}, {"text": " formula", "logprob": -0.5635900497436523}, {"text": " gives", "logprob": -2.673407554626465}], "answers": ["true"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'railway stations are locations where dances are held.' true or false?", "pred": " \n\nA) False\n\nB) False in general but could happen in very limited", "completions_tokens": [{"text": " \n\n", "logprob": -0.14773912727832794}, {"text": "A", "logprob": -0.1541118174791336}, {"text": ")", "logprob": -1.1761302947998047}, {"text": " False", "logprob": -2.2663753032684326}, {"text": "\n\n", "logprob": -2.7787110805511475}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.5311263799667358}, {"text": " in", "logprob": -5.119352340698242}, {"text": " general", "logprob": -1.0550059080123901}, {"text": " but", "logprob": -0.3142465651035309}, {"text": " could", "logprob": -3.4033169746398926}, {"text": " happen", "logprob": -2.3258888721466064}, {"text": " in", "logprob": -0.36347854137420654}, {"text": " very", "logprob": -2.708432197570801}, {"text": " limited", "logprob": -3.0761187076568604}], "answers": ["false"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Many bacteria live naturally in our bodies without causing disease.' true or false?", "pred": " \nAnswer: True. 1.6k views\n\n## Step 1", "completions_tokens": [{"text": " \n", "logprob": -4.216622352600098}, {"text": "Answer", "logprob": -0.06869193911552429}, {"text": ":", "logprob": -1.329400897026062}, {"text": " True", "logprob": -0.569780170917511}, {"text": ".", "logprob": -0.036547619849443436}, {"text": " ", "logprob": -1.7861223220825195}, {"text": "1", "logprob": -2.570125102996826}, {"text": ".", "logprob": -0.8219461441040039}, {"text": "6", "logprob": -4.7985334396362305}, {"text": "k", "logprob": -0.8811433911323547}, {"text": " views", "logprob": -0.14714352786540985}, {"text": "\n\n", "logprob": -2.0410304069519043}, {"text": "##", "logprob": -0.00658532464876771}, {"text": " Step", "logprob": -0.00013767725613433868}, {"text": " ", "logprob": -0.00013779645087197423}, {"text": "1", "logprob": -0.00013767725613433868}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Cheese is a viscoelastic material that is able to flow under quite small stresses.' true or false?", "pred": " \n\nAnswer: FALSE.  Visit our question bank for more questions.\nVisit Creative", "completions_tokens": [{"text": " \n\n", "logprob": -0.1335870325565338}, {"text": "Answer", "logprob": -0.7019185423851013}, {"text": ":", "logprob": -0.14513736963272095}, {"text": " FALSE", "logprob": -0.3069407641887665}, {"text": ".", "logprob": -0.10307087749242783}, {"text": " ", "logprob": -0.7732278108596802}, {"text": " Visit", "logprob": -5.713028907775879}, {"text": " our", "logprob": -2.1964011192321777}, {"text": " question", "logprob": -2.0063865184783936}, {"text": " bank", "logprob": -0.003800314385443926}, {"text": " for", "logprob": -6.794906312279636e-06}, {"text": " more", "logprob": -0.00013779645087197423}, {"text": " questions", "logprob": -0.3922436237335205}, {"text": ".\n", "logprob": -0.8409892320632935}, {"text": "Visit", "logprob": -1.0483753681182861}, {"text": " Creative", "logprob": -8.05413818359375}], "answers": ["false"], "all_classes": "null", "length": 24}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Caves contain fragile formations which can easily be destroyed through carelessness or vandalism.' true or false?", "pred": " \n\nAnswer:\n\nTrue.  It is very easy for unique formations within caves to", "completions_tokens": [{"text": " \n\n", "logprob": -0.1619919240474701}, {"text": "Answer", "logprob": -0.6692118644714355}, {"text": ":\n\n", "logprob": -1.7774958610534668}, {"text": "True", "logprob": -1.5745866298675537}, {"text": ".", "logprob": -0.00016544880054425448}, {"text": " ", "logprob": -0.46008822321891785}, {"text": " It", "logprob": -3.1129186153411865}, {"text": " is", "logprob": -1.2061684131622314}, {"text": " very", "logprob": -4.104723930358887}, {"text": " easy", "logprob": -3.752476453781128}, {"text": " for", "logprob": -0.3367565870285034}, {"text": " unique", "logprob": -7.492591381072998}, {"text": " formations", "logprob": -1.235612392425537}, {"text": " within", "logprob": -2.5402050018310547}, {"text": " caves", "logprob": -0.11498060822486877}, {"text": " to", "logprob": -0.687869131565094}], "answers": ["true"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'ski areas provide comfort.' true or false?", "pred": " \nAnswer: \n\nFalse (alternative answer) Not necessarily true. (alternative answer", "completions_tokens": [{"text": " \n", "logprob": -3.780266761779785}, {"text": "Answer", "logprob": -0.02645556442439556}, {"text": ":", "logprob": -0.9176199436187744}, {"text": " \n\n", "logprob": -2.9425530433654785}, {"text": "False", "logprob": -0.22748734056949615}, {"text": " (", "logprob": -1.2628446817398071}, {"text": "alternative", "logprob": -9.036850929260254}, {"text": " answer", "logprob": -1.538608193397522}, {"text": ")", "logprob": -0.5011656284332275}, {"text": " Not", "logprob": -2.549335479736328}, {"text": " necessarily", "logprob": -0.34785225987434387}, {"text": " true", "logprob": -0.18238745629787445}, {"text": ".", "logprob": -0.10324549674987793}, {"text": " (", "logprob": -0.29824647307395935}, {"text": "alternative", "logprob": -0.8454537391662598}, {"text": " answer", "logprob": -0.00019369633810129017}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Astronomical objects have no end in the uncollapsed wavefunction.' true or false?", "pred": " 113\nNo source cited. HBC discussion: This principle has some similarity", "completions_tokens": [{"text": " ", "logprob": -3.7676336765289307}, {"text": "113", "logprob": -6.871108055114746}, {"text": "\n", "logprob": -1.552665114402771}, {"text": "No", "logprob": -8.986126899719238}, {"text": " source", "logprob": -9.274917602539062}, {"text": " cited", "logprob": -2.882343292236328}, {"text": ".", "logprob": -1.3778263330459595}, {"text": " H", "logprob": -9.244888305664062}, {"text": "BC", "logprob": -9.128530502319336}, {"text": " discussion", "logprob": -7.699306964874268}, {"text": ":", "logprob": -1.7006961107254028}, {"text": " This", "logprob": -1.5700733661651611}, {"text": " principle", "logprob": -5.776970386505127}, {"text": " has", "logprob": -1.99290132522583}, {"text": " some", "logprob": -3.511960983276367}, {"text": " similarity", "logprob": -2.2408647537231445}], "answers": ["false"], "all_classes": "null", "length": 19}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Sea is used for sail boats.' true or false?", "pred": " \n\nA) Fishing (involves fish)\nB) Desert (is very", "completions_tokens": [{"text": " \n\n", "logprob": -0.12014250457286835}, {"text": "A", "logprob": -0.8214548826217651}, {"text": ")", "logprob": -0.2705155611038208}, {"text": " Fishing", "logprob": -7.290605068206787}, {"text": " (", "logprob": -5.784778594970703}, {"text": "in", "logprob": -3.051771640777588}, {"text": "vol", "logprob": -1.547865867614746}, {"text": "ves", "logprob": -0.010729363188147545}, {"text": " fish", "logprob": -3.924191951751709}, {"text": ")\n", "logprob": -0.6866258978843689}, {"text": "B", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Desert", "logprob": -7.74431848526001}, {"text": " (", "logprob": -0.12754735350608826}, {"text": "is", "logprob": -1.5862836837768555}, {"text": " very", "logprob": -2.516636848449707}], "answers": ["false"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Ferns are among the most attractive of all foliage plants.' true or false?", "pred": " \n\nA) True\nB) False\nC)  A (whether '", "completions_tokens": [{"text": " \n\n", "logprob": -0.10898730158805847}, {"text": "A", "logprob": -0.2103429138660431}, {"text": ")", "logprob": -0.5105863809585571}, {"text": " True", "logprob": -0.685197114944458}, {"text": "\n", "logprob": -0.3338334560394287}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " False", "logprob": -0.8034525513648987}, {"text": "\n", "logprob": -0.04261455312371254}, {"text": "C", "logprob": -0.008935347199440002}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -3.2381067276000977}, {"text": " A", "logprob": -2.7631924152374268}, {"text": " (", "logprob": -4.181447982788086}, {"text": "whether", "logprob": -7.902159214019775}, {"text": " '", "logprob": -5.06788969039917}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'monoclonal antibodies have the advantage of mobility.' true or false?", "pred": " \n\nAnswer: FALSE.  Everyone of several hundred mechanisms which disinfect the irritating", "completions_tokens": [{"text": " \n\n", "logprob": -0.20564952492713928}, {"text": "Answer", "logprob": -1.297789216041565}, {"text": ":", "logprob": -0.19068482518196106}, {"text": " FALSE", "logprob": -0.2641414403915405}, {"text": ".", "logprob": -0.10546409338712692}, {"text": " ", "logprob": -1.2465097904205322}, {"text": " Everyone", "logprob": -7.94049072265625}, {"text": " of", "logprob": -3.3659462928771973}, {"text": " several", "logprob": -5.703195095062256}, {"text": " hundred", "logprob": -2.051358222961426}, {"text": " mechanisms", "logprob": -8.780778884887695}, {"text": " which", "logprob": -3.687148094177246}, {"text": " disin", "logprob": -13.920431137084961}, {"text": "fect", "logprob": -0.057994745671749115}, {"text": " the", "logprob": -0.9952436089515686}, {"text": " irritating", "logprob": -11.264381408691406}], "answers": ["true"], "all_classes": "null", "length": 17}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Oceans are important structures for human use of fresh water.' true or false?", "pred": " \n\nA. True\nB. False\n\nAnswer: B. False. ", "completions_tokens": [{"text": " \n\n", "logprob": -0.15233193337917328}, {"text": "A", "logprob": -0.38548994064331055}, {"text": ".", "logprob": -2.0257272720336914}, {"text": " True", "logprob": -0.9357010126113892}, {"text": "\n", "logprob": -0.13676466047763824}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -6.9141146923357155e-06}, {"text": " False", "logprob": -0.20543666183948517}, {"text": "\n\n", "logprob": -2.5623056888580322}, {"text": "Answer", "logprob": -0.036550264805555344}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " B", "logprob": -0.0807516947388649}, {"text": ".", "logprob": -0.02502318099141121}, {"text": " False", "logprob": -0.02459896169602871}, {"text": ".", "logprob": -0.460016667842865}, {"text": " ", "logprob": -1.0529898405075073}], "answers": ["true"], "all_classes": "null", "length": 20}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some bays are part of sea.' true or false?", "pred": " \n\nA) True\nB) True (accessing changing contexts meaning of sea", "completions_tokens": [{"text": " \n\n", "logprob": -0.13738226890563965}, {"text": "A", "logprob": -0.29160580039024353}, {"text": ")", "logprob": -0.43223947286605835}, {"text": " True", "logprob": -0.6967966556549072}, {"text": "\n", "logprob": -0.208840012550354}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -3.2783851623535156}, {"text": " (", "logprob": -2.350257396697998}, {"text": "access", "logprob": -11.151777267456055}, {"text": "ing", "logprob": -2.4140560626983643}, {"text": " changing", "logprob": -10.325323104858398}, {"text": " contexts", "logprob": -4.610739707946777}, {"text": " meaning", "logprob": -6.088841438293457}, {"text": " of", "logprob": -1.484885334968567}, {"text": " sea", "logprob": -1.1609281301498413}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'enzymes are arranged linearly along long chains of DNA sequence, called chromosomes .' true or false?", "pred": " \n\nA) True \nB) True \nC)  The entire sequence present", "completions_tokens": [{"text": " \n\n", "logprob": -0.18032175302505493}, {"text": "A", "logprob": -0.023190004751086235}, {"text": ")", "logprob": -0.7072726488113403}, {"text": " True", "logprob": -0.8920691013336182}, {"text": " \n", "logprob": -2.435123920440674}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -1.0046019554138184}, {"text": " \n", "logprob": -0.03790483996272087}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -0.9682765007019043}, {"text": " The", "logprob": -2.5304794311523438}, {"text": " entire", "logprob": -4.365025520324707}, {"text": " sequence", "logprob": -2.707705020904541}, {"text": " present", "logprob": -6.206608772277832}], "answers": ["false"], "all_classes": "null", "length": 23}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'towns have (part) waters.' true or false?", "pred": " \n\nAnswer: True. I made a Noun and Verb agreement-related mistake there", "completions_tokens": [{"text": " \n\n", "logprob": -0.09143251180648804}, {"text": "Answer", "logprob": -0.44913971424102783}, {"text": ":", "logprob": -0.00013767725613433868}, {"text": " True", "logprob": -2.7149791717529297}, {"text": ".", "logprob": -0.0687401294708252}, {"text": " I", "logprob": -5.416050910949707}, {"text": " made", "logprob": -3.2715635299682617}, {"text": " a", "logprob": -0.5568832755088806}, {"text": " N", "logprob": -10.542560577392578}, {"text": "oun", "logprob": -1.7415385246276855}, {"text": " and", "logprob": -3.9600024223327637}, {"text": " Verb", "logprob": -0.46471428871154785}, {"text": " agreement", "logprob": -1.1298954486846924}, {"text": "-related", "logprob": -9.52528190612793}, {"text": " mistake", "logprob": -0.30670875310897827}, {"text": " there", "logprob": -2.8130381107330322}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Horses are a potent symbol from almost every world religion and mythology.' true or false?", "pred": " \n\nA) Horses have been used in various purposes that give rise to their", "completions_tokens": [{"text": " \n\n", "logprob": -0.14458343386650085}, {"text": "A", "logprob": -0.4331449270248413}, {"text": ")", "logprob": -0.6488256454467773}, {"text": " H", "logprob": -2.118267774581909}, {"text": "orses", "logprob": -6.794906312279636e-06}, {"text": " have", "logprob": -1.4768457412719727}, {"text": " been", "logprob": -0.552506148815155}, {"text": " used", "logprob": -1.0886081457138062}, {"text": " in", "logprob": -0.37469348311424255}, {"text": " various", "logprob": -1.0681507587432861}, {"text": " purposes", "logprob": -7.977229118347168}, {"text": " that", "logprob": -4.365421295166016}, {"text": " give", "logprob": -4.715946197509766}, {"text": " rise", "logprob": -0.676371157169342}, {"text": " to", "logprob": -0.002806179691106081}, {"text": " their", "logprob": -3.32606840133667}], "answers": ["false"], "all_classes": "null", "length": 22}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Roads are gravel and can become rough and muddy after rains.' true or false?", "pred": " \n\nA) True B) False C) Some of the attributes in the statement", "completions_tokens": [{"text": " \n\n", "logprob": -0.11804991960525513}, {"text": "A", "logprob": -0.13789190351963043}, {"text": ")", "logprob": -0.28663307428359985}, {"text": " True", "logprob": -0.7619036436080933}, {"text": " B", "logprob": -2.635380744934082}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " False", "logprob": -6.9141146923357155e-06}, {"text": " C", "logprob": -0.5105621218681335}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Some", "logprob": -0.8620604276657104}, {"text": " of", "logprob": -1.5417895317077637}, {"text": " the", "logprob": -0.08656754344701767}, {"text": " attributes", "logprob": -9.788073539733887}, {"text": " in", "logprob": -2.85211443901062}, {"text": " the", "logprob": -0.24676282703876495}, {"text": " statement", "logprob": -0.07143505662679672}], "answers": ["true"], "all_classes": "null", "length": 21}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Skyscrapers have (part) walls.' true or false?", "pred": " \n\nAnswer: True.", "completions_tokens": [{"text": " \n\n", "logprob": -0.12378469109535217}, {"text": "Answer", "logprob": -0.10837104171514511}, {"text": ":", "logprob": -0.15158747136592865}, {"text": " True", "logprob": -0.9066246747970581}, {"text": ".", "logprob": -0.03679802641272545}, {"text": "<|eot_id|>", "logprob": -1.5819053649902344}], "answers": ["true"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'automobile engines are electro-chemical devices.' true or false?", "pred": " \n\nA) True\nB) True with restriction\nC) The question about", "completions_tokens": [{"text": " \n\n", "logprob": -0.26923754811286926}, {"text": "A", "logprob": -1.0842955112457275}, {"text": ")", "logprob": -0.5438144207000732}, {"text": " True", "logprob": -0.7869647741317749}, {"text": "\n", "logprob": -0.48681509494781494}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -2.2769155502319336}, {"text": " with", "logprob": -3.2798495292663574}, {"text": " restriction", "logprob": -4.045711517333984}, {"text": "\n", "logprob": -0.11422735452651978}, {"text": "C", "logprob": -0.00013791563105769455}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " The", "logprob": -4.284564971923828}, {"text": " question", "logprob": -2.27282977104187}, {"text": " about", "logprob": -3.532992124557495}], "answers": ["true"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Asteroids are video games.' true or false?", "pred": " \n\nA. True\nB. True\nC. True\nD. True", "completions_tokens": [{"text": " \n\n", "logprob": -0.10348522663116455}, {"text": "A", "logprob": -0.3777679204940796}, {"text": ".", "logprob": -0.10435519367456436}, {"text": " True", "logprob": -0.5539090633392334}, {"text": "\n", "logprob": -0.06392740458250046}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -6.9141146923357155e-06}, {"text": " True", "logprob": -2.5825722217559814}, {"text": "\n", "logprob": -0.6319521069526672}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -6.794906312279636e-06}, {"text": " True", "logprob": -0.12988737225532532}, {"text": "\n", "logprob": -0.00013755806139670312}, {"text": "D", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -6.9141146923357155e-06}, {"text": " True", "logprob": -3.020085573196411}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'brains fill with blood.' true or false?", "pred": " \n\nA) True\nB) True \nC)  True   \nD)", "completions_tokens": [{"text": " \n\n", "logprob": -0.15357929468154907}, {"text": "A", "logprob": -0.5335207581520081}, {"text": ")", "logprob": -0.09196849912405014}, {"text": " True", "logprob": -0.8599904775619507}, {"text": "\n", "logprob": -0.46444717049598694}, {"text": "B", "logprob": -0.00013767725613433868}, {"text": ")", "logprob": -0.00013791563105769455}, {"text": " True", "logprob": -1.2004480361938477}, {"text": " \n", "logprob": -1.5520023107528687}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -1.5258605480194092}, {"text": " True", "logprob": -2.1801819801330566}, {"text": "   \n", "logprob": -6.307028770446777}, {"text": "D", "logprob": -6.9141146923357155e-06}, {"text": ")", "logprob": -0.00013767725613433868}], "answers": ["false"], "all_classes": "null", "length": 14}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Some muscle organ fills ventricles.' true or false?", "pred": " \n\nA) false B) true C) Some muscles \nD) None of", "completions_tokens": [{"text": " \n\n", "logprob": -0.11108749359846115}, {"text": "A", "logprob": -0.6691312789916992}, {"text": ")", "logprob": -0.2778224050998688}, {"text": " false", "logprob": -1.705772876739502}, {"text": " B", "logprob": -1.6272491216659546}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " true", "logprob": -0.14164727926254272}, {"text": " C", "logprob": -0.2078903317451477}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Some", "logprob": -0.7087764739990234}, {"text": " muscles", "logprob": -1.5266027450561523}, {"text": " \n", "logprob": -5.604590892791748}, {"text": "D", "logprob": -0.012311416678130627}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " None", "logprob": -0.4017997980117798}, {"text": " of", "logprob": -0.098365418612957}], "answers": ["false"], "all_classes": "null", "length": 15}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Most music festivals arise from forces.' true or false?", "pred": " \n\nAnswer:\n\nFalse.  It seems you want us to answer \"forced.\"", "completions_tokens": [{"text": " \n\n", "logprob": -0.09989842772483826}, {"text": "Answer", "logprob": -2.2040798664093018}, {"text": ":\n\n", "logprob": -1.6119030714035034}, {"text": "False", "logprob": -1.6601479053497314}, {"text": ".", "logprob": -0.005621339660137892}, {"text": " ", "logprob": -0.5228974223136902}, {"text": " It", "logprob": -3.075470209121704}, {"text": " seems", "logprob": -2.083097219467163}, {"text": " you", "logprob": -3.3282575607299805}, {"text": " want", "logprob": -1.4986786842346191}, {"text": " us", "logprob": -6.996356010437012}, {"text": " to", "logprob": -6.9141146923357155e-06}, {"text": " answer", "logprob": -1.0758475065231323}, {"text": " \"", "logprob": -2.970306873321533}, {"text": "forced", "logprob": -6.3307647705078125}, {"text": ".\"", "logprob": -0.7007133364677429}], "answers": ["false"], "all_classes": "null", "length": 16}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nIs the statement 'Rivers are an important feature of Kentucky geography.' true or false?", "pred": " \n\nAnswer: True.", "completions_tokens": [{"text": " \n\n", "logprob": -0.21538476645946503}, {"text": "Answer", "logprob": -0.5514810085296631}, {"text": ":", "logprob": -0.15830256044864655}, {"text": " True", "logprob": -0.2672480344772339}, {"text": ".", "logprob": -0.041534554213285446}, {"text": "<|eot_id|>", "logprob": -1.5196518898010254}], "answers": ["true"], "all_classes": "null", "length": 18}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Tutu Chengcui, The Pierre, Waddesdon Manor, Astro Orbitor, Heian period, 2019 Canadian federal election, Paradiski, Tenughat Dam, Gros Michel banana, Reedy Glacier, Gangotri Glacier, Pinatubo, Interwar period, djon djon, Qiu Shiliang, Caciotta, Firth of Forth, 2011 Rugby World Cup, Cheng Yuanzhen, Pliocene, Sri Maha Bodhi, which one is the most conceptually similar with Botryosphaeria stevensii?", "pred": " \n\nAnswer: Caciotta. \n\nThankyou. \nPlease give answer to", "completions_tokens": [{"text": " \n\n", "logprob": -0.05109625682234764}, {"text": "Answer", "logprob": -0.36144205927848816}, {"text": ":", "logprob": -0.41823291778564453}, {"text": " C", "logprob": -2.2094273567199707}, {"text": "aci", "logprob": -0.00013779645087197423}, {"text": "otta", "logprob": -0.00013779645087197423}, {"text": ".", "logprob": -0.46864956617355347}, {"text": " \n\n", "logprob": -3.626450538635254}, {"text": "Thank", "logprob": -3.685213565826416}, {"text": "you", "logprob": -2.620520830154419}, {"text": ".", "logprob": -0.9504619836807251}, {"text": " \n", "logprob": -1.1892372369766235}, {"text": "Please", "logprob": -1.1927289962768555}, {"text": " give", "logprob": -0.06831780821084976}, {"text": " answer", "logprob": -0.7201209664344788}, {"text": " to", "logprob": -0.00013767725613433868}], "answers": ["djon djon"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong UEFA Euro 2004, potassium hydroxide, Queen Elizabeth Olympic Park, Nena, Rainbow Bar and Grill, Cleveland Clinic, poly(methyl methacrylate), Cilician Gates, Akbar Shah, CR2025, wagasi, lateral rotator group, Dorsal digital arteries of hand, Ruhleben internment camp, Europe, Small Magellanic Cloud, sodium carbonate, 60558 Echeclus, Llangorse Lake, Estrogen, Steinmetz Pink Diamond, which one is the most conceptually similar with fluoxetine?", "pred": " \n\nAnswer:\n\nsodium carbonate, DO not know the chemical formula or chemical nature", "completions_tokens": [{"text": " \n\n", "logprob": -0.05142582207918167}, {"text": "Answer", "logprob": -0.09287678450345993}, {"text": ":\n\n", "logprob": -1.8035047054290771}, {"text": "s", "logprob": -0.7804502248764038}, {"text": "odium", "logprob": -0.00013779645087197423}, {"text": " carbonate", "logprob": -6.794906312279636e-06}, {"text": ",", "logprob": -0.7771681547164917}, {"text": " DO", "logprob": -13.035660743713379}, {"text": " not", "logprob": -1.1775997877120972}, {"text": " know", "logprob": -1.561984658241272}, {"text": " the", "logprob": -1.948399305343628}, {"text": " chemical", "logprob": -1.3881959915161133}, {"text": " formula", "logprob": -1.7941628694534302}, {"text": " or", "logprob": -1.4905965328216553}, {"text": " chemical", "logprob": -1.5901765823364258}, {"text": " nature", "logprob": -4.852039337158203}], "answers": ["Estrogen"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Makemake, 2004 United States presidential election, San Gorgonio Pass, Penstrowed, Criollo cheese, Lactoperoxidase, solar eclipse of August 7, 1812, Canning Tunnel, Haunted Mansion Holiday, Egg hunt, Caciotta, Campanian, Gros Michel banana, Kveik, venous angle, Joint Mathematics Meetings, Plesetsk Cosmodrome Site 132, STS-122, Apollo 7, Miocene, Beech bark disease, which one is the most conceptually similar with Barnby Broad and Marshes?", "pred": " \n\nAnswer: Canning Tunnel. Conception of Canning Tunnel as well as", "completions_tokens": [{"text": " \n\n", "logprob": -0.04969887435436249}, {"text": "Answer", "logprob": -0.28600987792015076}, {"text": ":", "logprob": -0.79124915599823}, {"text": " C", "logprob": -1.5202577114105225}, {"text": "anning", "logprob": -0.17642374336719513}, {"text": " Tunnel", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -0.19357791543006897}, {"text": " Con", "logprob": -7.681931018829346}, {"text": "ception", "logprob": -1.2070212364196777}, {"text": " of", "logprob": -0.8812737464904785}, {"text": " C", "logprob": -1.0950002670288086}, {"text": "anning", "logprob": -6.9141146923357155e-06}, {"text": " Tunnel", "logprob": -0.047666650265455246}, {"text": " as", "logprob": -3.0165462493896484}, {"text": " well", "logprob": -6.162842750549316}, {"text": " as", "logprob": -6.794906312279636e-06}], "answers": ["Penstrowed"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Charles Bridge, French and Indian War, Elephanta Caves, Paris Commune, South China Sea, Dinefwr Park National Nature Reserve, Dresden Green Diamond, Greek fire, Clochette, The French Laundry, Egyptian cheese, Gatchina Palace, Allium ursinum, Agnes Edwards (craftworker), 2010 Commonwealth Games, Crush (soft drink), QF 3 pounder Hotchkiss, Poston War Relocation Center, valproic acid, Blue Serpent Clock, Palmar plate, which one is the most conceptually similar with Pont Neuf?", "pred": " \n\nAnswer: Pont Neuf. Note to Answerer: Pont Neuf (", "completions_tokens": [{"text": " \n\n", "logprob": -0.13735899329185486}, {"text": "Answer", "logprob": -0.2871869206428528}, {"text": ":", "logprob": -0.48027706146240234}, {"text": " Pont", "logprob": -0.3149338662624359}, {"text": " Ne", "logprob": -0.00013767725613433868}, {"text": "uf", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -0.5396854877471924}, {"text": " Note", "logprob": -3.0490975379943848}, {"text": " to", "logprob": -3.1497092247009277}, {"text": " Answer", "logprob": -4.895290374755859}, {"text": "er", "logprob": -0.2042594701051712}, {"text": ":", "logprob": -0.15456132590770721}, {"text": " Pont", "logprob": -0.9256901741027832}, {"text": " Ne", "logprob": -6.794906312279636e-06}, {"text": "uf", "logprob": -6.794906312279636e-06}, {"text": " (", "logprob": -2.3922204971313477}], "answers": ["Charles Bridge"], "all_classes": "null", "length": 96}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong mucin, Golden Gate Park, spiral artery, Edwards Air Force Base, PSR B1620-26 b, International Conference on Computer Vision, TUC338, sarin, Mechanistic target of rapamycin kinase, Nepenthes edwardsiana, Syon Park House, cyclosporine, Cannabinoid receptor 2, Lake of the Woods, Ferulic acid decarboxylase, Idursulfase, New Orleans Jazz & Heritage Festival, Soo Locks, Morocco, Cambrian Mountains, solar eclipse of July 22, 2028, which one is the most conceptually similar with gal operon?", "pred": " Gal operon\n\nSpiral artery my flair pretty gul respondent processes sp Binding", "completions_tokens": [{"text": " Gal", "logprob": -2.8604748249053955}, {"text": " oper", "logprob": -0.007962745614349842}, {"text": "on", "logprob": -0.00013767725613433868}, {"text": "\n\n", "logprob": -2.4254541397094727}, {"text": "S", "logprob": -1.4878162145614624}, {"text": "pir", "logprob": -0.16467301547527313}, {"text": "al", "logprob": -0.00013779645087197423}, {"text": " artery", "logprob": -0.3724149465560913}, {"text": " my", "logprob": -9.733064651489258}, {"text": " flair", "logprob": -12.004663467407227}, {"text": " pretty", "logprob": -7.344204902648926}, {"text": " gul", "logprob": -12.790191650390625}, {"text": " respondent", "logprob": -10.566922187805176}, {"text": " processes", "logprob": -12.632612228393555}, {"text": " sp", "logprob": -7.581517219543457}, {"text": " Binding", "logprob": -11.284147262573242}], "answers": ["TUC338"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Mall of America, adenosine diphosphate, Trawniki concentration camp, Ignalina Nuclear Power Plant, Ford Windsor engine, Lake Winnipeg, Bronx Zoo, Gliese 581g, Three Mile Island Nuclear Generating Station, 8.8 cm SK L/30 naval gun, Katiki Domokou, Australia, Battle of Chancellorsville, daf-5, Pontiac V8 engine, BMW M54, The Four Seasons Restaurant, Travelodge, Crawford Notch, CR2032 battery, Buick V8 engine, which one is the most conceptually similar with M61 Vulcan?", "pred": " \n\nAnswer: Pontiac V8 engine Hampton, NY, adenosine d", "completions_tokens": [{"text": " \n\n", "logprob": -0.206452876329422}, {"text": "Answer", "logprob": -0.13828159868717194}, {"text": ":", "logprob": -1.5498462915420532}, {"text": " Pont", "logprob": -1.0033581256866455}, {"text": "iac", "logprob": -6.794906312279636e-06}, {"text": " V", "logprob": -6.794906312279636e-06}, {"text": "8", "logprob": -0.00013767725613433868}, {"text": " engine", "logprob": -6.794906312279636e-06}, {"text": " Hampton", "logprob": -8.777629852294922}, {"text": ",", "logprob": -2.7948503494262695}, {"text": " NY", "logprob": -4.2763824462890625}, {"text": ",", "logprob": -4.459087371826172}, {"text": " ad", "logprob": -5.256826400756836}, {"text": "enos", "logprob": -0.00013779645087197423}, {"text": "ine", "logprob": -6.794906312279636e-06}, {"text": " d", "logprob": -0.021039282903075218}], "answers": ["8.8 cm SK L/30 naval gun"], "all_classes": "null", "length": 96}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Wivenhoe, cannabinoid receptor 1, Dancing on Ice, Carew Castle, Clochette, DNA-binding domain, Zojila Pass, Americas, Newgate Prison, Botryosphaeria stevensii, 1960 Democratic National Convention, Interleukin 2, Kakadu National Park, Brain derived neurotrophic factor, PTS-GFL superfamily, common facial vein, Seven Years War, Epidermal growth factor, San Francisco International Film Festival, chilihueque, Inca Kola, which one is the most conceptually similar with Hirudin?", "pred": " \n\nAnswer: PTS-GFL superfamily (PTG) similarity: Hirud", "completions_tokens": [{"text": " \n\n", "logprob": -0.14843446016311646}, {"text": "Answer", "logprob": -0.46188968420028687}, {"text": ":", "logprob": -0.3580925464630127}, {"text": " PTS", "logprob": -0.6491082310676575}, {"text": "-G", "logprob": -6.794906312279636e-06}, {"text": "FL", "logprob": -0.00013767725613433868}, {"text": " super", "logprob": -0.007489460054785013}, {"text": "family", "logprob": -0.00013767725613433868}, {"text": " (", "logprob": -1.2353214025497437}, {"text": "PT", "logprob": -4.200282096862793}, {"text": "G", "logprob": -1.39713454246521}, {"text": ")", "logprob": -0.8153188228607178}, {"text": " similarity", "logprob": -2.5692296028137207}, {"text": ":", "logprob": -0.9036237001419067}, {"text": " Hir", "logprob": -0.14532366394996643}, {"text": "ud", "logprob": -0.00569388410076499}], "answers": ["PTS-GFL superfamily"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 101955 Bennu, Holin superfamily VII, Corrugator cutis ani muscle, Second Sino-Japanese War, Winter Hill transmitting station, parasphenoid, Irish Rebellion of 1641, Reflex inguinal ligament, Battle of Trafalgar, Trivial Pursuit, tetrahydrofuran, Port Jackson, Griffith Park, 2019 Rugby World Cup, Al Hidayah, Epsilon Eridani, chitin, Renju, Autopia, KNM ER 1805, 1734 British general election, which one is the most conceptually similar with Submarine Voyage?", "pred": "____________________________________________________________________________________\n\nSimilarity: Submarine Voyage is similar with   Autopia", "completions_tokens": [{"text": "________________________________________________________________", "logprob": -11.974750518798828}, {"text": "________________", "logprob": -1.1500065326690674}, {"text": "____", "logprob": -0.53548264503479}, {"text": "\n\n", "logprob": -1.2734529972076416}, {"text": "Similar", "logprob": -2.2594375610351562}, {"text": "ity", "logprob": -0.18121561408042908}, {"text": ":", "logprob": -0.2665095329284668}, {"text": " Sub", "logprob": -1.8759729862213135}, {"text": "marine", "logprob": -6.794906312279636e-06}, {"text": " Voyage", "logprob": -6.794906312279636e-06}, {"text": " is", "logprob": -1.4148073196411133}, {"text": " similar", "logprob": -0.8205785751342773}, {"text": " with", "logprob": -1.26515793800354}, {"text": "  ", "logprob": -3.820756435394287}, {"text": " Aut", "logprob": -0.959614634513855}, {"text": "opia", "logprob": -0.00013791563105769455}], "answers": ["Autopia"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Iaido, Compound engine, Canary Islands, Renju, Star of Bethlehem, Grosvenor House Hotel, Cape Canaveral Air Force Station Launch Complex 6, London Zoo, Tehran Conference, Sonoma Valley AVA, Independence Day, Nepenthes aristolochioides, Petronas Towers, New Guinea, Sinnemahoning Creek, Barabar Caves, 2008 Democratic National Convention, Somerset Dam, Agnes Edwards (craftworker), Standedge Tunnels, Rock Creek Park, which one is the most conceptually similar with Campanian?", "pred": " \n\nAnswer:\n\nCampanian is a geological age of the Cretaceous period", "completions_tokens": [{"text": " \n\n", "logprob": -0.4331253170967102}, {"text": "Answer", "logprob": -0.21344539523124695}, {"text": ":\n\n", "logprob": -0.34874725341796875}, {"text": "Cam", "logprob": -0.12097222357988358}, {"text": "pan", "logprob": -6.794906312279636e-06}, {"text": "ian", "logprob": -0.12905003130435944}, {"text": " is", "logprob": -0.3795843720436096}, {"text": " a", "logprob": -0.33276602625846863}, {"text": " geological", "logprob": -0.31889432668685913}, {"text": " age", "logprob": -3.43267560005188}, {"text": " of", "logprob": -2.436645269393921}, {"text": " the", "logprob": -0.1883695423603058}, {"text": " C", "logprob": -1.0873900651931763}, {"text": "ret", "logprob": -6.794906312279636e-06}, {"text": "aceous", "logprob": -0.00013791563105769455}, {"text": " period", "logprob": -0.25553908944129944}], "answers": ["Independence Day"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Formula 5000, Late Cretaceous, Ure2, Holin superfamily II, djon djon, Ebensee concentration camp, Extrinsic extensor muscles of the hand, Ourasphaira giraldae, Ponticulus, Delaware Aqueduct, Baghdad Central Prison, Table Mountain, Fukushima Daiichi Nuclear Power Plant, Fifth Avenue, Comiket, solar eclipse of August 9, 1896, Coors Light, 1954 FIFA World Cup, Guadalcanal Campaign, Bart the Bear 2, Sex determining region Y, which one is the most conceptually similar with Interstate 5 in California?", "pred": " \n\nAnswer:\n\nDelaware Aqueduct Similarity: Delaware Aqueduct Interstate 5", "completions_tokens": [{"text": " \n\n", "logprob": -0.12220855802297592}, {"text": "Answer", "logprob": -0.2832963764667511}, {"text": ":\n\n", "logprob": -0.5361742973327637}, {"text": "Del", "logprob": -1.1367952823638916}, {"text": "aware", "logprob": -6.794906312279636e-06}, {"text": " Aqu", "logprob": -6.794906312279636e-06}, {"text": "educt", "logprob": -0.00013779645087197423}, {"text": " Similar", "logprob": -3.3524057865142822}, {"text": "ity", "logprob": -0.13864248991012573}, {"text": ":", "logprob": -0.3167877495288849}, {"text": " Delaware", "logprob": -1.2332797050476074}, {"text": " Aqu", "logprob": -0.004709936212748289}, {"text": "educt", "logprob": -6.794906312279636e-06}, {"text": " Interstate", "logprob": -0.6320211887359619}, {"text": " ", "logprob": -0.11782986670732498}, {"text": "5", "logprob": -6.9141146923357155e-06}], "answers": ["Fifth Avenue"], "all_classes": "null", "length": 97}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong entitlement, Caciotta, Pinconning cheese, Raghunathpur Thermal Power Station, Severn Valley Railway, Sagittarius Dwarf Elliptical Galaxy, Battle of the Somme, Cloth Hall, Ypres, Criollo cheese, Xynotyro, 2015 Rugby World Cup, Arc de Triomphe, Lambert Glacier, Kasat Suek Intersection, Palmar plate, Nabulsi cheese, Arlington Memorial Bridge, Hungerford Bridge and Golden Jubilee Bridges, dilator naris muscle, Sonoma County wine, Johnston Atoll, which one is the most conceptually similar with Perrier?", "pred": " \n\nAnswer: Sonoma County wine.  Rational: The most similar analogy between", "completions_tokens": [{"text": " \n\n", "logprob": -0.13080863654613495}, {"text": "Answer", "logprob": -0.20136012136936188}, {"text": ":", "logprob": -0.5693246126174927}, {"text": " Son", "logprob": -2.0376710891723633}, {"text": "oma", "logprob": -0.00013767725613433868}, {"text": " County", "logprob": -6.794906312279636e-06}, {"text": " wine", "logprob": -6.9141146923357155e-06}, {"text": ".", "logprob": -0.14058879017829895}, {"text": " ", "logprob": -2.601198434829712}, {"text": " Rational", "logprob": -9.35168170928955}, {"text": ":", "logprob": -0.2510095238685608}, {"text": " The", "logprob": -4.905388832092285}, {"text": " most", "logprob": -2.8822989463806152}, {"text": " similar", "logprob": -1.5278713703155518}, {"text": " analogy", "logprob": -8.983037948608398}, {"text": " between", "logprob": -1.3050440549850464}], "answers": ["Sonoma County wine"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Accessory soleus muscle, Nalanda, Wine auction, 1964 Alaska earthquake, 2009 World Championships in Athletics, Warhammer Fantasy Battle, Savoy wine, Kveik, Standedge Tunnels, Botryosphaeria stevensii, 2010 Commonwealth Games, Almaz, Oak Hill Country Club, late Middle Ages, Mobile Bay, Rolls-Royce Meteor, Frankfurt City Tunnel, The Pierre, 2002 European Athletics Championships, Eurovision Song Contest 2008, 1983 United Kingdom general election, which one is the most conceptually similar with Woodstock Festival?", "pred": " \n\nAnswer: Woodstock Festival. Similarity: 1964 Alaska earthquake.", "completions_tokens": [{"text": " \n\n", "logprob": -0.1567707657814026}, {"text": "Answer", "logprob": -0.13653267920017242}, {"text": ":", "logprob": -0.6549597382545471}, {"text": " Wood", "logprob": -1.0875800848007202}, {"text": "stock", "logprob": -0.00013767725613433868}, {"text": " Festival", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -7.019700050354004}, {"text": " Similar", "logprob": -1.9134989976882935}, {"text": "ity", "logprob": -0.1479434370994568}, {"text": ":", "logprob": -0.29329004883766174}, {"text": " ", "logprob": -3.9590296745300293}, {"text": "196", "logprob": -0.35076814889907837}, {"text": "4", "logprob": -0.36762920022010803}, {"text": " Alaska", "logprob": -0.2773919701576233}, {"text": " earthquake", "logprob": -6.9141146923357155e-06}, {"text": ".", "logprob": -0.307907372713089}], "answers": ["Eurovision Song Contest 2008"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1989 Loma Prieta earthquake, Asilomar Conference on Recombinant DNA, Nissan SR engine, Quebec Conference, KNM WT 17000, 1990 FIFA World Cup, Maurandya, Caciotta, Red Sea, 2016 Kumamoto earthquakes, Battle of Waterloo, 2001 United Kingdom general election, Coachella Valley Music and Arts Festival, Riviera Country Club, WASP-43b, TM 1517, table football, The Shard, solar eclipse of June 13, 2132, Oranienburg concentration camp, County Cricket Ground, Northampton, which one is the most conceptually similar with Gliese 436 b?", "pred": " \n\nAnswer: Gliese 436 b (exoplanet) => Table Football", "completions_tokens": [{"text": " \n\n", "logprob": -0.11281020939350128}, {"text": "Answer", "logprob": -0.21153603494167328}, {"text": ":", "logprob": -0.00013767725613433868}, {"text": " Gl", "logprob": -0.4439283609390259}, {"text": "iese", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -6.794906312279636e-06}, {"text": "436", "logprob": -6.794906312279636e-06}, {"text": " b", "logprob": -0.029990727081894875}, {"text": " (", "logprob": -1.5543407201766968}, {"text": "ex", "logprob": -1.4617321491241455}, {"text": "oplan", "logprob": -6.794906312279636e-06}, {"text": "et", "logprob": -0.1827159970998764}, {"text": ")", "logprob": -0.8469579219818115}, {"text": " =>", "logprob": -5.585497856140137}, {"text": " Table", "logprob": -4.153870105743408}, {"text": " Football", "logprob": -0.2387133687734604}], "answers": ["WASP-43b"], "all_classes": "null", "length": 102}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong University of Tennessee, Knoxville, HM Prison Holloway, 2013 AFL season, Philadelphia, Chevrolet big-block engine, Ludlow Castle, Kudankulam Nuclear Power Plant, 1983 World Championships in Athletics, Avalonia, Golden Horn, Makemake, Football Park, Gulf of Thailand, Congress of Monastir, Hampstead Heath, NGC 6946, Royal Porthcawl Golf Club, Virginia Tech, The Timekeeper, St Martin-in-the-Fields, malleolus, which one is the most conceptually similar with 1978 FIFA World Cup?", "pred": " \n\nANSWER: St Martin-in-the-Fields. Silly! It appears", "completions_tokens": [{"text": " \n\n", "logprob": -0.1284557729959488}, {"text": "ANS", "logprob": -2.8507277965545654}, {"text": "WER", "logprob": -6.9141146923357155e-06}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " St", "logprob": -2.9894020557403564}, {"text": " Martin", "logprob": -0.6089084148406982}, {"text": "-in", "logprob": -6.794906312279636e-06}, {"text": "-the", "logprob": -0.00013779645087197423}, {"text": "-", "logprob": -0.00013779645087197423}, {"text": "Fields", "logprob": -0.00013779645087197423}, {"text": ".", "logprob": -0.6633471846580505}, {"text": " Sil", "logprob": -7.901153564453125}, {"text": "ly", "logprob": -0.0859953984618187}, {"text": "!", "logprob": -3.262720823287964}, {"text": " It", "logprob": -1.6946948766708374}, {"text": " appears", "logprob": -6.163968086242676}], "answers": ["2013 AFL season"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Dutch elm disease, nopal, Rawicz, ethylene, Hadim Ali Pasha, Rhinogydd, Zhang Chengye, Petavius, David, Battle of Gettysburg, Ourasphaira giraldae, Mersey Tunnels, Warped Tour, Holin superfamily IV, plantar Lisfranc ligament, Kensington, Damavand, Tokyo Skytree, Royal Botanic Gardens Victoria, Nepenthes edwardsiana, Nepenthes lowii, which one is the most conceptually similar with Phytophthora ramorum?", "pred": " \n\nAnswer: Rhinogydd. - Read more\nNepenthes", "completions_tokens": [{"text": " \n\n", "logprob": -0.03499358147382736}, {"text": "Answer", "logprob": -0.09528549015522003}, {"text": ":", "logprob": -0.33971184492111206}, {"text": " Rh", "logprob": -2.8104751110076904}, {"text": "in", "logprob": -0.177573561668396}, {"text": "ogy", "logprob": -0.00013767725613433868}, {"text": "dd", "logprob": -0.00013779645087197423}, {"text": ".", "logprob": -0.07075712084770203}, {"text": " -", "logprob": -3.894489288330078}, {"text": " Read", "logprob": -4.0167083740234375}, {"text": " more", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -0.00013779645087197423}, {"text": "N", "logprob": -3.629917621612549}, {"text": "ep", "logprob": -0.3085312843322754}, {"text": "ent", "logprob": -0.005363716743886471}, {"text": "hes", "logprob": -0.00013779645087197423}], "answers": ["Ourasphaira giraldae"], "all_classes": "null", "length": 76}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong strychnine, Karla Caves, Gin rummy, Pawan Gupta, Goyet Caves, Circular error probable, Main Southern railway line, Vancouver International Film Festival, Savoy wine, 2001 Nisqually earthquake, Rhymney River, Battle of Stalingrad, World Forestry Congress, Arctic National Wildlife Refuge, Fort Tejon, Great Northern War, Shackleton Glacier, Sun Yat-sen Memorial Hall, anterolateral ligament, Nabulsi cheese, Super Bowl 50, which one is the most conceptually similar with 2009 World Aquatics Championships?", "pred": " \n\nAnswer:\n\nGin rummy. (nerdist), \"When I", "completions_tokens": [{"text": " \n\n", "logprob": -0.04998694360256195}, {"text": "Answer", "logprob": -0.398402601480484}, {"text": ":\n\n", "logprob": -1.0032556056976318}, {"text": "G", "logprob": -0.5838963985443115}, {"text": "in", "logprob": -0.02999095991253853}, {"text": " r", "logprob": -0.010730070993304253}, {"text": "ummy", "logprob": -6.9141146923357155e-06}, {"text": ".", "logprob": -0.2308959811925888}, {"text": " (", "logprob": -1.1538320779800415}, {"text": "ner", "logprob": -12.179915428161621}, {"text": "dist", "logprob": -4.889075756072998}, {"text": ")", "logprob": -0.7627041935920715}, {"text": ",", "logprob": -3.3517649173736572}, {"text": " \"", "logprob": -5.310413837432861}, {"text": "When", "logprob": -5.125877857208252}, {"text": " I", "logprob": -1.8379120826721191}], "answers": ["Super Bowl 50"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Eurovision Song Contest 2004, fluoxetine, Phytophthora ramorum, PSMB8, Ludgate Circus, Palmar plate, UEFA Euro 2000, Midland Main Line, glochidium, Hotel del Coronado, Bucheron, Rock and Roll Hall of Fame, Quabbin Aqueduct, New York Film Festival, Korean War, Invasion of Poland, Telluride Film Festival, Marshalsea, dilator naris muscle, Siege of Vicksburg, Irish Rebellion of 1641, which one is the most conceptually similar with Newark Airport Interchange?", "pred": " The answer is: PSMB8. Hope this does the trick! --- An", "completions_tokens": [{"text": " The", "logprob": -5.116804122924805}, {"text": " answer", "logprob": -0.8492768406867981}, {"text": " is", "logprob": -0.00013779645087197423}, {"text": ":", "logprob": -1.053511142730713}, {"text": " PS", "logprob": -3.313934087753296}, {"text": "MB", "logprob": -6.794906312279636e-06}, {"text": "8", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -0.08662865310907364}, {"text": " Hope", "logprob": -5.379252910614014}, {"text": " this", "logprob": -0.9004378318786621}, {"text": " does", "logprob": -3.838014841079712}, {"text": " the", "logprob": -3.8598201274871826}, {"text": " trick", "logprob": -0.06557292491197586}, {"text": "!", "logprob": -0.4744279980659485}, {"text": " ---", "logprob": -5.730900764465332}, {"text": " An", "logprob": -5.525849342346191}], "answers": ["Ludgate Circus"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Botryosphaeria stevensii, Diplodia mutila, Palms Casino Resort, Bahia Emerald, Brisbane Showgrounds, Nike Missile Site C47, County Cricket Ground, Chelmsford, Russian roulette, The Great Movie Ride, Gatchina Palace, Yugoslav Wars, Mount Everest, San Diego, Loch Lomond, stigmatomycosis, Royal Oak, Salton Sea, Bangladesh Liberation War, Mount Washington, Farakka Super Thermal Power Station, garlic salt, which one is the most conceptually similar with Liu Jishu?", "pred": " \n\nAnswer: stigmatomycosis (or Botryosphaeria ste", "completions_tokens": [{"text": " \n\n", "logprob": -0.3685971200466156}, {"text": "Answer", "logprob": -0.11941259354352951}, {"text": ":", "logprob": -0.00013767725613433868}, {"text": " st", "logprob": -1.749373435974121}, {"text": "igmat", "logprob": -0.00013791563105769455}, {"text": "om", "logprob": -6.794906312279636e-06}, {"text": "yc", "logprob": -6.794906312279636e-06}, {"text": "osis", "logprob": -0.00013779645087197423}, {"text": " (", "logprob": -1.6153875589370728}, {"text": "or", "logprob": -5.13619327545166}, {"text": " Bot", "logprob": -3.8183093070983887}, {"text": "ry", "logprob": -6.9141146923357155e-06}, {"text": "os", "logprob": -0.00013779645087197423}, {"text": "pha", "logprob": -6.794906312279636e-06}, {"text": "eria", "logprob": -0.00013791563105769455}, {"text": " ste", "logprob": -0.00013767725613433868}], "answers": ["Gatchina Palace"], "all_classes": "null", "length": 88}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong anterolateral ligament, Tangsudo, Princeton, Busan International Film Festival, Armstrong Gun, Moliterno, 2011 Rugby World Cup, False Creek, 2000 Rugby League World Cup, Sumner Tunnel, Trans-Siberian railway, Rummy, Oakland, Banked turn, Produce 101, Electronic Entertainment Expo, Charter Oak, Johnston Atoll, Shoot boxing, STS-74, Oswald Poche, which one is the most conceptually similar with Pawan Gupta?", "pred": " \n\nStep 1:  First, let's list down the entities mentioned in", "completions_tokens": [{"text": " \n\n", "logprob": -0.15604224801063538}, {"text": "Step", "logprob": -0.9641371965408325}, {"text": " ", "logprob": -6.794906312279636e-06}, {"text": "1", "logprob": -0.00013779645087197423}, {"text": ":", "logprob": -0.00013767725613433868}, {"text": " ", "logprob": -1.2862311601638794}, {"text": " First", "logprob": -0.9948402643203735}, {"text": ",", "logprob": -0.00013755806139670312}, {"text": " let", "logprob": -0.7266656756401062}, {"text": "'s", "logprob": -0.00013779645087197423}, {"text": " list", "logprob": -1.7288297414779663}, {"text": " down", "logprob": -0.9874894618988037}, {"text": " the", "logprob": -0.08981595188379288}, {"text": " entities", "logprob": -0.20725606381893158}, {"text": " mentioned", "logprob": -1.696094274520874}, {"text": " in", "logprob": -0.6574325561523438}], "answers": ["Oswald Poche"], "all_classes": "null", "length": 79}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Vallnord, Hirudin, M6 motorway, Dancing on Ice, Landsberg Prison, Brain derived neurotrophic factor, Fulton Street Line, MT-RNR1, 5-HTTLPR, solar eclipse of March 20, 2015, Holin superfamily IV, anterolateral ligament, BM-21 Grad, Three Mile Island Nuclear Generating Station, epitrochleoanconeus muscle, Apollo 13, Rockefeller Center, Ferulic acid decarboxylase, Haumea, Draco, CR2032 battery, which one is the most conceptually similar with Elastin?", "pred": " \n\nAnswer:\n\n8 (BM-21 Grad, but in a little specifics -", "completions_tokens": [{"text": " \n\n", "logprob": -0.08753393590450287}, {"text": "Answer", "logprob": -0.2531549334526062}, {"text": ":\n\n", "logprob": -0.5426820516586304}, {"text": "8", "logprob": -7.801583766937256}, {"text": " (", "logprob": -3.9147348403930664}, {"text": "BM", "logprob": -1.2540276050567627}, {"text": "-", "logprob": -0.00013767725613433868}, {"text": "21", "logprob": -0.00013779645087197423}, {"text": " Grad", "logprob": -6.794906312279636e-06}, {"text": ",", "logprob": -1.6761322021484375}, {"text": " but", "logprob": -2.204566717147827}, {"text": " in", "logprob": -6.239996910095215}, {"text": " a", "logprob": -1.9431085586547852}, {"text": " little", "logprob": -4.759576320648193}, {"text": " specifics", "logprob": -10.0596284866333}, {"text": " -", "logprob": -2.246896743774414}], "answers": ["Brain derived neurotrophic factor"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Interleukin 1 beta, Cdc14, Mobile Bay, Apollo, Ultra Music Festival, Wye Valley, Aponeurosis of the Obliquus externus abdominis, Cotswolds, Pluto, Doubletime, XIST, Battle of Fredericksburg, Holin superfamily I, Rock Creek Park, United States Naval Academy, Egg hunt, daf-5, Southwestern Exposition and Livestock Show, police auction, Australia, superficial veins of the brain, which one is the most conceptually similar with C-reactive protein?", "pred": " Answer:\n Doubletime Answer: C-reactive protein is a protein that is used", "completions_tokens": [{"text": " Answer", "logprob": -4.506824016571045}, {"text": ":\n", "logprob": -0.3626750111579895}, {"text": " Double", "logprob": -4.665905952453613}, {"text": "time", "logprob": -0.00013779645087197423}, {"text": " Answer", "logprob": -2.440220355987549}, {"text": ":", "logprob": -0.06758694350719452}, {"text": " C", "logprob": -1.4480730295181274}, {"text": "-react", "logprob": -0.26983442902565}, {"text": "ive", "logprob": -0.00013779645087197423}, {"text": " protein", "logprob": -0.00013767725613433868}, {"text": " is", "logprob": -0.23679836094379425}, {"text": " a", "logprob": -1.6044816970825195}, {"text": " protein", "logprob": -0.22392183542251587}, {"text": " that", "logprob": -0.36354416608810425}, {"text": " is", "logprob": -0.3744049370288849}, {"text": " used", "logprob": -2.836125135421753}], "answers": ["Interleukin 1 beta"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong American Revolutionary War, Kinzua Dam, 2017 Central Mexico earthquake, Kenorland, East Branch Fishing Creek, Coen Tunnel, East Gondwana, Woolworth Building, WonderCon, Battle of Britain, TCA Ground, myrrh, Topaz War Relocation Center, TRAPPIST-1h, St Kilda Junction, Almaz, Stockton and Darlington Railway, Bodie, Tihar Jail, Jawaharlal Nehru Stadium, Syrian Civil War, which one is the most conceptually similar with 2008 Republican National Convention?", "pred": " \n\nAnswer:\n\n2008 Republican National Convention East Branch Fishing Creek ___ Bodie ", "completions_tokens": [{"text": " \n\n", "logprob": -0.13003475964069366}, {"text": "Answer", "logprob": -0.37037384510040283}, {"text": ":\n\n", "logprob": -0.7998254299163818}, {"text": "200", "logprob": -1.36503267288208}, {"text": "8", "logprob": -6.794906312279636e-06}, {"text": " Republican", "logprob": -0.009520367719233036}, {"text": " National", "logprob": -0.00013779645087197423}, {"text": " Convention", "logprob": -6.794906312279636e-06}, {"text": " East", "logprob": -5.838830947875977}, {"text": " Branch", "logprob": -0.06257595121860504}, {"text": " Fishing", "logprob": -0.00013779645087197423}, {"text": " Creek", "logprob": -0.00013767725613433868}, {"text": " ___", "logprob": -14.341917037963867}, {"text": " Bod", "logprob": -3.3388123512268066}, {"text": "ie", "logprob": -6.794906312279636e-06}, {"text": " ", "logprob": -1.9813156127929688}], "answers": ["WonderCon"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong KNM ER 3733, sodium hydroxide, Tane Mahuta, Manuka Oval, Root rot, Taylor-Burton Diamond, Kazanjian Red Diamond, Prometheus, Tehran Conference, Antlia Dwarf, Peninj Mandible, Big Dig, acetylcholine, 1924 Democratic National Convention, Nassak Diamond, Haunted Mansion Holiday, Raffles Hotel, Goyet Caves, uterine venous plexus, ammonia, Chapultepec, which one is the most conceptually similar with frankincense?", "pred": " Answer:\nPeninj Mandible\n peninsula 4 similarity craniometric_", "completions_tokens": [{"text": " Answer", "logprob": -4.159824848175049}, {"text": ":\n", "logprob": -0.7049436569213867}, {"text": "Pen", "logprob": -2.899479389190674}, {"text": "in", "logprob": -0.00013779645087197423}, {"text": "j", "logprob": -0.00013767725613433868}, {"text": " Mand", "logprob": -0.00013779645087197423}, {"text": "ible", "logprob": -0.00013767725613433868}, {"text": "\n", "logprob": -3.00119686126709}, {"text": " peninsula", "logprob": -12.314421653747559}, {"text": " ", "logprob": -1.999995231628418}, {"text": "4", "logprob": -4.226810455322266}, {"text": " similarity", "logprob": -2.2593531608581543}, {"text": " cr", "logprob": -10.176888465881348}, {"text": "ani", "logprob": -2.5522539615631104}, {"text": "ometric", "logprob": -1.3813493251800537}, {"text": "_", "logprob": -6.439422607421875}], "answers": ["acetylcholine"], "all_classes": "null", "length": 77}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Ultraviolet, alanine aminotransferase, Kepler-62e, Cl-transporting ATPase, Palmar plate, Ostankino Tower, Jones Falls, Ponticulus, Plesetsk Cosmodrome Site 32, Bristol Motor Speedway, Clochette, Cross City Tunnel, Egg hunt, Doublesex, TOG superfamily, Parthenium argentatum, Tay Rail Bridge, Devonian, Xq28, MetroWest Water Supply Tunnel, Brain derived neurotrophic factor, which one is the most conceptually similar with glucagon?", "pred": " \n\nAnswer: Brain derived neurotrophic factor, Devanian, Doublesex are", "completions_tokens": [{"text": " \n\n", "logprob": -0.07921314239501953}, {"text": "Answer", "logprob": -0.0420030914247036}, {"text": ":", "logprob": -0.4182329773902893}, {"text": " Brain", "logprob": -2.385591506958008}, {"text": " derived", "logprob": -6.794906312279636e-06}, {"text": " neuro", "logprob": -0.00013767725613433868}, {"text": "t", "logprob": -0.00013779645087197423}, {"text": "rophic", "logprob": -0.00013779645087197423}, {"text": " factor", "logprob": -0.00013779645087197423}, {"text": ",", "logprob": -1.241141676902771}, {"text": " Dev", "logprob": -3.4896440505981445}, {"text": "anian", "logprob": -4.575206756591797}, {"text": ",", "logprob": -0.12413295358419418}, {"text": " Double", "logprob": -1.287963628768921}, {"text": "sex", "logprob": -0.0053990501910448074}, {"text": " are", "logprob": -1.4409343004226685}], "answers": ["Brain derived neurotrophic factor"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Conococheague Creek, OTO Melara 76 mm, Caudal artery, Korean War, 2009 World Aquatics Championships, Joint Direct Attack Munition, 2017 Central Mexico earthquake, Arctic National Wildlife Refuge, Bristol Motor Speedway, Socorro Island, solar eclipse of May 29, 1919, Montreal International Jazz Festival, Croatia, Fifth Avenue, Palm Springs International Film Festival, Coca-Cola Life, Moscow International Film Festival, compressed tea, solar eclipse of August 1, 2008, Eurovision Song Contest 2005, 1950 United Kingdom general election, which one is the most conceptually similar with Mexico?", "pred": " \n\nAnswer: Fifth Avenue, Bristol Motor Speedway, Arctic National Wildlife Refuge. ", "completions_tokens": [{"text": " \n\n", "logprob": -0.15457889437675476}, {"text": "Answer", "logprob": -0.19104276597499847}, {"text": ":", "logprob": -0.3628150224685669}, {"text": " Fifth", "logprob": -3.228424310684204}, {"text": " Avenue", "logprob": -6.794906312279636e-06}, {"text": ",", "logprob": -0.5399727821350098}, {"text": " Bristol", "logprob": -0.5208257436752319}, {"text": " Motor", "logprob": -0.00013779645087197423}, {"text": " Speedway", "logprob": -0.00013791563105769455}, {"text": ",", "logprob": -0.07708955556154251}, {"text": " Arctic", "logprob": -1.265434741973877}, {"text": " National", "logprob": -0.00013791563105769455}, {"text": " Wildlife", "logprob": -0.00013779645087197423}, {"text": " Refuge", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -1.0130865573883057}, {"text": " ", "logprob": -1.7529934644699097}], "answers": ["Croatia"], "all_classes": "null", "length": 107}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Drax power station, Lake Van, Quebec Conference, King Arthur Carrousel, tooth loss, Els Quatre Gats, Warragamba Dam, RuneQuest, Suntec City, Wine auction, Pawan Gupta, Verrazzano-Narrows Bridge, 25143 Itokawa, Las Vegas Valley, Marble Arch, Alhambra, Oltermanni, police auction, Park Avenue, Cluedo, Banked turn, which one is the most conceptually similar with team pursuit?", "pred": " Team Pursuit\n\nA)\nLake Van\nB) Alhambra\n", "completions_tokens": [{"text": " Team", "logprob": -2.18243670463562}, {"text": " Purs", "logprob": -0.5777523517608643}, {"text": "uit", "logprob": -6.9141146923357155e-06}, {"text": "\n\n", "logprob": -1.084328532218933}, {"text": "A", "logprob": -0.49054160714149475}, {"text": ")\n", "logprob": -3.8561782836914062}, {"text": "Lake", "logprob": -3.3504157066345215}, {"text": " Van", "logprob": -0.12952110171318054}, {"text": "\n", "logprob": -1.2390297651290894}, {"text": "B", "logprob": -0.00013791563105769455}, {"text": ")", "logprob": -1.4171113967895508}, {"text": " Al", "logprob": -2.4429428577423096}, {"text": "h", "logprob": -6.9141146923357155e-06}, {"text": "amb", "logprob": -6.794906312279636e-06}, {"text": "ra", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -0.00013767725613433868}], "answers": ["Banked turn"], "all_classes": "null", "length": 77}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong NBA Draft Lottery, Congressional Cemetery, Formula 5000, East Delaware Tunnel, MT-TW, Kanchenjunga, aluminum oxide, The Proms, 1976 Tangshan earthquake, Produce 101, Midtown Manhattan, Laramidia, table football, Trans-Canada Highway, police auction, Fort Sill, Warwick Castle, Agnes Edwards (craftworker), Hercules, Bay of Plenty, Doncaster Racecourse, which one is the most conceptually similar with Florida Championship Wrestling?", "pred": " \n\nANSWER: Waterspout. Florida Championship Wrestling is more similar to a", "completions_tokens": [{"text": " \n\n", "logprob": -0.32120373845100403}, {"text": "ANS", "logprob": -0.8851918578147888}, {"text": "WER", "logprob": -6.9141146923357155e-06}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " Waters", "logprob": -11.507445335388184}, {"text": "p", "logprob": -2.735489845275879}, {"text": "out", "logprob": -0.017135193571448326}, {"text": ".", "logprob": -0.27030497789382935}, {"text": " Florida", "logprob": -2.929936408996582}, {"text": " Championship", "logprob": -6.794906312279636e-06}, {"text": " Wrestling", "logprob": -0.00013767725613433868}, {"text": " is", "logprob": -0.5783559679985046}, {"text": " more", "logprob": -4.246332168579102}, {"text": " similar", "logprob": -1.2830517292022705}, {"text": " to", "logprob": -0.5631240606307983}, {"text": " a", "logprob": -1.5229110717773438}], "answers": ["Formula 5000"], "all_classes": "null", "length": 81}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong meningohypophyseal artery, Holin superfamily I, Staff College, Camberley, Russian River Valley AVA, Oxbridge, Pine Barrens, Normandy landings, XIST, South China Sea, Eagle Diamond, Nepenthes murudensis, MT-RNR1, 1989 Loma Prieta earthquake, Osterley Park, Keno, Saldanha man, kho kho, 1992 United Kingdom general election, CR2032 battery, PTS-GFL superfamily, Downtown Seattle Transit Tunnel, which one is the most conceptually similar with Dubrovnik?", "pred": "  \n Dubrovnik\n\nAlong the west coast of the Adriatic Sea\n Norm", "completions_tokens": [{"text": "  \n", "logprob": -6.921504020690918}, {"text": " Dub", "logprob": -1.448830246925354}, {"text": "rov", "logprob": -0.00013779645087197423}, {"text": "nik", "logprob": -6.794906312279636e-06}, {"text": "\n\n", "logprob": -0.2724938690662384}, {"text": "Along", "logprob": -7.407113075256348}, {"text": " the", "logprob": -0.5947836637496948}, {"text": " west", "logprob": -7.1467084884643555}, {"text": " coast", "logprob": -0.14771835505962372}, {"text": " of", "logprob": -0.03845239803195}, {"text": " the", "logprob": -0.6238695383071899}, {"text": " Adri", "logprob": -0.2188033163547516}, {"text": "atic", "logprob": -6.9141146923357155e-06}, {"text": " Sea", "logprob": -0.1880645751953125}, {"text": "\n", "logprob": -3.663104295730591}, {"text": " Norm", "logprob": -7.641236305236816}], "answers": ["Staff College, Camberley"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Produce 101, Show hunter, Paleogene, Cluedo, 6 Hebe, Procyon, SM Mall of Asia, Tattletales, spiral artery, M. A. Chidambaram Stadium, Minidoka National Historic Site, Wine auction, Oxford University Parks, Siracourt V-1 bunker, Nagarjuna Sagar Dam, Martinsville Speedway, 1954 FIFA World Cup, Risk, Voskhod 2, Caribbean Sea, Durham Cathedral, which one is the most conceptually similar with Pawan Gupta?", "pred": " \n\nAnswer: Knowledge production/ 6 Hebe. WikiServe records. (", "completions_tokens": [{"text": " \n\n", "logprob": -0.24225974082946777}, {"text": "Answer", "logprob": -0.14391659200191498}, {"text": ":", "logprob": -0.5492691993713379}, {"text": " Knowledge", "logprob": -4.052175998687744}, {"text": " production", "logprob": -4.111666679382324}, {"text": "/", "logprob": -5.076118469238281}, {"text": " ", "logprob": -3.6600418090820312}, {"text": "6", "logprob": -1.7329658269882202}, {"text": " He", "logprob": -0.09245822578668594}, {"text": "be", "logprob": -6.9141146923357155e-06}, {"text": ".", "logprob": -0.5777550935745239}, {"text": " Wiki", "logprob": -7.4126505851745605}, {"text": "Serve", "logprob": -12.247166633605957}, {"text": " records", "logprob": -10.654946327209473}, {"text": ".", "logprob": -2.8131654262542725}, {"text": " (", "logprob": -3.082315444946289}], "answers": ["Wine auction"], "all_classes": "null", "length": 83}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong American Golden Topaz, propane, naloxone, Reggianito, Caciotta, valproic acid, Lake Maracaibo, 1976 Tangshan earthquake, Woodhead Tunnel, Tiffany Yellow Diamond, nopal, Humber Bridge, Port Jackson, Bonnaroo Music Festival, codeine, Scott Glacier, KNM ER 1813, Prometheus, Mogao Caves, Pret a Manger, Kedleston Hall, which one is the most conceptually similar with ethylene?", "pred": " \n\nAnswer: Narbonephiline\n\n Note: This response is based on a", "completions_tokens": [{"text": " \n\n", "logprob": -0.11045128852128983}, {"text": "Answer", "logprob": -0.08331052213907242}, {"text": ":", "logprob": -0.3822237253189087}, {"text": " Nar", "logprob": -8.943123817443848}, {"text": "bon", "logprob": -0.6343114972114563}, {"text": "eph", "logprob": -8.81628704071045}, {"text": "iline", "logprob": -5.33591365814209}, {"text": "\n\n", "logprob": -4.490889549255371}, {"text": " Note", "logprob": -3.8384196758270264}, {"text": ":", "logprob": -0.002372071845456958}, {"text": " This", "logprob": -2.449233055114746}, {"text": " response", "logprob": -2.458918333053589}, {"text": " is", "logprob": -2.950532913208008}, {"text": " based", "logprob": -0.8055283427238464}, {"text": " on", "logprob": -0.01503786351531744}, {"text": " a", "logprob": -1.0668137073516846}], "answers": ["propane"], "all_classes": "null", "length": 74}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Brahma, naloxone, ADC Cirrus, Karawanks Tunnel, Hadim Suleiman Pasha, Alexander III Commemorative, hydrogen peroxide, Paul the Octopus, Monterey Bay, nitric acid, crisantaspase, Lewis gun, Gulf of California, renin, Eclipse of Thales, Settle to Carlisle Line, Sonoma Coast AVA, Wintergreen, Tesla Powerwall, Crystal the Monkey, Ourasphaira giraldae, which one is the most conceptually similar with Nepenthes murudensis?", "pred": " \n\nAnswer: Tesla Powerwall. This answer can vary depends on individual perspective,", "completions_tokens": [{"text": " \n\n", "logprob": -0.08817712962627411}, {"text": "Answer", "logprob": -0.2440401315689087}, {"text": ":", "logprob": -0.9259729981422424}, {"text": " Tesla", "logprob": -1.9051709175109863}, {"text": " Power", "logprob": -0.00013779645087197423}, {"text": "wall", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -0.32739078998565674}, {"text": " This", "logprob": -4.158978462219238}, {"text": " answer", "logprob": -1.2371315956115723}, {"text": " can", "logprob": -2.645108461380005}, {"text": " vary", "logprob": -5.748290538787842}, {"text": " depends", "logprob": -3.5512516498565674}, {"text": " on", "logprob": -0.037073638290166855}, {"text": " individual", "logprob": -5.79267692565918}, {"text": " perspective", "logprob": -1.2032328844070435}, {"text": ",", "logprob": -3.0429399013519287}], "answers": ["Wintergreen"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Monitor-Merrimac Memorial Bridge-Tunnel, STS-51-B, Sampson artery, Ford Modular engine, Hadassah Medical Center, mucin, Peninj Mandible, 2019 Rugby World Cup, Vredefort crater, solar eclipse of March 29, 2006, BMW 801, Pinconning cheese, perforator vein, War on Terror, STS-121, Deneb, Beau Sancy, Mauer 1, TRAPPIST-1f, Swatara Creek, trabecular veins, which one is the most conceptually similar with Hole-in-the-Ground?", "pred": " \n\nAnswer: Sampson artery. (It is also known as \"arteria", "completions_tokens": [{"text": " \n\n", "logprob": -0.26958438754081726}, {"text": "Answer", "logprob": -0.41920366883277893}, {"text": ":", "logprob": -1.2898541688919067}, {"text": " Samp", "logprob": -3.908580780029297}, {"text": "son", "logprob": -0.00013779645087197423}, {"text": " artery", "logprob": -0.30532705783843994}, {"text": ".", "logprob": -0.13830921053886414}, {"text": " (", "logprob": -1.091773271560669}, {"text": "It", "logprob": -1.9894740581512451}, {"text": " is", "logprob": -0.8731308579444885}, {"text": " also", "logprob": -1.5660216808319092}, {"text": " known", "logprob": -0.18324792385101318}, {"text": " as", "logprob": -0.0053177098743617535}, {"text": " \"", "logprob": -1.516405701637268}, {"text": "arter", "logprob": -0.7101919054985046}, {"text": "ia", "logprob": -0.8937911987304688}], "answers": ["Vredefort crater"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Lake Lucerne, Warwick Castle, English Dresden, Soyuz 5, Radicular artery, Julier Pass, Forest of Bowland, Siege of Yorktown, High Five Interchange, Sydney Film Festival, Mount Erebus, Super Bowl XXXV, 12.7 cm/40 Type 89 naval gun, Shasta Dam, French Revolutionary Wars, Horizons, Clyde Tunnel, Interleukin 2, Church of the Holy Sepulchre, General Theological Seminary, Battle of Waterloo, which one is the most conceptually similar with STS-41-B?", "pred": " \n\nAnswer: Horizon. (Each \"STS-\" represents Space Transportation System during shuttle", "completions_tokens": [{"text": " \n\n", "logprob": -0.13467378914356232}, {"text": "Answer", "logprob": -0.07655911147594452}, {"text": ":", "logprob": -0.8084359169006348}, {"text": " Horizon", "logprob": -4.470178604125977}, {"text": ".", "logprob": -0.7935575842857361}, {"text": " (", "logprob": -1.2431617975234985}, {"text": "Each", "logprob": -8.392555236816406}, {"text": " \"", "logprob": -3.8082876205444336}, {"text": "STS", "logprob": -0.10746345669031143}, {"text": "-\"", "logprob": -0.11317604780197144}, {"text": " represents", "logprob": -2.5950281620025635}, {"text": " Space", "logprob": -0.9545611143112183}, {"text": " Transportation", "logprob": -0.1329377442598343}, {"text": " System", "logprob": -6.794906312279636e-06}, {"text": " during", "logprob": -8.240078926086426}, {"text": " shuttle", "logprob": -3.651257038116455}], "answers": ["Soyuz 5"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Miocene, Corviglia, Perrier, Oltermanni, Pom1, Bodo cranium, Eridge Park, dilator naris muscle, Mrs. Ples, Trp operon, Filchner-Ronne Ice Shelf, Diet Pepsi, anterolateral ligament, Reflex inguinal ligament, Tycho, Fusarium wilt, Friuli-Venezia Giulia wine, Monster Energy, Coca-Cola Life, 1990 FIFA World Cup, throwball, which one is the most conceptually similar with Clochette?", "pred": " \n\nAnswer:\n\nClochette is a French term describing the musical sound of a", "completions_tokens": [{"text": " \n\n", "logprob": -0.14291371405124664}, {"text": "Answer", "logprob": -0.48309504985809326}, {"text": ":\n\n", "logprob": -1.2119377851486206}, {"text": "Clo", "logprob": -0.36065495014190674}, {"text": "ch", "logprob": -0.004929531831294298}, {"text": "ette", "logprob": -0.00013767725613433868}, {"text": " is", "logprob": -0.2671303153038025}, {"text": " a", "logprob": -0.25042328238487244}, {"text": " French", "logprob": -3.0343377590179443}, {"text": " term", "logprob": -2.4782474040985107}, {"text": " describing", "logprob": -8.077031135559082}, {"text": " the", "logprob": -0.472805917263031}, {"text": " musical", "logprob": -5.92111873626709}, {"text": " sound", "logprob": -1.197885513305664}, {"text": " of", "logprob": -0.21039517223834991}, {"text": " a", "logprob": -0.4587845802307129}], "answers": ["Oltermanni"], "all_classes": "null", "length": 74}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong epitrochleoanconeus muscle, Palmar plate, Late Antiquity, Brain derived neurotrophic factor, congress of Berlin, 2010 FIFA World Cup, Battle of Britain, Leopard complex, English Channel, Spanish colonization of the Americas, Jurassic, Sam Yan, Star Tours, Bay of Biscay, Mar-a-Lago, Battle of Crete, police auction, International Film Festival of India, Little Boy, Oswald Poche, Poston War Relocation Center, which one is the most conceptually similar with Weddell Sea?", "pred": " \n\nAnswer:\n\nWeddell Sea Galaxy III (similarity not asked before)", "completions_tokens": [{"text": " \n\n", "logprob": -0.09701387584209442}, {"text": "Answer", "logprob": -0.26571106910705566}, {"text": ":\n\n", "logprob": -0.21949347853660583}, {"text": "Wed", "logprob": -2.8274600505828857}, {"text": "d", "logprob": -6.794906312279636e-06}, {"text": "ell", "logprob": -0.00013767725613433868}, {"text": " Sea", "logprob": -6.9141146923357155e-06}, {"text": " Galaxy", "logprob": -7.400360107421875}, {"text": " III", "logprob": -4.344294548034668}, {"text": " (", "logprob": -2.306307077407837}, {"text": "sim", "logprob": -2.5434861183166504}, {"text": "ilarity", "logprob": -6.794906312279636e-06}, {"text": " not", "logprob": -0.5744598507881165}, {"text": " asked", "logprob": -1.9215716123580933}, {"text": " before", "logprob": -2.81101131439209}, {"text": ")", "logprob": -2.5355780124664307}], "answers": ["English Channel"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong NGC 379, Nepenthes glabrata, Chota Nagpur Plateau, Smithsonian American Art Museum, Mount Vernon, Parthenium argentatum, solar eclipse of July 10, 1972, Meiji period, Georgian Bay, Powerade, Pont Neuf, Brisbane Powerhouse, gallium arsenide, RSL-3, Chelyabinsk meteor, Scapa Flow, Theia, Hotel del Coronado, Lake Superior, lateral rotator group, rs6314, which one is the most conceptually similar with Silurian?", "pred": "  Scapa Flow\n\nANSWER: Theia (at 1 point similarity", "completions_tokens": [{"text": " ", "logprob": -5.027079105377197}, {"text": " Sc", "logprob": -6.261882305145264}, {"text": "apa", "logprob": -0.00013779645087197423}, {"text": " Flow", "logprob": -0.00013779645087197423}, {"text": "\n\n", "logprob": -0.4546746015548706}, {"text": "ANS", "logprob": -1.010803461074829}, {"text": "WER", "logprob": -0.018801216036081314}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " The", "logprob": -2.3686695098876953}, {"text": "ia", "logprob": -0.0025766051840037107}, {"text": " (", "logprob": -1.9019489288330078}, {"text": "at", "logprob": -7.302550792694092}, {"text": " ", "logprob": -2.399538040161133}, {"text": "1", "logprob": -1.9837734699249268}, {"text": " point", "logprob": -3.4166643619537354}, {"text": " similarity", "logprob": -1.57061767578125}], "answers": ["Meiji period"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1998 FIFA World Cup, Spring Grove Cemetery, Ford Island, Epidermal growth factor, Diplodia mutila, King Kong Encounter, Phytophthora ramorum, Borneo, Caldecott Tunnel, The Indian Bean Tree, St James Square, Monmouth, Bucheron, Royal Oak, ophthalmic veins, djon djon, Tanna Tunnel, Alexander Valley AVA, Christian the lion, Teatro Real, 5145 Pholus, Times Square, Michigan Central Railway Tunnel, which one is the most conceptually similar with Liu Jishu?", "pred": "\n\nStep 1:  First, let's take a closer look at each", "completions_tokens": [{"text": "\n\n", "logprob": -9.623908996582031}, {"text": "Step", "logprob": -3.491574764251709}, {"text": " ", "logprob": -6.794906312279636e-06}, {"text": "1", "logprob": -0.00013779645087197423}, {"text": ":", "logprob": -0.00013767725613433868}, {"text": " ", "logprob": -1.4285435676574707}, {"text": " First", "logprob": -0.8766418099403381}, {"text": ",", "logprob": -0.00013755806139670312}, {"text": " let", "logprob": -0.5733305811882019}, {"text": "'s", "logprob": -0.00013779645087197423}, {"text": " take", "logprob": -5.926890850067139}, {"text": " a", "logprob": -0.9326810836791992}, {"text": " closer", "logprob": -0.30016863346099854}, {"text": " look", "logprob": -6.794906312279636e-06}, {"text": " at", "logprob": -0.00013767725613433868}, {"text": " each", "logprob": -0.42492809891700745}], "answers": ["Christian the lion"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1990 Luzon earthquake, Centre Georges Pompidou, Solar eclipse of July 31, 1981, ELA-4, Bayreuth Festival, Karla Caves, Cullinan Diamond, Gulf of Tonkin, Salzburg Festival, Tian Lingzi, superficial dorsal vein of the penis, Nepenthes kerrii, Cunninghams Gap, Sun Yat-sen Memorial Hall, Phytophthora ramorum, River Teme, Super Bowl XLIV, Diplodia mutila, Kveik, stigmatomycosis, Bay of Bengal, which one is the most conceptually similar with Bart the Bear 2?", "pred": " \n\nAnswer: Bay of Bengal, Bart the Bear (mascot of Tampa", "completions_tokens": [{"text": " \n\n", "logprob": -0.16524988412857056}, {"text": "Answer", "logprob": -0.20652802288532257}, {"text": ":", "logprob": -0.330822616815567}, {"text": " Bay", "logprob": -0.6656510829925537}, {"text": " of", "logprob": -0.024446697905659676}, {"text": " Bengal", "logprob": -0.00013779645087197423}, {"text": ",", "logprob": -1.4192867279052734}, {"text": " Bart", "logprob": -1.0907256603240967}, {"text": " the", "logprob": -0.23525094985961914}, {"text": " Bear", "logprob": -0.032375436276197433}, {"text": " (", "logprob": -2.7695446014404297}, {"text": "m", "logprob": -5.194945335388184}, {"text": "asc", "logprob": -0.4987054467201233}, {"text": "ot", "logprob": -6.794906312279636e-06}, {"text": " of", "logprob": -0.2319634109735489}, {"text": " Tampa", "logprob": -2.2662954330444336}], "answers": ["Tian Lingzi"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 20 July plot, Radicular artery, Savoy wine, Super Bowl XXXIV, nandrolone, Washington National Cathedral, Kanchenjunga, Pepsi Max, (S)-corytuberine synthase, 1987 World Championships in Athletics, Star Wars Launch Bay, Battle of France, Diplodia mutila, Eridge Park, Outer Coastal Plain AVA, wagasi, stigmatomycosis, Antigua, Palmar plate, MT-TW, Christian the lion, which one is the most conceptually similar with Honshu?", "pred": " \n\nAnswer: MT-TW is unlikely to be related to Shikoku due", "completions_tokens": [{"text": " \n\n", "logprob": -0.15121932327747345}, {"text": "Answer", "logprob": -0.08579487353563309}, {"text": ":", "logprob": -0.2165164053440094}, {"text": " MT", "logprob": -1.1096928119659424}, {"text": "-T", "logprob": -6.794906312279636e-06}, {"text": "W", "logprob": -6.794906312279636e-06}, {"text": " is", "logprob": -2.057331085205078}, {"text": " unlikely", "logprob": -5.912322998046875}, {"text": " to", "logprob": -0.09632134437561035}, {"text": " be", "logprob": -0.06406818330287933}, {"text": " related", "logprob": -1.615741491317749}, {"text": " to", "logprob": -0.033659372478723526}, {"text": " Sh", "logprob": -7.693315505981445}, {"text": "ik", "logprob": -0.1869727373123169}, {"text": "oku", "logprob": -0.002059602178633213}, {"text": " due", "logprob": -4.579151630401611}], "answers": ["Antigua"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Kilmainham Gaol, Dubrovnik, Tango, Pinconning cheese, Mechanistic target of rapamycin kinase, anterolateral ligament, Marble Arch, Reggianito, Bucheron, mucin, Kasat Suek Intersection, KNM WT 17000, Donner Pass, 5145 Pholus, wagasi, Caciotta, Red Sea, Ferrar Glacier, 2011 Rugby World Cup, Baltoro Glacier, corticotropin, which one is the most conceptually similar with Leffe?", "pred": " \n\nAnswer:\n\nCaciotta. Not precisely similar but Caciotta is a", "completions_tokens": [{"text": " \n\n", "logprob": -0.07250011712312698}, {"text": "Answer", "logprob": -0.1148187592625618}, {"text": ":\n\n", "logprob": -1.3586485385894775}, {"text": "C", "logprob": -1.475645899772644}, {"text": "aci", "logprob": -0.007319893222302198}, {"text": "otta", "logprob": -0.00013779645087197423}, {"text": ".", "logprob": -0.30916404724121094}, {"text": " Not", "logprob": -4.647661209106445}, {"text": " precisely", "logprob": -7.229716777801514}, {"text": " similar", "logprob": -0.7689898014068604}, {"text": " but", "logprob": -0.46426501870155334}, {"text": " C", "logprob": -2.521786689758301}, {"text": "aci", "logprob": -0.00013767725613433868}, {"text": "otta", "logprob": -0.00013767725613433868}, {"text": " is", "logprob": -0.21012486517429352}, {"text": " a", "logprob": -0.5155962109565735}], "answers": ["Tango"], "all_classes": "null", "length": 74}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Super Bowl LI, Ford FE engine, chase gun, Mount of Olives, Stalag Luft III, djon djon, keel, Ecarin, 1924 Democratic National Convention, Formula 5000, Brenner Base Tunnel, Damavand, Hotchkiss gun, Early Cretaceous, Wine auction, 1962 FIFA World Cup, Before Present, TCA Ground, San Bernardino Tunnel, Irn-Bru, National Christmas Tree, which one is the most conceptually similar with Carrara Stadium?", "pred": " \n\nAnswer: Ford Super Bowl Vendor game  & Carrara Stadium  is name", "completions_tokens": [{"text": " \n\n", "logprob": -0.09480321407318115}, {"text": "Answer", "logprob": -0.3505285680294037}, {"text": ":", "logprob": -0.79124915599823}, {"text": " Ford", "logprob": -4.3631696701049805}, {"text": " Super", "logprob": -7.10023307800293}, {"text": " Bowl", "logprob": -0.29062309861183167}, {"text": " Vendor", "logprob": -10.793661117553711}, {"text": " game", "logprob": -7.992191314697266}, {"text": " ", "logprob": -2.630112409591675}, {"text": " &", "logprob": -6.387075424194336}, {"text": " Carr", "logprob": -2.9923582077026367}, {"text": "ara", "logprob": -6.794906312279636e-06}, {"text": " Stadium", "logprob": -0.19137674570083618}, {"text": " ", "logprob": -2.340576171875}, {"text": " is", "logprob": -1.0409172773361206}, {"text": " name", "logprob": -6.142317771911621}], "answers": ["TCA Ground"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong (15788) 1993 SB, 10.5 cm SK C/32 naval gun, 8.8 cm SK L/45 naval gun, Adirondack Park, carbon disulfide, Arlington National Cemetery, UEFA Euro 2004, Blenheim Park, RPG-7, Afon Irfon, Festning Tunnel, Winter War, Tesla Powerwall, Lewis gun, Syzygium guineense, Preseli Hills, Utopia Planitia, Risiera di San Sabba, Unteraar Glacier, histamine, Udayagiri and Khandagiri Caves, which one is the most conceptually similar with CR2032 battery?", "pred": " \n\nAnswer: Syzygium guineense.   However, Syzygium", "completions_tokens": [{"text": " \n\n", "logprob": -0.07807374000549316}, {"text": "Answer", "logprob": -0.634379506111145}, {"text": ":", "logprob": -0.2420664280653}, {"text": " Sy", "logprob": -1.4781677722930908}, {"text": "zy", "logprob": -6.794906312279636e-06}, {"text": "gium", "logprob": -6.794906312279636e-06}, {"text": " gu", "logprob": -0.00013779645087197423}, {"text": "ine", "logprob": -6.794906312279636e-06}, {"text": "ense", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -0.2028227150440216}, {"text": "  ", "logprob": -5.207082271575928}, {"text": " However", "logprob": -3.7397732734680176}, {"text": ",", "logprob": -0.10833756625652313}, {"text": " Sy", "logprob": -1.4063303470611572}, {"text": "zy", "logprob": -6.794906312279636e-06}, {"text": "gium", "logprob": -6.794906312279636e-06}], "answers": ["Tesla Powerwall"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Inca Kola, interclavicle, Russian Tea Room, Pula Film Festival, CR2032 battery, Staten Island Railway, calcium oxide, Xynotyro, Reflex inguinal ligament, San Diego, epitrochleoanconeus muscle, Nissan E engine, tooth loss, Fort Laramie National Historic Site, Rover V8 engine, National Soccer Hall of Fame, Four Mile Run, Heian period, fentanyl, plantar Lisfranc ligament, Cross City Tunnel, which one is the most conceptually similar with Vasai Creek?", "pred": " \n\nAnswer: Staten Island Railway. Similar By geographical area are the railroad carriers that", "completions_tokens": [{"text": " \n\n", "logprob": -1.1805438995361328}, {"text": "Answer", "logprob": -0.16560471057891846}, {"text": ":", "logprob": -0.7827461957931519}, {"text": " Staten", "logprob": -1.2826191186904907}, {"text": " Island", "logprob": -0.00013767725613433868}, {"text": " Railway", "logprob": -0.00013779645087197423}, {"text": ".", "logprob": -0.25769224762916565}, {"text": " Similar", "logprob": -1.7736872434616089}, {"text": " By", "logprob": -9.91282844543457}, {"text": " geographical", "logprob": -2.228379011154175}, {"text": " area", "logprob": -2.969188690185547}, {"text": " are", "logprob": -5.543313980102539}, {"text": " the", "logprob": -1.5138609409332275}, {"text": " railroad", "logprob": -4.851049423217773}, {"text": " carriers", "logprob": -7.401276588439941}, {"text": " that", "logprob": -0.6146427392959595}], "answers": ["Four Mile Run"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Caciotta, anterolateral ligament, Oltermanni, Algonquin Provincial Park, American Astronomical Society 215th meeting, Cloth Hall, Ypres, Blackfriars Bridge, Oswald Poche, Tokaj wine region, Moliterno, Fortress of Louisbourg, Jura wine, Egg hunt, The Pierre, Palmar plate, Centre Georges Pompidou, Burgess Shale, Finding Nemo Submarine Voyage, Criollo cheese, Reggianito, Holy See, which one is the most conceptually similar with Coca-Cola Life?", "pred": " Coke with a twist of lime.\nAnswer:\nCriollo cheese, Reggian", "completions_tokens": [{"text": " Coke", "logprob": -10.029672622680664}, {"text": " with", "logprob": -6.231268882751465}, {"text": " a", "logprob": -0.8419010639190674}, {"text": " twist", "logprob": -0.867499589920044}, {"text": " of", "logprob": -0.25130003690719604}, {"text": " lime", "logprob": -1.7178940773010254}, {"text": ".\n", "logprob": -4.732210636138916}, {"text": "Answer", "logprob": -0.2800023853778839}, {"text": ":\n", "logprob": -0.5127555727958679}, {"text": "Cri", "logprob": -0.20200465619564056}, {"text": "ollo", "logprob": -6.794906312279636e-06}, {"text": " cheese", "logprob": -0.00013767725613433868}, {"text": ",", "logprob": -1.789736032485962}, {"text": " Reg", "logprob": -0.09418314695358276}, {"text": "g", "logprob": -6.9141146923357155e-06}, {"text": "ian", "logprob": -0.00013767725613433868}], "answers": ["Jura wine"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong solar eclipse of May 28, 1900, Mrp superfamily, FERONIA, Semlin concentration camp, Ruhleben internment camp, Honshu, Xq28, Diplodia mutila, Prekallikrein, Spitsbergen, Wawona Tunnel, Pawan Gupta, nerve growth factor, Gunnison Tunnel, parathyroid artery, Lysine exporter, Sphenomandibularis, sulfuric acid, solar eclipse of March 20, 2015, fluoxetine, Raghunathpur Thermal Power Station, which one is the most conceptually similar with Myoglobin?", "pred": " \n\nAnswer: Sulphuric Acid  Myoglobin appears in sulfer metabolism", "completions_tokens": [{"text": " \n\n", "logprob": -0.14374789595603943}, {"text": "Answer", "logprob": -0.10132687538862228}, {"text": ":", "logprob": -0.4455922842025757}, {"text": " Sul", "logprob": -6.508781909942627}, {"text": "ph", "logprob": -0.09196849912405014}, {"text": "ur", "logprob": -0.12581601738929749}, {"text": "ic", "logprob": -0.00013779645087197423}, {"text": " Acid", "logprob": -0.20788393914699554}, {"text": " ", "logprob": -3.341416358947754}, {"text": " My", "logprob": -3.4373300075531006}, {"text": "oglobin", "logprob": -0.00011681827891152352}, {"text": " appears", "logprob": -8.188541412353516}, {"text": " in", "logprob": -0.47709399461746216}, {"text": " sul", "logprob": -6.766036033630371}, {"text": "fer", "logprob": -0.6065136194229126}, {"text": " metabolism", "logprob": -2.2079079151153564}], "answers": ["nerve growth factor"], "all_classes": "null", "length": 85}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Surfeit, Centaurus A, War on Terror, Resorts World Sentosa, guarana, 2015 United Kingdom general election, Common Era, Ure2, Criollo cheese, crisantaspase, East Delaware Tunnel, Battle of Crete, Thailand, Plasma membrane Ca2+ ATPase, Dumbo the Flying Elephant, Ruhleben internment camp, Missouri Botanical Garden, Elizabethan era, Ain Dubai, daf-7, Interleukin 2, which one is the most conceptually similar with Sex determining region Y?", "pred": " \n\nAuric Charge \n\nB. Caribbean Electric Resort World\n\nC. Tropical", "completions_tokens": [{"text": " \n\n", "logprob": -0.08025883883237839}, {"text": "A", "logprob": -0.8619629740715027}, {"text": "ur", "logprob": -4.7202229499816895}, {"text": "ic", "logprob": -1.398147463798523}, {"text": " Charge", "logprob": -13.319212913513184}, {"text": " \n\n", "logprob": -5.251531600952148}, {"text": "B", "logprob": -0.32727161049842834}, {"text": ".", "logprob": -0.8352138996124268}, {"text": " Caribbean", "logprob": -8.282458305358887}, {"text": " Electric", "logprob": -5.51649284362793}, {"text": " Resort", "logprob": -7.622414588928223}, {"text": " World", "logprob": -4.835268497467041}, {"text": "\n\n", "logprob": -1.328303337097168}, {"text": "C", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -0.006591483019292355}, {"text": " Tropical", "logprob": -7.702200412750244}], "answers": ["Interleukin 2"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Finding Nemo Submarine Voyage, compressed tea, Myanmar, San Pedro, TUC338, 1983 United Kingdom general election, Phytophthora ramorum, Super Bowl XXXVI, Horse Cave, Fort Laramie National Historic Site, Blue Glacier, Mount Ararat, Epidermal growth factor, Napa Valley AVA, Triassic, 1693 Sicily earthquake, Mauer 1, Sagittarius Dwarf Elliptical Galaxy, Daka skull, Thane Creek, Kyushu, which one is the most conceptually similar with Independence Day?", "pred": " Similarity:\n\nNapa Valley AVA \n\nLatitude:  37.269", "completions_tokens": [{"text": " Similar", "logprob": -7.2309465408325195}, {"text": "ity", "logprob": -0.006826531141996384}, {"text": ":\n\n", "logprob": -1.2910536527633667}, {"text": "N", "logprob": -4.946162223815918}, {"text": "apa", "logprob": -0.05053155496716499}, {"text": " Valley", "logprob": -6.794906312279636e-06}, {"text": " AV", "logprob": -0.005067243706434965}, {"text": "A", "logprob": -6.794906312279636e-06}, {"text": " \n\n", "logprob": -2.486574172973633}, {"text": "Latitude", "logprob": -9.532793045043945}, {"text": ":", "logprob": -0.6145830154418945}, {"text": " ", "logprob": -0.23233947157859802}, {"text": " ", "logprob": -3.782834053039551}, {"text": "37", "logprob": -1.9932091236114502}, {"text": ".", "logprob": -0.33831077814102173}, {"text": "269", "logprob": -8.157817840576172}], "answers": ["Triassic"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Holin superfamily II, Sawtooth National Recreation Area, BL Lacertae, MACPF, Queen Elizabeth Olympic Park, XIST, Myoglobin, French and Indian War, 1922 United Kingdom general election, Agnes Edwards (craftworker), Hollywood Roosevelt Hotel, Great Britain, solar eclipse of July 29, 1878, Ecarin, TOG superfamily, Grand Trunk Pacific Railway, 50000 Quaoar, Landsberg Prison, Crowsnest Pass, Battle of Fredericksburg, entitlement, which one is the most conceptually similar with Brain derived neurotrophic factor?", "pred": " \n\n Step 1: Analyze the given list of entities, including biological terms", "completions_tokens": [{"text": " \n\n", "logprob": -0.11948464065790176}, {"text": " Step", "logprob": -3.7936506271362305}, {"text": " ", "logprob": -6.794906312279636e-06}, {"text": "1", "logprob": -0.00013779645087197423}, {"text": ":", "logprob": -0.00013767725613433868}, {"text": " Analy", "logprob": -1.191969394683838}, {"text": "ze", "logprob": -0.1724535971879959}, {"text": " the", "logprob": -0.6932194232940674}, {"text": " given", "logprob": -0.9390004277229309}, {"text": " list", "logprob": -0.27907902002334595}, {"text": " of", "logprob": -0.14161933958530426}, {"text": " entities", "logprob": -0.05227663740515709}, {"text": ",", "logprob": -3.6415443420410156}, {"text": " including", "logprob": -3.235968828201294}, {"text": " biological", "logprob": -2.817382335662842}, {"text": " terms", "logprob": -1.505612850189209}], "answers": ["Myoglobin"], "all_classes": "null", "length": 95}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Gotthard railway, Coarse fishing, Castle Bravo, Liberty Tree, 2004 Indian Ocean earthquake, Welcome Stranger, CYP2J2, Lake Lucerne, Peace Tower, superior thalamic vein, Newport Folk Festival, Les Sybelles, 1971 San Fernando earthquake, cabin fever, Caspian Sea, Agnes Edwards (craftworker), 1963 Skopje earthquake, congress of Berlin, Van Cortlandt Park, Clochette, Tiffany Yellow Diamond, which one is the most conceptually similar with Vanderbilt University?", "pred": " \n\nANSWER: Liberty Tree. But that was not on the options. Vanderbilt", "completions_tokens": [{"text": " \n\n", "logprob": -0.30453044176101685}, {"text": "ANS", "logprob": -2.2155075073242188}, {"text": "WER", "logprob": -6.9141146923357155e-06}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " Liberty", "logprob": -0.41678670048713684}, {"text": " Tree", "logprob": -0.00013767725613433868}, {"text": ".", "logprob": -0.15717782080173492}, {"text": " But", "logprob": -5.719948768615723}, {"text": " that", "logprob": -2.6268577575683594}, {"text": " was", "logprob": -4.185084819793701}, {"text": " not", "logprob": -0.5663769245147705}, {"text": " on", "logprob": -3.784146785736084}, {"text": " the", "logprob": -0.09248713403940201}, {"text": " options", "logprob": -2.7349414825439453}, {"text": ".", "logprob": -0.16616366803646088}, {"text": " Vanderbilt", "logprob": -1.9435088634490967}], "answers": ["Van Cortlandt Park"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Xynotyro, Small Magellanic Cloud, Caciotta, wagasi, Frankfurt City Tunnel, Rolls-Royce Meteor, Kennedy Space Center Launch Complex 39B, solar eclipse of March 29, 2006, Jansky, Tsarskoye Selo, Katiki Domokou, Blue, Gurs internment camp, Moliterno, Vin jaune, Vallnord, Galleria Vittorio Emanuele II, Ursa Minor, Sabina Park, Banjica concentration camp, Teide, which one is the most conceptually similar with Faygo?", "pred": " \n\nAnswer:\n\nBlue (fruit-flavored soda) is similar, but most concept", "completions_tokens": [{"text": " \n\n", "logprob": -0.1742529422044754}, {"text": "Answer", "logprob": -0.3314098119735718}, {"text": ":\n\n", "logprob": -0.3533683717250824}, {"text": "Blue", "logprob": -1.9098259210586548}, {"text": " (", "logprob": -1.8004374504089355}, {"text": "fruit", "logprob": -4.634416580200195}, {"text": "-fl", "logprob": -1.6508007049560547}, {"text": "avored", "logprob": -0.002732830820605159}, {"text": " soda", "logprob": -0.3771478533744812}, {"text": ")", "logprob": -1.9517853260040283}, {"text": " is", "logprob": -0.4836273789405823}, {"text": " similar", "logprob": -0.9399877786636353}, {"text": ",", "logprob": -1.8799012899398804}, {"text": " but", "logprob": -1.7590577602386475}, {"text": " most", "logprob": -2.5502219200134277}, {"text": " concept", "logprob": -0.3042947053909302}], "answers": ["Vin jaune"], "all_classes": "null", "length": 83}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Bataan Death March, Ford Kent engine, Irish Rebellion of 1798, Second Sino-Japanese War, NGC 388, Manhattan Municipal Building, Royal Liverpool Golf Club, Hoylake, 2006 European Athletics Championships, 1700 Cascadia earthquake, Edinburgh International Film Festival, Middlesex Hospital, Criollo cheese, Liu Jishu, Bolivia, Battle of Shiloh, Filchner-Ronne Ice Shelf, Manila Bay, El Escorial, Queensway Tunnel, Hamilton Crescent, Via Lattea, which one is the most conceptually similar with Invasion of Poland?", "pred": " \n\nAnswer:\n\nBattle of Shiloh Would also like to ask one more question", "completions_tokens": [{"text": " \n\n", "logprob": -0.13130521774291992}, {"text": "Answer", "logprob": -0.47804898023605347}, {"text": ":\n\n", "logprob": -0.49836432933807373}, {"text": "Battle", "logprob": -1.285461664199829}, {"text": " of", "logprob": -6.794906312279636e-06}, {"text": " Sh", "logprob": -0.00013755806139670312}, {"text": "il", "logprob": -6.794906312279636e-06}, {"text": "oh", "logprob": -0.00013779645087197423}, {"text": " Would", "logprob": -7.951520919799805}, {"text": " also", "logprob": -5.906457901000977}, {"text": " like", "logprob": -1.1115604639053345}, {"text": " to", "logprob": -0.03176552802324295}, {"text": " ask", "logprob": -0.9932223558425903}, {"text": " one", "logprob": -2.8862502574920654}, {"text": " more", "logprob": -0.33984923362731934}, {"text": " question", "logprob": -0.06853622943162918}], "answers": ["Second Sino-Japanese War"], "all_classes": "null", "length": 95}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Congressional Cemetery, Poughkeepsie Bridge, Tank Stream, Root rot, Fet3p, Melaleuca alternifolia, HS.404, CR2025, Tesla Powerpack, Tesla Megapack, Alfa Romeo V6 engine, Hofmeyr Skull, Ourasphaira giraldae, Parthenium argentatum, Kinzua Dam, Beartooth Basin Summer Ski Area, Polaris, PSR B1913+16, Aldebaran, Indonesia, Chrysler Pentastar engine, which one is the most conceptually similar with RPG-7?", "pred": "__Aldebaran\n\n\nAnswer: Simularity cannot occur between Aldebar", "completions_tokens": [{"text": "__", "logprob": -10.22150993347168}, {"text": "Al", "logprob": -1.7838820219039917}, {"text": "de", "logprob": -0.06447888910770416}, {"text": "bar", "logprob": -6.794906312279636e-06}, {"text": "an", "logprob": -0.00013767725613433868}, {"text": "\n\n\n", "logprob": -3.6019020080566406}, {"text": "Answer", "logprob": -0.5730531811714172}, {"text": ":", "logprob": -0.0006381620769388974}, {"text": " Sim", "logprob": -7.119491100311279}, {"text": "ularity", "logprob": -2.5399372577667236}, {"text": " cannot", "logprob": -3.1479268074035645}, {"text": " occur", "logprob": -4.053568363189697}, {"text": " between", "logprob": -1.7954031229019165}, {"text": " Al", "logprob": -1.6930396556854248}, {"text": "de", "logprob": -0.00013791563105769455}, {"text": "bar", "logprob": -0.00013755806139670312}], "answers": ["HS.404"], "all_classes": "null", "length": 75}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong solar eclipse of November 25, 2011, Cueva de las Manos, daf-2, Oswald Poche, The Cenotaph, 2016 North Canterbury earthquake, County Ground, Friuli-Venezia Giulia wine, Yazaman al-Khadim, Flyball, Agnes Edwards (craftworker), Fortress of Louisbourg, 2014 FIFA World Cup, Madagascar, Warhammer 40,000, solar eclipse of March 29, 2006, Brandenburg Gate, Intergender wrestling, Pawan Gupta, dorsal digital arteries of foot, SK 46, which one is the most conceptually similar with Rummy?", "pred": " \n\nAICP, Anukul Sinha\nB. Hospital\nC", "completions_tokens": [{"text": " \n\n", "logprob": -0.21387700736522675}, {"text": "A", "logprob": -2.705902099609375}, {"text": "IC", "logprob": -4.76340913772583}, {"text": "P", "logprob": -3.557697296142578}, {"text": ",", "logprob": -3.2794930934906006}, {"text": " An", "logprob": -3.7860729694366455}, {"text": "uk", "logprob": -5.4853925704956055}, {"text": "ul", "logprob": -1.1460551023483276}, {"text": " Sin", "logprob": -5.679553985595703}, {"text": "ha", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -1.1701422929763794}, {"text": "B", "logprob": -0.03041393868625164}, {"text": ".", "logprob": -0.01761295646429062}, {"text": " Hospital", "logprob": -9.957956314086914}, {"text": "\n", "logprob": -0.6996434330940247}, {"text": "C", "logprob": -0.00013767725613433868}], "answers": ["Warhammer 40,000"], "all_classes": "null", "length": 97}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Bear Mountain Bridge, Bucheron, Raghunathpur Thermal Power Station, cerebellar artery, Pula Film Festival, South Branch Potomac River, Baikonur Cosmodrome Site 200, Northern Ireland, Accessory soleus muscle, 1960 Democratic National Convention, Yellowstone volcano, Adductor muscles of the hip, Bellevue Hospital Center, uterine venous plexus, Adirondack Park, Coen Tunnel, TRAPPIST-1g, lateral rotator group, Venice Film Festival, Spaceport Florida Launch Complex 46, pubovaginal muscle, which one is the most conceptually similar with common digital veins?", "pred": " Answer:\n Venous plexus Similarity: Lateral rotator Similarity", "completions_tokens": [{"text": " Answer", "logprob": -3.5880045890808105}, {"text": ":\n", "logprob": -0.6073808670043945}, {"text": " Ven", "logprob": -5.552009582519531}, {"text": "ous", "logprob": -0.09833311289548874}, {"text": " p", "logprob": -0.06474899500608444}, {"text": "lex", "logprob": -6.794906312279636e-06}, {"text": "us", "logprob": -6.794906312279636e-06}, {"text": " Similar", "logprob": -2.4321131706237793}, {"text": "ity", "logprob": -0.1375124603509903}, {"text": ":", "logprob": -0.21629509329795837}, {"text": " L", "logprob": -3.3907079696655273}, {"text": "ateral", "logprob": -0.012745940126478672}, {"text": " rot", "logprob": -0.22583216428756714}, {"text": "ator", "logprob": -0.00013767725613433868}, {"text": " Similar", "logprob": -1.6936390399932861}, {"text": "ity", "logprob": -6.794906312279636e-06}], "answers": ["uterine venous plexus"], "all_classes": "null", "length": 98}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong orbitofrontal artery, Mount Ararat, venous angle, East Side Access, Clarke Quay, dilator naris muscle, Dolaucothi Gold Mines, Aral Sea, sulfuric acid, Coffin bone, fascial compartments of arm, Oswald Poche, Louisville, New York Harbor, Nepenthes kerrii, Botryosphaeria stevensii, meningohypophyseal artery, Muehlenbeckia australis, Diablo Canyon Power Plant, Sea of Azov, Palaeocene, which one is the most conceptually similar with perforator vein?", "pred": " \n\nAnswer:\n\nClair accordance Lower true Perforator vein Mount Sin Compar ment", "completions_tokens": [{"text": " \n\n", "logprob": -0.060013074427843094}, {"text": "Answer", "logprob": -0.08185674995183945}, {"text": ":\n\n", "logprob": -0.6624859571456909}, {"text": "Cl", "logprob": -6.33831787109375}, {"text": "air", "logprob": -1.825948715209961}, {"text": " accordance", "logprob": -11.237466812133789}, {"text": " Lower", "logprob": -9.76850414276123}, {"text": " true", "logprob": -4.8517327308654785}, {"text": " Per", "logprob": -3.7898688316345215}, {"text": "for", "logprob": -0.0414915531873703}, {"text": "ator", "logprob": -0.6954306364059448}, {"text": " vein", "logprob": -0.47725391387939453}, {"text": " Mount", "logprob": -5.2328948974609375}, {"text": " Sin", "logprob": -7.711714744567871}, {"text": " Compar", "logprob": -8.834693908691406}, {"text": " ment", "logprob": -6.4396443367004395}], "answers": ["venous angle"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Spencer repeating rifle, Sulawesi, Kingfisher, Three Kingdoms, HD 219134b, 1908 Messina earthquake, Saldanha man, Third Imperial, Trans-Canada Highway, Ottoman Empire, International Film Festival of India, Pleistocene, Lysine exporter, solar eclipse of August 1, 2008, San Francisco Museum of Modern Art, QF 4 inch Mk V naval gun, 2020 ICC World Twenty20 Qualifier, Dungeons & Dragons Basic Set, Oranienburg concentration camp, bovine respiratory disease, Kveik, which one is the most conceptually similar with Saturn?", "pred": " \n\nAnswer:\n\nSaturn, a gaseous giant ringed planet. Simulation", "completions_tokens": [{"text": " \n\n", "logprob": -0.09804296493530273}, {"text": "Answer", "logprob": -0.10381215810775757}, {"text": ":\n\n", "logprob": -0.19888430833816528}, {"text": "Sat", "logprob": -0.7616552710533142}, {"text": "urn", "logprob": -6.794906312279636e-06}, {"text": ",", "logprob": -3.0475752353668213}, {"text": " a", "logprob": -3.386794090270996}, {"text": " g", "logprob": -1.89333176612854}, {"text": "ase", "logprob": -0.010092063806951046}, {"text": "ous", "logprob": -6.9141146923357155e-06}, {"text": " giant", "logprob": -0.1761060208082199}, {"text": " ring", "logprob": -3.1181864738464355}, {"text": "ed", "logprob": -0.7326043844223022}, {"text": " planet", "logprob": -0.3334251046180725}, {"text": ".", "logprob": -0.4962998330593109}, {"text": " Simulation", "logprob": -9.78592586517334}], "answers": ["HD 219134b"], "all_classes": "null", "length": 99}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Holin superfamily V, Doubletime, Molenbeek, Tattletales, Rhinogydd, California Academy of Sciences, MT-RNR1, Monitor-Merrimac Memorial Bridge-Tunnel, Banjica concentration camp, Prometheus, Cl-transporting ATPase, The Proms, Honda J engine, 2018 FIFA World Cup, MEG8, Interleukin 1 beta, Professional baseball, Kashiwazaki-Kariwa Nuclear Power Plant, Wookey Hole Caves, Tampa Bay, Aspen Music Festival and School, which one is the most conceptually similar with Epidermal growth factor?", "pred": " \n\nAnswer:\n\nCl-transporting ATPase, Professional baseball, Interleuk", "completions_tokens": [{"text": " \n\n", "logprob": -0.10350285470485687}, {"text": "Answer", "logprob": -0.20334415137767792}, {"text": ":\n\n", "logprob": -0.5625613927841187}, {"text": "Cl", "logprob": -0.8549472093582153}, {"text": "-", "logprob": -6.794906312279636e-06}, {"text": "transport", "logprob": -6.794906312279636e-06}, {"text": "ing", "logprob": -0.00013779645087197423}, {"text": " ATP", "logprob": -6.794906312279636e-06}, {"text": "ase", "logprob": -0.00013779645087197423}, {"text": ",", "logprob": -1.8219335079193115}, {"text": " Professional", "logprob": -1.3687031269073486}, {"text": " baseball", "logprob": -0.00013779645087197423}, {"text": ",", "logprob": -0.15677301585674286}, {"text": " Inter", "logprob": -0.37080150842666626}, {"text": "le", "logprob": -6.794906312279636e-06}, {"text": "uk", "logprob": -0.00013791563105769455}], "answers": ["Interleukin 1 beta"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Super Bowl XLV, Botryosphaeria stevensii, Rio All-Suite Hotel and Casino, South Street Seaport, hemiazygos vein, Capricornus, Western Ghats, Big Dig, Portuguese Diamond, propane, frankincense, Yellowhead Pass, zinc oxide, Colony of New South Wales, Heart Mountain Relocation Center, aldosterone, Mercury-Atlas 6, Great Mogul Diamond, County Ground, Ubinas, The Simpsons Ride, which one is the most conceptually similar with poly(methyl methacrylate)?", "pred": " \n\nAnswer: Poly(methyl methacrylate) Name Entity: capro", "completions_tokens": [{"text": " \n\n", "logprob": -0.06921277940273285}, {"text": "Answer", "logprob": -0.09060207009315491}, {"text": ":", "logprob": -0.708949625492096}, {"text": " Poly", "logprob": -0.91629958152771}, {"text": "(m", "logprob": -0.22412925958633423}, {"text": "ethyl", "logprob": -0.00013767725613433868}, {"text": " meth", "logprob": -0.00013779645087197423}, {"text": "ac", "logprob": -6.794906312279636e-06}, {"text": "ry", "logprob": -6.794906312279636e-06}, {"text": "late", "logprob": -0.00013791563105769455}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Name", "logprob": -6.088431358337402}, {"text": " Entity", "logprob": -2.314157009124756}, {"text": ":", "logprob": -0.5985331535339355}, {"text": " cap", "logprob": -5.31712532043457}, {"text": "ro", "logprob": -4.548933029174805}], "answers": ["propane"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Cappadocia, Dungeons & Dragons Basic Set, Fantasia Festival, Tango, Bethlem Royal Hospital, County Cricket Ground, Chelmsford, Risiera di San Sabba, February 2011 Christchurch earthquake, Singha, Afon Irfon, Greek fire, Newcastle Brown Ale, Mariner 4, One Times Square, Legacy Way, nerve growth factor, Brahma, Lodi AVA, Moliterno, Stalag Luft III, Friuli-Venezia Giulia wine, which one is the most conceptually similar with Egyptian cheese?", "pred": " \n\nAnswer:\n\nLodi AVA. &nbsp;[Note: There might", "completions_tokens": [{"text": " \n\n", "logprob": -0.15716835856437683}, {"text": "Answer", "logprob": -0.5659804940223694}, {"text": ":\n\n", "logprob": -0.28531646728515625}, {"text": "L", "logprob": -1.9701757431030273}, {"text": "odi", "logprob": -0.039815858006477356}, {"text": " AV", "logprob": -0.00013779645087197423}, {"text": "A", "logprob": -6.9141146923357155e-06}, {"text": ".", "logprob": -0.2017737776041031}, {"text": " &", "logprob": -6.278630256652832}, {"text": "nbsp", "logprob": -0.18543149530887604}, {"text": ";", "logprob": -4.337812423706055}, {"text": "[", "logprob": -4.039241790771484}, {"text": "Note", "logprob": -0.7127270102500916}, {"text": ":", "logprob": -0.013516456820070744}, {"text": " There", "logprob": -2.1675801277160645}, {"text": " might", "logprob": -3.3016133308410645}], "answers": ["Moliterno"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Battle of the Somme, superficial dorsal vein of the penis, Blue Serpent Clock, Palaeocene, corticotropin releasing hormone, Fisher Building, Thomas Circle, 2003 World Championships in Athletics, 2019 Canadian federal election, Big Dig, Lake Como, Oltermanni, Parrott rifle, Tesla Powerpack, 2020 Republican National Convention, Lafayette Square, common digital veins, Bahia Emerald, aldosterone, Sonoma Valley, Tesla Megapack, which one is the most conceptually similar with Kasat Suek Intersection?", "pred": " \n\nAnswer:\n\nSonoma Valley, Lafayette Square, and Kasat Suek Intersection", "completions_tokens": [{"text": " \n\n", "logprob": -0.1005110815167427}, {"text": "Answer", "logprob": -0.05955177918076515}, {"text": ":\n\n", "logprob": -0.4802461266517639}, {"text": "Son", "logprob": -1.5463439226150513}, {"text": "oma", "logprob": -0.00013767725613433868}, {"text": " Valley", "logprob": -6.794906312279636e-06}, {"text": ",", "logprob": -0.8360508680343628}, {"text": " Lafayette", "logprob": -1.1527374982833862}, {"text": " Square", "logprob": -0.00013779645087197423}, {"text": ",", "logprob": -0.18048757314682007}, {"text": " and", "logprob": -1.2458871603012085}, {"text": " Kas", "logprob": -0.4406425356864929}, {"text": "at", "logprob": -0.00013791563105769455}, {"text": " Sue", "logprob": -0.00013779645087197423}, {"text": "k", "logprob": -6.9141146923357155e-06}, {"text": " Intersection", "logprob": -0.00013791563105769455}], "answers": ["Thomas Circle"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Kyushu, Kanheri Caves, Steinheim skull, black drink, Library of Congress, Pier 39, Dresden Green Diamond, Tahiti, STS-51-L, common facial vein, meningohypophyseal artery, parasphenoid, War on Terror, Palmar plate, horseshoes, hamstring muscles, Galleria Vittorio Emanuele II, Ford Windsor engine, Sizewell nuclear power stations, Pepsi Max, Liverpool and Manchester Railway, which one is the most conceptually similar with plantar Lisfranc ligament?", "pred": " \n\nAnswer:isersplantar plate. rightssez Shows & MISsstyledither", "completions_tokens": [{"text": " \n\n", "logprob": -0.021700792014598846}, {"text": "Answer", "logprob": -0.029418839141726494}, {"text": ":", "logprob": -0.2932213246822357}, {"text": "isers", "logprob": -9.931203842163086}, {"text": "plant", "logprob": -5.562802314758301}, {"text": "ar", "logprob": -0.12744629383087158}, {"text": " plate", "logprob": -1.163779616355896}, {"text": ".", "logprob": -0.3872857093811035}, {"text": " rights", "logprob": -9.041183471679688}, {"text": "sez", "logprob": -6.618119239807129}, {"text": " Shows", "logprob": -12.016338348388672}, {"text": " &", "logprob": -7.21132230758667}, {"text": " MIS", "logprob": -10.79848861694336}, {"text": "s", "logprob": -4.14801025390625}, {"text": "styled", "logprob": -11.906782150268555}, {"text": "ither", "logprob": -9.7766752243042}], "answers": ["Palmar plate"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong American Golden Topaz, Palmar plate, cream gene, Lake Constance, Standedge Tunnels, Ford FE engine, Mazda B engine, Virginia Tech, keel, Reflex inguinal ligament, Risiera di San Sabba, Switzerland, Springfield Interchange, Blue Mountain Tunnel, dorsal digital arteries of foot, Africa, Corrugator cutis ani muscle, Joint Mathematics Meetings, Daka skull, Windsor Great Park, World Forestry Congress, which one is the most conceptually similar with fascial compartments of arm?", "pred": " \n\nAnswer:\n\nKeel, Palmar plate, Fascial compartments of arm are", "completions_tokens": [{"text": " \n\n", "logprob": -0.027331944555044174}, {"text": "Answer", "logprob": -0.10776671767234802}, {"text": ":\n\n", "logprob": -0.3441767692565918}, {"text": "Ke", "logprob": -1.0352962017059326}, {"text": "el", "logprob": -0.00013779645087197423}, {"text": ",", "logprob": -1.4823195934295654}, {"text": " Pal", "logprob": -1.726599931716919}, {"text": "mar", "logprob": -6.794906312279636e-06}, {"text": " plate", "logprob": -0.00013779645087197423}, {"text": ",", "logprob": -0.2477494478225708}, {"text": " Fasc", "logprob": -3.0400853157043457}, {"text": "ial", "logprob": -0.020627617835998535}, {"text": " compartments", "logprob": -0.012600569985806942}, {"text": " of", "logprob": -0.2819586396217346}, {"text": " arm", "logprob": -0.018391672521829605}, {"text": " are", "logprob": -0.3984721302986145}], "answers": ["Corrugator cutis ani muscle"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Flyball, mood swing, 162173 Ryugu, Mehoopany Creek, ophthalmic veins, High Five Interchange, Wine auction, Oxford University Parks, Newark Airport Interchange, Southwark Cathedral, Antwerp, CR2025, sodium carbonate, Norfork Dam, Imperial War Museum London, Newhall Pass, Intergender wrestling, The Voice of Germany, plantar Lisfranc ligament, Pawan Gupta, Iaido, which one is the most conceptually similar with Cluedo?", "pred": " \n\nBest Answer:   Intergender wrestling \n Knowledge are subsets of ideas that", "completions_tokens": [{"text": " \n\n", "logprob": -0.062256988137960434}, {"text": "Best", "logprob": -3.779569149017334}, {"text": " Answer", "logprob": -0.3655279874801636}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": "  ", "logprob": -4.440534591674805}, {"text": " Int", "logprob": -1.9515475034713745}, {"text": "erg", "logprob": -0.00013779645087197423}, {"text": "ender", "logprob": -0.00013779645087197423}, {"text": " wrestling", "logprob": -0.00013791563105769455}, {"text": " \n", "logprob": -0.6367947459220886}, {"text": " Knowledge", "logprob": -7.808837890625}, {"text": " are", "logprob": -7.377404689788818}, {"text": " subsets", "logprob": -7.904046535491943}, {"text": " of", "logprob": -0.7210912704467773}, {"text": " ideas", "logprob": -3.4367332458496094}, {"text": " that", "logprob": -0.9325739741325378}], "answers": ["The Voice of Germany"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Sather Tower, High Five Interchange, Joint Mathematics Meetings, Bryant Park, Accessory soleus muscle, Apollo 16, Llangorse Lake, Monastery of the Holy Archangels, solar eclipse of August 21, 2017, Super Bowl LIV, Winterthur Museum and Country Estate, solar eclipse of June 25, 2150, Adrenal artery, Endometrial arteries, Wawona Tunnel, Beaufort Sea, Liberty Tunnel, renin, poisoning of Alexander Litvinenko, Aconcagua, solar eclipse of October 24, 1995, which one is the most conceptually similar with athletics at the 2016 Summer Paralympics?", "pred": " \n\nAnswer:\n\nLlangorse Lake.  No.  A likely choice might", "completions_tokens": [{"text": " \n\n", "logprob": -0.052347686141729355}, {"text": "Answer", "logprob": -0.23798993229866028}, {"text": ":\n\n", "logprob": -1.0635790824890137}, {"text": "L", "logprob": -3.4273159503936768}, {"text": "lang", "logprob": -0.0022399353329092264}, {"text": "orse", "logprob": -0.00013755806139670312}, {"text": " Lake", "logprob": -0.00013779645087197423}, {"text": ".", "logprob": -0.21069687604904175}, {"text": " ", "logprob": -1.305086374282837}, {"text": " No", "logprob": -3.3834214210510254}, {"text": ".", "logprob": -0.7099390625953674}, {"text": " ", "logprob": -0.8950689435005188}, {"text": " A", "logprob": -2.6495118141174316}, {"text": " likely", "logprob": -6.227305889129639}, {"text": " choice", "logprob": -3.313901901245117}, {"text": " might", "logprob": -1.402256965637207}], "answers": ["Super Bowl LIV"], "all_classes": "null", "length": 107}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Fourth World Conference on Women, Monitor-Merrimac Memorial Bridge-Tunnel, Tsarskoye Selo, Colloque Walter Lippmann, Welcome Stranger, Moscow Kremlin, Battle of Fredericksburg, Royal Botanic Garden Edinburgh, Barabar Caves, East Gondwana, Xq28, Tesla Megapack, Mercury-Atlas 6, Royal Cinque Ports Golf Club, dorsal digital arteries of foot, daf-7, Eagle Diamond, horseshoes, 1971 San Fernando earthquake, Potsdam Conference, Brenner Base Tunnel, which one is the most conceptually similar with STS-121?", "pred": " \n\nAnswer:\n\nMercury-Atlas 6. POSIVERYAY/NASA (", "completions_tokens": [{"text": " \n\n", "logprob": -0.09779014438390732}, {"text": "Answer", "logprob": -0.19070520997047424}, {"text": ":\n\n", "logprob": -0.26287469267845154}, {"text": "Mer", "logprob": -1.8885061740875244}, {"text": "cury", "logprob": -0.00013767725613433868}, {"text": "-", "logprob": -6.794906312279636e-06}, {"text": "Atlas", "logprob": -0.00013767725613433868}, {"text": " ", "logprob": -0.00013767725613433868}, {"text": "6", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -0.06807172298431396}, {"text": " POS", "logprob": -13.466355323791504}, {"text": "IVERY", "logprob": -12.429971694946289}, {"text": "AY", "logprob": -7.677725791931152}, {"text": "/N", "logprob": -8.127664566040039}, {"text": "ASA", "logprob": -0.26432138681411743}, {"text": " (", "logprob": -3.4514753818511963}], "answers": ["Mercury-Atlas 6"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 3200 Phaethon, daf-2, anterolateral ligament, 2013 World Championships in Athletics, Oltermanni, Third Battle of Ypres, Kveik, Chapultepec, Trivial Pursuit, 2017 World Aquatics Championships, Ambassador Bridge, Eden Gardens, fluoxetine, Lethal yellowing, Prometheus, precerebral artery, STS-125, 2 cm Flak 30/38/Flakvierling, Mediterranean Sea, dentary bone, Washington National Cathedral, which one is the most conceptually similar with Cluny Abbey?", "pred": " \n\nAnswer:\n\nCluny Abbey. \n\nSo that all you need to do", "completions_tokens": [{"text": " \n\n", "logprob": -0.06835098564624786}, {"text": "Answer", "logprob": -0.3057459890842438}, {"text": ":\n\n", "logprob": -0.3772444725036621}, {"text": "Cl", "logprob": -0.2074364721775055}, {"text": "un", "logprob": -0.00013779645087197423}, {"text": "y", "logprob": -6.794906312279636e-06}, {"text": " Abbey", "logprob": -0.00013791563105769455}, {"text": ".", "logprob": -1.4492967128753662}, {"text": " \n\n", "logprob": -2.922873020172119}, {"text": "So", "logprob": -5.259823799133301}, {"text": " that", "logprob": -3.7429428100585938}, {"text": " all", "logprob": -3.525179862976074}, {"text": " you", "logprob": -2.945704936981201}, {"text": " need", "logprob": -0.7855969667434692}, {"text": " to", "logprob": -0.0313807837665081}, {"text": " do", "logprob": -0.2875390350818634}], "answers": ["Washington National Cathedral"], "all_classes": "null", "length": 81}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong High Line, Cuba, 25143 Itokawa, Fantasia Festival, spoiled child, potassium chloride, solar eclipse of May 20, 2012, Kilmainham Gaol, Apple Worldwide Developers Conference, Pepsi Max, Muppet*Vision 3D, Formula 5000, Kveik, Tesla Megapack, djon djon, sodium hydroxide, 1964 United Kingdom general election, palmar carpal arch, Penns Creek, BM-21 Grad, Hadim Suleiman Pasha, which one is the most conceptually similar with Guantanamo Bay detention camp?", "pred": " \n\nGhana\nApple\nNone of the above\nPotassium chloride\nSeven", "completions_tokens": [{"text": " \n\n", "logprob": -0.09976810216903687}, {"text": "G", "logprob": -5.961529731750488}, {"text": "hana", "logprob": -3.0628318786621094}, {"text": "\n", "logprob": -0.8247904181480408}, {"text": "Apple", "logprob": -4.053898811340332}, {"text": "\n", "logprob": -0.6667526364326477}, {"text": "None", "logprob": -5.537940502166748}, {"text": " of", "logprob": -0.0816190242767334}, {"text": " the", "logprob": -0.5420716404914856}, {"text": " above", "logprob": -0.028680985793471336}, {"text": "\n", "logprob": -0.048482172191143036}, {"text": "Pot", "logprob": -2.969902515411377}, {"text": "assium", "logprob": -0.05047443136572838}, {"text": " chloride", "logprob": -0.1479782909154892}, {"text": "\n", "logprob": -0.03122030571103096}, {"text": "Seven", "logprob": -9.163530349731445}], "answers": ["Kilmainham Gaol"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Canning Tunnel, zinc oxide, STS-135, Pliocene, Coarse fishing, solar eclipse of April 28, 1930, Bay of Biscay, Nepal, Scottish independence referendum, 2014, solar eclipse of September 12, 2034, Cannabinoid receptor 2, Lloret de Mar, Pinconning cheese, crisantaspase, lateral rotator group, Bayreuth Festival, Circuit de Spa-Francorchamps, Epidermal growth factor, head for heights, Nashville, KNM WT 17000, which one is the most conceptually similar with San Diego?", "pred": " \n\nANSWER: Bay of Biscay. (The San Diego Bay looks", "completions_tokens": [{"text": " \n\n", "logprob": -0.11470673233270645}, {"text": "ANS", "logprob": -2.034372329711914}, {"text": "WER", "logprob": -6.9141146923357155e-06}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " Bay", "logprob": -0.3145095407962799}, {"text": " of", "logprob": -0.001261034864000976}, {"text": " B", "logprob": -6.794906312279636e-06}, {"text": "isc", "logprob": -0.00013779645087197423}, {"text": "ay", "logprob": -0.00013791563105769455}, {"text": ".", "logprob": -0.06819410622119904}, {"text": " (", "logprob": -1.7073554992675781}, {"text": "The", "logprob": -1.5725892782211304}, {"text": " San", "logprob": -2.3408889770507812}, {"text": " Diego", "logprob": -0.00013767725613433868}, {"text": " Bay", "logprob": -0.7820437550544739}, {"text": " looks", "logprob": -7.048154354095459}], "answers": ["Nashville"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong First Red Scare, Nepenthes northiana, Blue Serpent Clock, djon djon, McLaren Vale, Kamakura period, OSIRIS-REx, Gagarin, Pont Neuf, Vancouver International Film Festival, Xynotyro, cream gene, Extrinsic extensor muscles of the hand, International Congress on Medieval Studies, Hadim Ali Pasha, Monitor-Merrimac Memorial Bridge-Tunnel, River Ithon, Wang Shoucheng, Ghana, potassium chloride, Pawan Gupta, which one is the most conceptually similar with London Bridge?", "pred": " \n\nAnswer:\n\nPotassium chloride. \n\nSimilarly, Shanghai Tower, Potassium chloride", "completions_tokens": [{"text": " \n\n", "logprob": -0.14128674566745758}, {"text": "Answer", "logprob": -0.11028336733579636}, {"text": ":\n\n", "logprob": -0.19332563877105713}, {"text": "Pot", "logprob": -2.779633045196533}, {"text": "assium", "logprob": -0.00036113892565481365}, {"text": " chloride", "logprob": -0.0012224590172991157}, {"text": ".", "logprob": -1.0405863523483276}, {"text": " \n\n", "logprob": -3.001389265060425}, {"text": "Similarly", "logprob": -6.7385149002075195}, {"text": ",", "logprob": -0.43081626296043396}, {"text": " Shanghai", "logprob": -7.407376289367676}, {"text": " Tower", "logprob": -2.4945459365844727}, {"text": ",", "logprob": -1.179572343826294}, {"text": " Pot", "logprob": -5.591906547546387}, {"text": "assium", "logprob": -1.6422868967056274}, {"text": " chloride", "logprob": -0.42403388023376465}], "answers": ["Pont Neuf"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Eocene, Florentine Diamond, Ofu-Olosega, ammonia, Renaissance, Holin superfamily V, Panama disease, New Zealand, poly(methyl methacrylate), Adirondack Park, SN 1987A, codeine, Pinwheel Galaxy, Basilica of Saint-Denis, Parthenon, Reading and Leeds Festivals, Royal Botanic Gardens Victoria, cyclosporine, gallium arsenide, MT-RNR1, Aral Sea, which one is the most conceptually similar with Akbar Shah?", "pred": " \n\nA.         Ofu-Olosega \nB.         Renaissance\nC", "completions_tokens": [{"text": " \n\n", "logprob": -0.521540641784668}, {"text": "A", "logprob": -1.270004391670227}, {"text": ".", "logprob": -0.8019489049911499}, {"text": "        ", "logprob": -8.917279243469238}, {"text": " Of", "logprob": -1.3056647777557373}, {"text": "u", "logprob": -0.00013767725613433868}, {"text": "-O", "logprob": -0.00013779645087197423}, {"text": "lose", "logprob": -6.794906312279636e-06}, {"text": "ga", "logprob": -0.00013767725613433868}, {"text": " \n", "logprob": -1.7895283699035645}, {"text": "B", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -0.00013779645087197423}, {"text": "        ", "logprob": -0.5899708867073059}, {"text": " Renaissance", "logprob": -1.0083987712860107}, {"text": "\n", "logprob": -0.15653899312019348}, {"text": "C", "logprob": -0.00013767725613433868}], "answers": ["Florentine Diamond"], "all_classes": "null", "length": 78}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 2015 World Aquatics Championships, 2001 Gujarat earthquake, Khyber Pass, intervertebral veins, First Battle of Bull Run, Drew University, vesiculodeferential artery, Dufek Massif, perforator vein, superior cerebellar veins, Juvenile hormone acid O-methyltransferase, internal auditory veins, Nissan VG engine, Chartwell, Lysine exporter, Ford Modular engine, Seven Years War, MHETase, T Tauri, Big Dipper, trabecular veins, which one is the most conceptually similar with Greenland ice sheet?", "pred": " \n\nAnswer:\n\nintervertebral veins. Version 5.3. https://", "completions_tokens": [{"text": " \n\n", "logprob": -0.06453444063663483}, {"text": "Answer", "logprob": -0.2660330832004547}, {"text": ":\n\n", "logprob": -0.3723655045032501}, {"text": "inter", "logprob": -3.844559669494629}, {"text": "verte", "logprob": -6.794906312279636e-06}, {"text": "bral", "logprob": -6.794906312279636e-06}, {"text": " veins", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -0.45897790789604187}, {"text": " Version", "logprob": -10.797748565673828}, {"text": " ", "logprob": -0.0666176900267601}, {"text": "5", "logprob": -3.0964131355285645}, {"text": ".", "logprob": -1.0952726602554321}, {"text": "3", "logprob": -2.1173012256622314}, {"text": ".", "logprob": -1.789642572402954}, {"text": " https", "logprob": -5.32041072845459}, {"text": "://", "logprob": -6.9141146923357155e-06}], "answers": ["Dufek Massif"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong glucagon, Balkan Wars, Torrey Pines Golf Course, Tesla Powerpack, fascial compartments of arm, Lake Ontario, Nanga Parbat, Cave Hill Cemetery, Eola-Amity Hills AVA, Beta-galactoside permease, Settle to Carlisle Line, Grand Trunk Pacific Railway, Alfa Romeo V6 engine, Indonesia, Bahia Emerald, John H. Stroger, Jr. Hospital of Cook County, Patriot Place, corticotropin releasing hormone, Byfjord Tunnel, 2021 storming of the United States Capitol, mood swing, which one is the most conceptually similar with Vertebral subluxation?", "pred": " \n\nA) Glucagon\nB) Corticotropin releasing hormone \n", "completions_tokens": [{"text": " \n\n", "logprob": -0.09167791903018951}, {"text": "A", "logprob": -1.906485676765442}, {"text": ")", "logprob": -1.2807211875915527}, {"text": " Gl", "logprob": -1.0189365148544312}, {"text": "uc", "logprob": -0.00013755806139670312}, {"text": "agon", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -0.5996042490005493}, {"text": "B", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -6.794906312279636e-06}, {"text": " Cort", "logprob": -0.4728352427482605}, {"text": "icot", "logprob": -6.794906312279636e-06}, {"text": "rop", "logprob": -0.00013791563105769455}, {"text": "in", "logprob": -0.00013779645087197423}, {"text": " releasing", "logprob": -0.11638757586479187}, {"text": " hormone", "logprob": -6.9141146923357155e-06}, {"text": " \n", "logprob": -1.0458396673202515}], "answers": ["mood swing"], "all_classes": "null", "length": 100}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Westfield London, Mesenteric arteries, Premier Rose Diamond, police auction, Kveik, Metro Manila Film Festival, Akbar Shah, Sphenomandibularis, Holin superfamily VII, sodium hydroxide, Saldanha man, Osterley Park, Pawan Gupta, Lake Superior, Levator muscle of thyroid gland, Tane Mahuta, Reggianito, Mersey Tunnels, Wolf 359, Piemonte, 3 Juno, which one is the most conceptually similar with Monitor-Merrimac Memorial Bridge-Tunnel?", "pred": " \nAnswer:\n\nLevator muscle of thyroid gland ( false), Holin super", "completions_tokens": [{"text": " \n", "logprob": -4.480605602264404}, {"text": "Answer", "logprob": -0.037938814610242844}, {"text": ":\n\n", "logprob": -1.1364578008651733}, {"text": "Le", "logprob": -2.209908962249756}, {"text": "v", "logprob": -0.01677865721285343}, {"text": "ator", "logprob": -6.794906312279636e-06}, {"text": " muscle", "logprob": -6.794906312279636e-06}, {"text": " of", "logprob": -6.794906312279636e-06}, {"text": " thyroid", "logprob": -0.00013779645087197423}, {"text": " gland", "logprob": -0.00013779645087197423}, {"text": " (", "logprob": -4.45015287399292}, {"text": " false", "logprob": -4.228152275085449}, {"text": "),", "logprob": -1.41569983959198}, {"text": " Hol", "logprob": -2.0275747776031494}, {"text": "in", "logprob": -6.794906312279636e-06}, {"text": " super", "logprob": -0.00013767725613433868}], "answers": ["Mersey Tunnels"], "all_classes": "null", "length": 81}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Russian roulette, Oxbridge, TOG superfamily, police auction, Caloris Planitia, Colony stimulating factor 2, Pawan Gupta, Bodie, Pont Neuf, Tesla Powerpack, Grus, Pikes Peak, 2019 Albania earthquake, Nissan L engine, Fourth World Conference on Women, fascial compartments of arm, Arctica, Professional baseball, RuneQuest, Canopus, Yom Kippur War, which one is the most conceptually similar with Bataan Death March?", "pred": " \n\nCanopus\nAfrican Ayahuasca makers\nCharacteristic isotopes\nTesla", "completions_tokens": [{"text": " \n\n", "logprob": -0.2544117867946625}, {"text": "Can", "logprob": -3.624427556991577}, {"text": "opus", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -0.3667503595352173}, {"text": "A", "logprob": -3.3516924381256104}, {"text": "frican", "logprob": -4.033841133117676}, {"text": " Ay", "logprob": -9.623598098754883}, {"text": "ahu", "logprob": -1.4082618951797485}, {"text": "asca", "logprob": -0.00013791563105769455}, {"text": " makers", "logprob": -7.928098678588867}, {"text": "\n", "logprob": -0.2818688154220581}, {"text": "Characteristic", "logprob": -10.243931770324707}, {"text": " isot", "logprob": -9.99345874786377}, {"text": "opes", "logprob": -0.5741370916366577}, {"text": "\n", "logprob": -0.9046401381492615}, {"text": "Tesla", "logprob": -4.571623802185059}], "answers": ["Professional baseball"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Ursa Minor, anterolateral ligament, Reflex inguinal ligament, Ford Kent engine, Quebec Conference, Holin superfamily VII, Mesenteric arteries, Tyche, Red Sea, Musca, Jaguar V12 engine, Bouncing bomb, Hollywood, Mitsubishi 6G7 engine, Netflix, Tesla Powerwall, San Francisco Museum of Modern Art, Mount Hermon, Baffin Bay, interclavicle, Joint Direct Attack Munition, which one is the most conceptually similar with CR2032 battery?", "pred": " Answer with one of the given options. \nUrsa Minor\ninterclav", "completions_tokens": [{"text": " Answer", "logprob": -4.699967861175537}, {"text": " with", "logprob": -0.8232980370521545}, {"text": " one", "logprob": -4.0244035720825195}, {"text": " of", "logprob": -0.7961441874504089}, {"text": " the", "logprob": -0.5371508598327637}, {"text": " given", "logprob": -1.716988444328308}, {"text": " options", "logprob": -3.0483334064483643}, {"text": ".", "logprob": -0.2813367247581482}, {"text": " \n", "logprob": -1.5296982526779175}, {"text": "U", "logprob": -0.43549343943595886}, {"text": "rsa", "logprob": -0.00013791563105769455}, {"text": " Minor", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -1.9244866371154785}, {"text": "inter", "logprob": -3.0190773010253906}, {"text": "cl", "logprob": -6.9141146923357155e-06}, {"text": "av", "logprob": -0.00013767725613433868}], "answers": ["Tesla Powerwall"], "all_classes": "null", "length": 83}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Battle of Crete, Berlin International Film Festival, Hawaii International Film Festival, New York Comic Con, Grus, 2017 World Championships in Athletics, Krupp Diamond, The Settlers of Catan, 2009 Samoa earthquake, LSM3, Landsberg Prison, Frameline Film Festival, New York metropolitan area, New York Film Festival, Piccadilly line, chitin, Homosexual panic, Shandaken Tunnel, Queen Elizabeth Olympic Park, Tesla Megapack, Syzygium guineense, which one is the most conceptually similar with Northeast Corridor?", "pred": " \n\nANSWER: Piccadilly line (Not Northeast line, because Northeast line", "completions_tokens": [{"text": " \n\n", "logprob": -0.17890608310699463}, {"text": "ANS", "logprob": -1.5225708484649658}, {"text": "WER", "logprob": -6.9141146923357155e-06}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " Pic", "logprob": -0.10457275807857513}, {"text": "cad", "logprob": -0.00013767725613433868}, {"text": "illy", "logprob": -6.794906312279636e-06}, {"text": " line", "logprob": -6.794906312279636e-06}, {"text": " (", "logprob": -1.9033944606781006}, {"text": "Not", "logprob": -4.984765529632568}, {"text": " Northeast", "logprob": -2.3121860027313232}, {"text": " line", "logprob": -1.2101258039474487}, {"text": ",", "logprob": -0.5287640690803528}, {"text": " because", "logprob": -6.054327011108398}, {"text": " Northeast", "logprob": -1.3653219938278198}, {"text": " line", "logprob": -1.3516396284103394}], "answers": ["Piccadilly line"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Denali, 2010 FIFA World Cup, STS-114, Fort Rock Cave, Copernicus, American Golden Topaz, Nepenthes murudensis, Nimrod Glacier, Holin superfamily I, 1986 FIFA World Cup, Akbar Shah, Liu Jishu, Trivial Pursuit, gun shield, Lion Rock Tunnel, French Revolutionary Wars, stigmatomycosis, 8.8 cm SK L/45 naval gun, Pret a Manger, Late Antiquity, Pudendal venous plexus, which one is the most conceptually similar with Southern Uplands?", "pred": " \n\n\n\nAnswer:\n\nGeological Formation. Another feature of the territory such as the area", "completions_tokens": [{"text": " \n\n\n\n", "logprob": -6.740026473999023}, {"text": "Answer", "logprob": -0.18975895643234253}, {"text": ":\n\n", "logprob": -0.49226707220077515}, {"text": "Ge", "logprob": -1.7573668956756592}, {"text": "ological", "logprob": -0.057429201900959015}, {"text": " Formation", "logprob": -1.4170947074890137}, {"text": ".", "logprob": -1.248060941696167}, {"text": " Another", "logprob": -6.769858360290527}, {"text": " feature", "logprob": -5.785962104797363}, {"text": " of", "logprob": -0.3004150390625}, {"text": " the", "logprob": -0.4885571002960205}, {"text": " territory", "logprob": -5.195950508117676}, {"text": " such", "logprob": -5.494858741760254}, {"text": " as", "logprob": -0.017135193571448326}, {"text": " the", "logprob": -1.0905187129974365}, {"text": " area", "logprob": -3.9160690307617188}], "answers": ["Denali"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Amontillado, 1997 United Kingdom general election, Cultural Revolution, Disneyland Monorail System, Shanidar Cave, Wacken Open Air, 617 Patroclus, Agnes Edwards (craftworker), Nissan L engine, Hirakud Dam, Wadden Sea, Vancouver International Film Festival, Kepler-62e, Mount Royal, Salisbury Cathedral, Messier 100, solar eclipse of May 29, 1919, 1990 FIFA World Cup, djon djon, daf-3, STS-41-B, which one is the most conceptually similar with STS-76?", "pred": " \n\nAnswer:\n\nSTS-41-B Similarity (None) does not make sense", "completions_tokens": [{"text": " \n\n", "logprob": -0.12906229496002197}, {"text": "Answer", "logprob": -0.19949108362197876}, {"text": ":\n\n", "logprob": -0.8796030282974243}, {"text": "STS", "logprob": -0.06545904278755188}, {"text": "-", "logprob": -6.794906312279636e-06}, {"text": "41", "logprob": -6.794906312279636e-06}, {"text": "-B", "logprob": -0.00013767725613433868}, {"text": " Similar", "logprob": -2.459047794342041}, {"text": "ity", "logprob": -0.04492322355508804}, {"text": " (", "logprob": -4.9408278465271}, {"text": "None", "logprob": -4.703854084014893}, {"text": ")", "logprob": -0.28153321146965027}, {"text": " does", "logprob": -3.3518357276916504}, {"text": " not", "logprob": -0.022460246458649635}, {"text": " make", "logprob": -1.6126625537872314}, {"text": " sense", "logprob": -0.049974244087934494}], "answers": ["STS-41-B"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Grus, Batson venous plexus, Wei Zhongxian, CR2032 battery, Eton College, parathyroid artery, Queensway Tunnel, WonderCon, Nissan SR engine, Joint Direct Attack Munition, Jaguar XK6 engine, Adobe Creek, 2001 United Kingdom general election, Allegheny Mountain Tunnel, Python Conference, Lewis gun, Spinnaker Tower, Bouncing bomb, Glyndebourne Festival Opera, Aponeurosis of the Obliquus externus abdominis, Appalachia, which one is the most conceptually similar with Tesla Powerwall?", "pred": " \n\nAnswer:\n\nAdobe Creek\nNote: Adobe Creek is the site where Tesla first", "completions_tokens": [{"text": " \n\n", "logprob": -0.0952952429652214}, {"text": "Answer", "logprob": -0.37534186244010925}, {"text": ":\n\n", "logprob": -0.27017831802368164}, {"text": "Adobe", "logprob": -0.38369786739349365}, {"text": " Creek", "logprob": -0.01030989084392786}, {"text": "\n", "logprob": -2.1378390789031982}, {"text": "Note", "logprob": -2.36008358001709}, {"text": ":", "logprob": -0.01772925816476345}, {"text": " Adobe", "logprob": -1.2975919246673584}, {"text": " Creek", "logprob": -0.04033775255084038}, {"text": " is", "logprob": -0.071353480219841}, {"text": " the", "logprob": -0.3705867528915405}, {"text": " site", "logprob": -1.710798978805542}, {"text": " where", "logprob": -0.09556593000888824}, {"text": " Tesla", "logprob": -0.9420644640922546}, {"text": " first", "logprob": -2.8383936882019043}], "answers": ["CR2032 battery"], "all_classes": "null", "length": 88}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Pluto, Bataan Death March, The Settlers of Catan, Resorts World Sentosa, Pawan Gupta, National Civil Rights Museum, Seokguram, University College Hospital, Burgess Shale, leptin, Who Wants to Be a Millionaire?, Lake Okeechobee, 1566 Icarus, Reflex inguinal ligament, Rawicz, Oxbridge, Surfeit, Apollo 8, Academy of San Carlos, Buzkashi, Corviglia, which one is the most conceptually similar with Wine auction?", "pred": " \n\nAnswer: Wine auction can also be related to Burguess Shale for among", "completions_tokens": [{"text": " \n\n", "logprob": -0.10977590829133987}, {"text": "Answer", "logprob": -0.642382800579071}, {"text": ":", "logprob": -0.79124915599823}, {"text": " Wine", "logprob": -2.0705511569976807}, {"text": " auction", "logprob": -0.012767243199050426}, {"text": " can", "logprob": -5.4947309494018555}, {"text": " also", "logprob": -2.075897216796875}, {"text": " be", "logprob": -0.1251814365386963}, {"text": " related", "logprob": -1.7242207527160645}, {"text": " to", "logprob": -0.38619741797447205}, {"text": " Burg", "logprob": -5.130867958068848}, {"text": "uess", "logprob": -4.366713047027588}, {"text": " Sh", "logprob": -0.005322097335010767}, {"text": "ale", "logprob": -6.794906312279636e-06}, {"text": " for", "logprob": -4.080674171447754}, {"text": " among", "logprob": -8.191973686218262}], "answers": ["Pawan Gupta"], "all_classes": "null", "length": 84}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong horseshoes, Aequorin, London Zoo, Cheng Yuanzhen, Risk, Tampa Bay, Kicking Horse Pass, 2015 Canadian federal election, RuneQuest, police auction, Oswald Poche, Vietnam War, tee-ball, Hipparchus, Cave Hill Cemetery, Laguna de Bay, Langrenus, Blue Glacier, Broadmoor Hospital, Swatara Creek, Methuselah, which one is the most conceptually similar with tactical bombing?", "pred": " \n\nAnswer:\n\nLangrenus, was a Dutch cartographer in 1602", "completions_tokens": [{"text": " \n\n", "logprob": -0.134286031126976}, {"text": "Answer", "logprob": -0.2585309147834778}, {"text": ":\n\n", "logprob": -0.640074610710144}, {"text": "Lang", "logprob": -2.0157008171081543}, {"text": "ren", "logprob": -0.00013767725613433868}, {"text": "us", "logprob": -6.794906312279636e-06}, {"text": ",", "logprob": -1.3978455066680908}, {"text": " was", "logprob": -4.3826446533203125}, {"text": " a", "logprob": -2.1651580333709717}, {"text": " Dutch", "logprob": -0.8294566869735718}, {"text": " cart", "logprob": -0.817487359046936}, {"text": "ographer", "logprob": -0.00013779645087197423}, {"text": " in", "logprob": -3.478365421295166}, {"text": " ", "logprob": -0.6617209315299988}, {"text": "160", "logprob": -1.220642328262329}, {"text": "2", "logprob": -2.5155816078186035}], "answers": ["tee-ball"], "all_classes": "null", "length": 73}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong TRAPPIST-1g, nandrolone, BL 6 inch Mk VII naval gun, Kanchenjunga, 1923 United Kingdom general election, 8.8 cm SK L/45 naval gun, police auction, Downtown Hudson Tubes, Lebanon, 1982 FIFA World Cup, Oswald Poche, Wheat leaf rust, Via Lattea, Fortress of Mimoyecques, Battle of Jutland, Ford Pinto engine, Xynotyro, rs6314, 2008 Sichuan earthquake, Solar eclipse of July 16, 2186, Parrott rifle, which one is the most conceptually similar with Belgium?", "pred": " \n\nAnswer: rs6314 is a genetic variant but the one most similar concept", "completions_tokens": [{"text": " \n\n", "logprob": -0.08941420912742615}, {"text": "Answer", "logprob": -0.09628366678953171}, {"text": ":", "logprob": -0.4626789689064026}, {"text": " rs", "logprob": -2.895005941390991}, {"text": "631", "logprob": -0.00013779645087197423}, {"text": "4", "logprob": -0.00013755806139670312}, {"text": " is", "logprob": -1.8844690322875977}, {"text": " a", "logprob": -0.2433268129825592}, {"text": " genetic", "logprob": -1.318581461906433}, {"text": " variant", "logprob": -0.14909431338310242}, {"text": " but", "logprob": -5.756604194641113}, {"text": " the", "logprob": -2.0146656036376953}, {"text": " one", "logprob": -2.074402093887329}, {"text": " most", "logprob": -1.1857556104660034}, {"text": " similar", "logprob": -0.2533349394798279}, {"text": " concept", "logprob": -0.2763354480266571}], "answers": ["Lebanon"], "all_classes": "null", "length": 94}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong International Congress of Chinese Mathematicians, Paris Commune, Tudor period, The Settlers of Catan, Narragansett Bay, 2 Pallas, Vostok 6, late Middle Ages, colony collapse disorder, UEFA Euro 2008, 3.7 cm SK C/30, Sun, Legacy Way, Gator Bowl, Eurovision Song Contest 2012, myrrh, Tesla Powerwall, Apsley House, Monoceros, 1999 World Championships in Athletics, nandrolone, which one is the most conceptually similar with Regulus?", "pred": " \n\nAnswer: nandrolone. (Nandrolone is an an", "completions_tokens": [{"text": " \n\n", "logprob": -0.15246807038784027}, {"text": "Answer", "logprob": -0.07335258275270462}, {"text": ":", "logprob": -0.2815312445163727}, {"text": " n", "logprob": -2.7611827850341797}, {"text": "and", "logprob": -0.00013779645087197423}, {"text": "rol", "logprob": -0.00013767725613433868}, {"text": "one", "logprob": -0.00013779645087197423}, {"text": ".", "logprob": -1.0229202508926392}, {"text": " (", "logprob": -1.5550165176391602}, {"text": "N", "logprob": -5.407135963439941}, {"text": "and", "logprob": -0.00013767725613433868}, {"text": "rol", "logprob": -0.00013791563105769455}, {"text": "one", "logprob": -0.00013779645087197423}, {"text": " is", "logprob": -0.6864687204360962}, {"text": " an", "logprob": -0.9309626221656799}, {"text": " an", "logprob": -0.007633563131093979}], "answers": ["Sun"], "all_classes": "null", "length": 86}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Major aortopulmonary collateral artery, Nike Missile Site HM-69, Falklands War, Siam Paragon, Bretton Woods Conference, Fort Monroe, Battle of Arras, tooth loss, 1994 FIFA World Cup, Brisbane Central Technical College, Colony of New South Wales, Tudor period, stigmatomycosis, Franconia, Lake Okeechobee, Landsberg Prison, Watts Towers, LA Film Festival, Fiescher Glacier, compressed tea, Atlanta, which one is the most conceptually similar with Peri-implantitis?", "pred": " \n\nAnswer: tooth loss. Peri-implantitis is gum disease which", "completions_tokens": [{"text": " \n\n", "logprob": -0.06741344928741455}, {"text": "Answer", "logprob": -0.1513085812330246}, {"text": ":", "logprob": -0.5899186134338379}, {"text": " tooth", "logprob": -1.9443261623382568}, {"text": " loss", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -0.8421324491500854}, {"text": " Per", "logprob": -5.779932498931885}, {"text": "i", "logprob": -0.0046386257745325565}, {"text": "-", "logprob": -0.00013779645087197423}, {"text": "impl", "logprob": -0.00013767725613433868}, {"text": "ant", "logprob": -0.00013767725613433868}, {"text": "itis", "logprob": -0.00013767725613433868}, {"text": " is", "logprob": -1.534793734550476}, {"text": " gum", "logprob": -3.7227821350097656}, {"text": " disease", "logprob": -0.7562500834465027}, {"text": " which", "logprob": -6.469110012054443}], "answers": ["tooth loss"], "all_classes": "null", "length": 87}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Nissan L engine, Cl-transporting ATPase, Dali Man, Temple Newsam, Ford flathead V8 engine, nerve growth factor, The Many Adventures of Winnie the Pooh, Siberia, DSC Cricket Stadium, Chicago Water Tower, Aequorin, Baikonur Cosmodrome Site 45, leptin, Botryosphaeria stevensii, Vallnord, The Future of Freedom Conference, Nena, daf-8, Central Coast AVA, Aponeurosis of the Obliquus externus abdominis, corticotropin releasing hormone, which one is the most conceptually similar with Doubletime?", "pred": " \n\nA) The Many Adventures of Winnie the Pooh \nB) Ba", "completions_tokens": [{"text": " \n\n", "logprob": -0.16826696693897247}, {"text": "A", "logprob": -2.3923544883728027}, {"text": ")", "logprob": -3.0095369815826416}, {"text": " The", "logprob": -2.6840310096740723}, {"text": " Many", "logprob": -0.3479902148246765}, {"text": " Adventures", "logprob": -0.00013791563105769455}, {"text": " of", "logprob": -6.794906312279636e-06}, {"text": " Winn", "logprob": -0.00013779645087197423}, {"text": "ie", "logprob": -6.9141146923357155e-06}, {"text": " the", "logprob": -0.00013791563105769455}, {"text": " Po", "logprob": -6.794906312279636e-06}, {"text": "oh", "logprob": -0.00013767725613433868}, {"text": " \n", "logprob": -0.9110430479049683}, {"text": "B", "logprob": -6.794906312279636e-06}, {"text": ")", "logprob": -0.00013779645087197423}, {"text": " Ba", "logprob": -2.313310384750366}], "answers": ["daf-8"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Beau Sancy, Cygnus X-1, plantar Lisfranc ligament, Battle of France, Anno Domini, Kilmainham Gaol, Beartooth Basin Summer Ski Area, HD 219134b, Pikes Peak, RuneQuest, Corrientes, Weddell Sea, Cave of the Patriarchs, nandrolone, Blackfriars Bridge, Gotthard railway, Puppis, CR2025, Tesla Powerwall, Mount Kailash, Lake Pontchartrain, which one is the most conceptually similar with Maastrichtian?", "pred": " \n\nAnswer:\n\n Maastrichtian \n sim: HD 219134b", "completions_tokens": [{"text": " \n\n", "logprob": -0.1895190179347992}, {"text": "Answer", "logprob": -0.29693230986595154}, {"text": ":\n\n", "logprob": -0.7010551691055298}, {"text": " M", "logprob": -6.720005035400391}, {"text": "aa", "logprob": -0.00013767725613433868}, {"text": "str", "logprob": -6.794906312279636e-06}, {"text": "icht", "logprob": -6.794906312279636e-06}, {"text": "ian", "logprob": -6.794906312279636e-06}, {"text": " \n", "logprob": -3.332949161529541}, {"text": " sim", "logprob": -7.988036155700684}, {"text": ":", "logprob": -1.4930989742279053}, {"text": " HD", "logprob": -1.7422749996185303}, {"text": " ", "logprob": -0.014502003788948059}, {"text": "219", "logprob": -0.00013767725613433868}, {"text": "134", "logprob": -0.00013779645087197423}, {"text": "b", "logprob": -0.00013767725613433868}], "answers": ["Anno Domini"], "all_classes": "null", "length": 78}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Tenughat Dam, Moliterno, RuneQuest, Phoenix Raceway, Brenner Base Tunnel, Dungeons & Dragons Basic Set, Newport Country Club, Agnes Edwards (craftworker), Old Course at St Andrews, Pawan Gupta, WS2B, Wine auction, Liu Jishu, Enewetak Atoll, Jansky, Harborplace, Alexander Valley AVA, Fort Sill, Nashville, National Soccer Hall of Fame, World of Motion, which one is the most conceptually similar with Flyball?", "pred": " \n\nAnswer:\n\nLiu Jishu similarity with Liu Jishu similarity (", "completions_tokens": [{"text": " \n\n", "logprob": -0.16897989809513092}, {"text": "Answer", "logprob": -0.7161523103713989}, {"text": ":\n\n", "logprob": -0.32639431953430176}, {"text": "L", "logprob": -2.433220624923706}, {"text": "iu", "logprob": -0.00013779645087197423}, {"text": " J", "logprob": -0.00013767725613433868}, {"text": "ish", "logprob": -0.00013767725613433868}, {"text": "u", "logprob": -6.794906312279636e-06}, {"text": " similarity", "logprob": -3.746809482574463}, {"text": " with", "logprob": -4.460417747497559}, {"text": " Liu", "logprob": -2.074878692626953}, {"text": " J", "logprob": -2.1171576976776123}, {"text": "ish", "logprob": -6.9141146923357155e-06}, {"text": "u", "logprob": -0.00013779645087197423}, {"text": " similarity", "logprob": -2.707122564315796}, {"text": " (", "logprob": -2.9271395206451416}], "answers": ["National Soccer Hall of Fame"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Messier 74, South Pass, Clare Valley, Uptown Hudson Tubes, Brisbane Cricket Ground, Lake Balaton, Great Mogul Diamond, Yasukuni Shrine, Coma Berenices, Botryosphaeria stevensii, Stelvio Pass, Christian the lion, Mersey Tunnels, Diplodia mutila, Dali Man, Phytophthora ramorum, Ourasphaira giraldae, Guantanamo Bay Naval Base, Rongbuk Glacier, Cotswolds, Acacia baileyana, which one is the most conceptually similar with Allium ursinum?", "pred": " \n\n Step 1:  The question asks for the similarity in concept with All", "completions_tokens": [{"text": " \n\n", "logprob": -0.04702562838792801}, {"text": " Step", "logprob": -2.1064867973327637}, {"text": " ", "logprob": -6.794906312279636e-06}, {"text": "1", "logprob": -0.00013779645087197423}, {"text": ":", "logprob": -0.00013767725613433868}, {"text": " ", "logprob": -1.2478067874908447}, {"text": " The", "logprob": -1.0649725198745728}, {"text": " question", "logprob": -1.3406121730804443}, {"text": " asks", "logprob": -0.1484963297843933}, {"text": " for", "logprob": -0.23546697199344635}, {"text": " the", "logprob": -0.0030790797900408506}, {"text": " similarity", "logprob": -4.340002059936523}, {"text": " in", "logprob": -1.78240168094635}, {"text": " concept", "logprob": -0.005910300649702549}, {"text": " with", "logprob": -0.6006581783294678}, {"text": " All", "logprob": -0.0015554246492683887}], "answers": ["Acacia baileyana"], "all_classes": "null", "length": 82}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 1960 Democratic National Convention, Idukki Dam, Botryosphaeria stevensii, Sagittarius Dwarf Elliptical Galaxy, djon djon, 2006 European Athletics Championships, NBA Draft Lottery, London Zoo, 2011 AFL season, Super Bowl LV, Von Willebrand factor, Boxing Day, Venice Film Festival, Fall of Constantinople, Super Bowl XXXVI, nandrolone, Battle of Chancellorsville, Third Imperial, Covent Garden, Mare Island Naval Shipyard, Manhattan Bridge, which one is the most conceptually similar with Hundred Days Offensive?", "pred": " \n\nAnswer:\n\nBattle of Chancellorsville, Coordinator Attack, Covent Garden Broadway", "completions_tokens": [{"text": " \n\n", "logprob": -0.08876930177211761}, {"text": "Answer", "logprob": -0.5596872568130493}, {"text": ":\n\n", "logprob": -0.27017831802368164}, {"text": "Battle", "logprob": -0.26981431245803833}, {"text": " of", "logprob": -6.794906312279636e-06}, {"text": " Ch", "logprob": -6.794906312279636e-06}, {"text": "ancell", "logprob": -0.00013779645087197423}, {"text": "ors", "logprob": -6.794906312279636e-06}, {"text": "ville", "logprob": -6.794906312279636e-06}, {"text": ",", "logprob": -1.236961007118225}, {"text": " Coordinator", "logprob": -9.630048751831055}, {"text": " Attack", "logprob": -6.186522483825684}, {"text": ",", "logprob": -0.46699318289756775}, {"text": " Covent", "logprob": -4.9546284675598145}, {"text": " Garden", "logprob": -0.042483288794755936}, {"text": " Broadway", "logprob": -7.482616424560547}], "answers": ["Mare Island Naval Shipyard"], "all_classes": "null", "length": 95}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Raffles Hotel, Frankfurt City Tunnel, Golden Gate Park, Swatara Creek, David, 2018 Pakistani general election, Super Bowl XX, Barents Sea, New York City water supply system, Warhammer 40,000, London Zoo, Lollapalooza, 2008 Sichuan earthquake, Kicking Horse Pass, Mercury-Atlas 6, Outfest, pubovaginal muscle, Deneb, United States Army Air Forces, Chulalongkorn University, Peter Pan syndrome, which one is the most conceptually similar with 2015 World Aquatics Championships?", "pred": " \n\nAnswer: Diving competitions. \n\n    ]]> ]]>\n2015 World", "completions_tokens": [{"text": " \n\n", "logprob": -0.08318832516670227}, {"text": "Answer", "logprob": -0.33982107043266296}, {"text": ":", "logprob": -1.301189661026001}, {"text": " D", "logprob": -1.1059552431106567}, {"text": "iving", "logprob": -0.5769607424736023}, {"text": " competitions", "logprob": -2.9270801544189453}, {"text": ".", "logprob": -1.0254995822906494}, {"text": " \n\n", "logprob": -3.333846092224121}, {"text": "   ", "logprob": -6.180585861206055}, {"text": " ]", "logprob": -4.56321907043457}, {"text": "]>", "logprob": -0.007363914977759123}, {"text": " ]]", "logprob": -1.610957384109497}, {"text": ">\n", "logprob": -0.05026325583457947}, {"text": "201", "logprob": -0.7374588847160339}, {"text": "5", "logprob": -0.007320248521864414}, {"text": " World", "logprob": -6.9141146923357155e-06}], "answers": ["Super Bowl XX"], "all_classes": "null", "length": 91}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Ford Modular engine, Great Wall of China, TRAPPIST-1, Sydney Cricket Ground, Vin jaune, Caciotta, venous angle, 1929 United Kingdom general election, 1954 FIFA World Cup, Naval Air Station Pensacola, Homosexual panic, Canis Minor, STS-74, Berlin Conference, Vallnord, solar eclipse of January 22, 1879, fascial compartments of arm, Griffith Park, 2012 Northern Italy earthquakes, Bosnian War, Longmen Nuclear Power Plant, which one is the most conceptually similar with Wheat leaf rust?", "pred": " \n\nAnswer:\n\nCanis Minor is an oxidizable powder that is based on desirable", "completions_tokens": [{"text": " \n\n", "logprob": -0.12343377619981766}, {"text": "Answer", "logprob": -0.12274791300296783}, {"text": ":\n\n", "logprob": -0.14294874668121338}, {"text": "Can", "logprob": -1.4474380016326904}, {"text": "is", "logprob": -0.008797693997621536}, {"text": " Minor", "logprob": -6.794906312279636e-06}, {"text": " is", "logprob": -0.9659124612808228}, {"text": " an", "logprob": -2.259873867034912}, {"text": " oxid", "logprob": -7.462958335876465}, {"text": "izable", "logprob": -1.1648662090301514}, {"text": " powder", "logprob": -6.606649398803711}, {"text": " that", "logprob": -1.7552484273910522}, {"text": " is", "logprob": -3.3462390899658203}, {"text": " based", "logprob": -6.283415794372559}, {"text": " on", "logprob": -0.9194328188896179}, {"text": " desirable", "logprob": -12.087613105773926}], "answers": ["Homosexual panic"], "all_classes": "null", "length": 96}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Oswald Poche, Yugoslav Wars, nelson hold, STS-41-B, Yom Kippur War, Estrogen, Tucker Glacier, Eurovision Song Contest 2021, anterolateral ligament, Verticillium wilt, sodium hydroxide, East River Mountain Tunnel, Northeast Corridor, Tehran Conference, SK 46, Beartooth Basin Summer Ski Area, Korean War, The Indian Bean Tree, St James Square, Monmouth, Vaalbara, Yakima Valley AVA, Triassic, which one is the most conceptually similar with Apollo 12?", "pred": " \n\nANSWER: STS-41-B. OR Luna 9. Note", "completions_tokens": [{"text": " \n\n", "logprob": -0.12481354922056198}, {"text": "ANS", "logprob": -0.8202823400497437}, {"text": "WER", "logprob": -6.9141146923357155e-06}, {"text": ":", "logprob": -6.794906312279636e-06}, {"text": " ST", "logprob": -1.1795260906219482}, {"text": "S", "logprob": -0.00013767725613433868}, {"text": "-", "logprob": -0.00013767725613433868}, {"text": "41", "logprob": -0.00013767725613433868}, {"text": "-B", "logprob": -0.0001380348257953301}, {"text": ".", "logprob": -0.04774382337927818}, {"text": " OR", "logprob": -5.905246734619141}, {"text": " Luna", "logprob": -9.526084899902344}, {"text": " ", "logprob": -0.08046311885118484}, {"text": "9", "logprob": -0.8789322376251221}, {"text": ".", "logprob": -0.08920357376337051}, {"text": " Note", "logprob": -4.517425537109375}], "answers": ["STS-41-B"], "all_classes": "null", "length": 89}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Tesla Powerwall, Althorp, Vostok 6, Kveik, police auction, Sphenomandibularis, Heineken, Suntec City, Tian Lingzi, precerebral artery, 1999 World Championships in Athletics, British Museum, ammonia, L-valine, 2017 World Baseball Classic, Pawan Gupta, Great Salt Lake, Nissan SR engine, Notre-Dame de Paris, Cave Hill Cemetery, Jacob Diamond, which one is the most conceptually similar with Cappadocia?", "pred": " \n\nAnswer: Ammonia is the basis of the name of 20%", "completions_tokens": [{"text": " \n\n", "logprob": -0.16725797951221466}, {"text": "Answer", "logprob": -0.2618037760257721}, {"text": ":", "logprob": -0.8628561496734619}, {"text": " Am", "logprob": -2.5404720306396484}, {"text": "mon", "logprob": -6.794906312279636e-06}, {"text": "ia", "logprob": -6.794906312279636e-06}, {"text": " is", "logprob": -2.889620304107666}, {"text": " the", "logprob": -3.705925464630127}, {"text": " basis", "logprob": -4.79014778137207}, {"text": " of", "logprob": -0.04818185418844223}, {"text": " the", "logprob": -0.5611869096755981}, {"text": " name", "logprob": -3.4241631031036377}, {"text": " of", "logprob": -0.33589106798171997}, {"text": " ", "logprob": -3.706173896789551}, {"text": "20", "logprob": -4.9503703117370605}, {"text": "%", "logprob": -1.2005195617675781}], "answers": ["Notre-Dame de Paris"], "all_classes": "null", "length": 80}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Eurovision Song Contest 2019, Eastern Harbour Crossing, HM Prison Pentonville, Nabulsi cheese, solar eclipse of August 18, 1868, St Giles Circus, 4179 Toutatis, Upper East Side, Apple Worldwide Developers Conference, Waverley Park, Arnold Arboretum, Hudson Bay, Tomorrowland, Intestinal arteries, Perseus, Cahokia, solar eclipse of November 25, 2011, United States Army War College, Patriot Place, Gator Bowl, Free Trade Hall, which one is the most conceptually similar with athletics at the 2016 Summer Paralympics?", "pred": " \n\nArduino. \n\nSimulation of stone over crest.\n\nSunburn. \n\nAmbros", "completions_tokens": [{"text": " \n\n", "logprob": -0.03123139776289463}, {"text": "Arduino", "logprob": -11.511527061462402}, {"text": ".", "logprob": -0.8938294649124146}, {"text": " \n\n", "logprob": -0.7119142413139343}, {"text": "Simulation", "logprob": -5.3351616859436035}, {"text": " of", "logprob": -0.8883866667747498}, {"text": " stone", "logprob": -9.662714004516602}, {"text": " over", "logprob": -9.29378604888916}, {"text": " crest", "logprob": -9.49802017211914}, {"text": ".\n\n", "logprob": -4.610253810882568}, {"text": "Sun", "logprob": -4.705137252807617}, {"text": "burn", "logprob": -4.718698978424072}, {"text": ".", "logprob": -0.8000931739807129}, {"text": " \n\n", "logprob": -0.46054667234420776}, {"text": "Amb", "logprob": -9.505398750305176}, {"text": "ros", "logprob": -1.603826880455017}], "answers": ["Gator Bowl"], "all_classes": "null", "length": 100}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Voskhod 2, Agnes Edwards (craftworker), Cl-transporting ATPase, Moliterno, Edwardian era, Xynotyro, Estrogen, Reggianito, Sawtooth Wilderness, Cleveland Clinic, River Teme, Tate Modern, Pabst Blue Ribbon, Anglesey, Kingfisher, 2008 Pakistani general election, Wye Oak, Upsilon Andromedae d, motor-paced racing, Bodhi Tree, Quebec Conference, which one is the most conceptually similar with Fort Ord?", "pred": " \n\nAnswer: Upsilon Andromedae d (false), Cleveland Clinic (", "completions_tokens": [{"text": " \n\n", "logprob": -0.22680258750915527}, {"text": "Answer", "logprob": -0.08517324179410934}, {"text": ":", "logprob": -0.7743037939071655}, {"text": " U", "logprob": -1.8827052116394043}, {"text": "psilon", "logprob": -0.07044108957052231}, {"text": " And", "logprob": -0.00013779645087197423}, {"text": "rom", "logprob": -0.00013767725613433868}, {"text": "ed", "logprob": -6.794906312279636e-06}, {"text": "ae", "logprob": -0.00013791563105769455}, {"text": " d", "logprob": -6.9141146923357155e-06}, {"text": " (", "logprob": -3.5118567943573}, {"text": "false", "logprob": -2.877610445022583}, {"text": "),", "logprob": -0.5792093276977539}, {"text": " Cleveland", "logprob": -3.7390804290771484}, {"text": " Clinic", "logprob": -0.00013815402053296566}, {"text": " (", "logprob": -0.018590496852993965}], "answers": ["Sawtooth Wilderness"], "all_classes": "null", "length": 78}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Buzkashi, Hoffman tunnel, parathyroid hormone, Zeta Sagittarii, solar eclipse of June 25, 2150, Super Bowl XXXV, Idursulfase, Eurovision Song Contest 2021, Saudi Arabia, Battersea Power Station, 2016 North Canterbury earthquake, 1953 Ionian Earthquake, 1755 Lisbon earthquake, Brisbane Cricket Ground, 2015 Rugby World Cup, Risk, STS-134, 3.7 cm SK C/30, Holin superfamily V, Charter Oak, Yellowstone volcano, which one is the most conceptually similar with SN 1572?", "pred": " SN 2006gy, SMIle creed,  SN 1054", "completions_tokens": [{"text": " SN", "logprob": -1.90382719039917}, {"text": " ", "logprob": -0.016758259385824203}, {"text": "200", "logprob": -5.611602783203125}, {"text": "6", "logprob": -0.8496949672698975}, {"text": "gy", "logprob": -0.12714232504367828}, {"text": ",", "logprob": -0.7896995544433594}, {"text": " S", "logprob": -5.174108505249023}, {"text": "MI", "logprob": -8.523321151733398}, {"text": "le", "logprob": -1.2634233236312866}, {"text": " creed", "logprob": -11.327540397644043}, {"text": ",", "logprob": -2.1323933601379395}, {"text": " ", "logprob": -2.91532564163208}, {"text": " SN", "logprob": -4.734450340270996}, {"text": " ", "logprob": -0.05494064465165138}, {"text": "105", "logprob": -3.5942952632904053}, {"text": "4", "logprob": -6.9141146923357155e-06}], "answers": ["Zeta Sagittarii"], "all_classes": "null", "length": 92}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong 2004 Canadian federal election, Manot 1, precerebral artery, Reflex inguinal ligament, 2020 ICC World Twenty20 Qualifier, Art Institute of Chicago, KNM WT 17000, Queensway Tunnel, St Andrews Links, thoracoepigastric vein, TM 1517, Mount Apo, Weddell Sea, Chilenia, Grus, Tsiolkovskiy, stigmatomycosis, Fort D.A. Russell, 2007 Swiss federal election, Antares, 1935 United Kingdom general election, which one is the most conceptually similar with dorsal carpal arch?", "pred": " \n\nA\nB\nC\nD\nE\nContinued from previous question", "completions_tokens": [{"text": " \n\n", "logprob": -0.07406894862651825}, {"text": "A", "logprob": -3.876319169998169}, {"text": "\n", "logprob": -2.2307775020599365}, {"text": "B", "logprob": -0.8175345063209534}, {"text": "\n", "logprob": -0.00013779645087197423}, {"text": "C", "logprob": -6.794906312279636e-06}, {"text": "\n", "logprob": -0.00013767725613433868}, {"text": "D", "logprob": -0.006915089208632708}, {"text": "\n", "logprob": -0.9635632038116455}, {"text": "E", "logprob": -0.10536657273769379}, {"text": "\n", "logprob": -0.10355348140001297}, {"text": "Contin", "logprob": -9.20231819152832}, {"text": "ued", "logprob": -1.0089058876037598}, {"text": " from", "logprob": -0.3451312780380249}, {"text": " previous", "logprob": -0.12727206945419312}, {"text": " question", "logprob": -0.088931605219841}], "answers": ["precerebral artery"], "all_classes": "null", "length": 90}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Irish Rebellion of 1798, Soyuz 5, Torrey Pines Golf Course, UEFA Euro 2012, 2015 World Championships in Athletics, Theoretical Archaeology Group, Greenland ice sheet, Osterley Park, Fleet Street, STS-122, 2003 Rugby World Cup, TIFF Bell Lightbox, Beaux-Arts de Paris, 1962 FIFA World Cup, The Proms, Botryosphaeria stevensii, Prestwick Golf Club, Four Mile Run, Bluewater (shopping centre), St Giles Circus, Three Mile Island Nuclear Generating Station, which one is the most conceptually similar with Prague Spring?", "pred": " \n\nAnswer:\n\nTheoretical Archaeology Group has had the name \"Theoretical Archae", "completions_tokens": [{"text": " \n\n", "logprob": -0.059881825000047684}, {"text": "Answer", "logprob": -0.31721770763397217}, {"text": ":\n\n", "logprob": -0.7743139266967773}, {"text": "The", "logprob": -1.119781732559204}, {"text": "oretical", "logprob": -0.13217273354530334}, {"text": " Archae", "logprob": -6.794906312279636e-06}, {"text": "ology", "logprob": -6.794906312279636e-06}, {"text": " Group", "logprob": -0.00013791563105769455}, {"text": " has", "logprob": -4.301929950714111}, {"text": " had", "logprob": -5.388906478881836}, {"text": " the", "logprob": -2.432633638381958}, {"text": " name", "logprob": -2.3822624683380127}, {"text": " \"", "logprob": -1.265101671218872}, {"text": "The", "logprob": -0.7143734693527222}, {"text": "oretical", "logprob": -0.5781852602958679}, {"text": " Archae", "logprob": -0.0022040142212063074}], "answers": ["Irish Rebellion of 1798"], "all_classes": "null", "length": 104}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Wine auction, Santa Fe Trail, chitin, twelfth grade, Circuit de Spa-Francorchamps, plantar Lisfranc ligament, recurrent artery of Heubner, South Pass, Austin Film Festival, 1700 Cascadia earthquake, Reflex inguinal ligament, The Whip, Phoenix Park, Michael Spondyles, Basilica di Santa Maria Maggiore, Sundance Film Festival, Sarawak General Hospital, Levator claviculae muscle, leptin, common facial vein, KNM ER 406, which one is the most conceptually similar with lateral rotator group?", "pred": " \n\nAnswer: Levator claviculae muscle. ==}}> Levator cl", "completions_tokens": [{"text": " \n\n", "logprob": -0.033959127962589264}, {"text": "Answer", "logprob": -0.08645646274089813}, {"text": ":", "logprob": -1.1684443950653076}, {"text": " Lev", "logprob": -0.22385349869728088}, {"text": "ator", "logprob": -6.794906312279636e-06}, {"text": " cl", "logprob": -6.794906312279636e-06}, {"text": "avic", "logprob": -0.00013779645087197423}, {"text": "ula", "logprob": -0.00013767725613433868}, {"text": "e", "logprob": -0.00013791563105769455}, {"text": " muscle", "logprob": -6.794906312279636e-06}, {"text": ".", "logprob": -0.07106639444828033}, {"text": " ==", "logprob": -7.594117164611816}, {"text": "}}>", "logprob": -11.25239372253418}, {"text": " Lev", "logprob": -1.6106674671173096}, {"text": "ator", "logprob": -0.00013779645087197423}, {"text": " cl", "logprob": -0.18766111135482788}], "answers": ["Levator claviculae muscle"], "all_classes": "null", "length": 93}
{"prompt": "Please give answer to the following question about knowledge. Note: If you are asked for true or false, just answer \"true\" or \"false\" only. If you are asked for similarity, just answer with the entity name only. Do not give anything other than the answers. Question:\n\nAmong Super Bowl XXXIV, Southwestern Exposition and Livestock Show, djon djon, bypass ratio, Leafy, Radicular artery, Augusta National Golf Club, intercostal veins, Palmar plate, Pikes Peak International Hill Climb, Autodromo Nazionale Monza, 2002 FIFA World Cup, Warhammer Fantasy Battle, Vega, Tokaj wine region, Tau9 Eridani, Battersea Power Station, Newport Folk Festival, Croatian War of Independence, BFI London Film Festival, UEFA Euro 2000, which one is the most conceptually similar with Holborn?", "pred": " $$Holborn$$ is a less prominent London Underground station.\n\nAcrobat is similar", "completions_tokens": [{"text": " $$", "logprob": -7.4148359298706055}, {"text": "Hol", "logprob": -2.9993128776550293}, {"text": "born", "logprob": -0.2092028111219406}, {"text": "$$", "logprob": -1.435623288154602}, {"text": " is", "logprob": -0.11116035282611847}, {"text": " a", "logprob": -0.28611811995506287}, {"text": " less", "logprob": -9.650943756103516}, {"text": " prominent", "logprob": -2.4670567512512207}, {"text": " London", "logprob": -2.1507797241210938}, {"text": " Underground", "logprob": -0.7714163661003113}, {"text": " station", "logprob": -0.9056504368782043}, {"text": ".\n\n", "logprob": -1.3362748622894287}, {"text": "Ac", "logprob": -6.733070373535156}, {"text": "robat", "logprob": -4.440730571746826}, {"text": " is", "logprob": -3.2712011337280273}, {"text": " similar", "logprob": -3.2406439781188965}], "answers": ["Autodromo Nazionale Monza"], "all_classes": "null", "length": 96}
