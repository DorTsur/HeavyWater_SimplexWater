/n/home12/dtsur/.conda/envs/nenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
finished importing
finished parsing model, model path ./data/models/llama-2-7b-chat-hf
device= cuda
importing llama
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.14s/it]
FINISHED importing model
finished loading model and tokenzier
trying to brekpoint:
short_finance_qa has began.........
  0%|          | 0/3 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:14<00:29, 14.88s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:29<00:14, 14.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:43<00:00, 14.52s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:43<00:00, 14.57s/it]
input id device cuda:0
tensor([29871,  3374,  6293,   363,   596,  1139, 29991, 15950,   263,  6460,
         6625,   537,   670,   327,  4316,  1156,  1933,   307,   346,   508,
         1207,   565, 29888,   504,   292,  2086, 14403,   262,   385,  3271,
        24806, 29889,   350,  4227, 29884,   372, 29915,  3844,   451,  9301,
        29936,  1244, 29915,  3844, 16699,  2086,  1136,   430,   261, 29936,
        24806,  1090, 16554,   756,  3939,  1400,   278,  2107,  3599,  1211,
        29892,   408,   756,   278,   982,   301,  2548, 21561, 14707,   278,
        16200,   310, 27942, 29893,   359,  1156,  1933,   307,   346, 29889,
          365, 21043,  1286,  2125,   964,  3633,   916, 13879,  8724, 16200,
          746, 24809,   292,   263,  2022, 29915,  3844, 11509,   304,  1634,
          388,   263, 24806, 29889,  2266,   526,  1047,   267, 25562,   304,
         1371, 11157,   366, 29872,   521,   273,  2395,   310, 14403,   262,
          262,   385,  3271, 24806,  2511,   509,  1933,   307,   346, 29901,
          259,    13, 29896, 29892,   830,   342, 12478,   275,   263, 13714,
        17869,  4840, 29899,   365, 21043,  5821,  9820,   340,   414,  1058,
          505,   263, 13714, 17869,  2752, 29889,   498,  1446,   377,  5819,
          967,   527,   407,  2273,   424,   304,  1510,   263, 13747,  5703,
          358,  4955, 29892,  1584,   281,   386,   263,  6460,  6625,   537,
          670,   327,  4316, 29892,   304, 11157,   366, 29872,   521,   273,
         2395,   310, 14403,   262,   262,   385,  3271, 24806, 29889,  1678,
           13, 29906,  1696, 10854,   738, 18161, 20706,   366,  1754,  1411,
         7192,   278, 25074,   346,  1889, 29899,   365, 21043,   674, 14707,
          278, 18161, 20706,   366,  1754,  1411,  7192,   278, 25074,   346,
         1889, 29889,   910,   508, 13654,   263, 16493, 29892, 24342,  1933,
         1000,   291, 29892, 25169,  4564,   952, 29892,  2992, 29871,   498,
         1039, 18161,  3603,   388,   508,   367,   502,  1319,   304,  1510,
          366, 29872, 11509,   304, 10933, 11782,  5584, 29892,  1584,   281,
          386,   263,  6460,  6625,   537,   670,   327,  4316, 29871,   869,
        29871, 29941,  1696,   922,  1416, 10257,  1371, 29899,   319,  1781,
         5758,  3249,   482,  2545,  3946,   470, 18161,   594, 19188,   508],
       device='cuda:0')
tensor([29871,  3374,  6293,   363,   596,  1139, 29991, 15950,   263,  6460,
         6625,   537,   670,   327,  4316,  1156,  1933,   307,   346,   508,
         1207,   565, 29888,   504,   292,  2086, 14403,   262,   385,  3271,
        24806, 29889,   350,  4227, 29884,   372, 29915,  3844,   451,  9301,
        29936,  1244, 29915,  3844, 16699,  2086,  1136,   430,   261, 29936,
        24806,  1090, 16554,   756,  3939,  1400,   278,  2107,  3599,  1211,
        29892,   408,   756,   278,   982,   301,  2548, 21561, 14707,   278,
        16200,   310, 27942, 29893,   359,  1156,  1933,   307,   346, 29889,
          365, 21043,  1286,  2125,   964,  3633,   916, 13879,  8724, 16200,
          746, 24809,   292,   263,  2022, 29915,  3844, 11509,   304,  1634,
          388,   263, 24806, 29889,  2266,   526,  1047,   267, 25562,   304,
         1371, 11157,   366, 29872,   521,   273,  2395,   310, 14403,   262,
          262,   385,  3271, 24806,  2511,   509,  1933,   307,   346, 29901,
          259,    13, 29896, 29892,   830,   342, 12478,   275,   263, 13714,
        17869,  4840, 29899,   365, 21043,  5821,  9820,   340,   414,  1058,
          505,   263, 13714, 17869,  2752, 29889,   498,  1446,   377,  5819,
          967,   527,   407,  2273,   424,   304,  1510,   263, 13747,  5703,
          358,  4955, 29892,  1584,   281,   386,   263,  6460,  6625,   537,
          670,   327,  4316, 29892,   304, 11157,   366, 29872,   521,   273,
         2395,   310, 14403,   262,   262,   385,  3271, 24806, 29889,  1678,
           13, 29906,  1696, 10854,   738, 18161, 20706,   366,  1754,  1411,
         7192,   278, 25074,   346,  1889, 29899,   365, 21043,   674, 14707,
          278, 18161, 20706,   366,  1754,  1411,  7192,   278, 25074,   346,
         1889, 29889,   910,   508, 13654,   263, 16493, 29892, 24342,  1933,
         1000,   291, 29892, 25169,  4564,   952, 29892,  2992, 29871,   498,
         1039, 18161,  3603,   388,   508,   367,   502,  1319,   304,  1510,
          366, 29872, 11509,   304, 10933, 11782,  5584, 29892,  1584,   281,
          386,   263,  6460,  6625,   537,   670,   327,  4316, 29871,   869,
        29871, 29941,  1696,   922,  1416, 10257,  1371, 29899,   319,  1781,
         5758,  3249,   482,  2545,  3946,   470, 18161,   594, 19188,   508],
       device='cuda:0')
tensor([29871,  3374,  6293,   363,   596,  1139, 29991, 15950,   263,  6460,
         6625,   537,   670,   327,  4316,  1156,  1933,   307,   346,   508,
         1207,   565, 29888,   504,   292,  2086, 14403,   262,   385,  3271,
        24806, 29889,   350,  4227, 29884,   372, 29915,  3844,   451,  9301,
        29936,  1244, 29915,  3844, 16699,  2086,  1136,   430,   261, 29936,
        24806,  1090, 16554,   756,  3939,  1400,   278,  2107,  3599,  1211,
        29892,   408,   756,   278,   982,   301,  2548, 21561, 14707,   278,
        16200,   310, 27942, 29893,   359,  1156,  1933,   307,   346, 29889,
          365, 21043,  1286,  2125,   964,  3633,   916, 13879,  8724, 16200,
          746, 24809,   292,   263,  2022, 29915,  3844, 11509,   304,  1634,
          388,   263, 24806, 29889,  2266,   526,  1047,   267, 25562,   304,
         1371, 11157,   366, 29872,   521,   273,  2395,   310, 14403,   262,
          262,   385,  3271, 24806,  2511,   509,  1933,   307,   346, 29901,
          259,    13, 29896, 29892,   830,   342, 12478,   275,   263, 13714,
        17869,  4840, 29899,   365, 21043,  5821,  9820,   340,   414,  1058,
          505,   263, 13714, 17869,  2752, 29889,   498,  1446,   377,  5819,
          967,   527,   407,  2273,   424,   304,  1510,   263, 13747,  5703,
          358,  4955, 29892,  1584,   281,   386,   263,  6460,  6625,   537,
          670,   327,  4316, 29892,   304, 11157,   366, 29872,   521,   273,
         2395,   310, 14403,   262,   262,   385,  3271, 24806, 29889,  1678,
           13, 29906,  1696, 10854,   738, 18161, 20706,   366,  1754,  1411,
         7192,   278, 25074,   346,  1889, 29899,   365, 21043,   674, 14707,
          278, 18161, 20706,   366,  1754,  1411,  7192,   278, 25074,   346,
         1889, 29889,   910,   508, 13654,   263, 16493, 29892, 24342,  1933,
         1000,   291, 29892, 25169,  4564,   952, 29892,  2992, 29871,   498,
         1039, 18161,  3603,   388,   508,   367,   502,  1319,   304,  1510,
          366, 29872, 11509,   304, 10933, 11782,  5584, 29892,  1584,   281,
          386,   263,  6460,  6625,   537,   670,   327,  4316, 29871,   869,
        29871, 29941,  1696,   922,  1416, 10257,  1371, 29899,   319,  1781,
         5758,  3249,   482,  2545,  3946,   470, 18161,   594, 19188,   508],
       device='cuda:0')
/n/home12/dtsur/.conda/envs/nenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
finished importing
finished parsing model, model path ./data/models/llama-2-7b-chat-hf
device= cuda
importing llama
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  1.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.01s/it]
FINISHED importing model
finished loading model and tokenzier
trying to brekpoint:
short_finance_qa has began.........
  0%|          | 0/3 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:14<00:29, 14.96s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:29<00:14, 14.69s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:43<00:00, 14.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:43<00:00, 14.65s/it]
input id device cuda:0
tensor([29871,  3374,  6293,   363,   596,  1139, 29991, 15950,   263,  6460,
         6625,   537,   670,   327,  4316,  1156,  1933,   307,   346,   508,
         1207,   565, 29888,   504,   292,  2086, 14403,   262,   385,  3271,
        24806, 29889,   350,  4227, 29884,   372, 29915,  3844,   451,  9301,
        29936,  1244, 29915,  3844, 16699,  2086,  1136,   430,   261, 29936,
        24806,  1090, 16554,   756,  3939,  1400,   278,  2107,  3599,  1211,
        29892,   408,   756,   278,   982,   301,  2548, 21561, 14707,   278,
        16200,   310, 27942, 29893,   359,  1156,  1933,   307,   346, 29889,
          365, 21043,  1286,  2125,   964,  3633,   916, 13879,  8724, 16200,
          746, 24809,   292,   263,  2022, 29915,  3844, 11509,   304,  1634,
          388,   263, 24806, 29889,  2266,   526,  1047,   267, 25562,   304,
         1371, 11157,   366, 29872,   521,   273,  2395,   310, 14403,   262,
          262,   385,  3271, 24806,  2511,   509,  1933,   307,   346, 29901,
          259,    13, 29896, 29892,   830,   342, 12478,   275,   263, 13714,
        17869,  4840, 29899,   365, 21043,  5821,  9820,   340,   414,  1058,
          505,   263, 13714, 17869,  2752, 29889,   498,  1446,   377,  5819,
          967,   527,   407,  2273,   424,   304,  1510,   263, 13747,  5703,
          358,  4955, 29892,  1584,   281,   386,   263,  6460,  6625,   537,
          670,   327,  4316, 29892,   304, 11157,   366, 29872,   521,   273,
         2395,   310, 14403,   262,   262,   385,  3271, 24806, 29889,  1678,
           13, 29906,  1696, 10854,   738, 18161, 20706,   366,  1754,  1411,
         7192,   278, 25074,   346,  1889, 29899,   365, 21043,   674, 14707,
          278, 18161, 20706,   366,  1754,  1411,  7192,   278, 25074,   346,
         1889, 29889,   910,   508, 13654,   263, 16493, 29892, 24342,  1933,
         1000,   291, 29892, 25169,  4564,   952, 29892,  2992, 29871,   498,
         1039, 18161,  3603,   388,   508,   367,   502,  1319,   304,  1510,
          366, 29872, 11509,   304, 10933, 11782,  5584, 29892,  1584,   281,
          386,   263,  6460,  6625,   537,   670,   327,  4316, 29871,   869,
        29871, 29941,  1696,   922,  1416, 10257,  1371, 29899,   319,  1781,
         5758,  3249,   482,  2545,  3946,   470, 18161,   594, 19188,   508],
       device='cuda:0')
tensor([29871,  3374,  6293,   363,   596,  1139, 29991, 15950,   263,  6460,
         6625,   537,   670,   327,  4316,  1156,  1933,   307,   346,   508,
         1207,   565, 29888,   504,   292,  2086, 14403,   262,   385,  3271,
        24806, 29889,   350,  4227, 29884,   372, 29915,  3844,   451,  9301,
        29936,  1244, 29915,  3844, 16699,  2086,  1136,   430,   261, 29936,
        24806,  1090, 16554,   756,  3939,  1400,   278,  2107,  3599,  1211,
        29892,   408,   756,   278,   982,   301,  2548, 21561, 14707,   278,
        16200,   310, 27942, 29893,   359,  1156,  1933,   307,   346, 29889,
          365, 21043,  1286,  2125,   964,  3633,   916, 13879,  8724, 16200,
          746, 24809,   292,   263,  2022, 29915,  3844, 11509,   304,  1634,
          388,   263, 24806, 29889,  2266,   526,  1047,   267, 25562,   304,
         1371, 11157,   366, 29872,   521,   273,  2395,   310, 14403,   262,
          262,   385,  3271, 24806,  2511,   509,  1933,   307,   346, 29901,
          259,    13, 29896, 29892,   830,   342, 12478,   275,   263, 13714,
        17869,  4840, 29899,   365, 21043,  5821,  9820,   340,   414,  1058,
          505,   263, 13714, 17869,  2752, 29889,   498,  1446,   377,  5819,
          967,   527,   407,  2273,   424,   304,  1510,   263, 13747,  5703,
          358,  4955, 29892,  1584,   281,   386,   263,  6460,  6625,   537,
          670,   327,  4316, 29892,   304, 11157,   366, 29872,   521,   273,
         2395,   310, 14403,   262,   262,   385,  3271, 24806, 29889,  1678,
           13, 29906,  1696, 10854,   738, 18161, 20706,   366,  1754,  1411,
         7192,   278, 25074,   346,  1889, 29899,   365, 21043,   674, 14707,
          278, 18161, 20706,   366,  1754,  1411,  7192,   278, 25074,   346,
         1889, 29889,   910,   508, 13654,   263, 16493, 29892, 24342,  1933,
         1000,   291, 29892, 25169,  4564,   952, 29892,  2992, 29871,   498,
         1039, 18161,  3603,   388,   508,   367,   502,  1319,   304,  1510,
          366, 29872, 11509,   304, 10933, 11782,  5584, 29892,  1584,   281,
          386,   263,  6460,  6625,   537,   670,   327,  4316, 29871,   869,
        29871, 29941,  1696,   922,  1416, 10257,  1371, 29899,   319,  1781,
         5758,  3249,   482,  2545,  3946,   470, 18161,   594, 19188,   508],
       device='cuda:0')
tensor([29871,  3374,  6293,   363,   596,  1139, 29991, 15950,   263,  6460,
         6625,   537,   670,   327,  4316,  1156,  1933,   307,   346,   508,
         1207,   565, 29888,   504,   292,  2086, 14403,   262,   385,  3271,
        24806, 29889,   350,  4227, 29884,   372, 29915,  3844,   451,  9301,
        29936,  1244, 29915,  3844, 16699,  2086,  1136,   430,   261, 29936,
        24806,  1090, 16554,   756,  3939,  1400,   278,  2107,  3599,  1211,
        29892,   408,   756,   278,   982,   301,  2548, 21561, 14707,   278,
        16200,   310, 27942, 29893,   359,  1156,  1933,   307,   346, 29889,
          365, 21043,  1286,  2125,   964,  3633,   916, 13879,  8724, 16200,
          746, 24809,   292,   263,  2022, 29915,  3844, 11509,   304,  1634,
          388,   263, 24806, 29889,  2266,   526,  1047,   267, 25562,   304,
         1371, 11157,   366, 29872,   521,   273,  2395,   310, 14403,   262,
          262,   385,  3271, 24806,  2511,   509,  1933,   307,   346, 29901,
          259,    13, 29896, 29892,   830,   342, 12478,   275,   263, 13714,
        17869,  4840, 29899,   365, 21043,  5821,  9820,   340,   414,  1058,
          505,   263, 13714, 17869,  2752, 29889,   498,  1446,   377,  5819,
          967,   527,   407,  2273,   424,   304,  1510,   263, 13747,  5703,
          358,  4955, 29892,  1584,   281,   386,   263,  6460,  6625,   537,
          670,   327,  4316, 29892,   304, 11157,   366, 29872,   521,   273,
         2395,   310, 14403,   262,   262,   385,  3271, 24806, 29889,  1678,
           13, 29906,  1696, 10854,   738, 18161, 20706,   366,  1754,  1411,
         7192,   278, 25074,   346,  1889, 29899,   365, 21043,   674, 14707,
          278, 18161, 20706,   366,  1754,  1411,  7192,   278, 25074,   346,
         1889, 29889,   910,   508, 13654,   263, 16493, 29892, 24342,  1933,
         1000,   291, 29892, 25169,  4564,   952, 29892,  2992, 29871,   498,
         1039, 18161,  3603,   388,   508,   367,   502,  1319,   304,  1510,
          366, 29872, 11509,   304, 10933, 11782,  5584, 29892,  1584,   281,
          386,   263,  6460,  6625,   537,   670,   327,  4316, 29871,   869,
        29871, 29941,  1696,   922,  1416, 10257,  1371, 29899,   319,  1781,
         5758,  3249,   482,  2545,  3946,   470, 18161,   594, 19188,   508],
       device='cuda:0')
/n/home12/dtsur/.conda/envs/nenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
finished importing
finished parsing model, model path ./data/models/llama-2-7b-chat-hf
device= cuda
importing llama
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  1.82s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.02s/it]
FINISHED importing model
finished loading model and tokenzier
trying to brekpoint:
short_finance_qa has began.........
  0%|          | 0/3 [00:00<?, ?it/s][7] > [33;01m/n/home12/dtsur/watermarking/WaterBench/watermark/cc_watermark.py[00m([36;01m1027[00m)__call__()
-> self.bl_proportion = 1/self.k
(Pdb++)   0%|          | 0/3 [00:00<?, ?it/s]

Traceback (most recent call last):
  File "/n/home12/dtsur/watermarking/WaterBench/pred.py", line 328, in <module>
    preds = get_pred(args, model, tokenizer, data, max_length, max_gen, prompt_format, dataset, device, model_name)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/home12/dtsur/watermarking/WaterBench/pred.py", line 206, in get_pred
    completions_text, completions_tokens  = generator.generate(input_ids=input.input_ids, max_new_tokens=max_gen)
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/home12/dtsur/watermarking/WaterBench/generate.py", line 193, in generate
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/n/home12/dtsur/.conda/envs/nenv/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/n/home12/dtsur/.conda/envs/nenv/lib/python3.11/site-packages/transformers/generation/utils.py", line 1588, in generate
    return self.sample(
           ^^^^^^^^^^^^
  File "/n/home12/dtsur/.conda/envs/nenv/lib/python3.11/site-packages/transformers/generation/utils.py", line 2655, in sample
    next_token_scores = logits_processor(input_ids, next_token_logits)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/home12/dtsur/.conda/envs/nenv/lib/python3.11/site-packages/transformers/generation/logits_process.py", line 97, in __call__
    scores = processor(input_ids, scores)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/home12/dtsur/watermarking/WaterBench/watermark/cc_watermark.py", line 1027, in __call__
    self.bl_proportion = 1/self.k
                         ^
  File "/n/home12/dtsur/.conda/envs/nenv/lib/python3.11/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/n/home12/dtsur/.conda/envs/nenv/lib/python3.11/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
