# Watermark Detection for LLM Outputs

This repository provides a unified script (`detect.py`) for detecting various types of watermarks in text generated by large language models (LLMs). It supports multiple watermarking schemes, statistical tests, and flexible configuration for research and evaluation.

---

## Features

- **Supports Multiple Watermarking Methods:**  
  - Classic, CC, Linear Code, Q-ary Linear Code, SynthID, Exponential, Heavy Tail, Inverse Transform, and more.
- **Flexible Input:**  
  - Works with `.jsonl` files containing prompts and model outputs.
- **Statistical Analysis:**  
  - Computes z-scores, p-values, and other relevant statistics for detection.
- **Batch Processing:**  
  - Processes entire datasets and saves results in organized output directories.
- **Customizable:**  
  - Many command-line arguments for fine-tuning detection and evaluation.

---

## Installation

1. **Clone the repository:**
   ```bash
   git clone <your-repo-url>
   cd <repo-directory>
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
   *(Make sure to include all required packages in `requirements.txt`, e.g., `torch`, `numpy`, `scipy`, `tqdm`.)*

---

## Input Format

- The script expects input directories containing `.jsonl` files.
- Each line in a `.jsonl` file should be a JSON object with at least:
  - `"prompt"`: The input prompt to the LLM.
  - `"pred"`: The generated output from the LLM.

---

## Usage

### Basic Command

```bash
python detect.py --input_dir <path-to-input-dir>
```

### Common Arguments

| Argument                | Type    | Default         | Description                                                                 |
|-------------------------|---------|-----------------|-----------------------------------------------------------------------------|
| `--input_dir`           | str     | pred/llama2-7b-chat-4k_cc_g0.5_d5.0 | Directory containing `.jsonl` files to process.                             |
| `--threshold`           | float   | 3.05            | Z-score threshold for detection.                                            |
| `--test_min_tokens`     | int     | 2               | Minimum number of tokens required for detection.                            |
| `--mission`             | str     | all             | Filter files by mission name.                                               |
| `--dataset`             | str     | all             | Filter files by dataset name.                                               |
| `--initial_seed_llm`    | int     | 42              | Initial seed for reproducibility.                                           |
| `--dynamic_seed`        | str     | markov_1        | Seeding procedure for watermarking.                                         |
| `--pval`                | float   | 1e-3            | P-value threshold for detection.                                            |
| `--threshold_p`         | float   | 1e-4            | P-value for PD@PFA (performance metric).                                    |
| `--collect_scores`      | bool    | False           | Whether to collect and save score distributions.                            |

*See the code for more advanced options related to specific watermarking schemes.*

---

## Output

- Results are saved in subdirectories (e.g., `z_score`, `z_s_score`, `chi_score`) within the input directory.
- Output files contain detection statistics, such as:
  - Average and standard deviation of p-values and z-scores
  - Detection indices
  - Watermark prediction rates
  - Full lists of computed statistics for further analysis

---

## Example

```bash
python detect.py \
  --input_dir pred/llama2-7b-chat-4k_cc_g0.5_d5.0 \
  --threshold 3.0 \
  --test_min_tokens 5 \
  --mission summarization \
  --dataset my_dataset
```

---

## Extending

- **Add new watermarking methods:**  
  Implement a new detector class in the `watermark/` directory and add it to the selection logic in `detect.py`.
- **Change statistical tests:**  
  Modify the relevant section in the main loop to use your preferred test or metric.

---

## Troubleshooting

- **Missing dependencies:**  
  Ensure all required Python packages are installed.
- **Input errors:**  
  Check that your `.jsonl` files are properly formatted.
- **CUDA errors:**  
  If you do not have a GPU, the script will automatically fall back to CPU.

---

## Citation

If you use this code in your research, please cite the original watermarking papers and this repository.

---

## License

[MIT License](LICENSE) (or your chosen license)

---

## Contact

For questions or contributions, please open an issue or contact the maintainer. 